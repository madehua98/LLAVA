nohup: 忽略输入
1,2,3,4,5,6,7,8
[2024-08-09 23:08:48,416] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-09 23:08:50,907] [WARNING] [runner.py:196:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2024-08-09 23:08:50,907] [INFO] [runner.py:555:main] cmd = /home/data_llm/anaconda3/envs/moellava/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMSwgMiwgMywgNCwgNSwgNiwgNywgOF19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None llava/train/train_xformers.py --deepspeed ./scripts/zero2.json --model_name_or_path /media/fast_data/model/vicuna-7b-v1.5 --version plain --data_path /mnt/data_llm/json_file/llava_pretrain_data.json --image_folder /media/fast_data --vision_tower /media/fast_data/model/clip-vit-large-patch14-336 --mm_projector_type mlp2x_gelu --tune_mm_mlp_adapter True --mm_vision_select_layer -2 --mm_use_im_start_end False --mm_use_im_patch_token False --bf16 True --output_dir /mnt/data_llm/model/checkpoints/llava1.5-7b-vitl-pretrain --num_train_epochs 1 --per_device_train_batch_size 4 --per_device_eval_batch_size 4 --gradient_accumulation_steps 8 --evaluation_strategy no --save_strategy epoch --save_total_limit 1 --learning_rate 1e-3 --weight_decay 0. --warmup_ratio 0.03 --lr_scheduler_type cosine --logging_steps 1 --tf32 True --model_max_length 1024 --gradient_checkpointing True --dataloader_num_workers 64 --lazy_preprocess True
[2024-08-09 23:08:52,188] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-09 23:08:54,578] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [1, 2, 3, 4, 5, 6, 7, 8]}
[2024-08-09 23:08:54,578] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=8, node_rank=0
[2024-08-09 23:08:54,578] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]})
[2024-08-09 23:08:54,578] [INFO] [launch.py:163:main] dist_world_size=8
[2024-08-09 23:08:54,578] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7,8
[2024-08-09 23:08:58,288] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-09 23:08:58,321] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-09 23:08:58,370] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-09 23:08:58,373] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-09 23:08:58,400] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-09 23:08:58,424] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-09 23:08:58,443] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-09 23:08:58,498] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-09 23:08:59,498] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-08-09 23:08:59,498] [INFO] [comm.py:594:init_distributed] cdb=None
[2024-08-09 23:08:59,568] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-08-09 23:08:59,568] [INFO] [comm.py:594:init_distributed] cdb=None
[2024-08-09 23:08:59,599] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-08-09 23:08:59,599] [INFO] [comm.py:594:init_distributed] cdb=None
[2024-08-09 23:08:59,623] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-08-09 23:08:59,624] [INFO] [comm.py:594:init_distributed] cdb=None
[2024-08-09 23:08:59,643] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-08-09 23:08:59,643] [INFO] [comm.py:594:init_distributed] cdb=None
[2024-08-09 23:08:59,666] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-08-09 23:08:59,666] [INFO] [comm.py:594:init_distributed] cdb=None
[2024-08-09 23:08:59,674] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-08-09 23:08:59,674] [INFO] [comm.py:594:init_distributed] cdb=None
[2024-08-09 23:08:59,674] [INFO] [comm.py:625:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-08-09 23:08:59,762] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-08-09 23:08:59,763] [INFO] [comm.py:594:init_distributed] cdb=None
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.98s/it]
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.53s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.16s/it]Formatting inputs...Skip in lazy mode
Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.15s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.89s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.91s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.71s/it]
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.51s/it]
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.48s/it]
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.34s/it]
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.24s/it]
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.32s/it]
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
Rank: 0 partition count [8, 8] and sizes[(2621440, False), (1024, False)] 
Rank: 5 partition count [8, 8] and sizes[(2621440, False), (1024, False)] 
Rank: 7 partition count [8, 8] and sizes[(2621440, False), (1024, False)] 
Rank: 1 partition count [8, 8] and sizes[(2621440, False), (1024, False)] 
Rank: 4 partition count [8, 8] and sizes[(2621440, False), (1024, False)] 
Rank: 2 partition count [8, 8] and sizes[(2621440, False), (1024, False)] 
Rank: 3 partition count [8, 8] and sizes[(2621440, False), (1024, False)] 
Rank: 6 partition count [8, 8] and sizes[(2621440, False), (1024, False)] 
  0%|          | 0/2382 [00:00<?, ?it/s]/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1828: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  overflow_gpu = get_accelerator().ByteTensor([overflow])
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1828: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  overflow_gpu = get_accelerator().ByteTensor([overflow])
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1828: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  overflow_gpu = get_accelerator().ByteTensor([overflow])
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1828: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  overflow_gpu = get_accelerator().ByteTensor([overflow])
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1828: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  overflow_gpu = get_accelerator().ByteTensor([overflow])
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1828: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  overflow_gpu = get_accelerator().ByteTensor([overflow])
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1828: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  overflow_gpu = get_accelerator().ByteTensor([overflow])
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1828: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  overflow_gpu = get_accelerator().ByteTensor([overflow])
  0%|          | 1/2382 [00:33<22:12:17, 33.57s/it]                                                   {'loss': 4.625, 'learning_rate': 1.3888888888888888e-05, 'epoch': 0.0}
  0%|          | 1/2382 [00:33<22:12:17, 33.57s/it]  0%|          | 2/2382 [00:44<13:28:32, 20.38s/it]                                                   {'loss': 4.5024, 'learning_rate': 2.7777777777777776e-05, 'epoch': 0.0}
  0%|          | 2/2382 [00:44<13:28:32, 20.38s/it]  0%|          | 3/2382 [00:55<10:32:26, 15.95s/it]                                                   {'loss': 4.3591, 'learning_rate': 4.1666666666666665e-05, 'epoch': 0.0}
  0%|          | 3/2382 [00:55<10:32:26, 15.95s/it]  0%|          | 4/2382 [01:06<9:19:39, 14.12s/it]                                                   {'loss': 3.3247, 'learning_rate': 5.555555555555555e-05, 'epoch': 0.0}
  0%|          | 4/2382 [01:06<9:19:39, 14.12s/it]  0%|          | 5/2382 [01:16<8:19:07, 12.60s/it]                                                  {'loss': 2.9459, 'learning_rate': 6.944444444444444e-05, 'epoch': 0.0}
  0%|          | 5/2382 [01:16<8:19:07, 12.60s/it]  0%|          | 6/2382 [01:26<7:46:19, 11.78s/it]                                                  {'loss': 2.8773, 'learning_rate': 8.333333333333333e-05, 'epoch': 0.0}
  0%|          | 6/2382 [01:26<7:46:19, 11.78s/it]  0%|          | 7/2382 [01:38<7:46:31, 11.79s/it]                                                  {'loss': 2.6915, 'learning_rate': 9.722222222222223e-05, 'epoch': 0.0}
  0%|          | 7/2382 [01:38<7:46:31, 11.79s/it]  0%|          | 8/2382 [01:51<7:56:56, 12.05s/it]                                                  {'loss': 2.628, 'learning_rate': 0.0001111111111111111, 'epoch': 0.0}
  0%|          | 8/2382 [01:51<7:56:56, 12.05s/it]  0%|          | 9/2382 [02:02<7:52:17, 11.94s/it]                                                  {'loss': 2.6739, 'learning_rate': 0.000125, 'epoch': 0.0}
  0%|          | 9/2382 [02:02<7:52:17, 11.94s/it]  0%|          | 10/2382 [02:14<7:43:41, 11.73s/it]                                                   {'loss': 2.5356, 'learning_rate': 0.0001388888888888889, 'epoch': 0.0}
  0%|          | 10/2382 [02:14<7:43:41, 11.73s/it]  0%|          | 11/2382 [02:25<7:37:38, 11.58s/it]                                                   {'loss': 2.635, 'learning_rate': 0.0001527777777777778, 'epoch': 0.0}
  0%|          | 11/2382 [02:25<7:37:38, 11.58s/it]  1%|          | 12/2382 [02:36<7:30:17, 11.40s/it]                                                   {'loss': 2.5891, 'learning_rate': 0.00016666666666666666, 'epoch': 0.01}
  1%|          | 12/2382 [02:36<7:30:17, 11.40s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1067 > 1024). Running this sequence through the model will result in indexing errors
  1%|          | 13/2382 [02:48<7:40:01, 11.65s/it]                                                   {'loss': 2.4725, 'learning_rate': 0.00018055555555555555, 'epoch': 0.01}
  1%|          | 13/2382 [02:48<7:40:01, 11.65s/it]  1%|          | 14/2382 [03:01<7:58:33, 12.13s/it]                                                   {'loss': 2.502, 'learning_rate': 0.00019444444444444446, 'epoch': 0.01}
  1%|          | 14/2382 [03:01<7:58:33, 12.13s/it]  1%|          | 15/2382 [03:15<8:12:54, 12.49s/it]                                                   {'loss': 2.6469, 'learning_rate': 0.00020833333333333335, 'epoch': 0.01}
  1%|          | 15/2382 [03:15<8:12:54, 12.49s/it]  1%|          | 16/2382 [03:28<8:24:53, 12.80s/it]                                                   {'loss': 2.5682, 'learning_rate': 0.0002222222222222222, 'epoch': 0.01}
  1%|          | 16/2382 [03:28<8:24:53, 12.80s/it]  1%|          | 17/2382 [03:39<7:57:19, 12.11s/it]                                                   {'loss': 2.5715, 'learning_rate': 0.00023611111111111112, 'epoch': 0.01}
  1%|          | 17/2382 [03:39<7:57:19, 12.11s/it]  1%|          | 18/2382 [03:51<7:53:35, 12.02s/it]                                                   {'loss': 2.6605, 'learning_rate': 0.00025, 'epoch': 0.01}
  1%|          | 18/2382 [03:51<7:53:35, 12.02s/it]  1%|          | 19/2382 [04:03<8:00:47, 12.21s/it]                                                   {'loss': 2.5118, 'learning_rate': 0.0002638888888888889, 'epoch': 0.01}
  1%|          | 19/2382 [04:03<8:00:47, 12.21s/it]  1%|          | 20/2382 [04:14<7:44:52, 11.81s/it]                                                   {'loss': 2.4921, 'learning_rate': 0.0002777777777777778, 'epoch': 0.01}
  1%|          | 20/2382 [04:14<7:44:52, 11.81s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1333 > 1024). Running this sequence through the model will result in indexing errors
  1%|          | 21/2382 [04:27<7:52:19, 12.00s/it]                                                   {'loss': 2.3948, 'learning_rate': 0.0002916666666666667, 'epoch': 0.01}
  1%|          | 21/2382 [04:27<7:52:19, 12.00s/it]  1%|          | 22/2382 [04:38<7:41:47, 11.74s/it]                                                   {'loss': 2.5235, 'learning_rate': 0.0003055555555555556, 'epoch': 0.01}
  1%|          | 22/2382 [04:38<7:41:47, 11.74s/it]  1%|          | 23/2382 [04:55<8:43:11, 13.31s/it]                                                   {'loss': 2.4188, 'learning_rate': 0.0003194444444444444, 'epoch': 0.01}
  1%|          | 23/2382 [04:55<8:43:11, 13.31s/it]  1%|          | 24/2382 [05:06<8:18:00, 12.67s/it]                                                   {'loss': 2.5427, 'learning_rate': 0.0003333333333333333, 'epoch': 0.01}
  1%|          | 24/2382 [05:06<8:18:00, 12.67s/it]  1%|          | 25/2382 [05:16<7:47:59, 11.91s/it]                                                   {'loss': 2.381, 'learning_rate': 0.00034722222222222224, 'epoch': 0.01}
  1%|          | 25/2382 [05:16<7:47:59, 11.91s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1657 > 1024). Running this sequence through the model will result in indexing errors
  1%|          | 26/2382 [05:28<7:43:54, 11.81s/it]                                                   {'loss': 2.4401, 'learning_rate': 0.0003611111111111111, 'epoch': 0.01}
  1%|          | 26/2382 [05:28<7:43:54, 11.81s/it]  1%|          | 27/2382 [05:40<7:53:18, 12.06s/it]                                                   {'loss': 2.4475, 'learning_rate': 0.000375, 'epoch': 0.01}
  1%|          | 27/2382 [05:40<7:53:18, 12.06s/it]  1%|          | 28/2382 [05:52<7:54:22, 12.09s/it]                                                   {'loss': 2.4577, 'learning_rate': 0.0003888888888888889, 'epoch': 0.01}
  1%|          | 28/2382 [05:52<7:54:22, 12.09s/it]  1%|          | 29/2382 [06:06<8:11:16, 12.53s/it]                                                   {'loss': 2.4126, 'learning_rate': 0.0004027777777777778, 'epoch': 0.01}
  1%|          | 29/2382 [06:06<8:11:16, 12.53s/it]  1%|▏         | 30/2382 [06:18<8:02:06, 12.30s/it]                                                   {'loss': 2.5081, 'learning_rate': 0.0004166666666666667, 'epoch': 0.01}
  1%|▏         | 30/2382 [06:18<8:02:06, 12.30s/it]  1%|▏         | 31/2382 [06:28<7:42:07, 11.79s/it]                                                   {'loss': 2.392, 'learning_rate': 0.0004305555555555556, 'epoch': 0.01}
  1%|▏         | 31/2382 [06:28<7:42:07, 11.79s/it]  1%|▏         | 32/2382 [06:39<7:29:30, 11.48s/it]                                                   {'loss': 2.4374, 'learning_rate': 0.0004444444444444444, 'epoch': 0.01}
  1%|▏         | 32/2382 [06:39<7:29:30, 11.48s/it]  1%|▏         | 33/2382 [06:51<7:31:36, 11.54s/it]                                                   {'loss': 2.3776, 'learning_rate': 0.0004583333333333333, 'epoch': 0.01}
  1%|▏         | 33/2382 [06:51<7:31:36, 11.54s/it]  1%|▏         | 34/2382 [07:01<7:13:14, 11.07s/it]                                                   {'loss': 2.299, 'learning_rate': 0.00047222222222222224, 'epoch': 0.01}
  1%|▏         | 34/2382 [07:01<7:13:14, 11.07s/it]  1%|▏         | 35/2382 [07:10<6:52:53, 10.56s/it]                                                   {'loss': 2.3764, 'learning_rate': 0.0004861111111111111, 'epoch': 0.01}
  1%|▏         | 35/2382 [07:10<6:52:53, 10.56s/it]  2%|▏         | 36/2382 [07:19<6:39:15, 10.21s/it]                                                   {'loss': 2.2877, 'learning_rate': 0.0005, 'epoch': 0.02}
  2%|▏         | 36/2382 [07:19<6:39:15, 10.21s/it]  2%|▏         | 37/2382 [07:32<7:03:53, 10.85s/it]                                                   {'loss': 2.4317, 'learning_rate': 0.0005138888888888888, 'epoch': 0.02}
  2%|▏         | 37/2382 [07:32<7:03:53, 10.85s/it]  2%|▏         | 38/2382 [07:43<7:08:20, 10.96s/it]                                                   {'loss': 2.2799, 'learning_rate': 0.0005277777777777778, 'epoch': 0.02}
  2%|▏         | 38/2382 [07:43<7:08:20, 10.96s/it]  2%|▏         | 39/2382 [07:56<7:30:50, 11.55s/it]                                                   {'loss': 2.3225, 'learning_rate': 0.0005416666666666666, 'epoch': 0.02}
  2%|▏         | 39/2382 [07:56<7:30:50, 11.55s/it]  2%|▏         | 40/2382 [08:07<7:24:44, 11.39s/it]                                                   {'loss': 2.2409, 'learning_rate': 0.0005555555555555556, 'epoch': 0.02}
  2%|▏         | 40/2382 [08:07<7:24:44, 11.39s/it]  2%|▏         | 41/2382 [08:18<7:18:24, 11.24s/it]                                                   {'loss': 2.0441, 'learning_rate': 0.0005694444444444445, 'epoch': 0.02}
  2%|▏         | 41/2382 [08:18<7:18:24, 11.24s/it]  2%|▏         | 42/2382 [08:29<7:18:05, 11.23s/it]                                                   {'loss': 2.2181, 'learning_rate': 0.0005833333333333334, 'epoch': 0.02}
  2%|▏         | 42/2382 [08:29<7:18:05, 11.23s/it]  2%|▏         | 43/2382 [08:40<7:14:00, 11.13s/it]                                                   {'loss': 2.3882, 'learning_rate': 0.0005972222222222222, 'epoch': 0.02}
  2%|▏         | 43/2382 [08:40<7:14:00, 11.13s/it]  2%|▏         | 44/2382 [08:51<7:07:52, 10.98s/it]                                                   {'loss': 2.3086, 'learning_rate': 0.0006111111111111112, 'epoch': 0.02}
  2%|▏         | 44/2382 [08:51<7:07:52, 10.98s/it]  2%|▏         | 45/2382 [09:03<7:21:06, 11.32s/it]                                                   {'loss': 2.2393, 'learning_rate': 0.000625, 'epoch': 0.02}
  2%|▏         | 45/2382 [09:03<7:21:06, 11.32s/it]  2%|▏         | 46/2382 [09:15<7:35:35, 11.70s/it]                                                   {'loss': 2.1947, 'learning_rate': 0.0006388888888888888, 'epoch': 0.02}
  2%|▏         | 46/2382 [09:15<7:35:35, 11.70s/it]  2%|▏         | 47/2382 [09:25<7:10:56, 11.07s/it]                                                   {'loss': 2.2325, 'learning_rate': 0.0006527777777777778, 'epoch': 0.02}
  2%|▏         | 47/2382 [09:25<7:10:56, 11.07s/it]  2%|▏         | 48/2382 [09:35<6:55:38, 10.68s/it]                                                   {'loss': 2.2559, 'learning_rate': 0.0006666666666666666, 'epoch': 0.02}
  2%|▏         | 48/2382 [09:35<6:55:38, 10.68s/it]  2%|▏         | 49/2382 [09:46<7:06:29, 10.97s/it]                                                   {'loss': 2.2042, 'learning_rate': 0.0006805555555555556, 'epoch': 0.02}
  2%|▏         | 49/2382 [09:46<7:06:29, 10.97s/it]  2%|▏         | 50/2382 [09:58<7:14:25, 11.18s/it]                                                   {'loss': 2.2861, 'learning_rate': 0.0006944444444444445, 'epoch': 0.02}
  2%|▏         | 50/2382 [09:58<7:14:25, 11.18s/it]  2%|▏         | 51/2382 [10:09<7:13:33, 11.16s/it]                                                   {'loss': 2.2988, 'learning_rate': 0.0007083333333333334, 'epoch': 0.02}
  2%|▏         | 51/2382 [10:09<7:13:33, 11.16s/it]  2%|▏         | 52/2382 [10:19<7:04:38, 10.93s/it]                                                   {'loss': 2.3632, 'learning_rate': 0.0007222222222222222, 'epoch': 0.02}
  2%|▏         | 52/2382 [10:19<7:04:38, 10.93s/it]  2%|▏         | 53/2382 [10:28<6:35:09, 10.18s/it]                                                   {'loss': 2.4442, 'learning_rate': 0.0007361111111111112, 'epoch': 0.02}
  2%|▏         | 53/2382 [10:28<6:35:09, 10.18s/it]  2%|▏         | 54/2382 [10:38<6:31:47, 10.10s/it]                                                   {'loss': 2.1965, 'learning_rate': 0.00075, 'epoch': 0.02}
  2%|▏         | 54/2382 [10:38<6:31:47, 10.10s/it]  2%|▏         | 55/2382 [10:49<6:39:09, 10.29s/it]                                                   {'loss': 2.3699, 'learning_rate': 0.0007638888888888888, 'epoch': 0.02}
  2%|▏         | 55/2382 [10:49<6:39:09, 10.29s/it]  2%|▏         | 56/2382 [10:59<6:44:22, 10.43s/it]                                                   {'loss': 2.2635, 'learning_rate': 0.0007777777777777778, 'epoch': 0.02}
  2%|▏         | 56/2382 [10:59<6:44:22, 10.43s/it]  2%|▏         | 57/2382 [11:08<6:28:54, 10.04s/it]                                                   {'loss': 2.2096, 'learning_rate': 0.0007916666666666666, 'epoch': 0.02}
  2%|▏         | 57/2382 [11:08<6:28:54, 10.04s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1245 > 1024). Running this sequence through the model will result in indexing errors
  2%|▏         | 58/2382 [11:18<6:24:41,  9.93s/it]                                                   {'loss': 2.2372, 'learning_rate': 0.0008055555555555556, 'epoch': 0.02}
  2%|▏         | 58/2382 [11:18<6:24:41,  9.93s/it]  2%|▏         | 59/2382 [11:28<6:27:07, 10.00s/it]                                                   {'loss': 2.1142, 'learning_rate': 0.0008194444444444445, 'epoch': 0.02}
  2%|▏         | 59/2382 [11:28<6:27:07, 10.00s/it]  3%|▎         | 60/2382 [11:40<6:41:52, 10.38s/it]                                                   {'loss': 2.268, 'learning_rate': 0.0008333333333333334, 'epoch': 0.03}
  3%|▎         | 60/2382 [11:40<6:41:52, 10.38s/it]  3%|▎         | 61/2382 [11:49<6:36:27, 10.25s/it]                                                   {'loss': 2.2363, 'learning_rate': 0.0008472222222222222, 'epoch': 0.03}
  3%|▎         | 61/2382 [11:49<6:36:27, 10.25s/it]  3%|▎         | 62/2382 [12:00<6:37:23, 10.28s/it]                                                   {'loss': 2.1487, 'learning_rate': 0.0008611111111111112, 'epoch': 0.03}
  3%|▎         | 62/2382 [12:00<6:37:23, 10.28s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1040 > 1024). Running this sequence through the model will result in indexing errors
  3%|▎         | 63/2382 [12:11<6:53:23, 10.70s/it]                                                   {'loss': 2.1406, 'learning_rate': 0.000875, 'epoch': 0.03}
  3%|▎         | 63/2382 [12:11<6:53:23, 10.70s/it]  3%|▎         | 64/2382 [12:21<6:43:12, 10.44s/it]                                                   {'loss': 2.1808, 'learning_rate': 0.0008888888888888888, 'epoch': 0.03}
  3%|▎         | 64/2382 [12:21<6:43:12, 10.44s/it]  3%|▎         | 65/2382 [12:33<7:00:05, 10.88s/it]                                                   {'loss': 2.1839, 'learning_rate': 0.0009027777777777778, 'epoch': 0.03}
  3%|▎         | 65/2382 [12:33<7:00:05, 10.88s/it]  3%|▎         | 66/2382 [12:44<6:55:28, 10.76s/it]                                                   {'loss': 2.2569, 'learning_rate': 0.0009166666666666666, 'epoch': 0.03}
  3%|▎         | 66/2382 [12:44<6:55:28, 10.76s/it]  3%|▎         | 67/2382 [12:55<6:56:18, 10.79s/it]                                                   {'loss': 2.2876, 'learning_rate': 0.0009305555555555556, 'epoch': 0.03}
  3%|▎         | 67/2382 [12:55<6:56:18, 10.79s/it]  3%|▎         | 68/2382 [13:06<7:00:06, 10.89s/it]                                                   {'loss': 2.123, 'learning_rate': 0.0009444444444444445, 'epoch': 0.03}
  3%|▎         | 68/2382 [13:06<7:00:06, 10.89s/it]  3%|▎         | 69/2382 [13:16<6:49:40, 10.63s/it]                                                   {'loss': 2.3377, 'learning_rate': 0.0009583333333333334, 'epoch': 0.03}
  3%|▎         | 69/2382 [13:16<6:49:40, 10.63s/it]  3%|▎         | 70/2382 [13:28<7:10:30, 11.17s/it]                                                   {'loss': 2.3053, 'learning_rate': 0.0009722222222222222, 'epoch': 0.03}
  3%|▎         | 70/2382 [13:28<7:10:30, 11.17s/it]  3%|▎         | 71/2382 [13:38<6:50:11, 10.65s/it]                                                   {'loss': 2.1591, 'learning_rate': 0.0009861111111111112, 'epoch': 0.03}
  3%|▎         | 71/2382 [13:38<6:50:11, 10.65s/it]  3%|▎         | 72/2382 [13:48<6:51:01, 10.68s/it]                                                   {'loss': 2.2467, 'learning_rate': 0.001, 'epoch': 0.03}
  3%|▎         | 72/2382 [13:48<6:51:01, 10.68s/it]  3%|▎         | 73/2382 [14:02<7:29:07, 11.67s/it]                                                   {'loss': 2.1608, 'learning_rate': 0.000999999537602234, 'epoch': 0.03}
  3%|▎         | 73/2382 [14:02<7:29:07, 11.67s/it]  3%|▎         | 74/2382 [14:11<7:00:26, 10.93s/it]                                                   {'loss': 2.2394, 'learning_rate': 0.0009999981504097905, 'epoch': 0.03}
  3%|▎         | 74/2382 [14:12<7:00:26, 10.93s/it]  3%|▎         | 75/2382 [14:22<6:56:27, 10.83s/it]                                                   {'loss': 2.2883, 'learning_rate': 0.0009999958384252362, 'epoch': 0.03}
  3%|▎         | 75/2382 [14:22<6:56:27, 10.83s/it]  3%|▎         | 76/2382 [14:34<7:03:45, 11.03s/it]                                                   {'loss': 2.241, 'learning_rate': 0.0009999926016528464, 'epoch': 0.03}
  3%|▎         | 76/2382 [14:34<7:03:45, 11.03s/it]  3%|▎         | 77/2382 [14:44<6:51:15, 10.71s/it]                                                   {'loss': 2.2982, 'learning_rate': 0.0009999884400986086, 'epoch': 0.03}
  3%|▎         | 77/2382 [14:44<6:51:15, 10.71s/it]  3%|▎         | 78/2382 [14:53<6:41:05, 10.45s/it]                                                   {'loss': 2.2814, 'learning_rate': 0.0009999833537702191, 'epoch': 0.03}
  3%|▎         | 78/2382 [14:53<6:41:05, 10.45s/it]  3%|▎         | 79/2382 [15:07<7:17:47, 11.41s/it]                                                   {'loss': 2.1666, 'learning_rate': 0.0009999773426770863, 'epoch': 0.03}
  3%|▎         | 79/2382 [15:07<7:17:47, 11.41s/it]  3%|▎         | 80/2382 [15:18<7:17:05, 11.39s/it]                                                   {'loss': 2.1641, 'learning_rate': 0.000999970406830328, 'epoch': 0.03}
  3%|▎         | 80/2382 [15:18<7:17:05, 11.39s/it]  3%|▎         | 81/2382 [15:32<7:42:22, 12.06s/it]                                                   {'loss': 2.1623, 'learning_rate': 0.0009999625462427729, 'epoch': 0.03}
  3%|▎         | 81/2382 [15:32<7:42:22, 12.06s/it]  3%|▎         | 82/2382 [15:44<7:42:53, 12.08s/it]                                                   {'loss': 2.1426, 'learning_rate': 0.0009999537609289592, 'epoch': 0.03}
  3%|▎         | 82/2382 [15:44<7:42:53, 12.08s/it]  3%|▎         | 83/2382 [15:57<7:49:36, 12.26s/it]                                                   {'loss': 2.2002, 'learning_rate': 0.0009999440509051367, 'epoch': 0.03}
  3%|▎         | 83/2382 [15:57<7:49:36, 12.26s/it]  4%|▎         | 84/2382 [16:08<7:33:40, 11.85s/it]                                                   {'loss': 2.1091, 'learning_rate': 0.0009999334161892649, 'epoch': 0.04}
  4%|▎         | 84/2382 [16:08<7:33:40, 11.85s/it]  4%|▎         | 85/2382 [16:19<7:30:09, 11.76s/it]                                                   {'loss': 2.3144, 'learning_rate': 0.0009999218568010136, 'epoch': 0.04}
  4%|▎         | 85/2382 [16:19<7:30:09, 11.76s/it]  4%|▎         | 86/2382 [16:31<7:29:11, 11.74s/it]                                                   {'loss': 2.1147, 'learning_rate': 0.000999909372761763, 'epoch': 0.04}
  4%|▎         | 86/2382 [16:31<7:29:11, 11.74s/it]  4%|▎         | 87/2382 [16:40<6:52:48, 10.79s/it]                                                   {'loss': 2.1645, 'learning_rate': 0.0009998959640946032, 'epoch': 0.04}
  4%|▎         | 87/2382 [16:40<6:52:48, 10.79s/it]  4%|▎         | 88/2382 [16:52<7:11:30, 11.29s/it]                                                   {'loss': 2.0012, 'learning_rate': 0.0009998816308243352, 'epoch': 0.04}
  4%|▎         | 88/2382 [16:52<7:11:30, 11.29s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1196 > 1024). Running this sequence through the model will result in indexing errors
  4%|▎         | 89/2382 [17:02<7:01:26, 11.03s/it]                                                   {'loss': 2.0844, 'learning_rate': 0.0009998663729774693, 'epoch': 0.04}
  4%|▎         | 89/2382 [17:02<7:01:26, 11.03s/it]  4%|▍         | 90/2382 [17:13<6:52:06, 10.79s/it]                                                   {'loss': 2.1771, 'learning_rate': 0.0009998501905822267, 'epoch': 0.04}
  4%|▍         | 90/2382 [17:13<6:52:06, 10.79s/it]  4%|▍         | 91/2382 [17:23<6:48:39, 10.70s/it]                                                   {'loss': 2.2174, 'learning_rate': 0.0009998330836685377, 'epoch': 0.04}
  4%|▍         | 91/2382 [17:23<6:48:39, 10.70s/it]  4%|▍         | 92/2382 [17:32<6:32:54, 10.29s/it]                                                   {'loss': 2.1485, 'learning_rate': 0.0009998150522680437, 'epoch': 0.04}
  4%|▍         | 92/2382 [17:32<6:32:54, 10.29s/it]  4%|▍         | 93/2382 [17:42<6:25:05, 10.09s/it]                                                   {'loss': 2.1799, 'learning_rate': 0.0009997960964140947, 'epoch': 0.04}
  4%|▍         | 93/2382 [17:42<6:25:05, 10.09s/it]  4%|▍         | 94/2382 [17:51<6:13:39,  9.80s/it]                                                   {'loss': 2.1838, 'learning_rate': 0.0009997762161417516, 'epoch': 0.04}
  4%|▍         | 94/2382 [17:51<6:13:39,  9.80s/it]  4%|▍         | 95/2382 [18:01<6:13:20,  9.79s/it]                                                   {'loss': 2.1809, 'learning_rate': 0.0009997554114877852, 'epoch': 0.04}
  4%|▍         | 95/2382 [18:01<6:13:20,  9.79s/it]  4%|▍         | 96/2382 [18:12<6:29:46, 10.23s/it]                                                   {'loss': 2.1749, 'learning_rate': 0.000999733682490675, 'epoch': 0.04}
  4%|▍         | 96/2382 [18:12<6:29:46, 10.23s/it]  4%|▍         | 97/2382 [18:24<6:51:27, 10.80s/it]                                                   {'loss': 2.2594, 'learning_rate': 0.0009997110291906108, 'epoch': 0.04}
  4%|▍         | 97/2382 [18:24<6:51:27, 10.80s/it]  4%|▍         | 98/2382 [18:36<6:56:45, 10.95s/it]                                                   {'loss': 2.2298, 'learning_rate': 0.0009996874516294925, 'epoch': 0.04}
  4%|▍         | 98/2382 [18:36<6:56:45, 10.95s/it]  4%|▍         | 99/2382 [18:46<6:55:06, 10.91s/it]                                                   {'loss': 2.1597, 'learning_rate': 0.0009996629498509283, 'epoch': 0.04}
  4%|▍         | 99/2382 [18:46<6:55:06, 10.91s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1547 > 1024). Running this sequence through the model will result in indexing errors
  4%|▍         | 100/2382 [19:02<7:45:45, 12.25s/it]                                                    {'loss': 2.2228, 'learning_rate': 0.0009996375239002368, 'epoch': 0.04}
  4%|▍         | 100/2382 [19:02<7:45:45, 12.25s/it]  4%|▍         | 101/2382 [19:13<7:32:31, 11.90s/it]                                                    {'loss': 2.171, 'learning_rate': 0.0009996111738244456, 'epoch': 0.04}
  4%|▍         | 101/2382 [19:13<7:32:31, 11.90s/it]  4%|▍         | 102/2382 [19:24<7:20:04, 11.58s/it]                                                    {'loss': 2.1124, 'learning_rate': 0.0009995838996722914, 'epoch': 0.04}
  4%|▍         | 102/2382 [19:24<7:20:04, 11.58s/it]  4%|▍         | 103/2382 [19:35<7:20:20, 11.59s/it]                                                    {'loss': 2.0965, 'learning_rate': 0.0009995557014942204, 'epoch': 0.04}
  4%|▍         | 103/2382 [19:35<7:20:20, 11.59s/it]  4%|▍         | 104/2382 [19:49<7:40:36, 12.13s/it]                                                    {'loss': 2.145, 'learning_rate': 0.0009995265793423878, 'epoch': 0.04}
  4%|▍         | 104/2382 [19:49<7:40:36, 12.13s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1059 > 1024). Running this sequence through the model will result in indexing errors
  4%|▍         | 105/2382 [20:05<8:25:56, 13.33s/it]                                                    {'loss': 2.265, 'learning_rate': 0.0009994965332706573, 'epoch': 0.04}
  4%|▍         | 105/2382 [20:05<8:25:56, 13.33s/it]  4%|▍         | 106/2382 [20:18<8:24:36, 13.30s/it]                                                    {'loss': 2.0702, 'learning_rate': 0.0009994655633346022, 'epoch': 0.04}
  4%|▍         | 106/2382 [20:18<8:24:36, 13.30s/it]  4%|▍         | 107/2382 [20:29<7:58:14, 12.61s/it]                                                    {'loss': 2.2212, 'learning_rate': 0.000999433669591504, 'epoch': 0.04}
  4%|▍         | 107/2382 [20:29<7:58:14, 12.61s/it]  5%|▍         | 108/2382 [20:39<7:30:32, 11.89s/it]                                                    {'loss': 2.1929, 'learning_rate': 0.0009994008521003533, 'epoch': 0.05}
  5%|▍         | 108/2382 [20:39<7:30:32, 11.89s/it]  5%|▍         | 109/2382 [20:49<7:05:37, 11.24s/it]                                                    {'loss': 2.1633, 'learning_rate': 0.0009993671109218487, 'epoch': 0.05}
  5%|▍         | 109/2382 [20:49<7:05:37, 11.24s/it]  5%|▍         | 110/2382 [21:01<7:16:07, 11.52s/it]                                                    {'loss': 2.1564, 'learning_rate': 0.0009993324461183978, 'epoch': 0.05}
  5%|▍         | 110/2382 [21:01<7:16:07, 11.52s/it]  5%|▍         | 111/2382 [21:11<6:59:12, 11.08s/it]                                                    {'loss': 2.2456, 'learning_rate': 0.0009992968577541164, 'epoch': 0.05}
  5%|▍         | 111/2382 [21:11<6:59:12, 11.08s/it]  5%|▍         | 112/2382 [21:21<6:46:58, 10.76s/it]                                                    {'loss': 2.2013, 'learning_rate': 0.0009992603458948283, 'epoch': 0.05}
  5%|▍         | 112/2382 [21:21<6:46:58, 10.76s/it]  5%|▍         | 113/2382 [21:31<6:35:04, 10.45s/it]                                                    {'loss': 2.1077, 'learning_rate': 0.0009992229106080654, 'epoch': 0.05}
  5%|▍         | 113/2382 [21:31<6:35:04, 10.45s/it]  5%|▍         | 114/2382 [21:42<6:38:49, 10.55s/it]                                                    {'loss': 2.2393, 'learning_rate': 0.0009991845519630679, 'epoch': 0.05}
  5%|▍         | 114/2382 [21:42<6:38:49, 10.55s/it]  5%|▍         | 115/2382 [21:52<6:36:48, 10.50s/it]                                                    {'loss': 2.3333, 'learning_rate': 0.0009991452700307834, 'epoch': 0.05}
  5%|▍         | 115/2382 [21:52<6:36:48, 10.50s/it]  5%|▍         | 116/2382 [22:05<7:01:07, 11.15s/it]                                                    {'loss': 2.1313, 'learning_rate': 0.0009991050648838675, 'epoch': 0.05}
  5%|▍         | 116/2382 [22:05<7:01:07, 11.15s/it]  5%|▍         | 117/2382 [22:17<7:13:05, 11.47s/it]                                                    {'loss': 2.2478, 'learning_rate': 0.0009990639365966836, 'epoch': 0.05}
  5%|▍         | 117/2382 [22:17<7:13:05, 11.47s/it]  5%|▍         | 118/2382 [22:30<7:30:28, 11.94s/it]                                                    {'loss': 2.1687, 'learning_rate': 0.0009990218852453014, 'epoch': 0.05}
  5%|▍         | 118/2382 [22:30<7:30:28, 11.94s/it]  5%|▍         | 119/2382 [22:42<7:28:11, 11.88s/it]                                                    {'loss': 2.2222, 'learning_rate': 0.0009989789109074996, 'epoch': 0.05}
  5%|▍         | 119/2382 [22:42<7:28:11, 11.88s/it]  5%|▌         | 120/2382 [22:54<7:30:31, 11.95s/it]                                                    {'loss': 2.1359, 'learning_rate': 0.0009989350136627626, 'epoch': 0.05}
  5%|▌         | 120/2382 [22:54<7:30:31, 11.95s/it]  5%|▌         | 121/2382 [23:07<7:44:18, 12.32s/it]                                                    {'loss': 2.2076, 'learning_rate': 0.0009988901935922825, 'epoch': 0.05}
  5%|▌         | 121/2382 [23:07<7:44:18, 12.32s/it]  5%|▌         | 122/2382 [23:16<7:06:02, 11.31s/it]                                                    {'loss': 2.114, 'learning_rate': 0.0009988444507789582, 'epoch': 0.05}
  5%|▌         | 122/2382 [23:16<7:06:02, 11.31s/it]  5%|▌         | 123/2382 [23:30<7:33:35, 12.05s/it]                                                    {'loss': 2.1827, 'learning_rate': 0.0009987977853073951, 'epoch': 0.05}
  5%|▌         | 123/2382 [23:30<7:33:35, 12.05s/it]  5%|▌         | 124/2382 [23:43<7:51:17, 12.52s/it]                                                    {'loss': 2.0689, 'learning_rate': 0.0009987501972639052, 'epoch': 0.05}
  5%|▌         | 124/2382 [23:43<7:51:17, 12.52s/it]  5%|▌         | 125/2382 [23:54<7:23:29, 11.79s/it]                                                    {'loss': 2.1706, 'learning_rate': 0.000998701686736507, 'epoch': 0.05}
  5%|▌         | 125/2382 [23:54<7:23:29, 11.79s/it]  5%|▌         | 126/2382 [24:02<6:44:52, 10.77s/it]                                                    {'loss': 2.1614, 'learning_rate': 0.000998652253814925, 'epoch': 0.05}
  5%|▌         | 126/2382 [24:02<6:44:52, 10.77s/it]  5%|▌         | 127/2382 [24:13<6:47:04, 10.83s/it]                                                    {'loss': 2.1118, 'learning_rate': 0.00099860189859059, 'epoch': 0.05}
  5%|▌         | 127/2382 [24:13<6:47:04, 10.83s/it]  5%|▌         | 128/2382 [24:24<6:46:37, 10.82s/it]                                                    {'loss': 2.1378, 'learning_rate': 0.0009985506211566387, 'epoch': 0.05}
  5%|▌         | 128/2382 [24:24<6:46:37, 10.82s/it]  5%|▌         | 129/2382 [24:32<6:20:37, 10.14s/it]                                                    {'loss': 2.229, 'learning_rate': 0.0009984984216079133, 'epoch': 0.05}
  5%|▌         | 129/2382 [24:32<6:20:37, 10.14s/it]  5%|▌         | 130/2382 [24:44<6:34:29, 10.51s/it]                                                    {'loss': 2.0856, 'learning_rate': 0.0009984453000409614, 'epoch': 0.05}
  5%|▌         | 130/2382 [24:44<6:34:29, 10.51s/it]  5%|▌         | 131/2382 [24:53<6:18:47, 10.10s/it]                                                    {'loss': 2.1099, 'learning_rate': 0.0009983912565540364, 'epoch': 0.05}
  5%|▌         | 131/2382 [24:53<6:18:47, 10.10s/it]  6%|▌         | 132/2382 [25:03<6:23:31, 10.23s/it]                                                    {'loss': 2.1219, 'learning_rate': 0.0009983362912470966, 'epoch': 0.06}
  6%|▌         | 132/2382 [25:03<6:23:31, 10.23s/it]  6%|▌         | 133/2382 [25:15<6:39:11, 10.65s/it]                                                    {'loss': 2.1232, 'learning_rate': 0.0009982804042218054, 'epoch': 0.06}
  6%|▌         | 133/2382 [25:15<6:39:11, 10.65s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1118 > 1024). Running this sequence through the model will result in indexing errors
  6%|▌         | 134/2382 [25:25<6:33:49, 10.51s/it]                                                    {'loss': 2.121, 'learning_rate': 0.0009982235955815308, 'epoch': 0.06}
  6%|▌         | 134/2382 [25:25<6:33:49, 10.51s/it]  6%|▌         | 135/2382 [25:38<7:02:51, 11.29s/it]                                                    {'loss': 2.1665, 'learning_rate': 0.0009981658654313456, 'epoch': 0.06}
  6%|▌         | 135/2382 [25:38<7:02:51, 11.29s/it]  6%|▌         | 136/2382 [25:50<7:04:45, 11.35s/it]                                                    {'loss': 2.1527, 'learning_rate': 0.000998107213878027, 'epoch': 0.06}
  6%|▌         | 136/2382 [25:50<7:04:45, 11.35s/it]  6%|▌         | 137/2382 [25:59<6:39:40, 10.68s/it]                                                    {'loss': 2.2021, 'learning_rate': 0.0009980476410300567, 'epoch': 0.06}
  6%|▌         | 137/2382 [25:59<6:39:40, 10.68s/it]  6%|▌         | 138/2382 [26:08<6:26:18, 10.33s/it]                                                    {'loss': 2.2056, 'learning_rate': 0.0009979871469976197, 'epoch': 0.06}
  6%|▌         | 138/2382 [26:08<6:26:18, 10.33s/it]  6%|▌         | 139/2382 [26:23<7:17:01, 11.69s/it]                                                    {'loss': 2.1619, 'learning_rate': 0.000997925731892605, 'epoch': 0.06}
  6%|▌         | 139/2382 [26:23<7:17:01, 11.69s/it]  6%|▌         | 140/2382 [26:34<7:07:33, 11.44s/it]                                                    {'loss': 2.0693, 'learning_rate': 0.0009978633958286059, 'epoch': 0.06}
  6%|▌         | 140/2382 [26:34<7:07:33, 11.44s/it]  6%|▌         | 141/2382 [26:44<6:51:57, 11.03s/it]                                                    {'loss': 2.2732, 'learning_rate': 0.0009978001389209187, 'epoch': 0.06}
  6%|▌         | 141/2382 [26:44<6:51:57, 11.03s/it]  6%|▌         | 142/2382 [26:52<6:19:24, 10.16s/it]                                                    {'loss': 2.256, 'learning_rate': 0.0009977359612865424, 'epoch': 0.06}
  6%|▌         | 142/2382 [26:52<6:19:24, 10.16s/it]  6%|▌         | 143/2382 [27:05<6:50:53, 11.01s/it]                                                    {'loss': 2.2041, 'learning_rate': 0.0009976708630441795, 'epoch': 0.06}
  6%|▌         | 143/2382 [27:05<6:50:53, 11.01s/it]  6%|▌         | 144/2382 [27:14<6:21:39, 10.23s/it]                                                    {'loss': 2.1698, 'learning_rate': 0.0009976048443142353, 'epoch': 0.06}
  6%|▌         | 144/2382 [27:14<6:21:39, 10.23s/it]  6%|▌         | 145/2382 [27:25<6:38:27, 10.69s/it]                                                    {'loss': 2.0809, 'learning_rate': 0.0009975379052188174, 'epoch': 0.06}
  6%|▌         | 145/2382 [27:25<6:38:27, 10.69s/it]  6%|▌         | 146/2382 [27:37<6:46:17, 10.90s/it]                                                    {'loss': 2.1544, 'learning_rate': 0.0009974700458817356, 'epoch': 0.06}
  6%|▌         | 146/2382 [27:37<6:46:17, 10.90s/it]  6%|▌         | 147/2382 [27:50<7:09:34, 11.53s/it]                                                    {'loss': 2.076, 'learning_rate': 0.000997401266428502, 'epoch': 0.06}
  6%|▌         | 147/2382 [27:50<7:09:34, 11.53s/it]  6%|▌         | 148/2382 [28:00<6:58:34, 11.24s/it]                                                    {'loss': 2.0486, 'learning_rate': 0.0009973315669863305, 'epoch': 0.06}
  6%|▌         | 148/2382 [28:00<6:58:34, 11.24s/it]  6%|▋         | 149/2382 [28:13<7:14:56, 11.69s/it]                                                    {'loss': 2.0137, 'learning_rate': 0.0009972609476841367, 'epoch': 0.06}
  6%|▋         | 149/2382 [28:13<7:14:56, 11.69s/it]  6%|▋         | 150/2382 [28:28<7:46:43, 12.55s/it]                                                    {'loss': 2.1572, 'learning_rate': 0.0009971894086525373, 'epoch': 0.06}
  6%|▋         | 150/2382 [28:28<7:46:43, 12.55s/it]  6%|▋         | 151/2382 [28:40<7:45:06, 12.51s/it]                                                    {'loss': 2.1307, 'learning_rate': 0.0009971169500238499, 'epoch': 0.06}
  6%|▋         | 151/2382 [28:40<7:45:06, 12.51s/it]  6%|▋         | 152/2382 [28:50<7:13:11, 11.66s/it]                                                    {'loss': 2.1655, 'learning_rate': 0.000997043571932094, 'epoch': 0.06}
  6%|▋         | 152/2382 [28:50<7:13:11, 11.66s/it]  6%|▋         | 153/2382 [29:00<6:55:17, 11.18s/it]                                                    {'loss': 2.235, 'learning_rate': 0.0009969692745129886, 'epoch': 0.06}
  6%|▋         | 153/2382 [29:00<6:55:17, 11.18s/it]  6%|▋         | 154/2382 [29:14<7:25:56, 12.01s/it]                                                    {'loss': 1.9897, 'learning_rate': 0.0009968940579039539, 'epoch': 0.06}
  6%|▋         | 154/2382 [29:14<7:25:56, 12.01s/it]  7%|▋         | 155/2382 [29:25<7:13:37, 11.68s/it]                                                    {'loss': 2.1606, 'learning_rate': 0.0009968179222441093, 'epoch': 0.07}
  7%|▋         | 155/2382 [29:25<7:13:37, 11.68s/it]  7%|▋         | 156/2382 [29:36<7:14:09, 11.70s/it]                                                    {'loss': 2.1608, 'learning_rate': 0.0009967408676742752, 'epoch': 0.07}
  7%|▋         | 156/2382 [29:36<7:14:09, 11.70s/it]  7%|▋         | 157/2382 [29:48<7:14:12, 11.71s/it]                                                    {'loss': 1.9889, 'learning_rate': 0.0009966628943369707, 'epoch': 0.07}
  7%|▋         | 157/2382 [29:48<7:14:12, 11.71s/it]  7%|▋         | 158/2382 [29:58<6:56:21, 11.23s/it]                                                    {'loss': 2.0315, 'learning_rate': 0.0009965840023764148, 'epoch': 0.07}
  7%|▋         | 158/2382 [29:58<6:56:21, 11.23s/it]  7%|▋         | 159/2382 [30:08<6:38:44, 10.76s/it]                                                    {'loss': 2.125, 'learning_rate': 0.0009965041919385252, 'epoch': 0.07}
  7%|▋         | 159/2382 [30:08<6:38:44, 10.76s/it]  7%|▋         | 160/2382 [30:19<6:40:12, 10.81s/it]                                                    {'loss': 2.1241, 'learning_rate': 0.0009964234631709187, 'epoch': 0.07}
  7%|▋         | 160/2382 [30:19<6:40:12, 10.81s/it]  7%|▋         | 161/2382 [30:31<6:50:08, 11.08s/it]                                                    {'loss': 2.174, 'learning_rate': 0.0009963418162229104, 'epoch': 0.07}
  7%|▋         | 161/2382 [30:31<6:50:08, 11.08s/it]  7%|▋         | 162/2382 [30:42<6:49:41, 11.07s/it]                                                    {'loss': 2.1302, 'learning_rate': 0.000996259251245514, 'epoch': 0.07}
  7%|▋         | 162/2382 [30:42<6:49:41, 11.07s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1084 > 1024). Running this sequence through the model will result in indexing errors
  7%|▋         | 163/2382 [30:51<6:33:10, 10.63s/it]                                                    {'loss': 2.1089, 'learning_rate': 0.0009961757683914405, 'epoch': 0.07}
  7%|▋         | 163/2382 [30:51<6:33:10, 10.63s/it]  7%|▋         | 164/2382 [31:06<7:12:59, 11.71s/it]                                                    {'loss': 2.0699, 'learning_rate': 0.0009960913678150995, 'epoch': 0.07}
  7%|▋         | 164/2382 [31:06<7:12:59, 11.71s/it]  7%|▋         | 165/2382 [31:16<7:03:10, 11.45s/it]                                                    {'loss': 2.0188, 'learning_rate': 0.0009960060496725974, 'epoch': 0.07}
  7%|▋         | 165/2382 [31:16<7:03:10, 11.45s/it]  7%|▋         | 166/2382 [31:27<6:55:48, 11.26s/it]                                                    {'loss': 2.1945, 'learning_rate': 0.0009959198141217375, 'epoch': 0.07}
  7%|▋         | 166/2382 [31:27<6:55:48, 11.26s/it]  7%|▋         | 167/2382 [31:37<6:41:22, 10.87s/it]                                                    {'loss': 2.0506, 'learning_rate': 0.000995832661322021, 'epoch': 0.07}
  7%|▋         | 167/2382 [31:37<6:41:22, 10.87s/it]  7%|▋         | 168/2382 [31:49<6:47:46, 11.05s/it]                                                    {'loss': 2.0543, 'learning_rate': 0.0009957445914346443, 'epoch': 0.07}
  7%|▋         | 168/2382 [31:49<6:47:46, 11.05s/it]  7%|▋         | 169/2382 [31:59<6:42:02, 10.90s/it]                                                    {'loss': 2.0546, 'learning_rate': 0.0009956556046225012, 'epoch': 0.07}
  7%|▋         | 169/2382 [31:59<6:42:02, 10.90s/it]  7%|▋         | 170/2382 [32:10<6:44:54, 10.98s/it]                                                    {'loss': 2.1456, 'learning_rate': 0.0009955657010501807, 'epoch': 0.07}
  7%|▋         | 170/2382 [32:10<6:44:54, 10.98s/it]  7%|▋         | 171/2382 [32:20<6:31:48, 10.63s/it]                                                    {'loss': 2.186, 'learning_rate': 0.0009954748808839674, 'epoch': 0.07}
  7%|▋         | 171/2382 [32:20<6:31:48, 10.63s/it]  7%|▋         | 172/2382 [32:33<7:01:00, 11.43s/it]                                                    {'loss': 2.0815, 'learning_rate': 0.0009953831442918418, 'epoch': 0.07}
  7%|▋         | 172/2382 [32:33<7:01:00, 11.43s/it]  7%|▋         | 173/2382 [32:43<6:45:46, 11.02s/it]                                                    {'loss': 2.1047, 'learning_rate': 0.0009952904914434788, 'epoch': 0.07}
  7%|▋         | 173/2382 [32:44<6:45:46, 11.02s/it]  7%|▋         | 174/2382 [32:56<7:05:35, 11.57s/it]                                                    {'loss': 2.0672, 'learning_rate': 0.0009951969225102486, 'epoch': 0.07}
  7%|▋         | 174/2382 [32:56<7:05:35, 11.57s/it]  7%|▋         | 175/2382 [33:08<7:02:19, 11.48s/it]                                                    {'loss': 2.1356, 'learning_rate': 0.0009951024376652154, 'epoch': 0.07}
  7%|▋         | 175/2382 [33:08<7:02:19, 11.48s/it]  7%|▋         | 176/2382 [33:18<6:54:09, 11.26s/it]                                                    {'loss': 2.1809, 'learning_rate': 0.0009950070370831371, 'epoch': 0.07}
  7%|▋         | 176/2382 [33:18<6:54:09, 11.26s/it]  7%|▋         | 177/2382 [33:28<6:37:49, 10.83s/it]                                                    {'loss': 2.1634, 'learning_rate': 0.0009949107209404665, 'epoch': 0.07}
  7%|▋         | 177/2382 [33:28<6:37:49, 10.83s/it]  7%|▋         | 178/2382 [33:37<6:16:28, 10.25s/it]                                                    {'loss': 2.115, 'learning_rate': 0.0009948134894153483, 'epoch': 0.07}
  7%|▋         | 178/2382 [33:37<6:16:28, 10.25s/it]  8%|▊         | 179/2382 [33:50<6:42:58, 10.98s/it]                                                    {'loss': 2.2273, 'learning_rate': 0.0009947153426876217, 'epoch': 0.08}
  8%|▊         | 179/2382 [33:50<6:42:58, 10.98s/it]  8%|▊         | 180/2382 [34:05<7:32:12, 12.32s/it]                                                    {'loss': 1.9859, 'learning_rate': 0.0009946162809388176, 'epoch': 0.08}
  8%|▊         | 180/2382 [34:05<7:32:12, 12.32s/it]  8%|▊         | 181/2382 [34:15<7:02:17, 11.51s/it]                                                    {'loss': 2.1299, 'learning_rate': 0.00099451630435216, 'epoch': 0.08}
  8%|▊         | 181/2382 [34:15<7:02:17, 11.51s/it]  8%|▊         | 182/2382 [34:27<7:05:06, 11.59s/it]                                                    {'loss': 2.0853, 'learning_rate': 0.0009944154131125641, 'epoch': 0.08}
  8%|▊         | 182/2382 [34:27<7:05:06, 11.59s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1227 > 1024). Running this sequence through the model will result in indexing errors
  8%|▊         | 183/2382 [34:37<6:51:52, 11.24s/it]                                                    {'loss': 2.2493, 'learning_rate': 0.0009943136074066384, 'epoch': 0.08}
  8%|▊         | 183/2382 [34:37<6:51:52, 11.24s/it]  8%|▊         | 184/2382 [34:45<6:15:34, 10.25s/it]                                                    {'loss': 2.1518, 'learning_rate': 0.0009942108874226813, 'epoch': 0.08}
  8%|▊         | 184/2382 [34:45<6:15:34, 10.25s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1813 > 1024). Running this sequence through the model will result in indexing errors
  8%|▊         | 185/2382 [34:57<6:29:27, 10.64s/it]                                                    {'loss': 2.1019, 'learning_rate': 0.0009941072533506826, 'epoch': 0.08}
  8%|▊         | 185/2382 [34:57<6:29:27, 10.64s/it]  8%|▊         | 186/2382 [35:07<6:24:55, 10.52s/it]                                                    {'loss': 2.1029, 'learning_rate': 0.0009940027053823232, 'epoch': 0.08}
  8%|▊         | 186/2382 [35:07<6:24:55, 10.52s/it]  8%|▊         | 187/2382 [35:18<6:38:11, 10.88s/it]                                                    {'loss': 2.1458, 'learning_rate': 0.000993897243710974, 'epoch': 0.08}
  8%|▊         | 187/2382 [35:18<6:38:11, 10.88s/it]  8%|▊         | 188/2382 [35:29<6:33:08, 10.75s/it]                                                    {'loss': 2.0343, 'learning_rate': 0.000993790868531696, 'epoch': 0.08}
  8%|▊         | 188/2382 [35:29<6:33:08, 10.75s/it]  8%|▊         | 189/2382 [35:43<7:13:22, 11.86s/it]                                                    {'loss': 1.997, 'learning_rate': 0.0009936835800412398, 'epoch': 0.08}
  8%|▊         | 189/2382 [35:43<7:13:22, 11.86s/it]  8%|▊         | 190/2382 [35:53<6:50:26, 11.23s/it]                                                    {'loss': 2.1891, 'learning_rate': 0.0009935753784380455, 'epoch': 0.08}
  8%|▊         | 190/2382 [35:53<6:50:26, 11.23s/it]  8%|▊         | 191/2382 [36:05<6:56:15, 11.40s/it]                                                    {'loss': 2.0739, 'learning_rate': 0.0009934662639222412, 'epoch': 0.08}
  8%|▊         | 191/2382 [36:05<6:56:15, 11.40s/it]  8%|▊         | 192/2382 [36:17<7:00:42, 11.53s/it]                                                    {'loss': 2.2747, 'learning_rate': 0.0009933562366956443, 'epoch': 0.08}
  8%|▊         | 192/2382 [36:17<7:00:42, 11.53s/it]  8%|▊         | 193/2382 [36:27<6:45:00, 11.10s/it]                                                    {'loss': 2.1041, 'learning_rate': 0.0009932452969617608, 'epoch': 0.08}
  8%|▊         | 193/2382 [36:27<6:45:00, 11.10s/it]  8%|▊         | 194/2382 [36:39<6:51:50, 11.29s/it]                                                    {'loss': 2.1527, 'learning_rate': 0.0009931334449257833, 'epoch': 0.08}
  8%|▊         | 194/2382 [36:39<6:51:50, 11.29s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1145 > 1024). Running this sequence through the model will result in indexing errors
  8%|▊         | 195/2382 [36:48<6:33:23, 10.79s/it]                                                    {'loss': 2.1884, 'learning_rate': 0.000993020680794592, 'epoch': 0.08}
  8%|▊         | 195/2382 [36:48<6:33:23, 10.79s/it]  8%|▊         | 196/2382 [37:00<6:46:04, 11.15s/it]                                                    {'loss': 2.2321, 'learning_rate': 0.000992907004776755, 'epoch': 0.08}
  8%|▊         | 196/2382 [37:00<6:46:04, 11.15s/it]  8%|▊         | 197/2382 [37:11<6:44:26, 11.11s/it]                                                    {'loss': 2.095, 'learning_rate': 0.0009927924170825264, 'epoch': 0.08}
  8%|▊         | 197/2382 [37:11<6:44:26, 11.11s/it]  8%|▊         | 198/2382 [37:19<6:05:59, 10.05s/it]                                                    {'loss': 2.2655, 'learning_rate': 0.0009926769179238466, 'epoch': 0.08}
  8%|▊         | 198/2382 [37:19<6:05:59, 10.05s/it]  8%|▊         | 199/2382 [37:31<6:23:35, 10.54s/it]                                                    {'loss': 2.0501, 'learning_rate': 0.0009925605075143413, 'epoch': 0.08}
  8%|▊         | 199/2382 [37:31<6:23:35, 10.54s/it]  8%|▊         | 200/2382 [37:42<6:35:47, 10.88s/it]                                                    {'loss': 2.1388, 'learning_rate': 0.000992443186069323, 'epoch': 0.08}
  8%|▊         | 200/2382 [37:42<6:35:47, 10.88s/it]  8%|▊         | 201/2382 [37:57<7:20:03, 12.11s/it]                                                    {'loss': 2.1112, 'learning_rate': 0.0009923249538057875, 'epoch': 0.08}
  8%|▊         | 201/2382 [37:57<7:20:03, 12.11s/it]  8%|▊         | 202/2382 [38:07<6:57:32, 11.49s/it]                                                    {'loss': 2.0381, 'learning_rate': 0.0009922058109424166, 'epoch': 0.08}
  8%|▊         | 202/2382 [38:07<6:57:32, 11.49s/it]  9%|▊         | 203/2382 [38:19<6:56:02, 11.46s/it]                                                    {'loss': 2.0005, 'learning_rate': 0.000992085757699576, 'epoch': 0.09}
  9%|▊         | 203/2382 [38:19<6:56:02, 11.46s/it]  9%|▊         | 204/2382 [38:32<7:17:39, 12.06s/it]                                                    {'loss': 2.1569, 'learning_rate': 0.0009919647942993148, 'epoch': 0.09}
  9%|▊         | 204/2382 [38:32<7:17:39, 12.06s/it]  9%|▊         | 205/2382 [38:43<7:07:14, 11.78s/it]                                                    {'loss': 2.2066, 'learning_rate': 0.0009918429209653662, 'epoch': 0.09}
  9%|▊         | 205/2382 [38:43<7:07:14, 11.78s/it]  9%|▊         | 206/2382 [38:54<7:02:20, 11.65s/it]                                                    {'loss': 2.1605, 'learning_rate': 0.0009917201379231455, 'epoch': 0.09}
  9%|▊         | 206/2382 [38:54<7:02:20, 11.65s/it]  9%|▊         | 207/2382 [39:05<6:46:32, 11.22s/it]                                                    {'loss': 2.1238, 'learning_rate': 0.0009915964453997516, 'epoch': 0.09}
  9%|▊         | 207/2382 [39:05<6:46:32, 11.22s/it]  9%|▊         | 208/2382 [39:18<7:03:45, 11.70s/it]                                                    {'loss': 2.158, 'learning_rate': 0.0009914718436239648, 'epoch': 0.09}
  9%|▊         | 208/2382 [39:18<7:03:45, 11.70s/it]  9%|▉         | 209/2382 [39:27<6:39:21, 11.03s/it]                                                    {'loss': 2.1619, 'learning_rate': 0.0009913463328262476, 'epoch': 0.09}
  9%|▉         | 209/2382 [39:27<6:39:21, 11.03s/it]  9%|▉         | 210/2382 [39:36<6:22:46, 10.57s/it]                                                    {'loss': 2.1096, 'learning_rate': 0.0009912199132387433, 'epoch': 0.09}
  9%|▉         | 210/2382 [39:37<6:22:46, 10.57s/it]  9%|▉         | 211/2382 [39:49<6:39:55, 11.05s/it]                                                    {'loss': 2.1394, 'learning_rate': 0.000991092585095277, 'epoch': 0.09}
  9%|▉         | 211/2382 [39:49<6:39:55, 11.05s/it]  9%|▉         | 212/2382 [40:00<6:40:30, 11.07s/it]                                                    {'loss': 2.1376, 'learning_rate': 0.0009909643486313534, 'epoch': 0.09}
  9%|▉         | 212/2382 [40:00<6:40:30, 11.07s/it]  9%|▉         | 213/2382 [40:10<6:27:48, 10.73s/it]                                                    {'loss': 2.0858, 'learning_rate': 0.0009908352040841576, 'epoch': 0.09}
  9%|▉         | 213/2382 [40:10<6:27:48, 10.73s/it]  9%|▉         | 214/2382 [40:21<6:28:29, 10.75s/it]                                                    {'loss': 2.0814, 'learning_rate': 0.0009907051516925538, 'epoch': 0.09}
  9%|▉         | 214/2382 [40:21<6:28:29, 10.75s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1480 > 1024). Running this sequence through the model will result in indexing errors
  9%|▉         | 215/2382 [40:33<6:41:54, 11.13s/it]                                                    {'loss': 2.1769, 'learning_rate': 0.0009905741916970863, 'epoch': 0.09}
  9%|▉         | 215/2382 [40:33<6:41:54, 11.13s/it]  9%|▉         | 216/2382 [40:43<6:33:55, 10.91s/it]                                                    {'loss': 2.2208, 'learning_rate': 0.0009904423243399774, 'epoch': 0.09}
  9%|▉         | 216/2382 [40:43<6:33:55, 10.91s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1121 > 1024). Running this sequence through the model will result in indexing errors
  9%|▉         | 217/2382 [40:54<6:35:17, 10.95s/it]                                                    {'loss': 2.087, 'learning_rate': 0.0009903095498651276, 'epoch': 0.09}
  9%|▉         | 217/2382 [40:54<6:35:17, 10.95s/it]  9%|▉         | 218/2382 [41:03<6:18:59, 10.51s/it]                                                    {'loss': 2.0964, 'learning_rate': 0.0009901758685181153, 'epoch': 0.09}
  9%|▉         | 218/2382 [41:03<6:18:59, 10.51s/it]  9%|▉         | 219/2382 [41:15<6:29:05, 10.79s/it]                                                    {'loss': 2.0585, 'learning_rate': 0.0009900412805461966, 'epoch': 0.09}
  9%|▉         | 219/2382 [41:15<6:29:05, 10.79s/it]  9%|▉         | 220/2382 [41:23<6:04:55, 10.13s/it]                                                    {'loss': 2.2149, 'learning_rate': 0.0009899057861983043, 'epoch': 0.09}
  9%|▉         | 220/2382 [41:23<6:04:55, 10.13s/it]  9%|▉         | 221/2382 [41:33<6:00:38, 10.01s/it]                                                    {'loss': 2.0664, 'learning_rate': 0.000989769385725047, 'epoch': 0.09}
  9%|▉         | 221/2382 [41:33<6:00:38, 10.01s/it]  9%|▉         | 222/2382 [41:42<5:51:14,  9.76s/it]                                                    {'loss': 1.9751, 'learning_rate': 0.0009896320793787105, 'epoch': 0.09}
  9%|▉         | 222/2382 [41:42<5:51:14,  9.76s/it]  9%|▉         | 223/2382 [41:54<6:11:10, 10.32s/it]                                                    {'loss': 2.0318, 'learning_rate': 0.000989493867413255, 'epoch': 0.09}
  9%|▉         | 223/2382 [41:54<6:11:10, 10.32s/it]  9%|▉         | 224/2382 [42:03<5:56:49,  9.92s/it]                                                    {'loss': 2.1723, 'learning_rate': 0.000989354750084316, 'epoch': 0.09}
  9%|▉         | 224/2382 [42:03<5:56:49,  9.92s/it]  9%|▉         | 225/2382 [42:12<5:46:14,  9.63s/it]                                                    {'loss': 2.1165, 'learning_rate': 0.0009892147276492039, 'epoch': 0.09}
  9%|▉         | 225/2382 [42:12<5:46:14,  9.63s/it]  9%|▉         | 226/2382 [42:24<6:06:54, 10.21s/it]                                                    {'loss': 2.1244, 'learning_rate': 0.0009890738003669028, 'epoch': 0.09}
  9%|▉         | 226/2382 [42:24<6:06:54, 10.21s/it] 10%|▉         | 227/2382 [42:34<6:11:31, 10.34s/it]                                                    {'loss': 2.0941, 'learning_rate': 0.0009889319684980706, 'epoch': 0.1}
 10%|▉         | 227/2382 [42:34<6:11:31, 10.34s/it] 10%|▉         | 228/2382 [42:45<6:20:06, 10.59s/it]                                                    {'loss': 2.1351, 'learning_rate': 0.0009887892323050384, 'epoch': 0.1}
 10%|▉         | 228/2382 [42:45<6:20:06, 10.59s/it] 10%|▉         | 229/2382 [42:56<6:25:29, 10.74s/it]                                                    {'loss': 2.0516, 'learning_rate': 0.0009886455920518095, 'epoch': 0.1}
 10%|▉         | 229/2382 [42:56<6:25:29, 10.74s/it] 10%|▉         | 230/2382 [43:08<6:30:34, 10.89s/it]                                                    {'loss': 1.9985, 'learning_rate': 0.0009885010480040598, 'epoch': 0.1}
 10%|▉         | 230/2382 [43:08<6:30:34, 10.89s/it] 10%|▉         | 231/2382 [43:21<6:53:29, 11.53s/it]                                                    {'loss': 2.1732, 'learning_rate': 0.0009883556004291368, 'epoch': 0.1}
 10%|▉         | 231/2382 [43:21<6:53:29, 11.53s/it] 10%|▉         | 232/2382 [43:32<6:47:01, 11.36s/it]                                                    {'loss': 2.1097, 'learning_rate': 0.0009882092495960588, 'epoch': 0.1}
 10%|▉         | 232/2382 [43:32<6:47:01, 11.36s/it] 10%|▉         | 233/2382 [43:44<6:53:17, 11.54s/it]                                                    {'loss': 2.0906, 'learning_rate': 0.000988061995775515, 'epoch': 0.1}
 10%|▉         | 233/2382 [43:44<6:53:17, 11.54s/it] 10%|▉         | 234/2382 [43:54<6:45:03, 11.31s/it]                                                    {'loss': 2.1316, 'learning_rate': 0.000987913839239865, 'epoch': 0.1}
 10%|▉         | 234/2382 [43:54<6:45:03, 11.31s/it] 10%|▉         | 235/2382 [44:06<6:46:04, 11.35s/it]                                                    {'loss': 2.056, 'learning_rate': 0.0009877647802631374, 'epoch': 0.1}
 10%|▉         | 235/2382 [44:06<6:46:04, 11.35s/it] 10%|▉         | 236/2382 [44:16<6:37:46, 11.12s/it]                                                    {'loss': 2.1097, 'learning_rate': 0.000987614819121031, 'epoch': 0.1}
 10%|▉         | 236/2382 [44:16<6:37:46, 11.12s/it] 10%|▉         | 237/2382 [44:26<6:18:27, 10.59s/it]                                                    {'loss': 2.0799, 'learning_rate': 0.0009874639560909118, 'epoch': 0.1}
 10%|▉         | 237/2382 [44:26<6:18:27, 10.59s/it] 10%|▉         | 238/2382 [44:37<6:21:36, 10.68s/it]                                                    {'loss': 2.0614, 'learning_rate': 0.0009873121914518153, 'epoch': 0.1}
 10%|▉         | 238/2382 [44:37<6:21:36, 10.68s/it] 10%|█         | 239/2382 [44:48<6:27:16, 10.84s/it]                                                    {'loss': 2.0898, 'learning_rate': 0.0009871595254844438, 'epoch': 0.1}
 10%|█         | 239/2382 [44:48<6:27:16, 10.84s/it] 10%|█         | 240/2382 [45:01<6:46:22, 11.38s/it]                                                    {'loss': 2.1214, 'learning_rate': 0.0009870059584711668, 'epoch': 0.1}
 10%|█         | 240/2382 [45:01<6:46:22, 11.38s/it] 10%|█         | 241/2382 [45:12<6:47:51, 11.43s/it]                                                    {'loss': 2.0531, 'learning_rate': 0.0009868514906960207, 'epoch': 0.1}
 10%|█         | 241/2382 [45:12<6:47:51, 11.43s/it] 10%|█         | 242/2382 [45:24<6:56:36, 11.68s/it]                                                    {'loss': 2.0016, 'learning_rate': 0.0009866961224447076, 'epoch': 0.1}
 10%|█         | 242/2382 [45:24<6:56:36, 11.68s/it] 10%|█         | 243/2382 [45:36<6:59:57, 11.78s/it]                                                    {'loss': 2.0528, 'learning_rate': 0.0009865398540045952, 'epoch': 0.1}
 10%|█         | 243/2382 [45:36<6:59:57, 11.78s/it] 10%|█         | 244/2382 [45:48<6:52:58, 11.59s/it]                                                    {'loss': 2.173, 'learning_rate': 0.0009863826856647163, 'epoch': 0.1}
 10%|█         | 244/2382 [45:48<6:52:58, 11.59s/it] 10%|█         | 245/2382 [45:57<6:30:47, 10.97s/it]                                                    {'loss': 2.1154, 'learning_rate': 0.000986224617715768, 'epoch': 0.1}
 10%|█         | 245/2382 [45:57<6:30:47, 10.97s/it] 10%|█         | 246/2382 [46:08<6:30:59, 10.98s/it]                                                    {'loss': 2.0286, 'learning_rate': 0.0009860656504501113, 'epoch': 0.1}
 10%|█         | 246/2382 [46:08<6:30:59, 10.98s/it] 10%|█         | 247/2382 [46:18<6:24:41, 10.81s/it]                                                    {'loss': 2.0884, 'learning_rate': 0.000985905784161771, 'epoch': 0.1}
 10%|█         | 247/2382 [46:18<6:24:41, 10.81s/it] 10%|█         | 248/2382 [46:28<6:13:55, 10.51s/it]                                                    {'loss': 2.0023, 'learning_rate': 0.0009857450191464337, 'epoch': 0.1}
 10%|█         | 248/2382 [46:28<6:13:55, 10.51s/it] 10%|█         | 249/2382 [46:43<6:55:18, 11.68s/it]                                                    {'loss': 2.0767, 'learning_rate': 0.0009855833557014496, 'epoch': 0.1}
 10%|█         | 249/2382 [46:43<6:55:18, 11.68s/it] 10%|█         | 250/2382 [46:53<6:39:44, 11.25s/it]                                                    {'loss': 2.1416, 'learning_rate': 0.0009854207941258294, 'epoch': 0.1}
 10%|█         | 250/2382 [46:53<6:39:44, 11.25s/it] 11%|█         | 251/2382 [47:05<6:50:30, 11.56s/it]                                                    {'loss': 2.0979, 'learning_rate': 0.0009852573347202461, 'epoch': 0.11}
 11%|█         | 251/2382 [47:05<6:50:30, 11.56s/it] 11%|█         | 252/2382 [47:16<6:41:57, 11.32s/it]                                                    {'loss': 2.1724, 'learning_rate': 0.0009850929777870322, 'epoch': 0.11}
 11%|█         | 252/2382 [47:16<6:41:57, 11.32s/it] 11%|█         | 253/2382 [47:27<6:38:34, 11.23s/it]                                                    {'loss': 2.0228, 'learning_rate': 0.0009849277236301812, 'epoch': 0.11}
 11%|█         | 253/2382 [47:27<6:38:34, 11.23s/it] 11%|█         | 254/2382 [47:36<6:12:16, 10.50s/it]                                                    {'loss': 2.1495, 'learning_rate': 0.0009847615725553456, 'epoch': 0.11}
 11%|█         | 254/2382 [47:36<6:12:16, 10.50s/it] 11%|█         | 255/2382 [47:48<6:32:11, 11.06s/it]                                                    {'loss': 2.1174, 'learning_rate': 0.000984594524869837, 'epoch': 0.11}
 11%|█         | 255/2382 [47:48<6:32:11, 11.06s/it] 11%|█         | 256/2382 [47:57<6:12:08, 10.50s/it]                                                    {'loss': 2.1288, 'learning_rate': 0.0009844265808826253, 'epoch': 0.11}
 11%|█         | 256/2382 [47:57<6:12:08, 10.50s/it] 11%|█         | 257/2382 [48:08<6:09:11, 10.42s/it]                                                    {'loss': 2.1134, 'learning_rate': 0.0009842577409043378, 'epoch': 0.11}
 11%|█         | 257/2382 [48:08<6:09:11, 10.42s/it] 11%|█         | 258/2382 [48:20<6:26:27, 10.92s/it]                                                    {'loss': 2.2137, 'learning_rate': 0.00098408800524726, 'epoch': 0.11}
 11%|█         | 258/2382 [48:20<6:26:27, 10.92s/it] 11%|█         | 259/2382 [48:31<6:26:45, 10.93s/it]                                                    {'loss': 2.1158, 'learning_rate': 0.0009839173742253334, 'epoch': 0.11}
 11%|█         | 259/2382 [48:31<6:26:45, 10.93s/it] 11%|█         | 260/2382 [48:40<6:14:15, 10.58s/it]                                                    {'loss': 2.1356, 'learning_rate': 0.000983745848154155, 'epoch': 0.11}
 11%|█         | 260/2382 [48:40<6:14:15, 10.58s/it] 11%|█         | 261/2382 [48:52<6:23:34, 10.85s/it]                                                    {'loss': 1.9363, 'learning_rate': 0.0009835734273509786, 'epoch': 0.11}
 11%|█         | 261/2382 [48:52<6:23:34, 10.85s/it] 11%|█         | 262/2382 [49:03<6:26:14, 10.93s/it]                                                    {'loss': 2.1287, 'learning_rate': 0.0009834001121347118, 'epoch': 0.11}
 11%|█         | 262/2382 [49:03<6:26:14, 10.93s/it] 11%|█         | 263/2382 [49:14<6:31:02, 11.07s/it]                                                    {'loss': 2.2277, 'learning_rate': 0.000983225902825917, 'epoch': 0.11}
 11%|█         | 263/2382 [49:14<6:31:02, 11.07s/it] 11%|█         | 264/2382 [49:24<6:19:37, 10.75s/it]                                                    {'loss': 2.2814, 'learning_rate': 0.00098305079974681, 'epoch': 0.11}
 11%|█         | 264/2382 [49:24<6:19:37, 10.75s/it] 11%|█         | 265/2382 [49:36<6:24:37, 10.90s/it]                                                    {'loss': 2.161, 'learning_rate': 0.0009828748032212602, 'epoch': 0.11}
 11%|█         | 265/2382 [49:36<6:24:37, 10.90s/it] 11%|█         | 266/2382 [49:45<6:10:43, 10.51s/it]                                                    {'loss': 2.0717, 'learning_rate': 0.0009826979135747892, 'epoch': 0.11}
 11%|█         | 266/2382 [49:45<6:10:43, 10.51s/it] 11%|█         | 267/2382 [49:56<6:15:27, 10.65s/it]                                                    {'loss': 2.0493, 'learning_rate': 0.00098252013113457, 'epoch': 0.11}
 11%|█         | 267/2382 [49:56<6:15:27, 10.65s/it] 11%|█▏        | 268/2382 [50:07<6:16:53, 10.70s/it]                                                    {'loss': 2.1707, 'learning_rate': 0.000982341456229428, 'epoch': 0.11}
 11%|█▏        | 268/2382 [50:07<6:16:53, 10.70s/it] 11%|█▏        | 269/2382 [50:20<6:39:50, 11.35s/it]                                                    {'loss': 2.2543, 'learning_rate': 0.0009821618891898384, 'epoch': 0.11}
 11%|█▏        | 269/2382 [50:20<6:39:50, 11.35s/it] 11%|█▏        | 270/2382 [50:30<6:28:52, 11.05s/it]                                                    {'loss': 2.2089, 'learning_rate': 0.0009819814303479266, 'epoch': 0.11}
 11%|█▏        | 270/2382 [50:30<6:28:52, 11.05s/it] 11%|█▏        | 271/2382 [50:42<6:31:09, 11.12s/it]                                                    {'loss': 2.0845, 'learning_rate': 0.0009818000800374683, 'epoch': 0.11}
 11%|█▏        | 271/2382 [50:42<6:31:09, 11.12s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1312 > 1024). Running this sequence through the model will result in indexing errors
 11%|█▏        | 272/2382 [50:52<6:25:33, 10.96s/it]                                                    {'loss': 2.0511, 'learning_rate': 0.0009816178385938868, 'epoch': 0.11}
 11%|█▏        | 272/2382 [50:52<6:25:33, 10.96s/it] 11%|█▏        | 273/2382 [51:02<6:09:39, 10.52s/it]                                                    {'loss': 2.2845, 'learning_rate': 0.0009814347063542546, 'epoch': 0.11}
 11%|█▏        | 273/2382 [51:02<6:09:39, 10.52s/it] 12%|█▏        | 274/2382 [51:11<5:57:43, 10.18s/it]                                                    {'loss': 2.1749, 'learning_rate': 0.0009812506836572913, 'epoch': 0.11}
 12%|█▏        | 274/2382 [51:11<5:57:43, 10.18s/it] 12%|█▏        | 275/2382 [51:23<6:17:51, 10.76s/it]                                                    {'loss': 2.221, 'learning_rate': 0.0009810657708433637, 'epoch': 0.12}
 12%|█▏        | 275/2382 [51:23<6:17:51, 10.76s/it] 12%|█▏        | 276/2382 [51:34<6:23:34, 10.93s/it]                                                    {'loss': 2.0448, 'learning_rate': 0.0009808799682544847, 'epoch': 0.12}
 12%|█▏        | 276/2382 [51:34<6:23:34, 10.93s/it] 12%|█▏        | 277/2382 [51:48<6:49:27, 11.67s/it]                                                    {'loss': 2.1122, 'learning_rate': 0.0009806932762343136, 'epoch': 0.12}
 12%|█▏        | 277/2382 [51:48<6:49:27, 11.67s/it] 12%|█▏        | 278/2382 [51:59<6:39:36, 11.40s/it]                                                    {'loss': 2.1929, 'learning_rate': 0.0009805056951281536, 'epoch': 0.12}
 12%|█▏        | 278/2382 [51:59<6:39:36, 11.40s/it] 12%|█▏        | 279/2382 [52:07<6:07:57, 10.50s/it]                                                    {'loss': 2.1593, 'learning_rate': 0.0009803172252829536, 'epoch': 0.12}
 12%|█▏        | 279/2382 [52:07<6:07:57, 10.50s/it] 12%|█▏        | 280/2382 [52:18<6:11:29, 10.60s/it]                                                    {'loss': 2.0772, 'learning_rate': 0.0009801278670473054, 'epoch': 0.12}
 12%|█▏        | 280/2382 [52:18<6:11:29, 10.60s/it] 12%|█▏        | 281/2382 [52:30<6:24:25, 10.98s/it]                                                    {'loss': 2.1248, 'learning_rate': 0.0009799376207714446, 'epoch': 0.12}
 12%|█▏        | 281/2382 [52:30<6:24:25, 10.98s/it] 12%|█▏        | 282/2382 [52:41<6:32:38, 11.22s/it]                                                    {'loss': 2.1149, 'learning_rate': 0.0009797464868072487, 'epoch': 0.12}
 12%|█▏        | 282/2382 [52:41<6:32:38, 11.22s/it] 12%|█▏        | 283/2382 [52:51<6:15:42, 10.74s/it]                                                    {'loss': 2.1319, 'learning_rate': 0.0009795544655082375, 'epoch': 0.12}
 12%|█▏        | 283/2382 [52:51<6:15:42, 10.74s/it] 12%|█▏        | 284/2382 [53:02<6:18:40, 10.83s/it]                                                    {'loss': 2.1634, 'learning_rate': 0.0009793615572295722, 'epoch': 0.12}
 12%|█▏        | 284/2382 [53:02<6:18:40, 10.83s/it] 12%|█▏        | 285/2382 [53:12<6:08:54, 10.56s/it]                                                    {'loss': 2.1497, 'learning_rate': 0.0009791677623280537, 'epoch': 0.12}
 12%|█▏        | 285/2382 [53:12<6:08:54, 10.56s/it] 12%|█▏        | 286/2382 [53:22<5:59:22, 10.29s/it]                                                    {'loss': 2.1286, 'learning_rate': 0.0009789730811621236, 'epoch': 0.12}
 12%|█▏        | 286/2382 [53:22<5:59:22, 10.29s/it] 12%|█▏        | 287/2382 [53:33<6:07:40, 10.53s/it]                                                    {'loss': 2.0887, 'learning_rate': 0.0009787775140918623, 'epoch': 0.12}
 12%|█▏        | 287/2382 [53:33<6:07:40, 10.53s/it] 12%|█▏        | 288/2382 [53:46<6:40:28, 11.47s/it]                                                    {'loss': 1.9992, 'learning_rate': 0.000978581061478989, 'epoch': 0.12}
 12%|█▏        | 288/2382 [53:46<6:40:28, 11.47s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1054 > 1024). Running this sequence through the model will result in indexing errors
 12%|█▏        | 289/2382 [53:55<6:10:37, 10.62s/it]                                                    {'loss': 2.1562, 'learning_rate': 0.0009783837236868609, 'epoch': 0.12}
 12%|█▏        | 289/2382 [53:55<6:10:37, 10.62s/it] 12%|█▏        | 290/2382 [54:06<6:08:25, 10.57s/it]                                                    {'loss': 2.0649, 'learning_rate': 0.000978185501080472, 'epoch': 0.12}
 12%|█▏        | 290/2382 [54:06<6:08:25, 10.57s/it] 12%|█▏        | 291/2382 [54:14<5:40:54,  9.78s/it]                                                    {'loss': 2.3045, 'learning_rate': 0.0009779863940264529, 'epoch': 0.12}
 12%|█▏        | 291/2382 [54:14<5:40:54,  9.78s/it] 12%|█▏        | 292/2382 [54:25<6:02:07, 10.40s/it]                                                    {'loss': 2.1984, 'learning_rate': 0.0009777864028930705, 'epoch': 0.12}
 12%|█▏        | 292/2382 [54:25<6:02:07, 10.40s/it] 12%|█▏        | 293/2382 [54:35<5:56:14, 10.23s/it]                                                    {'loss': 2.1205, 'learning_rate': 0.0009775855280502264, 'epoch': 0.12}
 12%|█▏        | 293/2382 [54:35<5:56:14, 10.23s/it] 12%|█▏        | 294/2382 [54:48<6:26:09, 11.10s/it]                                                    {'loss': 2.0836, 'learning_rate': 0.000977383769869457, 'epoch': 0.12}
 12%|█▏        | 294/2382 [54:48<6:26:09, 11.10s/it] 12%|█▏        | 295/2382 [55:02<6:48:48, 11.75s/it]                                                    {'loss': 2.1504, 'learning_rate': 0.0009771811287239327, 'epoch': 0.12}
 12%|█▏        | 295/2382 [55:02<6:48:48, 11.75s/it] 12%|█▏        | 296/2382 [55:12<6:33:26, 11.32s/it]                                                    {'loss': 2.1112, 'learning_rate': 0.0009769776049884564, 'epoch': 0.12}
 12%|█▏        | 296/2382 [55:12<6:33:26, 11.32s/it] 12%|█▏        | 297/2382 [55:24<6:45:47, 11.68s/it]                                                    {'loss': 2.1081, 'learning_rate': 0.0009767731990394637, 'epoch': 0.12}
 12%|█▏        | 297/2382 [55:24<6:45:47, 11.68s/it] 13%|█▎        | 298/2382 [55:35<6:39:12, 11.49s/it]                                                    {'loss': 2.0081, 'learning_rate': 0.0009765679112550226, 'epoch': 0.13}
 13%|█▎        | 298/2382 [55:35<6:39:12, 11.49s/it] 13%|█▎        | 299/2382 [55:47<6:42:17, 11.59s/it]                                                    {'loss': 1.9732, 'learning_rate': 0.000976361742014831, 'epoch': 0.13}
 13%|█▎        | 299/2382 [55:47<6:42:17, 11.59s/it] 13%|█▎        | 300/2382 [55:58<6:31:10, 11.27s/it]                                                    {'loss': 2.0659, 'learning_rate': 0.0009761546917002177, 'epoch': 0.13}
 13%|█▎        | 300/2382 [55:58<6:31:10, 11.27s/it] 13%|█▎        | 301/2382 [56:08<6:20:24, 10.97s/it]                                                    {'loss': 1.9977, 'learning_rate': 0.0009759467606941414, 'epoch': 0.13}
 13%|█▎        | 301/2382 [56:08<6:20:24, 10.97s/it] 13%|█▎        | 302/2382 [56:17<6:00:44, 10.41s/it]                                                    {'loss': 2.1708, 'learning_rate': 0.0009757379493811892, 'epoch': 0.13}
 13%|█▎        | 302/2382 [56:17<6:00:44, 10.41s/it] 13%|█▎        | 303/2382 [56:27<5:57:00, 10.30s/it]                                                    {'loss': 2.1986, 'learning_rate': 0.0009755282581475768, 'epoch': 0.13}
 13%|█▎        | 303/2382 [56:27<5:57:00, 10.30s/it] 13%|█▎        | 304/2382 [56:37<5:54:50, 10.25s/it]                                                    {'loss': 2.0699, 'learning_rate': 0.0009753176873811471, 'epoch': 0.13}
 13%|█▎        | 304/2382 [56:37<5:54:50, 10.25s/it] 13%|█▎        | 305/2382 [56:50<6:19:32, 10.96s/it]                                                    {'loss': 2.0996, 'learning_rate': 0.00097510623747137, 'epoch': 0.13}
 13%|█▎        | 305/2382 [56:50<6:19:32, 10.96s/it] 13%|█▎        | 306/2382 [57:01<6:15:49, 10.86s/it]                                                    {'loss': 2.1671, 'learning_rate': 0.0009748939088093414, 'epoch': 0.13}
 13%|█▎        | 306/2382 [57:01<6:15:49, 10.86s/it] 13%|█▎        | 307/2382 [57:12<6:23:54, 11.10s/it]                                                    {'loss': 2.1899, 'learning_rate': 0.0009746807017877823, 'epoch': 0.13}
 13%|█▎        | 307/2382 [57:12<6:23:54, 11.10s/it] 13%|█▎        | 308/2382 [57:23<6:15:03, 10.85s/it]                                                    {'loss': 2.0816, 'learning_rate': 0.0009744666168010387, 'epoch': 0.13}
 13%|█▎        | 308/2382 [57:23<6:15:03, 10.85s/it] 13%|█▎        | 309/2382 [57:32<5:57:35, 10.35s/it]                                                    {'loss': 2.0726, 'learning_rate': 0.0009742516542450803, 'epoch': 0.13}
 13%|█▎        | 309/2382 [57:32<5:57:35, 10.35s/it] 13%|█▎        | 310/2382 [57:41<5:49:01, 10.11s/it]                                                    {'loss': 2.1263, 'learning_rate': 0.0009740358145174998, 'epoch': 0.13}
 13%|█▎        | 310/2382 [57:41<5:49:01, 10.11s/it] 13%|█▎        | 311/2382 [57:52<5:59:14, 10.41s/it]                                                    {'loss': 2.0807, 'learning_rate': 0.0009738190980175123, 'epoch': 0.13}
 13%|█▎        | 311/2382 [57:52<5:59:14, 10.41s/it] 13%|█▎        | 312/2382 [58:02<5:48:24, 10.10s/it]                                                    {'loss': 2.1275, 'learning_rate': 0.0009736015051459551, 'epoch': 0.13}
 13%|█▎        | 312/2382 [58:02<5:48:24, 10.10s/it] 13%|█▎        | 313/2382 [58:14<6:06:05, 10.62s/it]                                                    {'loss': 2.1491, 'learning_rate': 0.0009733830363052856, 'epoch': 0.13}
 13%|█▎        | 313/2382 [58:14<6:06:05, 10.62s/it] 13%|█▎        | 314/2382 [58:27<6:29:48, 11.31s/it]                                                    {'loss': 2.1016, 'learning_rate': 0.0009731636918995821, 'epoch': 0.13}
 13%|█▎        | 314/2382 [58:27<6:29:48, 11.31s/it] 13%|█▎        | 315/2382 [58:37<6:25:34, 11.19s/it]                                                    {'loss': 2.0744, 'learning_rate': 0.0009729434723345419, 'epoch': 0.13}
 13%|█▎        | 315/2382 [58:37<6:25:34, 11.19s/it] 13%|█▎        | 316/2382 [58:48<6:17:56, 10.98s/it]                                                    {'loss': 2.1111, 'learning_rate': 0.0009727223780174813, 'epoch': 0.13}
 13%|█▎        | 316/2382 [58:48<6:17:56, 10.98s/it] 13%|█▎        | 317/2382 [58:59<6:19:24, 11.02s/it]                                                    {'loss': 2.014, 'learning_rate': 0.0009725004093573342, 'epoch': 0.13}
 13%|█▎        | 317/2382 [58:59<6:19:24, 11.02s/it] 13%|█▎        | 318/2382 [59:09<6:10:25, 10.77s/it]                                                    {'loss': 2.0829, 'learning_rate': 0.0009722775667646519, 'epoch': 0.13}
 13%|█▎        | 318/2382 [59:09<6:10:25, 10.77s/it] 13%|█▎        | 319/2382 [59:21<6:23:26, 11.15s/it]                                                    {'loss': 2.1025, 'learning_rate': 0.0009720538506516024, 'epoch': 0.13}
 13%|█▎        | 319/2382 [59:21<6:23:26, 11.15s/it] 13%|█▎        | 320/2382 [59:32<6:15:17, 10.92s/it]                                                    {'loss': 2.0957, 'learning_rate': 0.0009718292614319684, 'epoch': 0.13}
 13%|█▎        | 320/2382 [59:32<6:15:17, 10.92s/it] 13%|█▎        | 321/2382 [59:42<6:05:27, 10.64s/it]                                                    {'loss': 2.1362, 'learning_rate': 0.0009716037995211484, 'epoch': 0.13}
 13%|█▎        | 321/2382 [59:42<6:05:27, 10.64s/it] 14%|█▎        | 322/2382 [59:54<6:25:02, 11.21s/it]                                                    {'loss': 2.0751, 'learning_rate': 0.0009713774653361549, 'epoch': 0.14}
 14%|█▎        | 322/2382 [59:54<6:25:02, 11.21s/it] 14%|█▎        | 323/2382 [1:00:05<6:18:09, 11.02s/it]                                                      {'loss': 2.1002, 'learning_rate': 0.0009711502592956135, 'epoch': 0.14}
 14%|█▎        | 323/2382 [1:00:05<6:18:09, 11.02s/it] 14%|█▎        | 324/2382 [1:00:15<6:12:34, 10.86s/it]                                                      {'loss': 2.1179, 'learning_rate': 0.0009709221818197624, 'epoch': 0.14}
 14%|█▎        | 324/2382 [1:00:15<6:12:34, 10.86s/it] 14%|█▎        | 325/2382 [1:00:24<5:50:24, 10.22s/it]                                                      {'loss': 2.0838, 'learning_rate': 0.0009706932333304517, 'epoch': 0.14}
 14%|█▎        | 325/2382 [1:00:24<5:50:24, 10.22s/it] 14%|█▎        | 326/2382 [1:00:35<5:59:54, 10.50s/it]                                                      {'loss': 2.0134, 'learning_rate': 0.0009704634142511424, 'epoch': 0.14}
 14%|█▎        | 326/2382 [1:00:35<5:59:54, 10.50s/it] 14%|█▎        | 327/2382 [1:00:51<6:50:23, 11.98s/it]                                                      {'loss': 2.0621, 'learning_rate': 0.0009702327250069059, 'epoch': 0.14}
 14%|█▎        | 327/2382 [1:00:51<6:50:23, 11.98s/it] 14%|█▍        | 328/2382 [1:01:04<7:02:58, 12.36s/it]                                                      {'loss': 2.1285, 'learning_rate': 0.0009700011660244228, 'epoch': 0.14}
 14%|█▍        | 328/2382 [1:01:04<7:02:58, 12.36s/it] 14%|█▍        | 329/2382 [1:01:18<7:17:55, 12.80s/it]                                                      {'loss': 2.0362, 'learning_rate': 0.0009697687377319828, 'epoch': 0.14}
 14%|█▍        | 329/2382 [1:01:18<7:17:55, 12.80s/it] 14%|█▍        | 330/2382 [1:01:28<6:56:45, 12.19s/it]                                                      {'loss': 2.0482, 'learning_rate': 0.000969535440559483, 'epoch': 0.14}
 14%|█▍        | 330/2382 [1:01:28<6:56:45, 12.19s/it] 14%|█▍        | 331/2382 [1:01:41<7:04:10, 12.41s/it]                                                      {'loss': 2.0284, 'learning_rate': 0.0009693012749384279, 'epoch': 0.14}
 14%|█▍        | 331/2382 [1:01:41<7:04:10, 12.41s/it] 14%|█▍        | 332/2382 [1:01:52<6:42:53, 11.79s/it]                                                      {'loss': 2.0524, 'learning_rate': 0.000969066241301928, 'epoch': 0.14}
 14%|█▍        | 332/2382 [1:01:52<6:42:53, 11.79s/it] 14%|█▍        | 333/2382 [1:02:03<6:38:18, 11.66s/it]                                                      {'loss': 2.063, 'learning_rate': 0.0009688303400846995, 'epoch': 0.14}
 14%|█▍        | 333/2382 [1:02:03<6:38:18, 11.66s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 1024). Running this sequence through the model will result in indexing errors
 14%|█▍        | 334/2382 [1:02:14<6:35:24, 11.58s/it]                                                      {'loss': 2.0567, 'learning_rate': 0.0009685935717230632, 'epoch': 0.14}
 14%|█▍        | 334/2382 [1:02:14<6:35:24, 11.58s/it] 14%|█▍        | 335/2382 [1:02:27<6:41:05, 11.76s/it]                                                      {'loss': 2.1119, 'learning_rate': 0.0009683559366549437, 'epoch': 0.14}
 14%|█▍        | 335/2382 [1:02:27<6:41:05, 11.76s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1591 > 1024). Running this sequence through the model will result in indexing errors
 14%|█▍        | 336/2382 [1:02:38<6:38:36, 11.69s/it]                                                      {'loss': 2.1395, 'learning_rate': 0.0009681174353198686, 'epoch': 0.14}
 14%|█▍        | 336/2382 [1:02:38<6:38:36, 11.69s/it] 14%|█▍        | 337/2382 [1:02:48<6:22:26, 11.22s/it]                                                      {'loss': 2.0889, 'learning_rate': 0.0009678780681589681, 'epoch': 0.14}
 14%|█▍        | 337/2382 [1:02:48<6:22:26, 11.22s/it] 14%|█▍        | 338/2382 [1:03:02<6:49:16, 12.01s/it]                                                      {'loss': 2.0952, 'learning_rate': 0.0009676378356149733, 'epoch': 0.14}
 14%|█▍        | 338/2382 [1:03:02<6:49:16, 12.01s/it] 14%|█▍        | 339/2382 [1:03:13<6:38:56, 11.72s/it]                                                      {'loss': 1.9584, 'learning_rate': 0.0009673967381322163, 'epoch': 0.14}
 14%|█▍        | 339/2382 [1:03:13<6:38:56, 11.72s/it] 14%|█▍        | 340/2382 [1:03:23<6:15:40, 11.04s/it]                                                      {'loss': 2.3053, 'learning_rate': 0.0009671547761566288, 'epoch': 0.14}
 14%|█▍        | 340/2382 [1:03:23<6:15:40, 11.04s/it] 14%|█▍        | 341/2382 [1:03:32<5:59:32, 10.57s/it]                                                      {'loss': 2.2548, 'learning_rate': 0.0009669119501357416, 'epoch': 0.14}
 14%|█▍        | 341/2382 [1:03:32<5:59:32, 10.57s/it] 14%|█▍        | 342/2382 [1:03:40<5:32:07,  9.77s/it]                                                      {'loss': 2.1986, 'learning_rate': 0.0009666682605186834, 'epoch': 0.14}
 14%|█▍        | 342/2382 [1:03:40<5:32:07,  9.77s/it] 14%|█▍        | 343/2382 [1:03:51<5:46:55, 10.21s/it]                                                      {'loss': 2.048, 'learning_rate': 0.0009664237077561804, 'epoch': 0.14}
 14%|█▍        | 343/2382 [1:03:51<5:46:55, 10.21s/it] 14%|█▍        | 344/2382 [1:04:03<5:59:51, 10.59s/it]                                                      {'loss': 2.1062, 'learning_rate': 0.0009661782923005553, 'epoch': 0.14}
 14%|█▍        | 344/2382 [1:04:03<5:59:51, 10.59s/it] 14%|█▍        | 345/2382 [1:04:13<5:55:51, 10.48s/it]                                                      {'loss': 2.2011, 'learning_rate': 0.0009659320146057262, 'epoch': 0.14}
 14%|█▍        | 345/2382 [1:04:13<5:55:51, 10.48s/it] 15%|█▍        | 346/2382 [1:04:21<5:30:42,  9.75s/it]                                                      {'loss': 2.223, 'learning_rate': 0.0009656848751272061, 'epoch': 0.15}
 15%|█▍        | 346/2382 [1:04:21<5:30:42,  9.75s/it] 15%|█▍        | 347/2382 [1:04:33<5:53:50, 10.43s/it]                                                      {'loss': 2.157, 'learning_rate': 0.0009654368743221021, 'epoch': 0.15}
 15%|█▍        | 347/2382 [1:04:33<5:53:50, 10.43s/it] 15%|█▍        | 348/2382 [1:04:43<5:54:11, 10.45s/it]                                                      {'loss': 2.1717, 'learning_rate': 0.0009651880126491142, 'epoch': 0.15}
 15%|█▍        | 348/2382 [1:04:43<5:54:11, 10.45s/it] 15%|█▍        | 349/2382 [1:04:54<5:56:13, 10.51s/it]                                                      {'loss': 2.0695, 'learning_rate': 0.0009649382905685349, 'epoch': 0.15}
 15%|█▍        | 349/2382 [1:04:54<5:56:13, 10.51s/it] 15%|█▍        | 350/2382 [1:05:07<6:19:49, 11.22s/it]                                                      {'loss': 2.1063, 'learning_rate': 0.0009646877085422476, 'epoch': 0.15}
 15%|█▍        | 350/2382 [1:05:07<6:19:49, 11.22s/it] 15%|█▍        | 351/2382 [1:05:18<6:14:08, 11.05s/it]                                                      {'loss': 2.1591, 'learning_rate': 0.0009644362670337268, 'epoch': 0.15}
 15%|█▍        | 351/2382 [1:05:18<6:14:08, 11.05s/it] 15%|█▍        | 352/2382 [1:05:30<6:32:22, 11.60s/it]                                                      {'loss': 2.1733, 'learning_rate': 0.0009641839665080363, 'epoch': 0.15}
 15%|█▍        | 352/2382 [1:05:31<6:32:22, 11.60s/it] 15%|█▍        | 353/2382 [1:05:42<6:31:31, 11.58s/it]                                                      {'loss': 2.2232, 'learning_rate': 0.0009639308074318292, 'epoch': 0.15}
 15%|█▍        | 353/2382 [1:05:42<6:31:31, 11.58s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1065 > 1024). Running this sequence through the model will result in indexing errors
 15%|█▍        | 354/2382 [1:05:53<6:26:42, 11.44s/it]                                                      {'loss': 2.1146, 'learning_rate': 0.0009636767902733459, 'epoch': 0.15}
 15%|█▍        | 354/2382 [1:05:53<6:26:42, 11.44s/it] 15%|█▍        | 355/2382 [1:06:04<6:25:12, 11.40s/it]                                                      {'loss': 2.0789, 'learning_rate': 0.0009634219155024146, 'epoch': 0.15}
 15%|█▍        | 355/2382 [1:06:04<6:25:12, 11.40s/it] 15%|█▍        | 356/2382 [1:06:15<6:13:45, 11.07s/it]                                                      {'loss': 2.1279, 'learning_rate': 0.000963166183590449, 'epoch': 0.15}
 15%|█▍        | 356/2382 [1:06:15<6:13:45, 11.07s/it] 15%|█▍        | 357/2382 [1:06:27<6:28:39, 11.52s/it]                                                      {'loss': 1.9617, 'learning_rate': 0.0009629095950104491, 'epoch': 0.15}
 15%|█▍        | 357/2382 [1:06:27<6:28:39, 11.52s/it] 15%|█▌        | 358/2382 [1:06:37<6:11:17, 11.01s/it]                                                      {'loss': 2.1669, 'learning_rate': 0.0009626521502369983, 'epoch': 0.15}
 15%|█▌        | 358/2382 [1:06:37<6:11:17, 11.01s/it] 15%|█▌        | 359/2382 [1:06:46<5:53:52, 10.50s/it]                                                      {'loss': 2.0504, 'learning_rate': 0.0009623938497462645, 'epoch': 0.15}
 15%|█▌        | 359/2382 [1:06:46<5:53:52, 10.50s/it] 15%|█▌        | 360/2382 [1:06:58<6:06:57, 10.89s/it]                                                      {'loss': 2.1893, 'learning_rate': 0.0009621346940159981, 'epoch': 0.15}
 15%|█▌        | 360/2382 [1:06:58<6:06:57, 10.89s/it] 15%|█▌        | 361/2382 [1:07:08<5:56:06, 10.57s/it]                                                      {'loss': 1.9965, 'learning_rate': 0.0009618746835255307, 'epoch': 0.15}
 15%|█▌        | 361/2382 [1:07:08<5:56:06, 10.57s/it] 15%|█▌        | 362/2382 [1:07:24<6:45:07, 12.03s/it]                                                      {'loss': 1.9715, 'learning_rate': 0.0009616138187557757, 'epoch': 0.15}
 15%|█▌        | 362/2382 [1:07:24<6:45:07, 12.03s/it] 15%|█▌        | 363/2382 [1:07:33<6:20:24, 11.30s/it]                                                      {'loss': 2.067, 'learning_rate': 0.0009613521001892263, 'epoch': 0.15}
 15%|█▌        | 363/2382 [1:07:33<6:20:24, 11.30s/it] 15%|█▌        | 364/2382 [1:07:45<6:25:23, 11.46s/it]                                                      {'loss': 2.0434, 'learning_rate': 0.0009610895283099547, 'epoch': 0.15}
 15%|█▌        | 364/2382 [1:07:45<6:25:23, 11.46s/it] 15%|█▌        | 365/2382 [1:07:54<5:56:52, 10.62s/it]                                                      {'loss': 2.1192, 'learning_rate': 0.0009608261036036117, 'epoch': 0.15}
 15%|█▌        | 365/2382 [1:07:54<5:56:52, 10.62s/it] 15%|█▌        | 366/2382 [1:08:07<6:22:17, 11.38s/it]                                                      {'loss': 2.0155, 'learning_rate': 0.0009605618265574251, 'epoch': 0.15}
 15%|█▌        | 366/2382 [1:08:07<6:22:17, 11.38s/it] 15%|█▌        | 367/2382 [1:08:16<6:03:29, 10.82s/it]                                                      {'loss': 2.0334, 'learning_rate': 0.0009602966976601994, 'epoch': 0.15}
 15%|█▌        | 367/2382 [1:08:16<6:03:29, 10.82s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 1024). Running this sequence through the model will result in indexing errors
 15%|█▌        | 368/2382 [1:08:27<6:06:28, 10.92s/it]                                                      {'loss': 2.186, 'learning_rate': 0.0009600307174023145, 'epoch': 0.15}
 15%|█▌        | 368/2382 [1:08:27<6:06:28, 10.92s/it] 15%|█▌        | 369/2382 [1:08:38<5:58:03, 10.67s/it]                                                      {'loss': 1.9335, 'learning_rate': 0.0009597638862757254, 'epoch': 0.15}
 15%|█▌        | 369/2382 [1:08:38<5:58:03, 10.67s/it] 16%|█▌        | 370/2382 [1:08:50<6:20:46, 11.36s/it]                                                      {'loss': 2.0176, 'learning_rate': 0.0009594962047739603, 'epoch': 0.16}
 16%|█▌        | 370/2382 [1:08:50<6:20:46, 11.36s/it] 16%|█▌        | 371/2382 [1:09:01<6:14:35, 11.18s/it]                                                      {'loss': 2.0432, 'learning_rate': 0.0009592276733921206, 'epoch': 0.16}
 16%|█▌        | 371/2382 [1:09:01<6:14:35, 11.18s/it] 16%|█▌        | 372/2382 [1:09:12<6:06:40, 10.95s/it]                                                      {'loss': 2.0617, 'learning_rate': 0.0009589582926268797, 'epoch': 0.16}
 16%|█▌        | 372/2382 [1:09:12<6:06:40, 10.95s/it] 16%|█▌        | 373/2382 [1:09:21<5:47:20, 10.37s/it]                                                      {'loss': 2.0192, 'learning_rate': 0.0009586880629764817, 'epoch': 0.16}
 16%|█▌        | 373/2382 [1:09:21<5:47:20, 10.37s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1063 > 1024). Running this sequence through the model will result in indexing errors
 16%|█▌        | 374/2382 [1:09:31<5:51:09, 10.49s/it]                                                      {'loss': 2.1565, 'learning_rate': 0.000958416984940741, 'epoch': 0.16}
 16%|█▌        | 374/2382 [1:09:31<5:51:09, 10.49s/it] 16%|█▌        | 375/2382 [1:09:42<5:54:02, 10.58s/it]                                                      {'loss': 2.117, 'learning_rate': 0.000958145059021041, 'epoch': 0.16}
 16%|█▌        | 375/2382 [1:09:42<5:54:02, 10.58s/it] 16%|█▌        | 376/2382 [1:09:52<5:42:30, 10.24s/it]                                                      {'loss': 2.257, 'learning_rate': 0.0009578722857203336, 'epoch': 0.16}
 16%|█▌        | 376/2382 [1:09:52<5:42:30, 10.24s/it] 16%|█▌        | 377/2382 [1:10:03<5:49:13, 10.45s/it]                                                      {'loss': 2.1411, 'learning_rate': 0.0009575986655431377, 'epoch': 0.16}
 16%|█▌        | 377/2382 [1:10:03<5:49:13, 10.45s/it] 16%|█▌        | 378/2382 [1:10:13<5:47:43, 10.41s/it]                                                      {'loss': 2.2132, 'learning_rate': 0.000957324198995539, 'epoch': 0.16}
 16%|█▌        | 378/2382 [1:10:13<5:47:43, 10.41s/it] 16%|█▌        | 379/2382 [1:10:24<5:52:40, 10.56s/it]                                                      {'loss': 2.0836, 'learning_rate': 0.000957048886585188, 'epoch': 0.16}
 16%|█▌        | 379/2382 [1:10:24<5:52:40, 10.56s/it] 16%|█▌        | 380/2382 [1:10:36<6:07:37, 11.02s/it]                                                      {'loss': 2.0568, 'learning_rate': 0.0009567727288213005, 'epoch': 0.16}
 16%|█▌        | 380/2382 [1:10:36<6:07:37, 11.02s/it] 16%|█▌        | 381/2382 [1:10:46<5:56:43, 10.70s/it]                                                      {'loss': 2.0579, 'learning_rate': 0.0009564957262146551, 'epoch': 0.16}
 16%|█▌        | 381/2382 [1:10:46<5:56:43, 10.70s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1440 > 1024). Running this sequence through the model will result in indexing errors
 16%|█▌        | 382/2382 [1:10:54<5:33:50, 10.02s/it]                                                      {'loss': 2.17, 'learning_rate': 0.0009562178792775935, 'epoch': 0.16}
 16%|█▌        | 382/2382 [1:10:54<5:33:50, 10.02s/it] 16%|█▌        | 383/2382 [1:11:06<5:45:52, 10.38s/it]                                                      {'loss': 2.1592, 'learning_rate': 0.0009559391885240188, 'epoch': 0.16}
 16%|█▌        | 383/2382 [1:11:06<5:45:52, 10.38s/it] 16%|█▌        | 384/2382 [1:11:22<6:43:18, 12.11s/it]                                                      {'loss': 1.9492, 'learning_rate': 0.0009556596544693951, 'epoch': 0.16}
 16%|█▌        | 384/2382 [1:11:22<6:43:18, 12.11s/it] 16%|█▌        | 385/2382 [1:11:31<6:17:11, 11.33s/it]                                                      {'loss': 2.0963, 'learning_rate': 0.000955379277630746, 'epoch': 0.16}
 16%|█▌        | 385/2382 [1:11:31<6:17:11, 11.33s/it] 16%|█▌        | 386/2382 [1:11:42<6:07:27, 11.05s/it]                                                      {'loss': 2.136, 'learning_rate': 0.0009550980585266537, 'epoch': 0.16}
 16%|█▌        | 386/2382 [1:11:42<6:07:27, 11.05s/it] 16%|█▌        | 387/2382 [1:11:53<6:07:29, 11.05s/it]                                                      {'loss': 2.0313, 'learning_rate': 0.0009548159976772592, 'epoch': 0.16}
 16%|█▌        | 387/2382 [1:11:53<6:07:29, 11.05s/it] 16%|█▋        | 388/2382 [1:12:01<5:39:27, 10.21s/it]                                                      {'loss': 2.1191, 'learning_rate': 0.0009545330956042592, 'epoch': 0.16}
 16%|█▋        | 388/2382 [1:12:01<5:39:27, 10.21s/it] 16%|█▋        | 389/2382 [1:12:12<5:49:15, 10.51s/it]                                                      {'loss': 2.0497, 'learning_rate': 0.0009542493528309071, 'epoch': 0.16}
 16%|█▋        | 389/2382 [1:12:12<5:49:15, 10.51s/it] 16%|█▋        | 390/2382 [1:12:23<5:54:55, 10.69s/it]                                                      {'loss': 1.9884, 'learning_rate': 0.0009539647698820108, 'epoch': 0.16}
 16%|█▋        | 390/2382 [1:12:23<5:54:55, 10.69s/it] 16%|█▋        | 391/2382 [1:12:37<6:26:02, 11.63s/it]                                                      {'loss': 2.0916, 'learning_rate': 0.0009536793472839324, 'epoch': 0.16}
 16%|█▋        | 391/2382 [1:12:37<6:26:02, 11.63s/it] 16%|█▋        | 392/2382 [1:12:49<6:29:02, 11.73s/it]                                                      {'loss': 2.163, 'learning_rate': 0.0009533930855645872, 'epoch': 0.16}
 16%|█▋        | 392/2382 [1:12:49<6:29:02, 11.73s/it] 16%|█▋        | 393/2382 [1:13:01<6:27:30, 11.69s/it]                                                      {'loss': 2.0287, 'learning_rate': 0.0009531059852534422, 'epoch': 0.16}
 16%|█▋        | 393/2382 [1:13:01<6:27:30, 11.69s/it] 17%|█▋        | 394/2382 [1:13:11<6:19:05, 11.44s/it]                                                      {'loss': 1.9791, 'learning_rate': 0.0009528180468815154, 'epoch': 0.17}
 17%|█▋        | 394/2382 [1:13:11<6:19:05, 11.44s/it] 17%|█▋        | 395/2382 [1:13:22<6:04:53, 11.02s/it]                                                      {'loss': 2.1767, 'learning_rate': 0.0009525292709813753, 'epoch': 0.17}
 17%|█▋        | 395/2382 [1:13:22<6:04:53, 11.02s/it] 17%|█▋        | 396/2382 [1:13:34<6:15:17, 11.34s/it]                                                      {'loss': 2.133, 'learning_rate': 0.000952239658087139, 'epoch': 0.17}
 17%|█▋        | 396/2382 [1:13:34<6:15:17, 11.34s/it] 17%|█▋        | 397/2382 [1:13:45<6:18:37, 11.44s/it]                                                      {'loss': 2.0478, 'learning_rate': 0.0009519492087344723, 'epoch': 0.17}
 17%|█▋        | 397/2382 [1:13:45<6:18:37, 11.44s/it] 17%|█▋        | 398/2382 [1:13:56<6:08:36, 11.15s/it]                                                      {'loss': 2.1921, 'learning_rate': 0.0009516579234605874, 'epoch': 0.17}
 17%|█▋        | 398/2382 [1:13:56<6:08:36, 11.15s/it] 17%|█▋        | 399/2382 [1:14:05<5:52:28, 10.66s/it]                                                      {'loss': 2.1258, 'learning_rate': 0.0009513658028042429, 'epoch': 0.17}
 17%|█▋        | 399/2382 [1:14:05<5:52:28, 10.66s/it] 17%|█▋        | 400/2382 [1:14:16<5:50:32, 10.61s/it]                                                      {'loss': 2.0506, 'learning_rate': 0.0009510728473057426, 'epoch': 0.17}
 17%|█▋        | 400/2382 [1:14:16<5:50:32, 10.61s/it] 17%|█▋        | 401/2382 [1:14:26<5:48:21, 10.55s/it]                                                      {'loss': 2.1176, 'learning_rate': 0.0009507790575069346, 'epoch': 0.17}
 17%|█▋        | 401/2382 [1:14:26<5:48:21, 10.55s/it] 17%|█▋        | 402/2382 [1:14:36<5:45:23, 10.47s/it]                                                      {'loss': 2.1126, 'learning_rate': 0.0009504844339512095, 'epoch': 0.17}
 17%|█▋        | 402/2382 [1:14:36<5:45:23, 10.47s/it] 17%|█▋        | 403/2382 [1:14:47<5:46:17, 10.50s/it]                                                      {'loss': 2.1118, 'learning_rate': 0.0009501889771835008, 'epoch': 0.17}
 17%|█▋        | 403/2382 [1:14:47<5:46:17, 10.50s/it] 17%|█▋        | 404/2382 [1:14:59<6:03:17, 11.02s/it]                                                      {'loss': 2.0233, 'learning_rate': 0.0009498926877502824, 'epoch': 0.17}
 17%|█▋        | 404/2382 [1:14:59<6:03:17, 11.02s/it] 17%|█▋        | 405/2382 [1:15:10<6:04:50, 11.07s/it]                                                      {'loss': 2.1213, 'learning_rate': 0.000949595566199569, 'epoch': 0.17}
 17%|█▋        | 405/2382 [1:15:10<6:04:50, 11.07s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1196 > 1024). Running this sequence through the model will result in indexing errors
 17%|█▋        | 406/2382 [1:15:23<6:14:38, 11.38s/it]                                                      {'loss': 2.1323, 'learning_rate': 0.0009492976130809134, 'epoch': 0.17}
 17%|█▋        | 406/2382 [1:15:23<6:14:38, 11.38s/it] 17%|█▋        | 407/2382 [1:15:33<6:04:56, 11.09s/it]                                                      {'loss': 2.0275, 'learning_rate': 0.0009489988289454073, 'epoch': 0.17}
 17%|█▋        | 407/2382 [1:15:33<6:04:56, 11.09s/it] 17%|█▋        | 408/2382 [1:15:43<5:56:52, 10.85s/it]                                                      {'loss': 2.154, 'learning_rate': 0.0009486992143456792, 'epoch': 0.17}
 17%|█▋        | 408/2382 [1:15:43<5:56:52, 10.85s/it] 17%|█▋        | 409/2382 [1:15:53<5:47:30, 10.57s/it]                                                      {'loss': 2.069, 'learning_rate': 0.0009483987698358935, 'epoch': 0.17}
 17%|█▋        | 409/2382 [1:15:53<5:47:30, 10.57s/it] 17%|█▋        | 410/2382 [1:16:05<5:55:26, 10.81s/it]                                                      {'loss': 2.0053, 'learning_rate': 0.0009480974959717498, 'epoch': 0.17}
 17%|█▋        | 410/2382 [1:16:05<5:55:26, 10.81s/it] 17%|█▋        | 411/2382 [1:16:16<5:58:10, 10.90s/it]                                                      {'loss': 2.1587, 'learning_rate': 0.0009477953933104815, 'epoch': 0.17}
 17%|█▋        | 411/2382 [1:16:16<5:58:10, 10.90s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1042 > 1024). Running this sequence through the model will result in indexing errors
 17%|█▋        | 412/2382 [1:16:27<6:04:15, 11.09s/it]                                                      {'loss': 2.2322, 'learning_rate': 0.0009474924624108549, 'epoch': 0.17}
 17%|█▋        | 412/2382 [1:16:27<6:04:15, 11.09s/it] 17%|█▋        | 413/2382 [1:16:38<6:05:30, 11.14s/it]                                                      {'loss': 2.1683, 'learning_rate': 0.0009471887038331685, 'epoch': 0.17}
 17%|█▋        | 413/2382 [1:16:38<6:05:30, 11.14s/it] 17%|█▋        | 414/2382 [1:16:52<6:30:38, 11.91s/it]                                                      {'loss': 2.2077, 'learning_rate': 0.0009468841181392511, 'epoch': 0.17}
 17%|█▋        | 414/2382 [1:16:52<6:30:38, 11.91s/it] 17%|█▋        | 415/2382 [1:17:02<6:06:26, 11.18s/it]                                                      {'loss': 2.0346, 'learning_rate': 0.000946578705892462, 'epoch': 0.17}
 17%|█▋        | 415/2382 [1:17:02<6:06:26, 11.18s/it] 17%|█▋        | 416/2382 [1:17:16<6:36:29, 12.10s/it]                                                      {'loss': 2.0843, 'learning_rate': 0.0009462724676576887, 'epoch': 0.17}
 17%|█▋        | 416/2382 [1:17:16<6:36:29, 12.10s/it] 18%|█▊        | 417/2382 [1:17:30<6:54:23, 12.65s/it]                                                      {'loss': 2.1592, 'learning_rate': 0.000945965404001347, 'epoch': 0.17}
 18%|█▊        | 417/2382 [1:17:30<6:54:23, 12.65s/it] 18%|█▊        | 418/2382 [1:17:39<6:18:45, 11.57s/it]                                                      {'loss': 2.1943, 'learning_rate': 0.0009456575154913788, 'epoch': 0.18}
 18%|█▊        | 418/2382 [1:17:39<6:18:45, 11.57s/it] 18%|█▊        | 419/2382 [1:17:48<5:55:39, 10.87s/it]                                                      {'loss': 2.1031, 'learning_rate': 0.0009453488026972521, 'epoch': 0.18}
 18%|█▊        | 419/2382 [1:17:48<5:55:39, 10.87s/it] 18%|█▊        | 420/2382 [1:18:00<6:04:28, 11.15s/it]                                                      {'loss': 2.0206, 'learning_rate': 0.0009450392661899593, 'epoch': 0.18}
 18%|█▊        | 420/2382 [1:18:00<6:04:28, 11.15s/it] 18%|█▊        | 421/2382 [1:18:11<6:04:04, 11.14s/it]                                                      {'loss': 2.1603, 'learning_rate': 0.0009447289065420164, 'epoch': 0.18}
 18%|█▊        | 421/2382 [1:18:11<6:04:04, 11.14s/it] 18%|█▊        | 422/2382 [1:18:23<6:14:54, 11.48s/it]                                                      {'loss': 2.122, 'learning_rate': 0.0009444177243274617, 'epoch': 0.18}
 18%|█▊        | 422/2382 [1:18:23<6:14:54, 11.48s/it] 18%|█▊        | 423/2382 [1:18:34<6:02:53, 11.11s/it]                                                      {'loss': 2.1559, 'learning_rate': 0.0009441057201218553, 'epoch': 0.18}
 18%|█▊        | 423/2382 [1:18:34<6:02:53, 11.11s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1072 > 1024). Running this sequence through the model will result in indexing errors
 18%|█▊        | 424/2382 [1:18:44<5:57:09, 10.94s/it]                                                      {'loss': 2.0594, 'learning_rate': 0.0009437928945022771, 'epoch': 0.18}
 18%|█▊        | 424/2382 [1:18:44<5:57:09, 10.94s/it] 18%|█▊        | 425/2382 [1:18:55<5:59:15, 11.01s/it]                                                      {'loss': 2.1384, 'learning_rate': 0.0009434792480473267, 'epoch': 0.18}
 18%|█▊        | 425/2382 [1:18:55<5:59:15, 11.01s/it] 18%|█▊        | 426/2382 [1:19:06<5:52:37, 10.82s/it]                                                      {'loss': 2.0741, 'learning_rate': 0.0009431647813371218, 'epoch': 0.18}
 18%|█▊        | 426/2382 [1:19:06<5:52:37, 10.82s/it] 18%|█▊        | 427/2382 [1:19:16<5:45:36, 10.61s/it]                                                      {'loss': 2.0571, 'learning_rate': 0.000942849494953297, 'epoch': 0.18}
 18%|█▊        | 427/2382 [1:19:16<5:45:36, 10.61s/it] 18%|█▊        | 428/2382 [1:19:27<5:54:11, 10.88s/it]                                                      {'loss': 2.0771, 'learning_rate': 0.0009425333894790036, 'epoch': 0.18}
 18%|█▊        | 428/2382 [1:19:27<5:54:11, 10.88s/it] 18%|█▊        | 429/2382 [1:19:38<5:55:05, 10.91s/it]                                                      {'loss': 2.0422, 'learning_rate': 0.0009422164654989072, 'epoch': 0.18}
 18%|█▊        | 429/2382 [1:19:38<5:55:05, 10.91s/it] 18%|█▊        | 430/2382 [1:19:51<6:12:52, 11.46s/it]                                                      {'loss': 2.0766, 'learning_rate': 0.0009418987235991876, 'epoch': 0.18}
 18%|█▊        | 430/2382 [1:19:51<6:12:52, 11.46s/it] 18%|█▊        | 431/2382 [1:20:01<5:59:22, 11.05s/it]                                                      {'loss': 2.072, 'learning_rate': 0.0009415801643675373, 'epoch': 0.18}
 18%|█▊        | 431/2382 [1:20:01<5:59:22, 11.05s/it] 18%|█▊        | 432/2382 [1:20:11<5:48:39, 10.73s/it]                                                      {'loss': 2.1257, 'learning_rate': 0.0009412607883931606, 'epoch': 0.18}
 18%|█▊        | 432/2382 [1:20:11<5:48:39, 10.73s/it] 18%|█▊        | 433/2382 [1:20:22<5:47:49, 10.71s/it]                                                      {'loss': 2.047, 'learning_rate': 0.0009409405962667727, 'epoch': 0.18}
 18%|█▊        | 433/2382 [1:20:22<5:47:49, 10.71s/it] 18%|█▊        | 434/2382 [1:20:31<5:34:29, 10.30s/it]                                                      {'loss': 2.0921, 'learning_rate': 0.0009406195885805978, 'epoch': 0.18}
 18%|█▊        | 434/2382 [1:20:31<5:34:29, 10.30s/it] 18%|█▊        | 435/2382 [1:20:40<5:25:16, 10.02s/it]                                                      {'loss': 2.1746, 'learning_rate': 0.000940297765928369, 'epoch': 0.18}
 18%|█▊        | 435/2382 [1:20:40<5:25:16, 10.02s/it] 18%|█▊        | 436/2382 [1:20:52<5:40:46, 10.51s/it]                                                      {'loss': 2.1041, 'learning_rate': 0.0009399751289053266, 'epoch': 0.18}
 18%|█▊        | 436/2382 [1:20:52<5:40:46, 10.51s/it] 18%|█▊        | 437/2382 [1:21:03<5:44:06, 10.62s/it]                                                      {'loss': 2.0499, 'learning_rate': 0.0009396516781082172, 'epoch': 0.18}
 18%|█▊        | 437/2382 [1:21:03<5:44:06, 10.62s/it] 18%|█▊        | 438/2382 [1:21:12<5:29:07, 10.16s/it]                                                      {'loss': 2.2416, 'learning_rate': 0.0009393274141352924, 'epoch': 0.18}
 18%|█▊        | 438/2382 [1:21:12<5:29:07, 10.16s/it] 18%|█▊        | 439/2382 [1:21:23<5:36:00, 10.38s/it]                                                      {'loss': 2.015, 'learning_rate': 0.0009390023375863077, 'epoch': 0.18}
 18%|█▊        | 439/2382 [1:21:23<5:36:00, 10.38s/it] 18%|█▊        | 440/2382 [1:21:35<5:51:34, 10.86s/it]                                                      {'loss': 2.1022, 'learning_rate': 0.0009386764490625224, 'epoch': 0.18}
 18%|█▊        | 440/2382 [1:21:35<5:51:34, 10.86s/it] 19%|█▊        | 441/2382 [1:21:45<5:39:50, 10.51s/it]                                                      {'loss': 2.0956, 'learning_rate': 0.0009383497491666964, 'epoch': 0.19}
 19%|█▊        | 441/2382 [1:21:45<5:39:50, 10.51s/it] 19%|█▊        | 442/2382 [1:21:55<5:40:56, 10.54s/it]                                                      {'loss': 2.0784, 'learning_rate': 0.0009380222385030915, 'epoch': 0.19}
 19%|█▊        | 442/2382 [1:21:55<5:40:56, 10.54s/it] 19%|█▊        | 443/2382 [1:22:06<5:45:46, 10.70s/it]                                                      {'loss': 2.1739, 'learning_rate': 0.0009376939176774678, 'epoch': 0.19}
 19%|█▊        | 443/2382 [1:22:06<5:45:46, 10.70s/it] 19%|█▊        | 444/2382 [1:22:16<5:33:26, 10.32s/it]                                                      {'loss': 2.1439, 'learning_rate': 0.0009373647872970852, 'epoch': 0.19}
 19%|█▊        | 444/2382 [1:22:16<5:33:26, 10.32s/it] 19%|█▊        | 445/2382 [1:22:28<5:54:22, 10.98s/it]                                                      {'loss': 2.1131, 'learning_rate': 0.0009370348479706998, 'epoch': 0.19}
 19%|█▊        | 445/2382 [1:22:28<5:54:22, 10.98s/it] 19%|█▊        | 446/2382 [1:22:40<6:00:36, 11.18s/it]                                                      {'loss': 2.0754, 'learning_rate': 0.0009367041003085648, 'epoch': 0.19}
 19%|█▊        | 446/2382 [1:22:40<6:00:36, 11.18s/it] 19%|█▉        | 447/2382 [1:22:52<6:05:19, 11.33s/it]                                                      {'loss': 2.0765, 'learning_rate': 0.000936372544922428, 'epoch': 0.19}
 19%|█▉        | 447/2382 [1:22:52<6:05:19, 11.33s/it] 19%|█▉        | 448/2382 [1:23:02<5:54:08, 10.99s/it]                                                      {'loss': 2.0159, 'learning_rate': 0.0009360401824255313, 'epoch': 0.19}
 19%|█▉        | 448/2382 [1:23:02<5:54:08, 10.99s/it] 19%|█▉        | 449/2382 [1:23:15<6:18:02, 11.73s/it]                                                      {'loss': 1.9202, 'learning_rate': 0.0009357070134326093, 'epoch': 0.19}
 19%|█▉        | 449/2382 [1:23:15<6:18:02, 11.73s/it] 19%|█▉        | 450/2382 [1:23:27<6:13:53, 11.61s/it]                                                      {'loss': 2.0129, 'learning_rate': 0.0009353730385598887, 'epoch': 0.19}
 19%|█▉        | 450/2382 [1:23:27<6:13:53, 11.61s/it] 19%|█▉        | 451/2382 [1:23:37<6:05:05, 11.34s/it]                                                      {'loss': 2.0855, 'learning_rate': 0.0009350382584250859, 'epoch': 0.19}
 19%|█▉        | 451/2382 [1:23:37<6:05:05, 11.34s/it] 19%|█▉        | 452/2382 [1:23:48<5:57:26, 11.11s/it]                                                      {'loss': 2.0014, 'learning_rate': 0.0009347026736474076, 'epoch': 0.19}
 19%|█▉        | 452/2382 [1:23:48<5:57:26, 11.11s/it] 19%|█▉        | 453/2382 [1:23:59<6:01:07, 11.23s/it]                                                      {'loss': 2.0627, 'learning_rate': 0.0009343662848475485, 'epoch': 0.19}
 19%|█▉        | 453/2382 [1:23:59<6:01:07, 11.23s/it] 19%|█▉        | 454/2382 [1:24:10<5:54:23, 11.03s/it]                                                      {'loss': 2.0306, 'learning_rate': 0.0009340290926476901, 'epoch': 0.19}
 19%|█▉        | 454/2382 [1:24:10<5:54:23, 11.03s/it] 19%|█▉        | 455/2382 [1:24:20<5:45:06, 10.75s/it]                                                      {'loss': 2.1399, 'learning_rate': 0.0009336910976715003, 'epoch': 0.19}
 19%|█▉        | 455/2382 [1:24:20<5:45:06, 10.75s/it] 19%|█▉        | 456/2382 [1:24:31<5:49:49, 10.90s/it]                                                      {'loss': 2.127, 'learning_rate': 0.0009333523005441313, 'epoch': 0.19}
 19%|█▉        | 456/2382 [1:24:31<5:49:49, 10.90s/it] 19%|█▉        | 457/2382 [1:24:41<5:39:52, 10.59s/it]                                                      {'loss': 2.0966, 'learning_rate': 0.0009330127018922195, 'epoch': 0.19}
 19%|█▉        | 457/2382 [1:24:41<5:39:52, 10.59s/it] 19%|█▉        | 458/2382 [1:24:55<6:10:24, 11.55s/it]                                                      {'loss': 2.0538, 'learning_rate': 0.0009326723023438833, 'epoch': 0.19}
 19%|█▉        | 458/2382 [1:24:55<6:10:24, 11.55s/it] 19%|█▉        | 459/2382 [1:25:04<5:48:23, 10.87s/it]                                                      {'loss': 2.1201, 'learning_rate': 0.0009323311025287227, 'epoch': 0.19}
 19%|█▉        | 459/2382 [1:25:04<5:48:23, 10.87s/it] 19%|█▉        | 460/2382 [1:25:15<5:43:33, 10.72s/it]                                                      {'loss': 1.9121, 'learning_rate': 0.000931989103077818, 'epoch': 0.19}
 19%|█▉        | 460/2382 [1:25:15<5:43:33, 10.72s/it] 19%|█▉        | 461/2382 [1:25:25<5:42:41, 10.70s/it]                                                      {'loss': 2.0662, 'learning_rate': 0.0009316463046237282, 'epoch': 0.19}
 19%|█▉        | 461/2382 [1:25:25<5:42:41, 10.70s/it] 19%|█▉        | 462/2382 [1:25:35<5:37:40, 10.55s/it]                                                      {'loss': 2.1418, 'learning_rate': 0.0009313027078004903, 'epoch': 0.19}
 19%|█▉        | 462/2382 [1:25:35<5:37:40, 10.55s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1219 > 1024). Running this sequence through the model will result in indexing errors
 19%|█▉        | 463/2382 [1:25:44<5:17:59,  9.94s/it]                                                      {'loss': 2.1647, 'learning_rate': 0.0009309583132436181, 'epoch': 0.19}
 19%|█▉        | 463/2382 [1:25:44<5:17:59,  9.94s/it] 19%|█▉        | 464/2382 [1:25:53<5:10:23,  9.71s/it]                                                      {'loss': 2.1422, 'learning_rate': 0.0009306131215901003, 'epoch': 0.19}
 19%|█▉        | 464/2382 [1:25:53<5:10:23,  9.71s/it] 20%|█▉        | 465/2382 [1:26:04<5:20:27, 10.03s/it]                                                      {'loss': 2.0771, 'learning_rate': 0.0009302671334784006, 'epoch': 0.2}
 20%|█▉        | 465/2382 [1:26:04<5:20:27, 10.03s/it] 20%|█▉        | 466/2382 [1:26:16<5:42:08, 10.71s/it]                                                      {'loss': 2.1119, 'learning_rate': 0.0009299203495484554, 'epoch': 0.2}
 20%|█▉        | 466/2382 [1:26:16<5:42:08, 10.71s/it] 20%|█▉        | 467/2382 [1:26:27<5:45:29, 10.82s/it]                                                      {'loss': 2.1023, 'learning_rate': 0.0009295727704416731, 'epoch': 0.2}
 20%|█▉        | 467/2382 [1:26:27<5:45:29, 10.82s/it] 20%|█▉        | 468/2382 [1:26:38<5:41:41, 10.71s/it]                                                      {'loss': 2.0793, 'learning_rate': 0.000929224396800933, 'epoch': 0.2}
 20%|█▉        | 468/2382 [1:26:38<5:41:41, 10.71s/it] 20%|█▉        | 469/2382 [1:26:51<6:04:39, 11.44s/it]                                                      {'loss': 2.0719, 'learning_rate': 0.000928875229270584, 'epoch': 0.2}
 20%|█▉        | 469/2382 [1:26:51<6:04:39, 11.44s/it] 20%|█▉        | 470/2382 [1:27:02<5:58:38, 11.25s/it]                                                      {'loss': 2.0874, 'learning_rate': 0.000928525268496443, 'epoch': 0.2}
 20%|█▉        | 470/2382 [1:27:02<5:58:38, 11.25s/it] 20%|█▉        | 471/2382 [1:27:12<5:51:20, 11.03s/it]                                                      {'loss': 2.0356, 'learning_rate': 0.0009281745151257945, 'epoch': 0.2}
 20%|█▉        | 471/2382 [1:27:12<5:51:20, 11.03s/it] 20%|█▉        | 472/2382 [1:27:25<6:05:28, 11.48s/it]                                                      {'loss': 1.9474, 'learning_rate': 0.0009278229698073888, 'epoch': 0.2}
 20%|█▉        | 472/2382 [1:27:25<6:05:28, 11.48s/it] 20%|█▉        | 473/2382 [1:27:35<5:51:10, 11.04s/it]                                                      {'loss': 2.139, 'learning_rate': 0.0009274706331914407, 'epoch': 0.2}
 20%|█▉        | 473/2382 [1:27:35<5:51:10, 11.04s/it] 20%|█▉        | 474/2382 [1:27:46<5:51:26, 11.05s/it]                                                      {'loss': 2.0599, 'learning_rate': 0.0009271175059296292, 'epoch': 0.2}
 20%|█▉        | 474/2382 [1:27:46<5:51:26, 11.05s/it] 20%|█▉        | 475/2382 [1:27:59<6:06:49, 11.54s/it]                                                      {'loss': 2.0446, 'learning_rate': 0.0009267635886750952, 'epoch': 0.2}
 20%|█▉        | 475/2382 [1:27:59<6:06:49, 11.54s/it] 20%|█▉        | 476/2382 [1:28:09<5:54:02, 11.15s/it]                                                      {'loss': 2.0728, 'learning_rate': 0.0009264088820824408, 'epoch': 0.2}
 20%|█▉        | 476/2382 [1:28:09<5:54:02, 11.15s/it] 20%|██        | 477/2382 [1:28:21<6:06:59, 11.56s/it]                                                      {'loss': 2.0837, 'learning_rate': 0.0009260533868077283, 'epoch': 0.2}
 20%|██        | 477/2382 [1:28:21<6:06:59, 11.56s/it] 20%|██        | 478/2382 [1:28:33<6:08:02, 11.60s/it]                                                      {'loss': 2.1511, 'learning_rate': 0.0009256971035084784, 'epoch': 0.2}
 20%|██        | 478/2382 [1:28:33<6:08:02, 11.60s/it] 20%|██        | 479/2382 [1:28:46<6:24:16, 12.12s/it]                                                      {'loss': 2.0409, 'learning_rate': 0.0009253400328436698, 'epoch': 0.2}
 20%|██        | 479/2382 [1:28:46<6:24:16, 12.12s/it] 20%|██        | 480/2382 [1:28:57<6:11:20, 11.71s/it]                                                      {'loss': 1.9972, 'learning_rate': 0.0009249821754737369, 'epoch': 0.2}
 20%|██        | 480/2382 [1:28:57<6:11:20, 11.71s/it] 20%|██        | 481/2382 [1:29:08<6:02:59, 11.46s/it]                                                      {'loss': 2.1248, 'learning_rate': 0.0009246235320605697, 'epoch': 0.2}
 20%|██        | 481/2382 [1:29:08<6:02:59, 11.46s/it] 20%|██        | 482/2382 [1:29:23<6:40:36, 12.65s/it]                                                      {'loss': 1.958, 'learning_rate': 0.0009242641032675118, 'epoch': 0.2}
 20%|██        | 482/2382 [1:29:23<6:40:36, 12.65s/it] 20%|██        | 483/2382 [1:29:35<6:28:48, 12.28s/it]                                                      {'loss': 2.0372, 'learning_rate': 0.0009239038897593593, 'epoch': 0.2}
 20%|██        | 483/2382 [1:29:35<6:28:48, 12.28s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1145 > 1024). Running this sequence through the model will result in indexing errors
 20%|██        | 484/2382 [1:29:45<6:11:43, 11.75s/it]                                                      {'loss': 2.1094, 'learning_rate': 0.0009235428922023603, 'epoch': 0.2}
 20%|██        | 484/2382 [1:29:45<6:11:43, 11.75s/it] 20%|██        | 485/2382 [1:29:55<5:51:45, 11.13s/it]                                                      {'loss': 1.9882, 'learning_rate': 0.0009231811112642122, 'epoch': 0.2}
 20%|██        | 485/2382 [1:29:55<5:51:45, 11.13s/it] 20%|██        | 486/2382 [1:30:03<5:24:27, 10.27s/it]                                                      {'loss': 2.1452, 'learning_rate': 0.000922818547614062, 'epoch': 0.2}
 20%|██        | 486/2382 [1:30:03<5:24:27, 10.27s/it] 20%|██        | 487/2382 [1:30:15<5:36:54, 10.67s/it]                                                      {'loss': 2.179, 'learning_rate': 0.0009224552019225043, 'epoch': 0.2}
 20%|██        | 487/2382 [1:30:15<5:36:54, 10.67s/it] 20%|██        | 488/2382 [1:30:24<5:26:02, 10.33s/it]                                                      {'loss': 2.1289, 'learning_rate': 0.0009220910748615798, 'epoch': 0.2}
 20%|██        | 488/2382 [1:30:24<5:26:02, 10.33s/it] 21%|██        | 489/2382 [1:30:35<5:30:07, 10.46s/it]                                                      {'loss': 2.0239, 'learning_rate': 0.000921726167104775, 'epoch': 0.21}
 21%|██        | 489/2382 [1:30:35<5:30:07, 10.46s/it] 21%|██        | 490/2382 [1:30:49<6:06:24, 11.62s/it]                                                      {'loss': 1.9188, 'learning_rate': 0.0009213604793270196, 'epoch': 0.21}
 21%|██        | 490/2382 [1:30:49<6:06:24, 11.62s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1044 > 1024). Running this sequence through the model will result in indexing errors
 21%|██        | 491/2382 [1:31:01<6:02:57, 11.52s/it]                                                      {'loss': 2.1193, 'learning_rate': 0.0009209940122046867, 'epoch': 0.21}
 21%|██        | 491/2382 [1:31:01<6:02:57, 11.52s/it] 21%|██        | 492/2382 [1:31:14<6:18:46, 12.02s/it]                                                      {'loss': 2.1719, 'learning_rate': 0.0009206267664155906, 'epoch': 0.21}
 21%|██        | 492/2382 [1:31:14<6:18:46, 12.02s/it] 21%|██        | 493/2382 [1:31:25<6:10:44, 11.78s/it]                                                      {'loss': 2.0591, 'learning_rate': 0.0009202587426389858, 'epoch': 0.21}
 21%|██        | 493/2382 [1:31:25<6:10:44, 11.78s/it] 21%|██        | 494/2382 [1:31:36<6:04:33, 11.59s/it]                                                      {'loss': 2.0474, 'learning_rate': 0.0009198899415555658, 'epoch': 0.21}
 21%|██        | 494/2382 [1:31:36<6:04:33, 11.59s/it] 21%|██        | 495/2382 [1:31:48<6:03:21, 11.55s/it]                                                      {'loss': 2.0066, 'learning_rate': 0.0009195203638474618, 'epoch': 0.21}
 21%|██        | 495/2382 [1:31:48<6:03:21, 11.55s/it] 21%|██        | 496/2382 [1:32:00<6:09:13, 11.75s/it]                                                      {'loss': 2.1217, 'learning_rate': 0.0009191500101982413, 'epoch': 0.21}
 21%|██        | 496/2382 [1:32:00<6:09:13, 11.75s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1066 > 1024). Running this sequence through the model will result in indexing errors
 21%|██        | 497/2382 [1:32:10<5:55:22, 11.31s/it]                                                      {'loss': 1.993, 'learning_rate': 0.0009187788812929073, 'epoch': 0.21}
 21%|██        | 497/2382 [1:32:10<5:55:22, 11.31s/it] 21%|██        | 498/2382 [1:32:21<5:45:54, 11.02s/it]                                                      {'loss': 2.0765, 'learning_rate': 0.0009184069778178964, 'epoch': 0.21}
 21%|██        | 498/2382 [1:32:21<5:45:54, 11.02s/it] 21%|██        | 499/2382 [1:32:32<5:49:40, 11.14s/it]                                                      {'loss': 2.1742, 'learning_rate': 0.000918034300461078, 'epoch': 0.21}
 21%|██        | 499/2382 [1:32:32<5:49:40, 11.14s/it] 21%|██        | 500/2382 [1:32:43<5:50:56, 11.19s/it]                                                      {'loss': 2.0248, 'learning_rate': 0.0009176608499117527, 'epoch': 0.21}
 21%|██        | 500/2382 [1:32:43<5:50:56, 11.19s/it] 21%|██        | 501/2382 [1:32:52<5:26:03, 10.40s/it]                                                      {'loss': 2.0628, 'learning_rate': 0.0009172866268606513, 'epoch': 0.21}
 21%|██        | 501/2382 [1:32:52<5:26:03, 10.40s/it] 21%|██        | 502/2382 [1:33:06<5:59:26, 11.47s/it]                                                      {'loss': 2.11, 'learning_rate': 0.0009169116319999336, 'epoch': 0.21}
 21%|██        | 502/2382 [1:33:06<5:59:26, 11.47s/it] 21%|██        | 503/2382 [1:33:18<6:06:39, 11.71s/it]                                                      {'loss': 1.9531, 'learning_rate': 0.0009165358660231867, 'epoch': 0.21}
 21%|██        | 503/2382 [1:33:18<6:06:39, 11.71s/it] 21%|██        | 504/2382 [1:33:31<6:22:27, 12.22s/it]                                                      {'loss': 2.0475, 'learning_rate': 0.0009161593296254236, 'epoch': 0.21}
 21%|██        | 504/2382 [1:33:31<6:22:27, 12.22s/it] 21%|██        | 505/2382 [1:33:42<6:06:49, 11.73s/it]                                                      {'loss': 2.0156, 'learning_rate': 0.0009157820235030832, 'epoch': 0.21}
 21%|██        | 505/2382 [1:33:42<6:06:49, 11.73s/it] 21%|██        | 506/2382 [1:33:54<6:06:20, 11.72s/it]                                                      {'loss': 2.1361, 'learning_rate': 0.0009154039483540273, 'epoch': 0.21}
 21%|██        | 506/2382 [1:33:54<6:06:20, 11.72s/it] 21%|██▏       | 507/2382 [1:34:07<6:17:13, 12.07s/it]                                                      {'loss': 2.2007, 'learning_rate': 0.0009150251048775403, 'epoch': 0.21}
 21%|██▏       | 507/2382 [1:34:07<6:17:13, 12.07s/it] 21%|██▏       | 508/2382 [1:34:16<5:50:21, 11.22s/it]                                                      {'loss': 2.1622, 'learning_rate': 0.0009146454937743278, 'epoch': 0.21}
 21%|██▏       | 508/2382 [1:34:16<5:50:21, 11.22s/it] 21%|██▏       | 509/2382 [1:34:27<5:52:15, 11.28s/it]                                                      {'loss': 1.9786, 'learning_rate': 0.000914265115746515, 'epoch': 0.21}
 21%|██▏       | 509/2382 [1:34:27<5:52:15, 11.28s/it] 21%|██▏       | 510/2382 [1:34:37<5:40:47, 10.92s/it]                                                      {'loss': 2.1323, 'learning_rate': 0.0009138839714976456, 'epoch': 0.21}
 21%|██▏       | 510/2382 [1:34:37<5:40:47, 10.92s/it] 21%|██▏       | 511/2382 [1:34:51<6:06:06, 11.74s/it]                                                      {'loss': 2.1058, 'learning_rate': 0.0009135020617326808, 'epoch': 0.21}
 21%|██▏       | 511/2382 [1:34:51<6:06:06, 11.74s/it] 21%|██▏       | 512/2382 [1:35:01<5:52:21, 11.31s/it]                                                      {'loss': 2.1842, 'learning_rate': 0.0009131193871579975, 'epoch': 0.21}
 21%|██▏       | 512/2382 [1:35:01<5:52:21, 11.31s/it] 22%|██▏       | 513/2382 [1:35:14<6:05:06, 11.72s/it]                                                      {'loss': 2.0685, 'learning_rate': 0.000912735948481387, 'epoch': 0.22}
 22%|██▏       | 513/2382 [1:35:14<6:05:06, 11.72s/it] 22%|██▏       | 514/2382 [1:35:26<6:06:09, 11.76s/it]                                                      {'loss': 2.0602, 'learning_rate': 0.0009123517464120542, 'epoch': 0.22}
 22%|██▏       | 514/2382 [1:35:26<6:06:09, 11.76s/it] 22%|██▏       | 515/2382 [1:35:37<6:00:54, 11.60s/it]                                                      {'loss': 2.1227, 'learning_rate': 0.0009119667816606157, 'epoch': 0.22}
 22%|██▏       | 515/2382 [1:35:37<6:00:54, 11.60s/it] 22%|██▏       | 516/2382 [1:35:49<5:59:38, 11.56s/it]                                                      {'loss': 2.0458, 'learning_rate': 0.000911581054939099, 'epoch': 0.22}
 22%|██▏       | 516/2382 [1:35:49<5:59:38, 11.56s/it] 22%|██▏       | 517/2382 [1:35:58<5:41:46, 11.00s/it]                                                      {'loss': 2.1346, 'learning_rate': 0.0009111945669609407, 'epoch': 0.22}
 22%|██▏       | 517/2382 [1:35:58<5:41:46, 11.00s/it] 22%|██▏       | 518/2382 [1:36:11<5:59:24, 11.57s/it]                                                      {'loss': 2.0773, 'learning_rate': 0.0009108073184409855, 'epoch': 0.22}
 22%|██▏       | 518/2382 [1:36:11<5:59:24, 11.57s/it] 22%|██▏       | 519/2382 [1:36:22<5:52:18, 11.35s/it]                                                      {'loss': 2.0132, 'learning_rate': 0.000910419310095485, 'epoch': 0.22}
 22%|██▏       | 519/2382 [1:36:22<5:52:18, 11.35s/it] 22%|██▏       | 520/2382 [1:36:33<5:51:25, 11.32s/it]                                                      {'loss': 2.0773, 'learning_rate': 0.0009100305426420956, 'epoch': 0.22}
 22%|██▏       | 520/2382 [1:36:33<5:51:25, 11.32s/it] 22%|██▏       | 521/2382 [1:36:45<5:54:02, 11.41s/it]                                                      {'loss': 2.2292, 'learning_rate': 0.0009096410167998783, 'epoch': 0.22}
 22%|██▏       | 521/2382 [1:36:45<5:54:02, 11.41s/it] 22%|██▏       | 522/2382 [1:36:57<6:02:07, 11.68s/it]                                                      {'loss': 2.0042, 'learning_rate': 0.0009092507332892967, 'epoch': 0.22}
 22%|██▏       | 522/2382 [1:36:57<6:02:07, 11.68s/it] 22%|██▏       | 523/2382 [1:37:10<6:15:00, 12.10s/it]                                                      {'loss': 1.9866, 'learning_rate': 0.0009088596928322157, 'epoch': 0.22}
 22%|██▏       | 523/2382 [1:37:10<6:15:00, 12.10s/it] 22%|██▏       | 524/2382 [1:37:21<6:01:57, 11.69s/it]                                                      {'loss': 2.0288, 'learning_rate': 0.0009084678961519, 'epoch': 0.22}
 22%|██▏       | 524/2382 [1:37:21<6:01:57, 11.69s/it] 22%|██▏       | 525/2382 [1:37:30<5:36:58, 10.89s/it]                                                      {'loss': 2.1246, 'learning_rate': 0.0009080753439730136, 'epoch': 0.22}
 22%|██▏       | 525/2382 [1:37:30<5:36:58, 10.89s/it] 22%|██▏       | 526/2382 [1:37:41<5:39:09, 10.96s/it]                                                      {'loss': 2.1149, 'learning_rate': 0.0009076820370216173, 'epoch': 0.22}
 22%|██▏       | 526/2382 [1:37:41<5:39:09, 10.96s/it] 22%|██▏       | 527/2382 [1:37:51<5:25:36, 10.53s/it]                                                      {'loss': 2.181, 'learning_rate': 0.0009072879760251679, 'epoch': 0.22}
 22%|██▏       | 527/2382 [1:37:51<5:25:36, 10.53s/it] 22%|██▏       | 528/2382 [1:38:00<5:12:54, 10.13s/it]                                                      {'loss': 2.0141, 'learning_rate': 0.0009068931617125174, 'epoch': 0.22}
 22%|██▏       | 528/2382 [1:38:00<5:12:54, 10.13s/it] 22%|██▏       | 529/2382 [1:38:11<5:17:34, 10.28s/it]                                                      {'loss': 2.0682, 'learning_rate': 0.0009064975948139108, 'epoch': 0.22}
 22%|██▏       | 529/2382 [1:38:11<5:17:34, 10.28s/it] 22%|██▏       | 530/2382 [1:38:23<5:34:01, 10.82s/it]                                                      {'loss': 2.0355, 'learning_rate': 0.000906101276060985, 'epoch': 0.22}
 22%|██▏       | 530/2382 [1:38:23<5:34:01, 10.82s/it] 22%|██▏       | 531/2382 [1:38:33<5:30:56, 10.73s/it]                                                      {'loss': 2.0133, 'learning_rate': 0.0009057042061867678, 'epoch': 0.22}
 22%|██▏       | 531/2382 [1:38:33<5:30:56, 10.73s/it] 22%|██▏       | 532/2382 [1:38:46<5:46:34, 11.24s/it]                                                      {'loss': 2.1179, 'learning_rate': 0.0009053063859256758, 'epoch': 0.22}
 22%|██▏       | 532/2382 [1:38:46<5:46:34, 11.24s/it] 22%|██▏       | 533/2382 [1:38:55<5:30:43, 10.73s/it]                                                      {'loss': 2.0884, 'learning_rate': 0.0009049078160135141, 'epoch': 0.22}
 22%|██▏       | 533/2382 [1:38:55<5:30:43, 10.73s/it] 22%|██▏       | 534/2382 [1:39:06<5:34:24, 10.86s/it]                                                      {'loss': 2.138, 'learning_rate': 0.0009045084971874737, 'epoch': 0.22}
 22%|██▏       | 534/2382 [1:39:06<5:34:24, 10.86s/it] 22%|██▏       | 535/2382 [1:39:16<5:26:01, 10.59s/it]                                                      {'loss': 2.0862, 'learning_rate': 0.0009041084301861315, 'epoch': 0.22}
 22%|██▏       | 535/2382 [1:39:16<5:26:01, 10.59s/it] 23%|██▎       | 536/2382 [1:39:27<5:25:34, 10.58s/it]                                                      {'loss': 2.1184, 'learning_rate': 0.0009037076157494478, 'epoch': 0.22}
 23%|██▎       | 536/2382 [1:39:27<5:25:34, 10.58s/it] 23%|██▎       | 537/2382 [1:39:38<5:32:43, 10.82s/it]                                                      {'loss': 1.9559, 'learning_rate': 0.000903306054618765, 'epoch': 0.23}
 23%|██▎       | 537/2382 [1:39:38<5:32:43, 10.82s/it] 23%|██▎       | 538/2382 [1:39:48<5:24:06, 10.55s/it]                                                      {'loss': 2.082, 'learning_rate': 0.0009029037475368075, 'epoch': 0.23}
 23%|██▎       | 538/2382 [1:39:48<5:24:06, 10.55s/it] 23%|██▎       | 539/2382 [1:39:57<5:11:51, 10.15s/it]                                                      {'loss': 2.0801, 'learning_rate': 0.0009025006952476786, 'epoch': 0.23}
 23%|██▎       | 539/2382 [1:39:57<5:11:51, 10.15s/it] 23%|██▎       | 540/2382 [1:40:07<5:11:12, 10.14s/it]                                                      {'loss': 2.1786, 'learning_rate': 0.0009020968984968603, 'epoch': 0.23}
 23%|██▎       | 540/2382 [1:40:07<5:11:12, 10.14s/it] 23%|██▎       | 541/2382 [1:40:18<5:17:01, 10.33s/it]                                                      {'loss': 2.0519, 'learning_rate': 0.0009016923580312113, 'epoch': 0.23}
 23%|██▎       | 541/2382 [1:40:18<5:17:01, 10.33s/it] 23%|██▎       | 542/2382 [1:40:29<5:24:43, 10.59s/it]                                                      {'loss': 1.9206, 'learning_rate': 0.0009012870745989663, 'epoch': 0.23}
 23%|██▎       | 542/2382 [1:40:29<5:24:43, 10.59s/it] 23%|██▎       | 543/2382 [1:40:40<5:22:31, 10.52s/it]                                                      {'loss': 2.0065, 'learning_rate': 0.0009008810489497338, 'epoch': 0.23}
 23%|██▎       | 543/2382 [1:40:40<5:22:31, 10.52s/it] 23%|██▎       | 544/2382 [1:40:51<5:27:43, 10.70s/it]                                                      {'loss': 2.057, 'learning_rate': 0.000900474281834495, 'epoch': 0.23}
 23%|██▎       | 544/2382 [1:40:51<5:27:43, 10.70s/it] 23%|██▎       | 545/2382 [1:41:02<5:34:55, 10.94s/it]                                                      {'loss': 2.1169, 'learning_rate': 0.0009000667740056032, 'epoch': 0.23}
 23%|██▎       | 545/2382 [1:41:02<5:34:55, 10.94s/it] 23%|██▎       | 546/2382 [1:41:14<5:45:21, 11.29s/it]                                                      {'loss': 2.0461, 'learning_rate': 0.0008996585262167807, 'epoch': 0.23}
 23%|██▎       | 546/2382 [1:41:14<5:45:21, 11.29s/it] 23%|██▎       | 547/2382 [1:41:24<5:29:00, 10.76s/it]                                                      {'loss': 2.1422, 'learning_rate': 0.0008992495392231195, 'epoch': 0.23}
 23%|██▎       | 547/2382 [1:41:24<5:29:00, 10.76s/it] 23%|██▎       | 548/2382 [1:41:35<5:28:29, 10.75s/it]                                                      {'loss': 2.0728, 'learning_rate': 0.0008988398137810777, 'epoch': 0.23}
 23%|██▎       | 548/2382 [1:41:35<5:28:29, 10.75s/it] 23%|██▎       | 549/2382 [1:41:44<5:12:11, 10.22s/it]                                                      {'loss': 2.1907, 'learning_rate': 0.0008984293506484802, 'epoch': 0.23}
 23%|██▎       | 549/2382 [1:41:44<5:12:11, 10.22s/it] 23%|██▎       | 550/2382 [1:41:55<5:25:05, 10.65s/it]                                                      {'loss': 2.0845, 'learning_rate': 0.000898018150584516, 'epoch': 0.23}
 23%|██▎       | 550/2382 [1:41:55<5:25:05, 10.65s/it] 23%|██▎       | 551/2382 [1:42:09<5:53:29, 11.58s/it]                                                      {'loss': 2.1517, 'learning_rate': 0.0008976062143497368, 'epoch': 0.23}
 23%|██▎       | 551/2382 [1:42:09<5:53:29, 11.58s/it] 23%|██▎       | 552/2382 [1:42:20<5:44:10, 11.28s/it]                                                      {'loss': 1.9884, 'learning_rate': 0.0008971935427060562, 'epoch': 0.23}
 23%|██▎       | 552/2382 [1:42:20<5:44:10, 11.28s/it] 23%|██▎       | 553/2382 [1:42:33<5:59:56, 11.81s/it]                                                      {'loss': 1.9091, 'learning_rate': 0.0008967801364167484, 'epoch': 0.23}
 23%|██▎       | 553/2382 [1:42:33<5:59:56, 11.81s/it] 23%|██▎       | 554/2382 [1:42:45<5:59:58, 11.82s/it]                                                      {'loss': 2.1255, 'learning_rate': 0.0008963659962464455, 'epoch': 0.23}
 23%|██▎       | 554/2382 [1:42:45<5:59:58, 11.82s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1760 > 1024). Running this sequence through the model will result in indexing errors
 23%|██▎       | 555/2382 [1:42:54<5:36:22, 11.05s/it]                                                      {'loss': 2.2526, 'learning_rate': 0.0008959511229611376, 'epoch': 0.23}
 23%|██▎       | 555/2382 [1:42:54<5:36:22, 11.05s/it] 23%|██▎       | 556/2382 [1:43:03<5:20:35, 10.53s/it]                                                      {'loss': 2.036, 'learning_rate': 0.0008955355173281707, 'epoch': 0.23}
 23%|██▎       | 556/2382 [1:43:03<5:20:35, 10.53s/it] 23%|██▎       | 557/2382 [1:43:16<5:46:01, 11.38s/it]                                                      {'loss': 2.0331, 'learning_rate': 0.0008951191801162452, 'epoch': 0.23}
 23%|██▎       | 557/2382 [1:43:16<5:46:01, 11.38s/it] 23%|██▎       | 558/2382 [1:43:27<5:42:31, 11.27s/it]                                                      {'loss': 2.0819, 'learning_rate': 0.0008947021120954146, 'epoch': 0.23}
 23%|██▎       | 558/2382 [1:43:27<5:42:31, 11.27s/it] 23%|██▎       | 559/2382 [1:43:40<5:49:34, 11.51s/it]                                                      {'loss': 2.0152, 'learning_rate': 0.0008942843140370844, 'epoch': 0.23}
 23%|██▎       | 559/2382 [1:43:40<5:49:34, 11.51s/it] 24%|██▎       | 560/2382 [1:43:51<5:50:12, 11.53s/it]                                                      {'loss': 2.0865, 'learning_rate': 0.0008938657867140101, 'epoch': 0.24}
 24%|██▎       | 560/2382 [1:43:51<5:50:12, 11.53s/it] 24%|██▎       | 561/2382 [1:44:01<5:33:46, 11.00s/it]                                                      {'loss': 2.0902, 'learning_rate': 0.0008934465309002959, 'epoch': 0.24}
 24%|██▎       | 561/2382 [1:44:01<5:33:46, 11.00s/it] 24%|██▎       | 562/2382 [1:44:11<5:24:53, 10.71s/it]                                                      {'loss': 2.1215, 'learning_rate': 0.0008930265473713938, 'epoch': 0.24}
 24%|██▎       | 562/2382 [1:44:11<5:24:53, 10.71s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1143 > 1024). Running this sequence through the model will result in indexing errors
 24%|██▎       | 563/2382 [1:44:22<5:31:07, 10.92s/it]                                                      {'loss': 2.1095, 'learning_rate': 0.0008926058369041014, 'epoch': 0.24}
 24%|██▎       | 563/2382 [1:44:22<5:31:07, 10.92s/it] 24%|██▎       | 564/2382 [1:44:33<5:32:12, 10.96s/it]                                                      {'loss': 2.1136, 'learning_rate': 0.0008921844002765613, 'epoch': 0.24}
 24%|██▎       | 564/2382 [1:44:33<5:32:12, 10.96s/it] 24%|██▎       | 565/2382 [1:44:47<5:53:18, 11.67s/it]                                                      {'loss': 2.0243, 'learning_rate': 0.0008917622382682589, 'epoch': 0.24}
 24%|██▎       | 565/2382 [1:44:47<5:53:18, 11.67s/it] 24%|██▍       | 566/2382 [1:44:57<5:44:39, 11.39s/it]                                                      {'loss': 2.1359, 'learning_rate': 0.0008913393516600209, 'epoch': 0.24}
 24%|██▍       | 566/2382 [1:44:57<5:44:39, 11.39s/it] 24%|██▍       | 567/2382 [1:45:08<5:33:58, 11.04s/it]                                                      {'loss': 1.9965, 'learning_rate': 0.000890915741234015, 'epoch': 0.24}
 24%|██▍       | 567/2382 [1:45:08<5:33:58, 11.04s/it] 24%|██▍       | 568/2382 [1:45:20<5:45:40, 11.43s/it]                                                      {'loss': 2.0414, 'learning_rate': 0.0008904914077737469, 'epoch': 0.24}
 24%|██▍       | 568/2382 [1:45:20<5:45:40, 11.43s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1176 > 1024). Running this sequence through the model will result in indexing errors
 24%|██▍       | 569/2382 [1:45:29<5:19:24, 10.57s/it]                                                      {'loss': 1.9831, 'learning_rate': 0.0008900663520640604, 'epoch': 0.24}
 24%|██▍       | 569/2382 [1:45:29<5:19:24, 10.57s/it] 24%|██▍       | 570/2382 [1:45:39<5:18:38, 10.55s/it]                                                      {'loss': 2.0742, 'learning_rate': 0.0008896405748911345, 'epoch': 0.24}
 24%|██▍       | 570/2382 [1:45:39<5:18:38, 10.55s/it] 24%|██▍       | 571/2382 [1:45:54<5:57:03, 11.83s/it]                                                      {'loss': 2.0838, 'learning_rate': 0.0008892140770424827, 'epoch': 0.24}
 24%|██▍       | 571/2382 [1:45:54<5:57:03, 11.83s/it] 24%|██▍       | 572/2382 [1:46:06<5:58:05, 11.87s/it]                                                      {'loss': 2.1706, 'learning_rate': 0.0008887868593069519, 'epoch': 0.24}
 24%|██▍       | 572/2382 [1:46:06<5:58:05, 11.87s/it] 24%|██▍       | 573/2382 [1:46:18<5:57:19, 11.85s/it]                                                      {'loss': 2.1025, 'learning_rate': 0.0008883589224747201, 'epoch': 0.24}
 24%|██▍       | 573/2382 [1:46:18<5:57:19, 11.85s/it] 24%|██▍       | 574/2382 [1:46:29<5:49:45, 11.61s/it]                                                      {'loss': 2.0821, 'learning_rate': 0.0008879302673372953, 'epoch': 0.24}
 24%|██▍       | 574/2382 [1:46:29<5:49:45, 11.61s/it] 24%|██▍       | 575/2382 [1:46:38<5:27:19, 10.87s/it]                                                      {'loss': 2.1149, 'learning_rate': 0.0008875008946875144, 'epoch': 0.24}
 24%|██▍       | 575/2382 [1:46:38<5:27:19, 10.87s/it] 24%|██▍       | 576/2382 [1:46:47<5:12:30, 10.38s/it]                                                      {'loss': 2.1249, 'learning_rate': 0.0008870708053195413, 'epoch': 0.24}
 24%|██▍       | 576/2382 [1:46:47<5:12:30, 10.38s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1216 > 1024). Running this sequence through the model will result in indexing errors
 24%|██▍       | 577/2382 [1:46:59<5:28:58, 10.94s/it]                                                      {'loss': 2.0377, 'learning_rate': 0.0008866400000288651, 'epoch': 0.24}
 24%|██▍       | 577/2382 [1:46:59<5:28:58, 10.94s/it] 24%|██▍       | 578/2382 [1:47:11<5:31:32, 11.03s/it]                                                      {'loss': 2.0333, 'learning_rate': 0.0008862084796122997, 'epoch': 0.24}
 24%|██▍       | 578/2382 [1:47:11<5:31:32, 11.03s/it] 24%|██▍       | 579/2382 [1:47:23<5:47:05, 11.55s/it]                                                      {'loss': 2.0545, 'learning_rate': 0.0008857762448679815, 'epoch': 0.24}
 24%|██▍       | 579/2382 [1:47:23<5:47:05, 11.55s/it] 24%|██▍       | 580/2382 [1:47:35<5:45:11, 11.49s/it]                                                      {'loss': 1.9915, 'learning_rate': 0.0008853432965953676, 'epoch': 0.24}
 24%|██▍       | 580/2382 [1:47:35<5:45:11, 11.49s/it] 24%|██▍       | 581/2382 [1:47:46<5:43:46, 11.45s/it]                                                      {'loss': 2.003, 'learning_rate': 0.0008849096355952358, 'epoch': 0.24}
 24%|██▍       | 581/2382 [1:47:46<5:43:46, 11.45s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1267 > 1024). Running this sequence through the model will result in indexing errors
 24%|██▍       | 582/2382 [1:47:56<5:25:46, 10.86s/it]                                                      {'loss': 2.1117, 'learning_rate': 0.0008844752626696811, 'epoch': 0.24}
 24%|██▍       | 582/2382 [1:47:56<5:25:46, 10.86s/it] 24%|██▍       | 583/2382 [1:48:04<5:08:07, 10.28s/it]                                                      {'loss': 2.1182, 'learning_rate': 0.0008840401786221159, 'epoch': 0.24}
 24%|██▍       | 583/2382 [1:48:04<5:08:07, 10.28s/it] 25%|██▍       | 584/2382 [1:48:15<5:06:09, 10.22s/it]                                                      {'loss': 2.1927, 'learning_rate': 0.0008836043842572681, 'epoch': 0.25}
 25%|██▍       | 584/2382 [1:48:15<5:06:09, 10.22s/it] 25%|██▍       | 585/2382 [1:48:27<5:21:45, 10.74s/it]                                                      {'loss': 2.0992, 'learning_rate': 0.0008831678803811788, 'epoch': 0.25}
 25%|██▍       | 585/2382 [1:48:27<5:21:45, 10.74s/it] 25%|██▍       | 586/2382 [1:48:39<5:34:46, 11.18s/it]                                                      {'loss': 2.1904, 'learning_rate': 0.0008827306678012016, 'epoch': 0.25}
 25%|██▍       | 586/2382 [1:48:39<5:34:46, 11.18s/it] 25%|██▍       | 587/2382 [1:48:49<5:27:14, 10.94s/it]                                                      {'loss': 2.2083, 'learning_rate': 0.0008822927473260012, 'epoch': 0.25}
 25%|██▍       | 587/2382 [1:48:49<5:27:14, 10.94s/it] 25%|██▍       | 588/2382 [1:49:01<5:31:51, 11.10s/it]                                                      {'loss': 2.0285, 'learning_rate': 0.0008818541197655512, 'epoch': 0.25}
 25%|██▍       | 588/2382 [1:49:01<5:31:51, 11.10s/it] 25%|██▍       | 589/2382 [1:49:12<5:33:01, 11.14s/it]                                                      {'loss': 2.1184, 'learning_rate': 0.0008814147859311332, 'epoch': 0.25}
 25%|██▍       | 589/2382 [1:49:12<5:33:01, 11.14s/it] 25%|██▍       | 590/2382 [1:49:24<5:38:22, 11.33s/it]                                                      {'loss': 2.1405, 'learning_rate': 0.0008809747466353355, 'epoch': 0.25}
 25%|██▍       | 590/2382 [1:49:24<5:38:22, 11.33s/it] 25%|██▍       | 591/2382 [1:49:33<5:20:48, 10.75s/it]                                                      {'loss': 2.0239, 'learning_rate': 0.0008805340026920503, 'epoch': 0.25}
 25%|██▍       | 591/2382 [1:49:33<5:20:48, 10.75s/it] 25%|██▍       | 592/2382 [1:49:43<5:14:16, 10.53s/it]                                                      {'loss': 2.1652, 'learning_rate': 0.0008800925549164741, 'epoch': 0.25}
 25%|██▍       | 592/2382 [1:49:43<5:14:16, 10.53s/it] 25%|██▍       | 593/2382 [1:49:55<5:30:52, 11.10s/it]                                                      {'loss': 2.1185, 'learning_rate': 0.0008796504041251045, 'epoch': 0.25}
 25%|██▍       | 593/2382 [1:49:55<5:30:52, 11.10s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1127 > 1024). Running this sequence through the model will result in indexing errors
 25%|██▍       | 594/2382 [1:50:05<5:15:15, 10.58s/it]                                                      {'loss': 2.0674, 'learning_rate': 0.00087920755113574, 'epoch': 0.25}
 25%|██▍       | 594/2382 [1:50:05<5:15:15, 10.58s/it] 25%|██▍       | 595/2382 [1:50:15<5:12:19, 10.49s/it]                                                      {'loss': 2.1205, 'learning_rate': 0.000878763996767477, 'epoch': 0.25}
 25%|██▍       | 595/2382 [1:50:15<5:12:19, 10.49s/it] 25%|██▌       | 596/2382 [1:50:26<5:17:02, 10.65s/it]                                                      {'loss': 1.9602, 'learning_rate': 0.0008783197418407101, 'epoch': 0.25}
 25%|██▌       | 596/2382 [1:50:26<5:17:02, 10.65s/it] 25%|██▌       | 597/2382 [1:50:36<5:06:54, 10.32s/it]                                                      {'loss': 2.052, 'learning_rate': 0.0008778747871771292, 'epoch': 0.25}
 25%|██▌       | 597/2382 [1:50:36<5:06:54, 10.32s/it] 25%|██▌       | 598/2382 [1:50:51<5:51:51, 11.83s/it]                                                      {'loss': 2.0595, 'learning_rate': 0.0008774291335997182, 'epoch': 0.25}
 25%|██▌       | 598/2382 [1:50:51<5:51:51, 11.83s/it] 25%|██▌       | 599/2382 [1:51:00<5:27:12, 11.01s/it]                                                      {'loss': 2.0865, 'learning_rate': 0.0008769827819327543, 'epoch': 0.25}
 25%|██▌       | 599/2382 [1:51:00<5:27:12, 11.01s/it] 25%|██▌       | 600/2382 [1:51:12<5:31:41, 11.17s/it]                                                      {'loss': 2.1593, 'learning_rate': 0.0008765357330018055, 'epoch': 0.25}
 25%|██▌       | 600/2382 [1:51:12<5:31:41, 11.17s/it] 25%|██▌       | 601/2382 [1:51:23<5:32:43, 11.21s/it]                                                      {'loss': 2.0669, 'learning_rate': 0.0008760879876337294, 'epoch': 0.25}
 25%|██▌       | 601/2382 [1:51:23<5:32:43, 11.21s/it] 25%|██▌       | 602/2382 [1:51:35<5:40:13, 11.47s/it]                                                      {'loss': 1.942, 'learning_rate': 0.0008756395466566717, 'epoch': 0.25}
 25%|██▌       | 602/2382 [1:51:35<5:40:13, 11.47s/it] 25%|██▌       | 603/2382 [1:51:50<6:13:26, 12.60s/it]                                                      {'loss': 2.0131, 'learning_rate': 0.0008751904109000652, 'epoch': 0.25}
 25%|██▌       | 603/2382 [1:51:50<6:13:26, 12.60s/it] 25%|██▌       | 604/2382 [1:52:04<6:24:57, 12.99s/it]                                                      {'loss': 2.0447, 'learning_rate': 0.0008747405811946271, 'epoch': 0.25}
 25%|██▌       | 604/2382 [1:52:04<6:24:57, 12.99s/it] 25%|██▌       | 605/2382 [1:52:14<5:56:49, 12.05s/it]                                                      {'loss': 2.057, 'learning_rate': 0.0008742900583723583, 'epoch': 0.25}
 25%|██▌       | 605/2382 [1:52:14<5:56:49, 12.05s/it] 25%|██▌       | 606/2382 [1:52:26<5:57:43, 12.09s/it]                                                      {'loss': 1.9974, 'learning_rate': 0.0008738388432665423, 'epoch': 0.25}
 25%|██▌       | 606/2382 [1:52:26<5:57:43, 12.09s/it] 25%|██▌       | 607/2382 [1:52:37<5:49:51, 11.83s/it]                                                      {'loss': 2.0786, 'learning_rate': 0.000873386936711742, 'epoch': 0.25}
 25%|██▌       | 607/2382 [1:52:37<5:49:51, 11.83s/it] 26%|██▌       | 608/2382 [1:52:46<5:21:20, 10.87s/it]                                                      {'loss': 2.146, 'learning_rate': 0.0008729343395437999, 'epoch': 0.26}
 26%|██▌       | 608/2382 [1:52:46<5:21:20, 10.87s/it] 26%|██▌       | 609/2382 [1:52:54<4:59:06, 10.12s/it]                                                      {'loss': 2.1, 'learning_rate': 0.0008724810525998357, 'epoch': 0.26}
 26%|██▌       | 609/2382 [1:52:54<4:59:06, 10.12s/it] 26%|██▌       | 610/2382 [1:53:08<5:26:38, 11.06s/it]                                                      {'loss': 2.1374, 'learning_rate': 0.0008720270767182448, 'epoch': 0.26}
 26%|██▌       | 610/2382 [1:53:08<5:26:38, 11.06s/it] 26%|██▌       | 611/2382 [1:53:18<5:22:52, 10.94s/it]                                                      {'loss': 2.1105, 'learning_rate': 0.0008715724127386971, 'epoch': 0.26}
 26%|██▌       | 611/2382 [1:53:18<5:22:52, 10.94s/it] 26%|██▌       | 612/2382 [1:53:29<5:16:54, 10.74s/it]                                                      {'loss': 2.2185, 'learning_rate': 0.000871117061502135, 'epoch': 0.26}
 26%|██▌       | 612/2382 [1:53:29<5:16:54, 10.74s/it] 26%|██▌       | 613/2382 [1:53:39<5:12:13, 10.59s/it]                                                      {'loss': 2.0989, 'learning_rate': 0.000870661023850772, 'epoch': 0.26}
 26%|██▌       | 613/2382 [1:53:39<5:12:13, 10.59s/it] 26%|██▌       | 614/2382 [1:53:49<5:10:34, 10.54s/it]                                                      {'loss': 2.0365, 'learning_rate': 0.0008702043006280912, 'epoch': 0.26}
 26%|██▌       | 614/2382 [1:53:49<5:10:34, 10.54s/it] 26%|██▌       | 615/2382 [1:53:58<4:57:28, 10.10s/it]                                                      {'loss': 2.0546, 'learning_rate': 0.0008697468926788438, 'epoch': 0.26}
 26%|██▌       | 615/2382 [1:53:58<4:57:28, 10.10s/it] 26%|██▌       | 616/2382 [1:54:08<4:57:41, 10.11s/it]                                                      {'loss': 2.0738, 'learning_rate': 0.0008692888008490478, 'epoch': 0.26}
 26%|██▌       | 616/2382 [1:54:08<4:57:41, 10.11s/it] 26%|██▌       | 617/2382 [1:54:21<5:17:13, 10.78s/it]                                                      {'loss': 2.0585, 'learning_rate': 0.0008688300259859854, 'epoch': 0.26}
 26%|██▌       | 617/2382 [1:54:21<5:17:13, 10.78s/it] 26%|██▌       | 618/2382 [1:54:33<5:29:45, 11.22s/it]                                                      {'loss': 2.013, 'learning_rate': 0.0008683705689382025, 'epoch': 0.26}
 26%|██▌       | 618/2382 [1:54:33<5:29:45, 11.22s/it] 26%|██▌       | 619/2382 [1:54:42<5:05:48, 10.41s/it]                                                      {'loss': 2.1111, 'learning_rate': 0.0008679104305555068, 'epoch': 0.26}
 26%|██▌       | 619/2382 [1:54:42<5:05:48, 10.41s/it] 26%|██▌       | 620/2382 [1:54:51<4:53:10,  9.98s/it]                                                      {'loss': 2.0451, 'learning_rate': 0.0008674496116889663, 'epoch': 0.26}
 26%|██▌       | 620/2382 [1:54:51<4:53:10,  9.98s/it] 26%|██▌       | 621/2382 [1:55:01<5:01:09, 10.26s/it]                                                      {'loss': 2.0419, 'learning_rate': 0.0008669881131909072, 'epoch': 0.26}
 26%|██▌       | 621/2382 [1:55:01<5:01:09, 10.26s/it] 26%|██▌       | 622/2382 [1:55:12<5:03:39, 10.35s/it]                                                      {'loss': 2.0351, 'learning_rate': 0.0008665259359149131, 'epoch': 0.26}
 26%|██▌       | 622/2382 [1:55:12<5:03:39, 10.35s/it] 26%|██▌       | 623/2382 [1:55:22<4:58:36, 10.19s/it]                                                      {'loss': 2.0535, 'learning_rate': 0.0008660630807158232, 'epoch': 0.26}
 26%|██▌       | 623/2382 [1:55:22<4:58:36, 10.19s/it] 26%|██▌       | 624/2382 [1:55:35<5:24:52, 11.09s/it]                                                      {'loss': 2.052, 'learning_rate': 0.0008655995484497298, 'epoch': 0.26}
 26%|██▌       | 624/2382 [1:55:35<5:24:52, 11.09s/it] 26%|██▌       | 625/2382 [1:55:47<5:32:03, 11.34s/it]                                                      {'loss': 1.9297, 'learning_rate': 0.0008651353399739787, 'epoch': 0.26}
 26%|██▌       | 625/2382 [1:55:47<5:32:03, 11.34s/it] 26%|██▋       | 626/2382 [1:55:57<5:21:33, 10.99s/it]                                                      {'loss': 2.1575, 'learning_rate': 0.0008646704561471652, 'epoch': 0.26}
 26%|██▋       | 626/2382 [1:55:57<5:21:33, 10.99s/it] 26%|██▋       | 627/2382 [1:56:07<5:15:07, 10.77s/it]                                                      {'loss': 2.0179, 'learning_rate': 0.0008642048978291345, 'epoch': 0.26}
 26%|██▋       | 627/2382 [1:56:07<5:15:07, 10.77s/it] 26%|██▋       | 628/2382 [1:56:17<5:01:27, 10.31s/it]                                                      {'loss': 2.1309, 'learning_rate': 0.0008637386658809791, 'epoch': 0.26}
 26%|██▋       | 628/2382 [1:56:17<5:01:27, 10.31s/it] 26%|██▋       | 629/2382 [1:56:27<4:58:08, 10.20s/it]                                                      {'loss': 2.1293, 'learning_rate': 0.0008632717611650376, 'epoch': 0.26}
 26%|██▋       | 629/2382 [1:56:27<4:58:08, 10.20s/it] 26%|██▋       | 630/2382 [1:56:38<5:06:09, 10.49s/it]                                                      {'loss': 2.1022, 'learning_rate': 0.0008628041845448924, 'epoch': 0.26}
 26%|██▋       | 630/2382 [1:56:38<5:06:09, 10.49s/it] 26%|██▋       | 631/2382 [1:56:48<5:06:46, 10.51s/it]                                                      {'loss': 1.9731, 'learning_rate': 0.0008623359368853694, 'epoch': 0.26}
 26%|██▋       | 631/2382 [1:56:48<5:06:46, 10.51s/it] 27%|██▋       | 632/2382 [1:56:59<5:09:43, 10.62s/it]                                                      {'loss': 2.2374, 'learning_rate': 0.000861867019052535, 'epoch': 0.27}
 27%|██▋       | 632/2382 [1:56:59<5:09:43, 10.62s/it] 27%|██▋       | 633/2382 [1:57:10<5:13:29, 10.75s/it]                                                      {'loss': 2.0297, 'learning_rate': 0.0008613974319136957, 'epoch': 0.27}
 27%|██▋       | 633/2382 [1:57:10<5:13:29, 10.75s/it] 27%|██▋       | 634/2382 [1:57:21<5:14:34, 10.80s/it]                                                      {'loss': 2.1247, 'learning_rate': 0.0008609271763373956, 'epoch': 0.27}
 27%|██▋       | 634/2382 [1:57:21<5:14:34, 10.80s/it] 27%|██▋       | 635/2382 [1:57:32<5:18:24, 10.94s/it]                                                      {'loss': 2.1615, 'learning_rate': 0.0008604562531934151, 'epoch': 0.27}
 27%|██▋       | 635/2382 [1:57:32<5:18:24, 10.94s/it] 27%|██▋       | 636/2382 [1:57:44<5:22:49, 11.09s/it]                                                      {'loss': 2.0875, 'learning_rate': 0.0008599846633527696, 'epoch': 0.27}
 27%|██▋       | 636/2382 [1:57:44<5:22:49, 11.09s/it] 27%|██▋       | 637/2382 [1:57:53<5:03:11, 10.42s/it]                                                      {'loss': 2.056, 'learning_rate': 0.0008595124076877073, 'epoch': 0.27}
 27%|██▋       | 637/2382 [1:57:53<5:03:11, 10.42s/it] 27%|██▋       | 638/2382 [1:58:04<5:09:37, 10.65s/it]                                                      {'loss': 2.0827, 'learning_rate': 0.0008590394870717081, 'epoch': 0.27}
 27%|██▋       | 638/2382 [1:58:04<5:09:37, 10.65s/it] 27%|██▋       | 639/2382 [1:58:15<5:09:22, 10.65s/it]                                                      {'loss': 1.995, 'learning_rate': 0.0008585659023794818, 'epoch': 0.27}
 27%|██▋       | 639/2382 [1:58:15<5:09:22, 10.65s/it] 27%|██▋       | 640/2382 [1:58:25<5:08:50, 10.64s/it]                                                      {'loss': 2.0287, 'learning_rate': 0.0008580916544869663, 'epoch': 0.27}
 27%|██▋       | 640/2382 [1:58:25<5:08:50, 10.64s/it] 27%|██▋       | 641/2382 [1:58:38<5:29:08, 11.34s/it]                                                      {'loss': 1.9554, 'learning_rate': 0.0008576167442713265, 'epoch': 0.27}
 27%|██▋       | 641/2382 [1:58:38<5:29:08, 11.34s/it] 27%|██▋       | 642/2382 [1:58:48<5:17:29, 10.95s/it]                                                      {'loss': 2.0433, 'learning_rate': 0.0008571411726109519, 'epoch': 0.27}
 27%|██▋       | 642/2382 [1:58:48<5:17:29, 10.95s/it] 27%|██▋       | 643/2382 [1:59:00<5:21:38, 11.10s/it]                                                      {'loss': 2.0742, 'learning_rate': 0.0008566649403854555, 'epoch': 0.27}
 27%|██▋       | 643/2382 [1:59:00<5:21:38, 11.10s/it] 27%|██▋       | 644/2382 [1:59:12<5:36:28, 11.62s/it]                                                      {'loss': 2.1356, 'learning_rate': 0.0008561880484756724, 'epoch': 0.27}
 27%|██▋       | 644/2382 [1:59:12<5:36:28, 11.62s/it] 27%|██▋       | 645/2382 [1:59:23<5:24:20, 11.20s/it]                                                      {'loss': 2.1431, 'learning_rate': 0.0008557104977636576, 'epoch': 0.27}
 27%|██▋       | 645/2382 [1:59:23<5:24:20, 11.20s/it] 27%|██▋       | 646/2382 [1:59:34<5:21:24, 11.11s/it]                                                      {'loss': 2.062, 'learning_rate': 0.0008552322891326845, 'epoch': 0.27}
 27%|██▋       | 646/2382 [1:59:34<5:21:24, 11.11s/it] 27%|██▋       | 647/2382 [1:59:46<5:35:05, 11.59s/it]                                                      {'loss': 2.1271, 'learning_rate': 0.0008547534234672433, 'epoch': 0.27}
 27%|██▋       | 647/2382 [1:59:46<5:35:05, 11.59s/it] 27%|██▋       | 648/2382 [1:59:56<5:19:42, 11.06s/it]                                                      {'loss': 2.0793, 'learning_rate': 0.0008542739016530403, 'epoch': 0.27}
 27%|██▋       | 648/2382 [1:59:56<5:19:42, 11.06s/it] 27%|██▋       | 649/2382 [2:00:07<5:21:26, 11.13s/it]                                                      {'loss': 2.1301, 'learning_rate': 0.0008537937245769943, 'epoch': 0.27}
 27%|██▋       | 649/2382 [2:00:07<5:21:26, 11.13s/it] 27%|██▋       | 650/2382 [2:00:22<5:51:39, 12.18s/it]                                                      {'loss': 2.0983, 'learning_rate': 0.0008533128931272365, 'epoch': 0.27}
 27%|██▋       | 650/2382 [2:00:22<5:51:39, 12.18s/it] 27%|██▋       | 651/2382 [2:00:33<5:41:05, 11.82s/it]                                                      {'loss': 1.9948, 'learning_rate': 0.0008528314081931085, 'epoch': 0.27}
 27%|██▋       | 651/2382 [2:00:33<5:41:05, 11.82s/it] 27%|██▋       | 652/2382 [2:00:42<5:17:25, 11.01s/it]                                                      {'loss': 2.1632, 'learning_rate': 0.0008523492706651607, 'epoch': 0.27}
 27%|██▋       | 652/2382 [2:00:42<5:17:25, 11.01s/it] 27%|██▋       | 653/2382 [2:00:53<5:13:35, 10.88s/it]                                                      {'loss': 2.2284, 'learning_rate': 0.0008518664814351503, 'epoch': 0.27}
 27%|██▋       | 653/2382 [2:00:53<5:13:35, 10.88s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1160 > 1024). Running this sequence through the model will result in indexing errors
 27%|██▋       | 654/2382 [2:01:06<5:30:59, 11.49s/it]                                                      {'loss': 2.0676, 'learning_rate': 0.0008513830413960399, 'epoch': 0.27}
 27%|██▋       | 654/2382 [2:01:06<5:30:59, 11.49s/it] 27%|██▋       | 655/2382 [2:01:17<5:25:35, 11.31s/it]                                                      {'loss': 2.1032, 'learning_rate': 0.0008508989514419958, 'epoch': 0.27}
 27%|██▋       | 655/2382 [2:01:17<5:25:35, 11.31s/it] 28%|██▊       | 656/2382 [2:01:27<5:17:56, 11.05s/it]                                                      {'loss': 2.1514, 'learning_rate': 0.0008504142124683865, 'epoch': 0.28}
 28%|██▊       | 656/2382 [2:01:27<5:17:56, 11.05s/it] 28%|██▊       | 657/2382 [2:01:39<5:24:24, 11.28s/it]                                                      {'loss': 2.0311, 'learning_rate': 0.0008499288253717809, 'epoch': 0.28}
 28%|██▊       | 657/2382 [2:01:39<5:24:24, 11.28s/it] 28%|██▊       | 658/2382 [2:01:49<5:15:15, 10.97s/it]                                                      {'loss': 1.9821, 'learning_rate': 0.0008494427910499467, 'epoch': 0.28}
 28%|██▊       | 658/2382 [2:01:49<5:15:15, 10.97s/it] 28%|██▊       | 659/2382 [2:02:03<5:40:00, 11.84s/it]                                                      {'loss': 2.1219, 'learning_rate': 0.0008489561104018486, 'epoch': 0.28}
 28%|██▊       | 659/2382 [2:02:03<5:40:00, 11.84s/it] 28%|██▊       | 660/2382 [2:02:16<5:49:41, 12.18s/it]                                                      {'loss': 2.1237, 'learning_rate': 0.0008484687843276469, 'epoch': 0.28}
 28%|██▊       | 660/2382 [2:02:16<5:49:41, 12.18s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1512 > 1024). Running this sequence through the model will result in indexing errors
 28%|██▊       | 661/2382 [2:02:26<5:30:50, 11.53s/it]                                                      {'loss': 2.0609, 'learning_rate': 0.000847980813728695, 'epoch': 0.28}
 28%|██▊       | 661/2382 [2:02:26<5:30:50, 11.53s/it] 28%|██▊       | 662/2382 [2:02:35<5:13:45, 10.95s/it]                                                      {'loss': 2.0029, 'learning_rate': 0.0008474921995075398, 'epoch': 0.28}
 28%|██▊       | 662/2382 [2:02:35<5:13:45, 10.95s/it] 28%|██▊       | 663/2382 [2:02:48<5:24:07, 11.31s/it]                                                      {'loss': 2.0947, 'learning_rate': 0.0008470029425679171, 'epoch': 0.28}
 28%|██▊       | 663/2382 [2:02:48<5:24:07, 11.31s/it] 28%|██▊       | 664/2382 [2:02:59<5:23:54, 11.31s/it]                                                      {'loss': 1.9676, 'learning_rate': 0.0008465130438147526, 'epoch': 0.28}
 28%|██▊       | 664/2382 [2:02:59<5:23:54, 11.31s/it] 28%|██▊       | 665/2382 [2:03:11<5:30:35, 11.55s/it]                                                      {'loss': 2.1176, 'learning_rate': 0.0008460225041541584, 'epoch': 0.28}
 28%|██▊       | 665/2382 [2:03:11<5:30:35, 11.55s/it] 28%|██▊       | 666/2382 [2:03:22<5:26:21, 11.41s/it]                                                      {'loss': 2.1645, 'learning_rate': 0.0008455313244934324, 'epoch': 0.28}
 28%|██▊       | 666/2382 [2:03:22<5:26:21, 11.41s/it] 28%|██▊       | 667/2382 [2:03:32<5:15:31, 11.04s/it]                                                      {'loss': 2.096, 'learning_rate': 0.000845039505741056, 'epoch': 0.28}
 28%|██▊       | 667/2382 [2:03:32<5:15:31, 11.04s/it] 28%|██▊       | 668/2382 [2:03:45<5:26:57, 11.45s/it]                                                      {'loss': 2.0464, 'learning_rate': 0.0008445470488066929, 'epoch': 0.28}
 28%|██▊       | 668/2382 [2:03:45<5:26:57, 11.45s/it] 28%|██▊       | 669/2382 [2:03:54<5:12:27, 10.94s/it]                                                      {'loss': 2.1181, 'learning_rate': 0.000844053954601187, 'epoch': 0.28}
 28%|██▊       | 669/2382 [2:03:54<5:12:27, 10.94s/it] 28%|██▊       | 670/2382 [2:04:05<5:06:34, 10.74s/it]                                                      {'loss': 2.2244, 'learning_rate': 0.0008435602240365609, 'epoch': 0.28}
 28%|██▊       | 670/2382 [2:04:05<5:06:34, 10.74s/it] 28%|██▊       | 671/2382 [2:04:18<5:26:37, 11.45s/it]                                                      {'loss': 2.0339, 'learning_rate': 0.0008430658580260143, 'epoch': 0.28}
 28%|██▊       | 671/2382 [2:04:18<5:26:37, 11.45s/it] 28%|██▊       | 672/2382 [2:04:28<5:13:13, 10.99s/it]                                                      {'loss': 2.0132, 'learning_rate': 0.0008425708574839221, 'epoch': 0.28}
 28%|██▊       | 672/2382 [2:04:28<5:13:13, 10.99s/it] 28%|██▊       | 673/2382 [2:04:38<5:05:17, 10.72s/it]                                                      {'loss': 1.9384, 'learning_rate': 0.0008420752233258329, 'epoch': 0.28}
 28%|██▊       | 673/2382 [2:04:38<5:05:17, 10.72s/it] 28%|██▊       | 674/2382 [2:04:47<4:52:22, 10.27s/it]                                                      {'loss': 2.0713, 'learning_rate': 0.0008415789564684673, 'epoch': 0.28}
 28%|██▊       | 674/2382 [2:04:47<4:52:22, 10.27s/it] 28%|██▊       | 675/2382 [2:04:58<4:55:48, 10.40s/it]                                                      {'loss': 2.0682, 'learning_rate': 0.0008410820578297158, 'epoch': 0.28}
 28%|██▊       | 675/2382 [2:04:58<4:55:48, 10.40s/it] 28%|██▊       | 676/2382 [2:05:08<4:53:12, 10.31s/it]                                                      {'loss': 2.054, 'learning_rate': 0.000840584528328638, 'epoch': 0.28}
 28%|██▊       | 676/2382 [2:05:08<4:53:12, 10.31s/it] 28%|██▊       | 677/2382 [2:05:21<5:14:58, 11.08s/it]                                                      {'loss': 2.067, 'learning_rate': 0.0008400863688854596, 'epoch': 0.28}
 28%|██▊       | 677/2382 [2:05:21<5:14:58, 11.08s/it] 28%|██▊       | 678/2382 [2:05:31<5:11:05, 10.95s/it]                                                      {'loss': 2.0647, 'learning_rate': 0.0008395875804215725, 'epoch': 0.28}
 28%|██▊       | 678/2382 [2:05:31<5:11:05, 10.95s/it] 29%|██▊       | 679/2382 [2:05:45<5:33:30, 11.75s/it]                                                      {'loss': 2.0286, 'learning_rate': 0.0008390881638595306, 'epoch': 0.28}
 29%|██▊       | 679/2382 [2:05:45<5:33:30, 11.75s/it] 29%|██▊       | 680/2382 [2:05:54<5:11:44, 10.99s/it]                                                      {'loss': 2.1278, 'learning_rate': 0.000838588120123051, 'epoch': 0.29}
 29%|██▊       | 680/2382 [2:05:54<5:11:44, 10.99s/it] 29%|██▊       | 681/2382 [2:06:05<5:08:51, 10.89s/it]                                                      {'loss': 2.1239, 'learning_rate': 0.0008380874501370098, 'epoch': 0.29}
 29%|██▊       | 681/2382 [2:06:05<5:08:51, 10.89s/it] 29%|██▊       | 682/2382 [2:06:15<5:05:44, 10.79s/it]                                                      {'loss': 2.1814, 'learning_rate': 0.0008375861548274417, 'epoch': 0.29}
 29%|██▊       | 682/2382 [2:06:15<5:05:44, 10.79s/it] 29%|██▊       | 683/2382 [2:06:26<5:07:13, 10.85s/it]                                                      {'loss': 2.0481, 'learning_rate': 0.000837084235121538, 'epoch': 0.29}
 29%|██▊       | 683/2382 [2:06:26<5:07:13, 10.85s/it] 29%|██▊       | 684/2382 [2:06:37<5:04:51, 10.77s/it]                                                      {'loss': 2.2128, 'learning_rate': 0.0008365816919476452, 'epoch': 0.29}
 29%|██▊       | 684/2382 [2:06:37<5:04:51, 10.77s/it] 29%|██▉       | 685/2382 [2:06:49<5:12:57, 11.06s/it]                                                      {'loss': 1.9701, 'learning_rate': 0.0008360785262352624, 'epoch': 0.29}
 29%|██▉       | 685/2382 [2:06:49<5:12:57, 11.06s/it] 29%|██▉       | 686/2382 [2:06:58<4:53:33, 10.39s/it]                                                      {'loss': 2.0549, 'learning_rate': 0.0008355747389150403, 'epoch': 0.29}
 29%|██▉       | 686/2382 [2:06:58<4:53:33, 10.39s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1049 > 1024). Running this sequence through the model will result in indexing errors
 29%|██▉       | 687/2382 [2:07:09<5:01:44, 10.68s/it]                                                      {'loss': 2.01, 'learning_rate': 0.0008350703309187798, 'epoch': 0.29}
 29%|██▉       | 687/2382 [2:07:09<5:01:44, 10.68s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 1024). Running this sequence through the model will result in indexing errors
 29%|██▉       | 688/2382 [2:07:22<5:20:43, 11.36s/it]                                                      {'loss': 2.0482, 'learning_rate': 0.0008345653031794292, 'epoch': 0.29}
 29%|██▉       | 688/2382 [2:07:22<5:20:43, 11.36s/it] 29%|██▉       | 689/2382 [2:07:32<5:10:31, 11.00s/it]                                                      {'loss': 2.1184, 'learning_rate': 0.0008340596566310832, 'epoch': 0.29}
 29%|██▉       | 689/2382 [2:07:32<5:10:31, 11.00s/it] 29%|██▉       | 690/2382 [2:07:44<5:19:01, 11.31s/it]                                                      {'loss': 2.0174, 'learning_rate': 0.0008335533922089813, 'epoch': 0.29}
 29%|██▉       | 690/2382 [2:07:44<5:19:01, 11.31s/it] 29%|██▉       | 691/2382 [2:07:55<5:16:02, 11.21s/it]                                                      {'loss': 2.0264, 'learning_rate': 0.0008330465108495055, 'epoch': 0.29}
 29%|██▉       | 691/2382 [2:07:55<5:16:02, 11.21s/it] 29%|██▉       | 692/2382 [2:08:07<5:23:39, 11.49s/it]                                                      {'loss': 2.1015, 'learning_rate': 0.0008325390134901793, 'epoch': 0.29}
 29%|██▉       | 692/2382 [2:08:07<5:23:39, 11.49s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1045 > 1024). Running this sequence through the model will result in indexing errors
 29%|██▉       | 693/2382 [2:08:17<5:11:08, 11.05s/it]                                                      {'loss': 2.1296, 'learning_rate': 0.0008320309010696652, 'epoch': 0.29}
 29%|██▉       | 693/2382 [2:08:17<5:11:08, 11.05s/it] 29%|██▉       | 694/2382 [2:08:28<5:12:25, 11.11s/it]                                                      {'loss': 2.0863, 'learning_rate': 0.000831522174527763, 'epoch': 0.29}
 29%|██▉       | 694/2382 [2:08:28<5:12:25, 11.11s/it] 29%|██▉       | 695/2382 [2:08:38<4:57:41, 10.59s/it]                                                      {'loss': 2.14, 'learning_rate': 0.0008310128348054094, 'epoch': 0.29}
 29%|██▉       | 695/2382 [2:08:38<4:57:41, 10.59s/it] 29%|██▉       | 696/2382 [2:08:48<4:51:18, 10.37s/it]                                                      {'loss': 2.2023, 'learning_rate': 0.000830502882844674, 'epoch': 0.29}
 29%|██▉       | 696/2382 [2:08:48<4:51:18, 10.37s/it] 29%|██▉       | 697/2382 [2:09:02<5:22:44, 11.49s/it]                                                      {'loss': 2.0458, 'learning_rate': 0.0008299923195887597, 'epoch': 0.29}
 29%|██▉       | 697/2382 [2:09:02<5:22:44, 11.49s/it] 29%|██▉       | 698/2382 [2:09:13<5:15:38, 11.25s/it]                                                      {'loss': 2.0682, 'learning_rate': 0.0008294811459819998, 'epoch': 0.29}
 29%|██▉       | 698/2382 [2:09:13<5:15:38, 11.25s/it] 29%|██▉       | 699/2382 [2:09:23<5:08:49, 11.01s/it]                                                      {'loss': 2.0443, 'learning_rate': 0.0008289693629698564, 'epoch': 0.29}
 29%|██▉       | 699/2382 [2:09:23<5:08:49, 11.01s/it] 29%|██▉       | 700/2382 [2:09:34<5:08:22, 11.00s/it]                                                      {'loss': 1.9971, 'learning_rate': 0.0008284569714989185, 'epoch': 0.29}
 29%|██▉       | 700/2382 [2:09:34<5:08:22, 11.00s/it] 29%|██▉       | 701/2382 [2:09:46<5:18:04, 11.35s/it]                                                      {'loss': 2.113, 'learning_rate': 0.0008279439725169011, 'epoch': 0.29}
 29%|██▉       | 701/2382 [2:09:46<5:18:04, 11.35s/it] 29%|██▉       | 702/2382 [2:09:59<5:29:17, 11.76s/it]                                                      {'loss': 2.01, 'learning_rate': 0.0008274303669726426, 'epoch': 0.29}
 29%|██▉       | 702/2382 [2:09:59<5:29:17, 11.76s/it] 30%|██▉       | 703/2382 [2:10:13<5:48:04, 12.44s/it]                                                      {'loss': 2.053, 'learning_rate': 0.0008269161558161029, 'epoch': 0.3}
 30%|██▉       | 703/2382 [2:10:13<5:48:04, 12.44s/it] 30%|██▉       | 704/2382 [2:10:25<5:47:42, 12.43s/it]                                                      {'loss': 2.0083, 'learning_rate': 0.0008264013399983625, 'epoch': 0.3}
 30%|██▉       | 704/2382 [2:10:25<5:47:42, 12.43s/it] 30%|██▉       | 705/2382 [2:10:37<5:40:58, 12.20s/it]                                                      {'loss': 2.1369, 'learning_rate': 0.0008258859204716203, 'epoch': 0.3}
 30%|██▉       | 705/2382 [2:10:37<5:40:58, 12.20s/it] 30%|██▉       | 706/2382 [2:10:50<5:45:57, 12.39s/it]                                                      {'loss': 2.0665, 'learning_rate': 0.0008253698981891915, 'epoch': 0.3}
 30%|██▉       | 706/2382 [2:10:50<5:45:57, 12.39s/it] 30%|██▉       | 707/2382 [2:11:03<5:53:06, 12.65s/it]                                                      {'loss': 2.08, 'learning_rate': 0.0008248532741055062, 'epoch': 0.3}
 30%|██▉       | 707/2382 [2:11:03<5:53:06, 12.65s/it] 30%|██▉       | 708/2382 [2:11:13<5:26:45, 11.71s/it]                                                      {'loss': 2.0167, 'learning_rate': 0.0008243360491761078, 'epoch': 0.3}
 30%|██▉       | 708/2382 [2:11:13<5:26:45, 11.71s/it] 30%|██▉       | 709/2382 [2:11:25<5:35:17, 12.02s/it]                                                      {'loss': 2.1376, 'learning_rate': 0.0008238182243576511, 'epoch': 0.3}
 30%|██▉       | 709/2382 [2:11:25<5:35:17, 12.02s/it] 30%|██▉       | 710/2382 [2:11:40<5:58:02, 12.85s/it]                                                      {'loss': 2.064, 'learning_rate': 0.0008232998006078997, 'epoch': 0.3}
 30%|██▉       | 710/2382 [2:11:40<5:58:02, 12.85s/it] 30%|██▉       | 711/2382 [2:11:51<5:42:17, 12.29s/it]                                                      {'loss': 2.0215, 'learning_rate': 0.0008227807788857264, 'epoch': 0.3}
 30%|██▉       | 711/2382 [2:11:51<5:42:17, 12.29s/it] 30%|██▉       | 712/2382 [2:12:04<5:47:18, 12.48s/it]                                                      {'loss': 2.0256, 'learning_rate': 0.0008222611601511083, 'epoch': 0.3}
 30%|██▉       | 712/2382 [2:12:04<5:47:18, 12.48s/it] 30%|██▉       | 713/2382 [2:12:15<5:34:59, 12.04s/it]                                                      {'loss': 1.9505, 'learning_rate': 0.000821740945365128, 'epoch': 0.3}
 30%|██▉       | 713/2382 [2:12:15<5:34:59, 12.04s/it] 30%|██▉       | 714/2382 [2:12:25<5:21:26, 11.56s/it]                                                      {'loss': 2.0925, 'learning_rate': 0.00082122013548997, 'epoch': 0.3}
 30%|██▉       | 714/2382 [2:12:25<5:21:26, 11.56s/it] 30%|███       | 715/2382 [2:12:35<5:06:20, 11.03s/it]                                                      {'loss': 2.0747, 'learning_rate': 0.0008206987314889197, 'epoch': 0.3}
 30%|███       | 715/2382 [2:12:35<5:06:20, 11.03s/it] 30%|███       | 716/2382 [2:12:45<4:58:15, 10.74s/it]                                                      {'loss': 2.0547, 'learning_rate': 0.0008201767343263612, 'epoch': 0.3}
 30%|███       | 716/2382 [2:12:45<4:58:15, 10.74s/it] 30%|███       | 717/2382 [2:12:56<4:59:35, 10.80s/it]                                                      {'loss': 2.0881, 'learning_rate': 0.0008196541449677758, 'epoch': 0.3}
 30%|███       | 717/2382 [2:12:56<4:59:35, 10.80s/it] 30%|███       | 718/2382 [2:13:07<4:57:47, 10.74s/it]                                                      {'loss': 2.0776, 'learning_rate': 0.00081913096437974, 'epoch': 0.3}
 30%|███       | 718/2382 [2:13:07<4:57:47, 10.74s/it] 30%|███       | 719/2382 [2:13:19<5:07:16, 11.09s/it]                                                      {'loss': 2.069, 'learning_rate': 0.0008186071935299242, 'epoch': 0.3}
 30%|███       | 719/2382 [2:13:19<5:07:16, 11.09s/it] 30%|███       | 720/2382 [2:13:29<5:03:24, 10.95s/it]                                                      {'loss': 2.1605, 'learning_rate': 0.00081808283338709, 'epoch': 0.3}
 30%|███       | 720/2382 [2:13:29<5:03:24, 10.95s/it] 30%|███       | 721/2382 [2:13:40<5:01:00, 10.87s/it]                                                      {'loss': 2.2027, 'learning_rate': 0.0008175578849210894, 'epoch': 0.3}
 30%|███       | 721/2382 [2:13:40<5:01:00, 10.87s/it] 30%|███       | 722/2382 [2:13:50<4:56:13, 10.71s/it]                                                      {'loss': 2.1376, 'learning_rate': 0.0008170323491028624, 'epoch': 0.3}
 30%|███       | 722/2382 [2:13:50<4:56:13, 10.71s/it] 30%|███       | 723/2382 [2:14:02<5:07:25, 11.12s/it]                                                      {'loss': 2.0321, 'learning_rate': 0.0008165062269044352, 'epoch': 0.3}
 30%|███       | 723/2382 [2:14:02<5:07:25, 11.12s/it] 30%|███       | 724/2382 [2:14:13<5:04:43, 11.03s/it]                                                      {'loss': 2.0483, 'learning_rate': 0.0008159795192989189, 'epoch': 0.3}
 30%|███       | 724/2382 [2:14:13<5:04:43, 11.03s/it] 30%|███       | 725/2382 [2:14:24<5:05:26, 11.06s/it]                                                      {'loss': 1.9889, 'learning_rate': 0.0008154522272605071, 'epoch': 0.3}
 30%|███       | 725/2382 [2:14:24<5:05:26, 11.06s/it] 30%|███       | 726/2382 [2:14:37<5:14:50, 11.41s/it]                                                      {'loss': 2.1032, 'learning_rate': 0.0008149243517644744, 'epoch': 0.3}
 30%|███       | 726/2382 [2:14:37<5:14:50, 11.41s/it] 31%|███       | 727/2382 [2:14:49<5:22:27, 11.69s/it]                                                      {'loss': 1.9116, 'learning_rate': 0.0008143958937871747, 'epoch': 0.31}
 31%|███       | 727/2382 [2:14:49<5:22:27, 11.69s/it] 31%|███       | 728/2382 [2:15:02<5:34:05, 12.12s/it]                                                      {'loss': 2.0329, 'learning_rate': 0.0008138668543060391, 'epoch': 0.31}
 31%|███       | 728/2382 [2:15:02<5:34:05, 12.12s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1511 > 1024). Running this sequence through the model will result in indexing errors
 31%|███       | 729/2382 [2:15:13<5:25:25, 11.81s/it]                                                      {'loss': 2.1013, 'learning_rate': 0.0008133372342995744, 'epoch': 0.31}
 31%|███       | 729/2382 [2:15:13<5:25:25, 11.81s/it] 31%|███       | 730/2382 [2:15:25<5:28:54, 11.95s/it]                                                      {'loss': 2.1073, 'learning_rate': 0.0008128070347473608, 'epoch': 0.31}
 31%|███       | 730/2382 [2:15:25<5:28:54, 11.95s/it] 31%|███       | 731/2382 [2:15:37<5:27:56, 11.92s/it]                                                      {'loss': 2.1513, 'learning_rate': 0.0008122762566300508, 'epoch': 0.31}
 31%|███       | 731/2382 [2:15:37<5:27:56, 11.92s/it] 31%|███       | 732/2382 [2:15:48<5:19:26, 11.62s/it]                                                      {'loss': 2.0343, 'learning_rate': 0.0008117449009293668, 'epoch': 0.31}
 31%|███       | 732/2382 [2:15:48<5:19:26, 11.62s/it] 31%|███       | 733/2382 [2:16:01<5:25:34, 11.85s/it]                                                      {'loss': 2.1646, 'learning_rate': 0.0008112129686280996, 'epoch': 0.31}
 31%|███       | 733/2382 [2:16:01<5:25:34, 11.85s/it] 31%|███       | 734/2382 [2:16:13<5:29:07, 11.98s/it]                                                      {'loss': 2.0859, 'learning_rate': 0.0008106804607101066, 'epoch': 0.31}
 31%|███       | 734/2382 [2:16:13<5:29:07, 11.98s/it] 31%|███       | 735/2382 [2:16:22<5:05:52, 11.14s/it]                                                      {'loss': 2.1571, 'learning_rate': 0.0008101473781603094, 'epoch': 0.31}
 31%|███       | 735/2382 [2:16:22<5:05:52, 11.14s/it] 31%|███       | 736/2382 [2:16:31<4:51:26, 10.62s/it]                                                      {'loss': 2.1481, 'learning_rate': 0.0008096137219646928, 'epoch': 0.31}
 31%|███       | 736/2382 [2:16:31<4:51:26, 10.62s/it] 31%|███       | 737/2382 [2:16:43<4:59:11, 10.91s/it]                                                      {'loss': 2.0095, 'learning_rate': 0.0008090794931103026, 'epoch': 0.31}
 31%|███       | 737/2382 [2:16:43<4:59:11, 10.91s/it] 31%|███       | 738/2382 [2:16:54<4:58:49, 10.91s/it]                                                      {'loss': 1.99, 'learning_rate': 0.0008085446925852437, 'epoch': 0.31}
 31%|███       | 738/2382 [2:16:54<4:58:49, 10.91s/it] 31%|███       | 739/2382 [2:17:03<4:43:42, 10.36s/it]                                                      {'loss': 2.2162, 'learning_rate': 0.0008080093213786783, 'epoch': 0.31}
 31%|███       | 739/2382 [2:17:03<4:43:42, 10.36s/it] 31%|███       | 740/2382 [2:17:15<4:58:06, 10.89s/it]                                                      {'loss': 2.016, 'learning_rate': 0.0008074733804808245, 'epoch': 0.31}
 31%|███       | 740/2382 [2:17:15<4:58:06, 10.89s/it] 31%|███       | 741/2382 [2:17:27<5:09:34, 11.32s/it]                                                      {'loss': 1.9874, 'learning_rate': 0.0008069368708829534, 'epoch': 0.31}
 31%|███       | 741/2382 [2:17:28<5:09:34, 11.32s/it] 31%|███       | 742/2382 [2:17:37<4:51:45, 10.67s/it]                                                      {'loss': 1.9969, 'learning_rate': 0.0008063997935773884, 'epoch': 0.31}
 31%|███       | 742/2382 [2:17:37<4:51:45, 10.67s/it] 31%|███       | 743/2382 [2:17:47<4:50:44, 10.64s/it]                                                      {'loss': 2.0672, 'learning_rate': 0.0008058621495575032, 'epoch': 0.31}
 31%|███       | 743/2382 [2:17:47<4:50:44, 10.64s/it] 31%|███       | 744/2382 [2:17:59<4:56:36, 10.86s/it]                                                      {'loss': 2.0837, 'learning_rate': 0.0008053239398177191, 'epoch': 0.31}
 31%|███       | 744/2382 [2:17:59<4:56:36, 10.86s/it] 31%|███▏      | 745/2382 [2:18:09<4:53:15, 10.75s/it]                                                      {'loss': 2.1935, 'learning_rate': 0.0008047851653535041, 'epoch': 0.31}
 31%|███▏      | 745/2382 [2:18:09<4:53:15, 10.75s/it] 31%|███▏      | 746/2382 [2:18:20<4:52:39, 10.73s/it]                                                      {'loss': 2.1053, 'learning_rate': 0.0008042458271613706, 'epoch': 0.31}
 31%|███▏      | 746/2382 [2:18:20<4:52:39, 10.73s/it] 31%|███▏      | 747/2382 [2:18:30<4:48:37, 10.59s/it]                                                      {'loss': 2.0386, 'learning_rate': 0.0008037059262388738, 'epoch': 0.31}
 31%|███▏      | 747/2382 [2:18:30<4:48:37, 10.59s/it] 31%|███▏      | 748/2382 [2:18:42<4:57:28, 10.92s/it]                                                      {'loss': 2.1945, 'learning_rate': 0.0008031654635846095, 'epoch': 0.31}
 31%|███▏      | 748/2382 [2:18:42<4:57:28, 10.92s/it] 31%|███▏      | 749/2382 [2:18:53<5:03:05, 11.14s/it]                                                      {'loss': 2.0675, 'learning_rate': 0.0008026244401982127, 'epoch': 0.31}
 31%|███▏      | 749/2382 [2:18:53<5:03:05, 11.14s/it] 31%|███▏      | 750/2382 [2:19:04<4:58:58, 10.99s/it]                                                      {'loss': 2.0734, 'learning_rate': 0.0008020828570803553, 'epoch': 0.31}
 31%|███▏      | 750/2382 [2:19:04<4:58:58, 10.99s/it] 32%|███▏      | 751/2382 [2:19:15<5:02:18, 11.12s/it]                                                      {'loss': 2.0911, 'learning_rate': 0.0008015407152327448, 'epoch': 0.32}
 32%|███▏      | 751/2382 [2:19:15<5:02:18, 11.12s/it] 32%|███▏      | 752/2382 [2:19:27<5:08:56, 11.37s/it]                                                      {'loss': 2.1036, 'learning_rate': 0.0008009980156581216, 'epoch': 0.32}
 32%|███▏      | 752/2382 [2:19:27<5:08:56, 11.37s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1097 > 1024). Running this sequence through the model will result in indexing errors
 32%|███▏      | 753/2382 [2:19:39<5:09:02, 11.38s/it]                                                      {'loss': 2.1345, 'learning_rate': 0.0008004547593602585, 'epoch': 0.32}
 32%|███▏      | 753/2382 [2:19:39<5:09:02, 11.38s/it] 32%|███▏      | 754/2382 [2:19:48<4:49:19, 10.66s/it]                                                      {'loss': 2.0981, 'learning_rate': 0.0007999109473439569, 'epoch': 0.32}
 32%|███▏      | 754/2382 [2:19:48<4:49:19, 10.66s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1274 > 1024). Running this sequence through the model will result in indexing errors
 32%|███▏      | 755/2382 [2:19:58<4:48:21, 10.63s/it]                                                      {'loss': 2.0195, 'learning_rate': 0.000799366580615047, 'epoch': 0.32}
 32%|███▏      | 755/2382 [2:19:58<4:48:21, 10.63s/it] 32%|███▏      | 756/2382 [2:20:10<4:57:24, 10.97s/it]                                                      {'loss': 2.1487, 'learning_rate': 0.0007988216601803844, 'epoch': 0.32}
 32%|███▏      | 756/2382 [2:20:10<4:57:24, 10.97s/it] 32%|███▏      | 757/2382 [2:20:21<4:55:21, 10.91s/it]                                                      {'loss': 2.0448, 'learning_rate': 0.0007982761870478494, 'epoch': 0.32}
 32%|███▏      | 757/2382 [2:20:21<4:55:21, 10.91s/it] 32%|███▏      | 758/2382 [2:20:33<5:02:37, 11.18s/it]                                                      {'loss': 2.0417, 'learning_rate': 0.000797730162226344, 'epoch': 0.32}
 32%|███▏      | 758/2382 [2:20:33<5:02:37, 11.18s/it] 32%|███▏      | 759/2382 [2:20:46<5:18:28, 11.77s/it]                                                      {'loss': 2.105, 'learning_rate': 0.0007971835867257909, 'epoch': 0.32}
 32%|███▏      | 759/2382 [2:20:46<5:18:28, 11.77s/it] 32%|███▏      | 760/2382 [2:20:58<5:18:45, 11.79s/it]                                                      {'loss': 1.9916, 'learning_rate': 0.0007966364615571314, 'epoch': 0.32}
 32%|███▏      | 760/2382 [2:20:58<5:18:45, 11.79s/it] 32%|███▏      | 761/2382 [2:21:12<5:39:08, 12.55s/it]                                                      {'loss': 2.0437, 'learning_rate': 0.0007960887877323229, 'epoch': 0.32}
 32%|███▏      | 761/2382 [2:21:12<5:39:08, 12.55s/it] 32%|███▏      | 762/2382 [2:21:22<5:18:53, 11.81s/it]                                                      {'loss': 2.0891, 'learning_rate': 0.0007955405662643383, 'epoch': 0.32}
 32%|███▏      | 762/2382 [2:21:22<5:18:53, 11.81s/it] 32%|███▏      | 763/2382 [2:21:31<4:56:28, 10.99s/it]                                                      {'loss': 2.1171, 'learning_rate': 0.0007949917981671632, 'epoch': 0.32}
 32%|███▏      | 763/2382 [2:21:31<4:56:28, 10.99s/it] 32%|███▏      | 764/2382 [2:21:41<4:47:43, 10.67s/it]                                                      {'loss': 2.1304, 'learning_rate': 0.0007944424844557941, 'epoch': 0.32}
 32%|███▏      | 764/2382 [2:21:41<4:47:43, 10.67s/it] 32%|███▏      | 765/2382 [2:21:52<4:49:52, 10.76s/it]                                                      {'loss': 2.1144, 'learning_rate': 0.0007938926261462366, 'epoch': 0.32}
 32%|███▏      | 765/2382 [2:21:52<4:49:52, 10.76s/it] 32%|███▏      | 766/2382 [2:22:03<4:47:31, 10.68s/it]                                                      {'loss': 2.1289, 'learning_rate': 0.000793342224255504, 'epoch': 0.32}
 32%|███▏      | 766/2382 [2:22:03<4:47:31, 10.68s/it] 32%|███▏      | 767/2382 [2:22:12<4:38:13, 10.34s/it]                                                      {'loss': 2.144, 'learning_rate': 0.0007927912798016143, 'epoch': 0.32}
 32%|███▏      | 767/2382 [2:22:12<4:38:13, 10.34s/it] 32%|███▏      | 768/2382 [2:22:21<4:26:23,  9.90s/it]                                                      {'loss': 2.159, 'learning_rate': 0.00079223979380359, 'epoch': 0.32}
 32%|███▏      | 768/2382 [2:22:21<4:26:23,  9.90s/it] 32%|███▏      | 769/2382 [2:22:33<4:44:52, 10.60s/it]                                                      {'loss': 2.0549, 'learning_rate': 0.000791687767281454, 'epoch': 0.32}
 32%|███▏      | 769/2382 [2:22:33<4:44:52, 10.60s/it] 32%|███▏      | 770/2382 [2:22:47<5:09:27, 11.52s/it]                                                      {'loss': 2.0132, 'learning_rate': 0.0007911352012562301, 'epoch': 0.32}
 32%|███▏      | 770/2382 [2:22:47<5:09:27, 11.52s/it] 32%|███▏      | 771/2382 [2:22:59<5:15:49, 11.76s/it]                                                      {'loss': 2.0213, 'learning_rate': 0.0007905820967499395, 'epoch': 0.32}
 32%|███▏      | 771/2382 [2:22:59<5:15:49, 11.76s/it] 32%|███▏      | 772/2382 [2:23:09<4:56:55, 11.07s/it]                                                      {'loss': 2.0538, 'learning_rate': 0.0007900284547855992, 'epoch': 0.32}
 32%|███▏      | 772/2382 [2:23:09<4:56:55, 11.07s/it] 32%|███▏      | 773/2382 [2:23:22<5:18:52, 11.89s/it]                                                      {'loss': 2.1078, 'learning_rate': 0.0007894742763872203, 'epoch': 0.32}
 32%|███▏      | 773/2382 [2:23:22<5:18:52, 11.89s/it] 32%|███▏      | 774/2382 [2:23:31<4:51:30, 10.88s/it]                                                      {'loss': 2.0998, 'learning_rate': 0.0007889195625798064, 'epoch': 0.32}
 32%|███▏      | 774/2382 [2:23:31<4:51:30, 10.88s/it] 33%|███▎      | 775/2382 [2:23:44<5:12:00, 11.65s/it]                                                      {'loss': 2.0543, 'learning_rate': 0.0007883643143893513, 'epoch': 0.33}
 33%|███▎      | 775/2382 [2:23:44<5:12:00, 11.65s/it] 33%|███▎      | 776/2382 [2:23:58<5:24:48, 12.14s/it]                                                      {'loss': 2.1326, 'learning_rate': 0.0007878085328428368, 'epoch': 0.33}
 33%|███▎      | 776/2382 [2:23:58<5:24:48, 12.14s/it] 33%|███▎      | 777/2382 [2:24:10<5:27:24, 12.24s/it]                                                      {'loss': 1.926, 'learning_rate': 0.0007872522189682318, 'epoch': 0.33}
 33%|███▎      | 777/2382 [2:24:10<5:27:24, 12.24s/it] 33%|███▎      | 778/2382 [2:24:19<5:01:48, 11.29s/it]                                                      {'loss': 2.2496, 'learning_rate': 0.0007866953737944891, 'epoch': 0.33}
 33%|███▎      | 778/2382 [2:24:19<5:01:48, 11.29s/it] 33%|███▎      | 779/2382 [2:24:29<4:52:58, 10.97s/it]                                                      {'loss': 2.0777, 'learning_rate': 0.0007861379983515449, 'epoch': 0.33}
 33%|███▎      | 779/2382 [2:24:29<4:52:58, 10.97s/it] 33%|███▎      | 780/2382 [2:24:41<4:59:13, 11.21s/it]                                                      {'loss': 1.9183, 'learning_rate': 0.0007855800936703157, 'epoch': 0.33}
 33%|███▎      | 780/2382 [2:24:41<4:59:13, 11.21s/it] 33%|███▎      | 781/2382 [2:24:53<5:02:52, 11.35s/it]                                                      {'loss': 2.118, 'learning_rate': 0.0007850216607826969, 'epoch': 0.33}
 33%|███▎      | 781/2382 [2:24:53<5:02:52, 11.35s/it] 33%|███▎      | 782/2382 [2:25:03<4:56:04, 11.10s/it]                                                      {'loss': 2.021, 'learning_rate': 0.0007844627007215613, 'epoch': 0.33}
 33%|███▎      | 782/2382 [2:25:03<4:56:04, 11.10s/it] 33%|███▎      | 783/2382 [2:25:15<4:59:43, 11.25s/it]                                                      {'loss': 2.0292, 'learning_rate': 0.000783903214520756, 'epoch': 0.33}
 33%|███▎      | 783/2382 [2:25:15<4:59:43, 11.25s/it] 33%|███▎      | 784/2382 [2:25:26<4:58:58, 11.23s/it]                                                      {'loss': 2.1605, 'learning_rate': 0.000783343203215102, 'epoch': 0.33}
 33%|███▎      | 784/2382 [2:25:26<4:58:58, 11.23s/it] 33%|███▎      | 785/2382 [2:25:38<5:02:27, 11.36s/it]                                                      {'loss': 2.0145, 'learning_rate': 0.0007827826678403912, 'epoch': 0.33}
 33%|███▎      | 785/2382 [2:25:38<5:02:27, 11.36s/it] 33%|███▎      | 786/2382 [2:25:47<4:43:52, 10.67s/it]                                                      {'loss': 2.144, 'learning_rate': 0.0007822216094333848, 'epoch': 0.33}
 33%|███▎      | 786/2382 [2:25:47<4:43:52, 10.67s/it] 33%|███▎      | 787/2382 [2:25:58<4:44:54, 10.72s/it]                                                      {'loss': 1.9961, 'learning_rate': 0.000781660029031811, 'epoch': 0.33}
 33%|███▎      | 787/2382 [2:25:58<4:44:54, 10.72s/it] 33%|███▎      | 788/2382 [2:26:05<4:20:40,  9.81s/it]                                                      {'loss': 2.0478, 'learning_rate': 0.0007810979276743646, 'epoch': 0.33}
 33%|███▎      | 788/2382 [2:26:05<4:20:40,  9.81s/it] 33%|███▎      | 789/2382 [2:26:20<4:56:29, 11.17s/it]                                                      {'loss': 1.9958, 'learning_rate': 0.0007805353064007027, 'epoch': 0.33}
 33%|███▎      | 789/2382 [2:26:20<4:56:29, 11.17s/it] 33%|███▎      | 790/2382 [2:26:32<5:05:21, 11.51s/it]                                                      {'loss': 1.9034, 'learning_rate': 0.0007799721662514448, 'epoch': 0.33}
 33%|███▎      | 790/2382 [2:26:32<5:05:21, 11.51s/it] 33%|███▎      | 791/2382 [2:26:44<5:10:39, 11.72s/it]                                                      {'loss': 2.0293, 'learning_rate': 0.0007794085082681699, 'epoch': 0.33}
 33%|███▎      | 791/2382 [2:26:44<5:10:39, 11.72s/it] 33%|███▎      | 792/2382 [2:26:56<5:07:12, 11.59s/it]                                                      {'loss': 2.0257, 'learning_rate': 0.0007788443334934147, 'epoch': 0.33}
 33%|███▎      | 792/2382 [2:26:56<5:07:12, 11.59s/it] 33%|███▎      | 793/2382 [2:27:05<4:50:39, 10.97s/it]                                                      {'loss': 2.0614, 'learning_rate': 0.000778279642970672, 'epoch': 0.33}
 33%|███▎      | 793/2382 [2:27:05<4:50:39, 10.97s/it] 33%|███▎      | 794/2382 [2:27:17<4:55:34, 11.17s/it]                                                      {'loss': 1.9722, 'learning_rate': 0.0007777144377443881, 'epoch': 0.33}
 33%|███▎      | 794/2382 [2:27:17<4:55:34, 11.17s/it] 33%|███▎      | 795/2382 [2:27:27<4:50:16, 10.97s/it]                                                      {'loss': 2.1669, 'learning_rate': 0.0007771487188599615, 'epoch': 0.33}
 33%|███▎      | 795/2382 [2:27:27<4:50:16, 10.97s/it] 33%|███▎      | 796/2382 [2:27:40<5:01:28, 11.41s/it]                                                      {'loss': 2.0769, 'learning_rate': 0.000776582487363741, 'epoch': 0.33}
 33%|███▎      | 796/2382 [2:27:40<5:01:28, 11.41s/it] 33%|███▎      | 797/2382 [2:27:50<4:51:27, 11.03s/it]                                                      {'loss': 2.2114, 'learning_rate': 0.0007760157443030233, 'epoch': 0.33}
 33%|███▎      | 797/2382 [2:27:50<4:51:27, 11.03s/it] 34%|███▎      | 798/2382 [2:28:03<5:07:38, 11.65s/it]                                                      {'loss': 2.0431, 'learning_rate': 0.0007754484907260512, 'epoch': 0.33}
 34%|███▎      | 798/2382 [2:28:03<5:07:38, 11.65s/it] 34%|███▎      | 799/2382 [2:28:15<5:11:01, 11.79s/it]                                                      {'loss': 2.0261, 'learning_rate': 0.000774880727682012, 'epoch': 0.34}
 34%|███▎      | 799/2382 [2:28:15<5:11:01, 11.79s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1223 > 1024). Running this sequence through the model will result in indexing errors
 34%|███▎      | 800/2382 [2:28:25<4:53:07, 11.12s/it]                                                      {'loss': 2.0532, 'learning_rate': 0.0007743124562210351, 'epoch': 0.34}
 34%|███▎      | 800/2382 [2:28:25<4:53:07, 11.12s/it] 34%|███▎      | 801/2382 [2:28:34<4:37:40, 10.54s/it]                                                      {'loss': 1.9618, 'learning_rate': 0.00077374367739419, 'epoch': 0.34}
 34%|███▎      | 801/2382 [2:28:34<4:37:40, 10.54s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1462 > 1024). Running this sequence through the model will result in indexing errors
 34%|███▎      | 802/2382 [2:28:48<5:04:52, 11.58s/it]                                                      {'loss': 2.0872, 'learning_rate': 0.0007731743922534853, 'epoch': 0.34}
 34%|███▎      | 802/2382 [2:28:48<5:04:52, 11.58s/it] 34%|███▎      | 803/2382 [2:28:58<4:52:55, 11.13s/it]                                                      {'loss': 2.0025, 'learning_rate': 0.0007726046018518657, 'epoch': 0.34}
 34%|███▎      | 803/2382 [2:28:58<4:52:55, 11.13s/it] 34%|███▍      | 804/2382 [2:29:10<5:00:09, 11.41s/it]                                                      {'loss': 2.0735, 'learning_rate': 0.0007720343072432104, 'epoch': 0.34}
 34%|███▍      | 804/2382 [2:29:10<5:00:09, 11.41s/it] 34%|███▍      | 805/2382 [2:29:24<5:19:37, 12.16s/it]                                                      {'loss': 1.9546, 'learning_rate': 0.0007714635094823309, 'epoch': 0.34}
 34%|███▍      | 805/2382 [2:29:24<5:19:37, 12.16s/it] 34%|███▍      | 806/2382 [2:29:34<5:05:19, 11.62s/it]                                                      {'loss': 2.1085, 'learning_rate': 0.0007708922096249701, 'epoch': 0.34}
 34%|███▍      | 806/2382 [2:29:34<5:05:19, 11.62s/it] 34%|███▍      | 807/2382 [2:29:42<4:34:07, 10.44s/it]                                                      {'loss': 2.0905, 'learning_rate': 0.0007703204087277988, 'epoch': 0.34}
 34%|███▍      | 807/2382 [2:29:42<4:34:07, 10.44s/it] 34%|███▍      | 808/2382 [2:29:52<4:30:48, 10.32s/it]                                                      {'loss': 2.1074, 'learning_rate': 0.000769748107848415, 'epoch': 0.34}
 34%|███▍      | 808/2382 [2:29:52<4:30:48, 10.32s/it] 34%|███▍      | 809/2382 [2:30:08<5:12:05, 11.90s/it]                                                      {'loss': 1.9422, 'learning_rate': 0.0007691753080453412, 'epoch': 0.34}
 34%|███▍      | 809/2382 [2:30:08<5:12:05, 11.90s/it] 34%|███▍      | 810/2382 [2:30:18<5:03:15, 11.57s/it]                                                      {'loss': 2.079, 'learning_rate': 0.0007686020103780228, 'epoch': 0.34}
 34%|███▍      | 810/2382 [2:30:18<5:03:15, 11.57s/it] 34%|███▍      | 811/2382 [2:30:28<4:49:45, 11.07s/it]                                                      {'loss': 2.0439, 'learning_rate': 0.0007680282159068262, 'epoch': 0.34}
 34%|███▍      | 811/2382 [2:30:28<4:49:45, 11.07s/it] 34%|███▍      | 812/2382 [2:30:37<4:32:16, 10.41s/it]                                                      {'loss': 1.9308, 'learning_rate': 0.0007674539256930363, 'epoch': 0.34}
 34%|███▍      | 812/2382 [2:30:37<4:32:16, 10.41s/it] 34%|███▍      | 813/2382 [2:30:49<4:43:38, 10.85s/it]                                                      {'loss': 1.9652, 'learning_rate': 0.0007668791407988551, 'epoch': 0.34}
 34%|███▍      | 813/2382 [2:30:49<4:43:38, 10.85s/it] 34%|███▍      | 814/2382 [2:31:02<5:01:10, 11.52s/it]                                                      {'loss': 2.014, 'learning_rate': 0.0007663038622873999, 'epoch': 0.34}
 34%|███▍      | 814/2382 [2:31:02<5:01:10, 11.52s/it] 34%|███▍      | 815/2382 [2:31:13<4:55:38, 11.32s/it]                                                      {'loss': 2.0695, 'learning_rate': 0.0007657280912227008, 'epoch': 0.34}
 34%|███▍      | 815/2382 [2:31:13<4:55:38, 11.32s/it] 34%|███▍      | 816/2382 [2:31:28<5:24:52, 12.45s/it]                                                      {'loss': 2.0243, 'learning_rate': 0.0007651518286696981, 'epoch': 0.34}
 34%|███▍      | 816/2382 [2:31:28<5:24:52, 12.45s/it] 34%|███▍      | 817/2382 [2:31:38<5:03:15, 11.63s/it]                                                      {'loss': 2.1168, 'learning_rate': 0.0007645750756942424, 'epoch': 0.34}
 34%|███▍      | 817/2382 [2:31:38<5:03:15, 11.63s/it] 34%|███▍      | 818/2382 [2:31:50<5:04:25, 11.68s/it]                                                      {'loss': 2.2168, 'learning_rate': 0.0007639978333630911, 'epoch': 0.34}
 34%|███▍      | 818/2382 [2:31:50<5:04:25, 11.68s/it] 34%|███▍      | 819/2382 [2:32:03<5:15:38, 12.12s/it]                                                      {'loss': 1.9671, 'learning_rate': 0.0007634201027439058, 'epoch': 0.34}
 34%|███▍      | 819/2382 [2:32:03<5:15:38, 12.12s/it] 34%|███▍      | 820/2382 [2:32:12<4:55:56, 11.37s/it]                                                      {'loss': 2.2296, 'learning_rate': 0.0007628418849052523, 'epoch': 0.34}
 34%|███▍      | 820/2382 [2:32:12<4:55:56, 11.37s/it] 34%|███▍      | 821/2382 [2:32:21<4:38:10, 10.69s/it]                                                      {'loss': 2.0963, 'learning_rate': 0.0007622631809165971, 'epoch': 0.34}
 34%|███▍      | 821/2382 [2:32:21<4:38:10, 10.69s/it] 35%|███▍      | 822/2382 [2:32:31<4:33:08, 10.51s/it]                                                      {'loss': 2.173, 'learning_rate': 0.000761683991848306, 'epoch': 0.34}
 35%|███▍      | 822/2382 [2:32:31<4:33:08, 10.51s/it] 35%|███▍      | 823/2382 [2:32:42<4:30:41, 10.42s/it]                                                      {'loss': 2.1258, 'learning_rate': 0.0007611043187716418, 'epoch': 0.35}
 35%|███▍      | 823/2382 [2:32:42<4:30:41, 10.42s/it] 35%|███▍      | 824/2382 [2:32:53<4:37:04, 10.67s/it]                                                      {'loss': 2.0671, 'learning_rate': 0.0007605241627587627, 'epoch': 0.35}
 35%|███▍      | 824/2382 [2:32:53<4:37:04, 10.67s/it] 35%|███▍      | 825/2382 [2:33:05<4:47:13, 11.07s/it]                                                      {'loss': 2.0708, 'learning_rate': 0.0007599435248827198, 'epoch': 0.35}
 35%|███▍      | 825/2382 [2:33:05<4:47:13, 11.07s/it] 35%|███▍      | 826/2382 [2:33:18<5:01:24, 11.62s/it]                                                      {'loss': 2.1379, 'learning_rate': 0.0007593624062174562, 'epoch': 0.35}
 35%|███▍      | 826/2382 [2:33:18<5:01:24, 11.62s/it] 35%|███▍      | 827/2382 [2:33:27<4:43:36, 10.94s/it]                                                      {'loss': 2.0324, 'learning_rate': 0.0007587808078378036, 'epoch': 0.35}
 35%|███▍      | 827/2382 [2:33:27<4:43:36, 10.94s/it] 35%|███▍      | 828/2382 [2:33:37<4:37:11, 10.70s/it]                                                      {'loss': 1.9297, 'learning_rate': 0.000758198730819481, 'epoch': 0.35}
 35%|███▍      | 828/2382 [2:33:37<4:37:11, 10.70s/it] 35%|███▍      | 829/2382 [2:33:48<4:39:37, 10.80s/it]                                                      {'loss': 1.9727, 'learning_rate': 0.000757616176239093, 'epoch': 0.35}
 35%|███▍      | 829/2382 [2:33:48<4:39:37, 10.80s/it] 35%|███▍      | 830/2382 [2:33:59<4:41:10, 10.87s/it]                                                      {'loss': 2.0036, 'learning_rate': 0.0007570331451741274, 'epoch': 0.35}
 35%|███▍      | 830/2382 [2:33:59<4:41:10, 10.87s/it] 35%|███▍      | 831/2382 [2:34:10<4:38:01, 10.76s/it]                                                      {'loss': 2.0792, 'learning_rate': 0.0007564496387029531, 'epoch': 0.35}
 35%|███▍      | 831/2382 [2:34:10<4:38:01, 10.76s/it] 35%|███▍      | 832/2382 [2:34:20<4:31:55, 10.53s/it]                                                      {'loss': 2.097, 'learning_rate': 0.0007558656579048185, 'epoch': 0.35}
 35%|███▍      | 832/2382 [2:34:20<4:31:55, 10.53s/it] 35%|███▍      | 833/2382 [2:34:32<4:44:10, 11.01s/it]                                                      {'loss': 1.9971, 'learning_rate': 0.0007552812038598494, 'epoch': 0.35}
 35%|███▍      | 833/2382 [2:34:32<4:44:10, 11.01s/it] 35%|███▌      | 834/2382 [2:34:43<4:40:29, 10.87s/it]                                                      {'loss': 2.0609, 'learning_rate': 0.0007546962776490467, 'epoch': 0.35}
 35%|███▌      | 834/2382 [2:34:43<4:40:29, 10.87s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1719 > 1024). Running this sequence through the model will result in indexing errors
 35%|███▌      | 835/2382 [2:34:54<4:42:19, 10.95s/it]                                                      {'loss': 2.0182, 'learning_rate': 0.0007541108803542846, 'epoch': 0.35}
 35%|███▌      | 835/2382 [2:34:54<4:42:19, 10.95s/it] 35%|███▌      | 836/2382 [2:35:06<4:55:18, 11.46s/it]                                                      {'loss': 2.0281, 'learning_rate': 0.0007535250130583088, 'epoch': 0.35}
 35%|███▌      | 836/2382 [2:35:06<4:55:18, 11.46s/it] 35%|███▌      | 837/2382 [2:35:18<4:56:54, 11.53s/it]                                                      {'loss': 2.0027, 'learning_rate': 0.0007529386768447342, 'epoch': 0.35}
 35%|███▌      | 837/2382 [2:35:18<4:56:54, 11.53s/it] 35%|███▌      | 838/2382 [2:35:29<4:52:38, 11.37s/it]                                                      {'loss': 2.1483, 'learning_rate': 0.000752351872798043, 'epoch': 0.35}
 35%|███▌      | 838/2382 [2:35:29<4:52:38, 11.37s/it] 35%|███▌      | 839/2382 [2:35:38<4:33:41, 10.64s/it]                                                      {'loss': 2.0897, 'learning_rate': 0.0007517646020035827, 'epoch': 0.35}
 35%|███▌      | 839/2382 [2:35:38<4:33:41, 10.64s/it] 35%|███▌      | 840/2382 [2:35:51<4:49:11, 11.25s/it]                                                      {'loss': 2.0698, 'learning_rate': 0.0007511768655475642, 'epoch': 0.35}
 35%|███▌      | 840/2382 [2:35:51<4:49:11, 11.25s/it] 35%|███▌      | 841/2382 [2:36:00<4:31:03, 10.55s/it]                                                      {'loss': 2.0585, 'learning_rate': 0.0007505886645170594, 'epoch': 0.35}
 35%|███▌      | 841/2382 [2:36:00<4:31:03, 10.55s/it] 35%|███▌      | 842/2382 [2:36:10<4:31:02, 10.56s/it]                                                      {'loss': 2.1602, 'learning_rate': 0.00075, 'epoch': 0.35}
 35%|███▌      | 842/2382 [2:36:10<4:31:02, 10.56s/it] 35%|███▌      | 843/2382 [2:36:20<4:23:33, 10.28s/it]                                                      {'loss': 2.116, 'learning_rate': 0.0007494108730851744, 'epoch': 0.35}
 35%|███▌      | 843/2382 [2:36:20<4:23:33, 10.28s/it] 35%|███▌      | 844/2382 [2:36:30<4:20:01, 10.14s/it]                                                      {'loss': 2.0251, 'learning_rate': 0.0007488212848622266, 'epoch': 0.35}
 35%|███▌      | 844/2382 [2:36:30<4:20:01, 10.14s/it] 35%|███▌      | 845/2382 [2:36:41<4:29:25, 10.52s/it]                                                      {'loss': 2.0526, 'learning_rate': 0.0007482312364216535, 'epoch': 0.35}
 35%|███▌      | 845/2382 [2:36:41<4:29:25, 10.52s/it] 36%|███▌      | 846/2382 [2:36:55<4:55:57, 11.56s/it]                                                      {'loss': 2.0169, 'learning_rate': 0.0007476407288548036, 'epoch': 0.36}
 36%|███▌      | 846/2382 [2:36:55<4:55:57, 11.56s/it] 36%|███▌      | 847/2382 [2:37:06<4:52:36, 11.44s/it]                                                      {'loss': 1.9965, 'learning_rate': 0.0007470497632538743, 'epoch': 0.36}
 36%|███▌      | 847/2382 [2:37:06<4:52:36, 11.44s/it] 36%|███▌      | 848/2382 [2:37:15<4:33:35, 10.70s/it]                                                      {'loss': 2.126, 'learning_rate': 0.0007464583407119106, 'epoch': 0.36}
 36%|███▌      | 848/2382 [2:37:15<4:33:35, 10.70s/it] 36%|███▌      | 849/2382 [2:37:28<4:51:37, 11.41s/it]                                                      {'loss': 2.0556, 'learning_rate': 0.000745866462322802, 'epoch': 0.36}
 36%|███▌      | 849/2382 [2:37:28<4:51:37, 11.41s/it] 36%|███▌      | 850/2382 [2:37:38<4:38:33, 10.91s/it]                                                      {'loss': 2.104, 'learning_rate': 0.0007452741291812814, 'epoch': 0.36}
 36%|███▌      | 850/2382 [2:37:38<4:38:33, 10.91s/it] 36%|███▌      | 851/2382 [2:37:51<4:52:56, 11.48s/it]                                                      {'loss': 2.0128, 'learning_rate': 0.0007446813423829233, 'epoch': 0.36}
 36%|███▌      | 851/2382 [2:37:51<4:52:56, 11.48s/it] 36%|███▌      | 852/2382 [2:38:01<4:45:16, 11.19s/it]                                                      {'loss': 2.0017, 'learning_rate': 0.0007440881030241406, 'epoch': 0.36}
 36%|███▌      | 852/2382 [2:38:01<4:45:16, 11.19s/it] 36%|███▌      | 853/2382 [2:38:12<4:38:48, 10.94s/it]                                                      {'loss': 1.9629, 'learning_rate': 0.0007434944122021837, 'epoch': 0.36}
 36%|███▌      | 853/2382 [2:38:12<4:38:48, 10.94s/it] 36%|███▌      | 854/2382 [2:38:24<4:52:16, 11.48s/it]                                                      {'loss': 2.091, 'learning_rate': 0.0007429002710151375, 'epoch': 0.36}
 36%|███▌      | 854/2382 [2:38:24<4:52:16, 11.48s/it] 36%|███▌      | 855/2382 [2:38:34<4:35:36, 10.83s/it]                                                      {'loss': 2.0791, 'learning_rate': 0.0007423056805619206, 'epoch': 0.36}
 36%|███▌      | 855/2382 [2:38:34<4:35:36, 10.83s/it] 36%|███▌      | 856/2382 [2:38:45<4:38:35, 10.95s/it]                                                      {'loss': 2.1374, 'learning_rate': 0.0007417106419422819, 'epoch': 0.36}
 36%|███▌      | 856/2382 [2:38:45<4:38:35, 10.95s/it] 36%|███▌      | 857/2382 [2:38:58<4:56:37, 11.67s/it]                                                      {'loss': 2.0003, 'learning_rate': 0.0007411151562567998, 'epoch': 0.36}
 36%|███▌      | 857/2382 [2:38:58<4:56:37, 11.67s/it] 36%|███▌      | 858/2382 [2:39:07<4:35:30, 10.85s/it]                                                      {'loss': 2.1315, 'learning_rate': 0.000740519224606879, 'epoch': 0.36}
 36%|███▌      | 858/2382 [2:39:07<4:35:30, 10.85s/it] 36%|███▌      | 859/2382 [2:39:17<4:25:58, 10.48s/it]                                                      {'loss': 2.106, 'learning_rate': 0.0007399228480947495, 'epoch': 0.36}
 36%|███▌      | 859/2382 [2:39:17<4:25:58, 10.48s/it] 36%|███▌      | 860/2382 [2:39:26<4:19:16, 10.22s/it]                                                      {'loss': 2.0482, 'learning_rate': 0.0007393260278234641, 'epoch': 0.36}
 36%|███▌      | 860/2382 [2:39:26<4:19:16, 10.22s/it] 36%|███▌      | 861/2382 [2:39:38<4:28:19, 10.58s/it]                                                      {'loss': 2.0305, 'learning_rate': 0.000738728764896896, 'epoch': 0.36}
 36%|███▌      | 861/2382 [2:39:38<4:28:19, 10.58s/it] 36%|███▌      | 862/2382 [2:39:49<4:32:04, 10.74s/it]                                                      {'loss': 2.1124, 'learning_rate': 0.0007381310604197374, 'epoch': 0.36}
 36%|███▌      | 862/2382 [2:39:49<4:32:04, 10.74s/it] 36%|███▌      | 863/2382 [2:40:01<4:41:53, 11.13s/it]                                                      {'loss': 2.1253, 'learning_rate': 0.0007375329154974975, 'epoch': 0.36}
 36%|███▌      | 863/2382 [2:40:01<4:41:53, 11.13s/it] 36%|███▋      | 864/2382 [2:40:14<4:55:10, 11.67s/it]                                                      {'loss': 2.0507, 'learning_rate': 0.0007369343312364993, 'epoch': 0.36}
 36%|███▋      | 864/2382 [2:40:14<4:55:10, 11.67s/it] 36%|███▋      | 865/2382 [2:40:24<4:44:13, 11.24s/it]                                                      {'loss': 1.9515, 'learning_rate': 0.0007363353087438792, 'epoch': 0.36}
 36%|███▋      | 865/2382 [2:40:24<4:44:13, 11.24s/it] 36%|███▋      | 866/2382 [2:40:35<4:44:01, 11.24s/it]                                                      {'loss': 2.021, 'learning_rate': 0.000735735849127584, 'epoch': 0.36}
 36%|███▋      | 866/2382 [2:40:35<4:44:01, 11.24s/it] 36%|███▋      | 867/2382 [2:40:47<4:49:24, 11.46s/it]                                                      {'loss': 2.0447, 'learning_rate': 0.0007351359534963684, 'epoch': 0.36}
 36%|███▋      | 867/2382 [2:40:47<4:49:24, 11.46s/it] 36%|███▋      | 868/2382 [2:40:58<4:43:31, 11.24s/it]                                                      {'loss': 2.0664, 'learning_rate': 0.0007345356229597943, 'epoch': 0.36}
 36%|███▋      | 868/2382 [2:40:58<4:43:31, 11.24s/it] 36%|███▋      | 869/2382 [2:41:11<4:54:58, 11.70s/it]                                                      {'loss': 2.1616, 'learning_rate': 0.0007339348586282278, 'epoch': 0.36}
 36%|███▋      | 869/2382 [2:41:11<4:54:58, 11.70s/it] 37%|███▋      | 870/2382 [2:41:21<4:40:45, 11.14s/it]                                                      {'loss': 2.0001, 'learning_rate': 0.0007333336616128369, 'epoch': 0.37}
 37%|███▋      | 870/2382 [2:41:21<4:40:45, 11.14s/it] 37%|███▋      | 871/2382 [2:41:31<4:30:55, 10.76s/it]                                                      {'loss': 2.1727, 'learning_rate': 0.0007327320330255904, 'epoch': 0.37}
 37%|███▋      | 871/2382 [2:41:31<4:30:55, 10.76s/it] 37%|███▋      | 872/2382 [2:41:42<4:35:51, 10.96s/it]                                                      {'loss': 2.0872, 'learning_rate': 0.0007321299739792553, 'epoch': 0.37}
 37%|███▋      | 872/2382 [2:41:42<4:35:51, 10.96s/it] 37%|███▋      | 873/2382 [2:41:50<4:14:42, 10.13s/it]                                                      {'loss': 2.0238, 'learning_rate': 0.0007315274855873943, 'epoch': 0.37}
 37%|███▋      | 873/2382 [2:41:50<4:14:42, 10.13s/it] 37%|███▋      | 874/2382 [2:42:03<4:32:25, 10.84s/it]                                                      {'loss': 1.9617, 'learning_rate': 0.000730924568964365, 'epoch': 0.37}
 37%|███▋      | 874/2382 [2:42:03<4:32:25, 10.84s/it] 37%|███▋      | 875/2382 [2:42:15<4:43:44, 11.30s/it]                                                      {'loss': 1.8922, 'learning_rate': 0.0007303212252253162, 'epoch': 0.37}
 37%|███▋      | 875/2382 [2:42:15<4:43:44, 11.30s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1362 > 1024). Running this sequence through the model will result in indexing errors
 37%|███▋      | 876/2382 [2:42:27<4:51:28, 11.61s/it]                                                      {'loss': 2.1423, 'learning_rate': 0.0007297174554861871, 'epoch': 0.37}
 37%|███▋      | 876/2382 [2:42:27<4:51:28, 11.61s/it] 37%|███▋      | 877/2382 [2:42:37<4:38:37, 11.11s/it]                                                      {'loss': 2.0802, 'learning_rate': 0.0007291132608637052, 'epoch': 0.37}
 37%|███▋      | 877/2382 [2:42:37<4:38:37, 11.11s/it] 37%|███▋      | 878/2382 [2:42:49<4:45:34, 11.39s/it]                                                      {'loss': 1.9817, 'learning_rate': 0.0007285086424753832, 'epoch': 0.37}
 37%|███▋      | 878/2382 [2:42:49<4:45:34, 11.39s/it] 37%|███▋      | 879/2382 [2:42:59<4:28:15, 10.71s/it]                                                      {'loss': 2.1481, 'learning_rate': 0.0007279036014395178, 'epoch': 0.37}
 37%|███▋      | 879/2382 [2:42:59<4:28:15, 10.71s/it] 37%|███▋      | 880/2382 [2:43:09<4:23:04, 10.51s/it]                                                      {'loss': 1.9633, 'learning_rate': 0.0007272981388751875, 'epoch': 0.37}
 37%|███▋      | 880/2382 [2:43:09<4:23:04, 10.51s/it] 37%|███▋      | 881/2382 [2:43:21<4:40:30, 11.21s/it]                                                      {'loss': 2.0049, 'learning_rate': 0.0007266922559022506, 'epoch': 0.37}
 37%|███▋      | 881/2382 [2:43:21<4:40:30, 11.21s/it] 37%|███▋      | 882/2382 [2:43:33<4:41:03, 11.24s/it]                                                      {'loss': 2.1376, 'learning_rate': 0.0007260859536413429, 'epoch': 0.37}
 37%|███▋      | 882/2382 [2:43:33<4:41:03, 11.24s/it] 37%|███▋      | 883/2382 [2:43:42<4:29:35, 10.79s/it]                                                      {'loss': 2.0647, 'learning_rate': 0.0007254792332138753, 'epoch': 0.37}
 37%|███▋      | 883/2382 [2:43:42<4:29:35, 10.79s/it] 37%|███▋      | 884/2382 [2:43:54<4:33:27, 10.95s/it]                                                      {'loss': 1.9779, 'learning_rate': 0.0007248720957420329, 'epoch': 0.37}
 37%|███▋      | 884/2382 [2:43:54<4:33:27, 10.95s/it] 37%|███▋      | 885/2382 [2:44:06<4:41:16, 11.27s/it]                                                      {'loss': 2.007, 'learning_rate': 0.0007242645423487714, 'epoch': 0.37}
 37%|███▋      | 885/2382 [2:44:06<4:41:16, 11.27s/it] 37%|███▋      | 886/2382 [2:44:17<4:37:04, 11.11s/it]                                                      {'loss': 2.0179, 'learning_rate': 0.0007236565741578163, 'epoch': 0.37}
 37%|███▋      | 886/2382 [2:44:17<4:37:04, 11.11s/it] 37%|███▋      | 887/2382 [2:44:28<4:42:15, 11.33s/it]                                                      {'loss': 2.0198, 'learning_rate': 0.0007230481922936602, 'epoch': 0.37}
 37%|███▋      | 887/2382 [2:44:28<4:42:15, 11.33s/it] 37%|███▋      | 888/2382 [2:44:39<4:38:52, 11.20s/it]                                                      {'loss': 2.0377, 'learning_rate': 0.0007224393978815604, 'epoch': 0.37}
 37%|███▋      | 888/2382 [2:44:39<4:38:52, 11.20s/it] 37%|███▋      | 889/2382 [2:44:50<4:33:03, 10.97s/it]                                                      {'loss': 2.0802, 'learning_rate': 0.000721830192047538, 'epoch': 0.37}
 37%|███▋      | 889/2382 [2:44:50<4:33:03, 10.97s/it] 37%|███▋      | 890/2382 [2:45:01<4:31:49, 10.93s/it]                                                      {'loss': 2.0288, 'learning_rate': 0.0007212205759183748, 'epoch': 0.37}
 37%|███▋      | 890/2382 [2:45:01<4:31:49, 10.93s/it] 37%|███▋      | 891/2382 [2:45:11<4:25:00, 10.66s/it]                                                      {'loss': 2.0578, 'learning_rate': 0.0007206105506216106, 'epoch': 0.37}
 37%|███▋      | 891/2382 [2:45:11<4:25:00, 10.66s/it] 37%|███▋      | 892/2382 [2:45:21<4:24:37, 10.66s/it]                                                      {'loss': 2.1835, 'learning_rate': 0.0007200001172855435, 'epoch': 0.37}
 37%|███▋      | 892/2382 [2:45:21<4:24:37, 10.66s/it] 37%|███▋      | 893/2382 [2:45:33<4:35:51, 11.12s/it]                                                      {'loss': 1.9715, 'learning_rate': 0.0007193892770392252, 'epoch': 0.37}
 37%|███▋      | 893/2382 [2:45:33<4:35:51, 11.12s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1157 > 1024). Running this sequence through the model will result in indexing errors
 38%|███▊      | 894/2382 [2:45:43<4:22:33, 10.59s/it]                                                      {'loss': 2.1228, 'learning_rate': 0.0007187780310124604, 'epoch': 0.38}
 38%|███▊      | 894/2382 [2:45:43<4:22:33, 10.59s/it] 38%|███▊      | 895/2382 [2:45:52<4:13:07, 10.21s/it]                                                      {'loss': 2.1054, 'learning_rate': 0.0007181663803358043, 'epoch': 0.38}
 38%|███▊      | 895/2382 [2:45:52<4:13:07, 10.21s/it] 38%|███▊      | 896/2382 [2:46:04<4:22:02, 10.58s/it]                                                      {'loss': 2.0326, 'learning_rate': 0.0007175543261405607, 'epoch': 0.38}
 38%|███▊      | 896/2382 [2:46:04<4:22:02, 10.58s/it] 38%|███▊      | 897/2382 [2:46:16<4:36:03, 11.15s/it]                                                      {'loss': 2.0339, 'learning_rate': 0.0007169418695587791, 'epoch': 0.38}
 38%|███▊      | 897/2382 [2:46:16<4:36:03, 11.15s/it] 38%|███▊      | 898/2382 [2:46:27<4:37:24, 11.22s/it]                                                      {'loss': 2.0766, 'learning_rate': 0.0007163290117232541, 'epoch': 0.38}
 38%|███▊      | 898/2382 [2:46:27<4:37:24, 11.22s/it] 38%|███▊      | 899/2382 [2:46:38<4:34:45, 11.12s/it]                                                      {'loss': 1.9438, 'learning_rate': 0.000715715753767522, 'epoch': 0.38}
 38%|███▊      | 899/2382 [2:46:38<4:34:45, 11.12s/it] 38%|███▊      | 900/2382 [2:46:50<4:35:11, 11.14s/it]                                                      {'loss': 2.0055, 'learning_rate': 0.0007151020968258595, 'epoch': 0.38}
 38%|███▊      | 900/2382 [2:46:50<4:35:11, 11.14s/it] 38%|███▊      | 901/2382 [2:47:00<4:32:20, 11.03s/it]                                                      {'loss': 2.0174, 'learning_rate': 0.0007144880420332804, 'epoch': 0.38}
 38%|███▊      | 901/2382 [2:47:00<4:32:20, 11.03s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1044 > 1024). Running this sequence through the model will result in indexing errors
 38%|███▊      | 902/2382 [2:47:11<4:26:55, 10.82s/it]                                                      {'loss': 2.1055, 'learning_rate': 0.0007138735905255354, 'epoch': 0.38}
 38%|███▊      | 902/2382 [2:47:11<4:26:55, 10.82s/it] 38%|███▊      | 903/2382 [2:47:20<4:19:25, 10.52s/it]                                                      {'loss': 2.068, 'learning_rate': 0.0007132587434391086, 'epoch': 0.38}
 38%|███▊      | 903/2382 [2:47:20<4:19:25, 10.52s/it] 38%|███▊      | 904/2382 [2:47:31<4:18:32, 10.50s/it]                                                      {'loss': 2.0371, 'learning_rate': 0.0007126435019112152, 'epoch': 0.38}
 38%|███▊      | 904/2382 [2:47:31<4:18:32, 10.50s/it] 38%|███▊      | 905/2382 [2:47:42<4:24:46, 10.76s/it]                                                      {'loss': 2.0852, 'learning_rate': 0.0007120278670798009, 'epoch': 0.38}
 38%|███▊      | 905/2382 [2:47:42<4:24:46, 10.76s/it] 38%|███▊      | 906/2382 [2:47:53<4:26:07, 10.82s/it]                                                      {'loss': 2.1592, 'learning_rate': 0.0007114118400835381, 'epoch': 0.38}
 38%|███▊      | 906/2382 [2:47:53<4:26:07, 10.82s/it] 38%|███▊      | 907/2382 [2:48:03<4:17:27, 10.47s/it]                                                      {'loss': 2.0691, 'learning_rate': 0.000710795422061825, 'epoch': 0.38}
 38%|███▊      | 907/2382 [2:48:03<4:17:27, 10.47s/it] 38%|███▊      | 908/2382 [2:48:14<4:25:24, 10.80s/it]                                                      {'loss': 2.0259, 'learning_rate': 0.0007101786141547828, 'epoch': 0.38}
 38%|███▊      | 908/2382 [2:48:14<4:25:24, 10.80s/it] 38%|███▊      | 909/2382 [2:48:29<4:52:01, 11.90s/it]                                                      {'loss': 2.1566, 'learning_rate': 0.0007095614175032539, 'epoch': 0.38}
 38%|███▊      | 909/2382 [2:48:29<4:52:01, 11.90s/it] 38%|███▊      | 910/2382 [2:48:43<5:06:01, 12.47s/it]                                                      {'loss': 2.0408, 'learning_rate': 0.0007089438332487997, 'epoch': 0.38}
 38%|███▊      | 910/2382 [2:48:43<5:06:01, 12.47s/it] 38%|███▊      | 911/2382 [2:48:55<5:03:39, 12.39s/it]                                                      {'loss': 2.0468, 'learning_rate': 0.0007083258625336983, 'epoch': 0.38}
 38%|███▊      | 911/2382 [2:48:55<5:03:39, 12.39s/it] 38%|███▊      | 912/2382 [2:49:07<5:01:33, 12.31s/it]                                                      {'loss': 2.274, 'learning_rate': 0.0007077075065009433, 'epoch': 0.38}
 38%|███▊      | 912/2382 [2:49:07<5:01:33, 12.31s/it] 38%|███▊      | 913/2382 [2:49:18<4:50:20, 11.86s/it]                                                      {'loss': 1.9998, 'learning_rate': 0.0007070887662942401, 'epoch': 0.38}
 38%|███▊      | 913/2382 [2:49:18<4:50:20, 11.86s/it] 38%|███▊      | 914/2382 [2:49:29<4:47:24, 11.75s/it]                                                      {'loss': 2.0333, 'learning_rate': 0.0007064696430580051, 'epoch': 0.38}
 38%|███▊      | 914/2382 [2:49:29<4:47:24, 11.75s/it] 38%|███▊      | 915/2382 [2:49:38<4:25:36, 10.86s/it]                                                      {'loss': 2.0954, 'learning_rate': 0.0007058501379373634, 'epoch': 0.38}
 38%|███▊      | 915/2382 [2:49:38<4:25:36, 10.86s/it] 38%|███▊      | 916/2382 [2:49:50<4:32:48, 11.17s/it]                                                      {'loss': 2.0374, 'learning_rate': 0.0007052302520781458, 'epoch': 0.38}
 38%|███▊      | 916/2382 [2:49:50<4:32:48, 11.17s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1414 > 1024). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (1168 > 1024). Running this sequence through the model will result in indexing errors
 38%|███▊      | 917/2382 [2:50:00<4:23:58, 10.81s/it]                                                      {'loss': 2.1308, 'learning_rate': 0.0007046099866268877, 'epoch': 0.38}
 38%|███▊      | 917/2382 [2:50:00<4:23:58, 10.81s/it] 39%|███▊      | 918/2382 [2:50:14<4:47:19, 11.78s/it]                                                      {'loss': 2.0781, 'learning_rate': 0.0007039893427308268, 'epoch': 0.39}
 39%|███▊      | 918/2382 [2:50:14<4:47:19, 11.78s/it] 39%|███▊      | 919/2382 [2:50:27<4:54:34, 12.08s/it]                                                      {'loss': 2.0638, 'learning_rate': 0.0007033683215379002, 'epoch': 0.39}
 39%|███▊      | 919/2382 [2:50:27<4:54:34, 12.08s/it] 39%|███▊      | 920/2382 [2:50:38<4:48:39, 11.85s/it]                                                      {'loss': 2.0358, 'learning_rate': 0.0007027469241967432, 'epoch': 0.39}
 39%|███▊      | 920/2382 [2:50:38<4:48:39, 11.85s/it] 39%|███▊      | 921/2382 [2:50:46<4:21:15, 10.73s/it]                                                      {'loss': 2.2369, 'learning_rate': 0.0007021251518566868, 'epoch': 0.39}
 39%|███▊      | 921/2382 [2:50:46<4:21:15, 10.73s/it] 39%|███▊      | 922/2382 [2:50:56<4:15:58, 10.52s/it]                                                      {'loss': 2.0876, 'learning_rate': 0.0007015030056677558, 'epoch': 0.39}
 39%|███▊      | 922/2382 [2:50:56<4:15:58, 10.52s/it] 39%|███▊      | 923/2382 [2:51:08<4:25:32, 10.92s/it]                                                      {'loss': 2.2419, 'learning_rate': 0.0007008804867806659, 'epoch': 0.39}
 39%|███▊      | 923/2382 [2:51:08<4:25:32, 10.92s/it] 39%|███▉      | 924/2382 [2:51:20<4:32:23, 11.21s/it]                                                      {'loss': 2.1247, 'learning_rate': 0.0007002575963468225, 'epoch': 0.39}
 39%|███▉      | 924/2382 [2:51:20<4:32:23, 11.21s/it] 39%|███▉      | 925/2382 [2:51:31<4:34:11, 11.29s/it]                                                      {'loss': 2.1193, 'learning_rate': 0.0006996343355183185, 'epoch': 0.39}
 39%|███▉      | 925/2382 [2:51:31<4:34:11, 11.29s/it] 39%|███▉      | 926/2382 [2:51:40<4:15:55, 10.55s/it]                                                      {'loss': 2.0584, 'learning_rate': 0.0006990107054479312, 'epoch': 0.39}
 39%|███▉      | 926/2382 [2:51:40<4:15:55, 10.55s/it] 39%|███▉      | 927/2382 [2:51:52<4:22:51, 10.84s/it]                                                      {'loss': 2.0792, 'learning_rate': 0.0006983867072891212, 'epoch': 0.39}
 39%|███▉      | 927/2382 [2:51:52<4:22:51, 10.84s/it] 39%|███▉      | 928/2382 [2:52:02<4:14:40, 10.51s/it]                                                      {'loss': 2.0787, 'learning_rate': 0.0006977623421960303, 'epoch': 0.39}
 39%|███▉      | 928/2382 [2:52:02<4:14:40, 10.51s/it] 39%|███▉      | 929/2382 [2:52:14<4:29:54, 11.15s/it]                                                      {'loss': 2.0435, 'learning_rate': 0.0006971376113234782, 'epoch': 0.39}
 39%|███▉      | 929/2382 [2:52:14<4:29:54, 11.15s/it] 39%|███▉      | 930/2382 [2:52:26<4:34:44, 11.35s/it]                                                      {'loss': 2.2136, 'learning_rate': 0.0006965125158269618, 'epoch': 0.39}
 39%|███▉      | 930/2382 [2:52:26<4:34:44, 11.35s/it] 39%|███▉      | 931/2382 [2:52:35<4:16:41, 10.61s/it]                                                      {'loss': 2.1777, 'learning_rate': 0.0006958870568626521, 'epoch': 0.39}
 39%|███▉      | 931/2382 [2:52:35<4:16:41, 10.61s/it] 39%|███▉      | 932/2382 [2:52:46<4:23:17, 10.89s/it]                                                      {'loss': 2.1985, 'learning_rate': 0.0006952612355873922, 'epoch': 0.39}
 39%|███▉      | 932/2382 [2:52:46<4:23:17, 10.89s/it] 39%|███▉      | 933/2382 [2:53:03<5:02:23, 12.52s/it]                                                      {'loss': 2.0446, 'learning_rate': 0.0006946350531586958, 'epoch': 0.39}
 39%|███▉      | 933/2382 [2:53:03<5:02:23, 12.52s/it] 39%|███▉      | 934/2382 [2:53:14<4:53:41, 12.17s/it]                                                      {'loss': 2.0272, 'learning_rate': 0.0006940085107347443, 'epoch': 0.39}
 39%|███▉      | 934/2382 [2:53:14<4:53:41, 12.17s/it] 39%|███▉      | 935/2382 [2:53:24<4:40:15, 11.62s/it]                                                      {'loss': 1.9522, 'learning_rate': 0.0006933816094743846, 'epoch': 0.39}
 39%|███▉      | 935/2382 [2:53:24<4:40:15, 11.62s/it] 39%|███▉      | 936/2382 [2:53:37<4:48:49, 11.98s/it]                                                      {'loss': 2.0511, 'learning_rate': 0.0006927543505371281, 'epoch': 0.39}
 39%|███▉      | 936/2382 [2:53:37<4:48:49, 11.98s/it] 39%|███▉      | 937/2382 [2:53:48<4:41:09, 11.67s/it]                                                      {'loss': 2.0091, 'learning_rate': 0.0006921267350831473, 'epoch': 0.39}
 39%|███▉      | 937/2382 [2:53:48<4:41:09, 11.67s/it] 39%|███▉      | 938/2382 [2:53:58<4:23:56, 10.97s/it]                                                      {'loss': 2.0434, 'learning_rate': 0.0006914987642732738, 'epoch': 0.39}
 39%|███▉      | 938/2382 [2:53:58<4:23:56, 10.97s/it] 39%|███▉      | 939/2382 [2:54:07<4:15:13, 10.61s/it]                                                      {'loss': 2.0485, 'learning_rate': 0.0006908704392689972, 'epoch': 0.39}
 39%|███▉      | 939/2382 [2:54:07<4:15:13, 10.61s/it] 39%|███▉      | 940/2382 [2:54:16<4:00:42, 10.02s/it]                                                      {'loss': 2.1289, 'learning_rate': 0.0006902417612324615, 'epoch': 0.39}
 39%|███▉      | 940/2382 [2:54:16<4:00:42, 10.02s/it] 40%|███▉      | 941/2382 [2:54:27<4:11:23, 10.47s/it]                                                      {'loss': 2.119, 'learning_rate': 0.0006896127313264643, 'epoch': 0.39}
 40%|███▉      | 941/2382 [2:54:27<4:11:23, 10.47s/it] 40%|███▉      | 942/2382 [2:54:38<4:08:47, 10.37s/it]                                                      {'loss': 2.1267, 'learning_rate': 0.0006889833507144532, 'epoch': 0.4}
 40%|███▉      | 942/2382 [2:54:38<4:08:47, 10.37s/it] 40%|███▉      | 943/2382 [2:54:47<4:03:10, 10.14s/it]                                                      {'loss': 2.0637, 'learning_rate': 0.0006883536205605255, 'epoch': 0.4}
 40%|███▉      | 943/2382 [2:54:47<4:03:10, 10.14s/it] 40%|███▉      | 944/2382 [2:55:00<4:25:10, 11.06s/it]                                                      {'loss': 1.9883, 'learning_rate': 0.0006877235420294244, 'epoch': 0.4}
 40%|███▉      | 944/2382 [2:55:00<4:25:10, 11.06s/it] 40%|███▉      | 945/2382 [2:55:12<4:30:38, 11.30s/it]                                                      {'loss': 1.9665, 'learning_rate': 0.0006870931162865369, 'epoch': 0.4}
 40%|███▉      | 945/2382 [2:55:12<4:30:38, 11.30s/it] 40%|███▉      | 946/2382 [2:55:24<4:35:29, 11.51s/it]                                                      {'loss': 2.0407, 'learning_rate': 0.0006864623444978934, 'epoch': 0.4}
 40%|███▉      | 946/2382 [2:55:24<4:35:29, 11.51s/it] 40%|███▉      | 947/2382 [2:55:35<4:28:50, 11.24s/it]                                                      {'loss': 2.0557, 'learning_rate': 0.0006858312278301637, 'epoch': 0.4}
 40%|███▉      | 947/2382 [2:55:35<4:28:50, 11.24s/it] 40%|███▉      | 948/2382 [2:55:45<4:20:58, 10.92s/it]                                                      {'loss': 2.0995, 'learning_rate': 0.0006851997674506556, 'epoch': 0.4}
 40%|███▉      | 948/2382 [2:55:45<4:20:58, 10.92s/it] 40%|███▉      | 949/2382 [2:55:55<4:15:36, 10.70s/it]                                                      {'loss': 1.9819, 'learning_rate': 0.0006845679645273124, 'epoch': 0.4}
 40%|███▉      | 949/2382 [2:55:55<4:15:36, 10.70s/it] 40%|███▉      | 950/2382 [2:56:06<4:15:14, 10.69s/it]                                                      {'loss': 2.0479, 'learning_rate': 0.000683935820228711, 'epoch': 0.4}
 40%|███▉      | 950/2382 [2:56:06<4:15:14, 10.69s/it] 40%|███▉      | 951/2382 [2:56:16<4:08:27, 10.42s/it]                                                      {'loss': 2.0431, 'learning_rate': 0.0006833033357240602, 'epoch': 0.4}
 40%|███▉      | 951/2382 [2:56:16<4:08:27, 10.42s/it] 40%|███▉      | 952/2382 [2:56:26<4:08:22, 10.42s/it]                                                      {'loss': 2.0855, 'learning_rate': 0.0006826705121831977, 'epoch': 0.4}
 40%|███▉      | 952/2382 [2:56:26<4:08:22, 10.42s/it] 40%|████      | 953/2382 [2:56:35<3:59:29, 10.06s/it]                                                      {'loss': 2.1076, 'learning_rate': 0.0006820373507765878, 'epoch': 0.4}
 40%|████      | 953/2382 [2:56:35<3:59:29, 10.06s/it] 40%|████      | 954/2382 [2:56:50<4:33:07, 11.48s/it]                                                      {'loss': 2.0295, 'learning_rate': 0.0006814038526753205, 'epoch': 0.4}
 40%|████      | 954/2382 [2:56:50<4:33:07, 11.48s/it] 40%|████      | 955/2382 [2:57:03<4:39:39, 11.76s/it]                                                      {'loss': 1.9871, 'learning_rate': 0.0006807700190511084, 'epoch': 0.4}
 40%|████      | 955/2382 [2:57:03<4:39:39, 11.76s/it] 40%|████      | 956/2382 [2:57:15<4:45:06, 12.00s/it]                                                      {'loss': 2.0437, 'learning_rate': 0.0006801358510762842, 'epoch': 0.4}
 40%|████      | 956/2382 [2:57:15<4:45:06, 12.00s/it] 40%|████      | 957/2382 [2:57:26<4:35:39, 11.61s/it]                                                      {'loss': 2.1507, 'learning_rate': 0.0006795013499237994, 'epoch': 0.4}
 40%|████      | 957/2382 [2:57:26<4:35:39, 11.61s/it] 40%|████      | 958/2382 [2:57:39<4:43:45, 11.96s/it]                                                      {'loss': 2.0423, 'learning_rate': 0.0006788665167672217, 'epoch': 0.4}
 40%|████      | 958/2382 [2:57:39<4:43:45, 11.96s/it] 40%|████      | 959/2382 [2:57:51<4:43:27, 11.95s/it]                                                      {'loss': 1.9781, 'learning_rate': 0.0006782313527807329, 'epoch': 0.4}
 40%|████      | 959/2382 [2:57:51<4:43:27, 11.95s/it] 40%|████      | 960/2382 [2:58:02<4:41:29, 11.88s/it]                                                      {'loss': 2.0942, 'learning_rate': 0.0006775958591391265, 'epoch': 0.4}
 40%|████      | 960/2382 [2:58:02<4:41:29, 11.88s/it] 40%|████      | 961/2382 [2:58:14<4:38:26, 11.76s/it]                                                      {'loss': 2.014, 'learning_rate': 0.0006769600370178059, 'epoch': 0.4}
 40%|████      | 961/2382 [2:58:14<4:38:26, 11.76s/it] 40%|████      | 962/2382 [2:58:24<4:29:49, 11.40s/it]                                                      {'loss': 2.0448, 'learning_rate': 0.0006763238875927822, 'epoch': 0.4}
 40%|████      | 962/2382 [2:58:24<4:29:49, 11.40s/it] 40%|████      | 963/2382 [2:58:34<4:17:14, 10.88s/it]                                                      {'loss': 2.0619, 'learning_rate': 0.0006756874120406714, 'epoch': 0.4}
 40%|████      | 963/2382 [2:58:34<4:17:14, 10.88s/it] 40%|████      | 964/2382 [2:58:44<4:12:25, 10.68s/it]                                                      {'loss': 1.9759, 'learning_rate': 0.0006750506115386932, 'epoch': 0.4}
 40%|████      | 964/2382 [2:58:44<4:12:25, 10.68s/it] 41%|████      | 965/2382 [2:58:55<4:10:46, 10.62s/it]                                                      {'loss': 2.1137, 'learning_rate': 0.0006744134872646679, 'epoch': 0.4}
 41%|████      | 965/2382 [2:58:55<4:10:46, 10.62s/it] 41%|████      | 966/2382 [2:59:04<3:59:50, 10.16s/it]                                                      {'loss': 2.0467, 'learning_rate': 0.0006737760403970151, 'epoch': 0.41}
 41%|████      | 966/2382 [2:59:04<3:59:50, 10.16s/it] 41%|████      | 967/2382 [2:59:15<4:05:02, 10.39s/it]                                                      {'loss': 2.1572, 'learning_rate': 0.0006731382721147509, 'epoch': 0.41}
 41%|████      | 967/2382 [2:59:15<4:05:02, 10.39s/it] 41%|████      | 968/2382 [2:59:26<4:12:51, 10.73s/it]                                                      {'loss': 2.0317, 'learning_rate': 0.0006725001835974853, 'epoch': 0.41}
 41%|████      | 968/2382 [2:59:26<4:12:51, 10.73s/it] 41%|████      | 969/2382 [2:59:38<4:21:17, 11.10s/it]                                                      {'loss': 2.0469, 'learning_rate': 0.0006718617760254216, 'epoch': 0.41}
 41%|████      | 969/2382 [2:59:38<4:21:17, 11.10s/it] 41%|████      | 970/2382 [2:59:49<4:21:15, 11.10s/it]                                                      {'loss': 2.042, 'learning_rate': 0.0006712230505793529, 'epoch': 0.41}
 41%|████      | 970/2382 [2:59:49<4:21:15, 11.10s/it] 41%|████      | 971/2382 [2:59:59<4:13:47, 10.79s/it]                                                      {'loss': 2.0242, 'learning_rate': 0.0006705840084406595, 'epoch': 0.41}
 41%|████      | 971/2382 [2:59:59<4:13:47, 10.79s/it] 41%|████      | 972/2382 [3:00:12<4:29:02, 11.45s/it]                                                      {'loss': 2.1383, 'learning_rate': 0.0006699446507913083, 'epoch': 0.41}
 41%|████      | 972/2382 [3:00:12<4:29:02, 11.45s/it] 41%|████      | 973/2382 [3:00:23<4:25:20, 11.30s/it]                                                      {'loss': 2.0778, 'learning_rate': 0.0006693049788138496, 'epoch': 0.41}
 41%|████      | 973/2382 [3:00:23<4:25:20, 11.30s/it] 41%|████      | 974/2382 [3:00:36<4:32:20, 11.61s/it]                                                      {'loss': 1.9722, 'learning_rate': 0.0006686649936914151, 'epoch': 0.41}
 41%|████      | 974/2382 [3:00:36<4:32:20, 11.61s/it] 41%|████      | 975/2382 [3:00:46<4:21:19, 11.14s/it]                                                      {'loss': 2.0204, 'learning_rate': 0.000668024696607715, 'epoch': 0.41}
 41%|████      | 975/2382 [3:00:46<4:21:19, 11.14s/it] 41%|████      | 976/2382 [3:00:56<4:16:03, 10.93s/it]                                                      {'loss': 2.1194, 'learning_rate': 0.0006673840887470377, 'epoch': 0.41}
 41%|████      | 976/2382 [3:00:56<4:16:03, 10.93s/it] 41%|████      | 977/2382 [3:01:07<4:14:40, 10.88s/it]                                                      {'loss': 2.1212, 'learning_rate': 0.0006667431712942453, 'epoch': 0.41}
 41%|████      | 977/2382 [3:01:07<4:14:40, 10.88s/it] 41%|████      | 978/2382 [3:01:18<4:17:25, 11.00s/it]                                                      {'loss': 2.1578, 'learning_rate': 0.0006661019454347733, 'epoch': 0.41}
 41%|████      | 978/2382 [3:01:18<4:17:25, 11.00s/it] 41%|████      | 979/2382 [3:01:31<4:27:17, 11.43s/it]                                                      {'loss': 2.0223, 'learning_rate': 0.0006654604123546273, 'epoch': 0.41}
 41%|████      | 979/2382 [3:01:31<4:27:17, 11.43s/it] 41%|████      | 980/2382 [3:01:42<4:28:01, 11.47s/it]                                                      {'loss': 1.9655, 'learning_rate': 0.0006648185732403809, 'epoch': 0.41}
 41%|████      | 980/2382 [3:01:42<4:28:01, 11.47s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1058 > 1024). Running this sequence through the model will result in indexing errors
 41%|████      | 981/2382 [3:01:52<4:19:13, 11.10s/it]                                                      {'loss': 2.1289, 'learning_rate': 0.0006641764292791742, 'epoch': 0.41}
 41%|████      | 981/2382 [3:01:52<4:19:13, 11.10s/it] 41%|████      | 982/2382 [3:02:03<4:16:37, 11.00s/it]                                                      {'loss': 2.1163, 'learning_rate': 0.0006635339816587109, 'epoch': 0.41}
 41%|████      | 982/2382 [3:02:03<4:16:37, 11.00s/it] 41%|████▏     | 983/2382 [3:02:15<4:21:04, 11.20s/it]                                                      {'loss': 2.0786, 'learning_rate': 0.0006628912315672562, 'epoch': 0.41}
 41%|████▏     | 983/2382 [3:02:15<4:21:04, 11.20s/it] 41%|████▏     | 984/2382 [3:02:26<4:18:09, 11.08s/it]                                                      {'loss': 2.1187, 'learning_rate': 0.0006622481801936353, 'epoch': 0.41}
 41%|████▏     | 984/2382 [3:02:26<4:18:09, 11.08s/it] 41%|████▏     | 985/2382 [3:02:37<4:17:36, 11.06s/it]                                                      {'loss': 2.1887, 'learning_rate': 0.0006616048287272301, 'epoch': 0.41}
 41%|████▏     | 985/2382 [3:02:37<4:17:36, 11.06s/it] 41%|████▏     | 986/2382 [3:02:47<4:09:38, 10.73s/it]                                                      {'loss': 2.0831, 'learning_rate': 0.0006609611783579775, 'epoch': 0.41}
 41%|████▏     | 986/2382 [3:02:47<4:09:38, 10.73s/it] 41%|████▏     | 987/2382 [3:02:59<4:21:43, 11.26s/it]                                                      {'loss': 2.0387, 'learning_rate': 0.0006603172302763677, 'epoch': 0.41}
 41%|████▏     | 987/2382 [3:02:59<4:21:43, 11.26s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1118 > 1024). Running this sequence through the model will result in indexing errors
 41%|████▏     | 988/2382 [3:03:10<4:23:02, 11.32s/it]                                                      {'loss': 2.0569, 'learning_rate': 0.0006596729856734413, 'epoch': 0.41}
 41%|████▏     | 988/2382 [3:03:10<4:23:02, 11.32s/it] 42%|████▏     | 989/2382 [3:03:22<4:26:12, 11.47s/it]                                                      {'loss': 2.0424, 'learning_rate': 0.0006590284457407876, 'epoch': 0.42}
 42%|████▏     | 989/2382 [3:03:22<4:26:12, 11.47s/it] 42%|████▏     | 990/2382 [3:03:34<4:30:28, 11.66s/it]                                                      {'loss': 1.9775, 'learning_rate': 0.0006583836116705413, 'epoch': 0.42}
 42%|████▏     | 990/2382 [3:03:34<4:30:28, 11.66s/it] 42%|████▏     | 991/2382 [3:03:44<4:13:07, 10.92s/it]                                                      {'loss': 2.1185, 'learning_rate': 0.0006577384846553822, 'epoch': 0.42}
 42%|████▏     | 991/2382 [3:03:44<4:13:07, 10.92s/it] 42%|████▏     | 992/2382 [3:03:54<4:07:29, 10.68s/it]                                                      {'loss': 2.0739, 'learning_rate': 0.0006570930658885314, 'epoch': 0.42}
 42%|████▏     | 992/2382 [3:03:54<4:07:29, 10.68s/it] 42%|████▏     | 993/2382 [3:04:03<3:58:32, 10.30s/it]                                                      {'loss': 2.0841, 'learning_rate': 0.0006564473565637494, 'epoch': 0.42}
 42%|████▏     | 993/2382 [3:04:03<3:58:32, 10.30s/it] 42%|████▏     | 994/2382 [3:04:14<4:02:18, 10.47s/it]                                                      {'loss': 2.0802, 'learning_rate': 0.0006558013578753347, 'epoch': 0.42}
 42%|████▏     | 994/2382 [3:04:14<4:02:18, 10.47s/it] 42%|████▏     | 995/2382 [3:04:27<4:22:57, 11.38s/it]                                                      {'loss': 2.0135, 'learning_rate': 0.0006551550710181207, 'epoch': 0.42}
 42%|████▏     | 995/2382 [3:04:27<4:22:57, 11.38s/it] 42%|████▏     | 996/2382 [3:04:37<4:07:53, 10.73s/it]                                                      {'loss': 2.0091, 'learning_rate': 0.0006545084971874737, 'epoch': 0.42}
 42%|████▏     | 996/2382 [3:04:37<4:07:53, 10.73s/it] 42%|████▏     | 997/2382 [3:04:48<4:13:02, 10.96s/it]                                                      {'loss': 2.1257, 'learning_rate': 0.000653861637579291, 'epoch': 0.42}
 42%|████▏     | 997/2382 [3:04:48<4:13:02, 10.96s/it] 42%|████▏     | 998/2382 [3:05:00<4:15:39, 11.08s/it]                                                      {'loss': 1.9784, 'learning_rate': 0.0006532144933899981, 'epoch': 0.42}
 42%|████▏     | 998/2382 [3:05:00<4:15:39, 11.08s/it] 42%|████▏     | 999/2382 [3:05:12<4:22:06, 11.37s/it]                                                      {'loss': 2.004, 'learning_rate': 0.0006525670658165473, 'epoch': 0.42}
 42%|████▏     | 999/2382 [3:05:12<4:22:06, 11.37s/it] 42%|████▏     | 1000/2382 [3:05:22<4:17:34, 11.18s/it]                                                       {'loss': 2.0566, 'learning_rate': 0.0006519193560564149, 'epoch': 0.42}
 42%|████▏     | 1000/2382 [3:05:22<4:17:34, 11.18s/it] 42%|████▏     | 1001/2382 [3:05:32<4:05:35, 10.67s/it]                                                       {'loss': 2.0056, 'learning_rate': 0.0006512713653075988, 'epoch': 0.42}
 42%|████▏     | 1001/2382 [3:05:32<4:05:35, 10.67s/it] 42%|████▏     | 1002/2382 [3:05:42<4:02:22, 10.54s/it]                                                       {'loss': 1.9299, 'learning_rate': 0.0006506230947686171, 'epoch': 0.42}
 42%|████▏     | 1002/2382 [3:05:42<4:02:22, 10.54s/it] 42%|████▏     | 1003/2382 [3:05:54<4:11:51, 10.96s/it]                                                       {'loss': 2.0432, 'learning_rate': 0.0006499745456385053, 'epoch': 0.42}
 42%|████▏     | 1003/2382 [3:05:54<4:11:51, 10.96s/it] 42%|████▏     | 1004/2382 [3:06:07<4:24:31, 11.52s/it]                                                       {'loss': 2.1102, 'learning_rate': 0.000649325719116814, 'epoch': 0.42}
 42%|████▏     | 1004/2382 [3:06:07<4:24:31, 11.52s/it] 42%|████▏     | 1005/2382 [3:06:17<4:18:18, 11.26s/it]                                                       {'loss': 2.0136, 'learning_rate': 0.0006486766164036069, 'epoch': 0.42}
 42%|████▏     | 1005/2382 [3:06:17<4:18:18, 11.26s/it] 42%|████▏     | 1006/2382 [3:06:28<4:15:28, 11.14s/it]                                                       {'loss': 1.9856, 'learning_rate': 0.0006480272386994585, 'epoch': 0.42}
 42%|████▏     | 1006/2382 [3:06:28<4:15:28, 11.14s/it] 42%|████▏     | 1007/2382 [3:06:38<4:03:12, 10.61s/it]                                                       {'loss': 2.0937, 'learning_rate': 0.0006473775872054521, 'epoch': 0.42}
 42%|████▏     | 1007/2382 [3:06:38<4:03:12, 10.61s/it] 42%|████▏     | 1008/2382 [3:06:46<3:48:23,  9.97s/it]                                                       {'loss': 2.0717, 'learning_rate': 0.0006467276631231773, 'epoch': 0.42}
 42%|████▏     | 1008/2382 [3:06:46<3:48:23,  9.97s/it] 42%|████▏     | 1009/2382 [3:06:58<4:00:11, 10.50s/it]                                                       {'loss': 2.0875, 'learning_rate': 0.000646077467654728, 'epoch': 0.42}
 42%|████▏     | 1009/2382 [3:06:58<4:00:11, 10.50s/it] 42%|████▏     | 1010/2382 [3:07:09<4:00:56, 10.54s/it]                                                       {'loss': 2.091, 'learning_rate': 0.0006454270020026995, 'epoch': 0.42}
 42%|████▏     | 1010/2382 [3:07:09<4:00:56, 10.54s/it] 42%|████▏     | 1011/2382 [3:07:22<4:22:15, 11.48s/it]                                                       {'loss': 2.03, 'learning_rate': 0.0006447762673701878, 'epoch': 0.42}
 42%|████▏     | 1011/2382 [3:07:22<4:22:15, 11.48s/it] 42%|████▏     | 1012/2382 [3:07:32<4:06:58, 10.82s/it]                                                       {'loss': 2.0992, 'learning_rate': 0.0006441252649607855, 'epoch': 0.42}
 42%|████▏     | 1012/2382 [3:07:32<4:06:58, 10.82s/it] 43%|████▎     | 1013/2382 [3:07:42<4:06:30, 10.80s/it]                                                       {'loss': 2.1102, 'learning_rate': 0.000643473995978581, 'epoch': 0.43}
 43%|████▎     | 1013/2382 [3:07:42<4:06:30, 10.80s/it] 43%|████▎     | 1014/2382 [3:07:53<4:07:25, 10.85s/it]                                                       {'loss': 2.0886, 'learning_rate': 0.0006428224616281554, 'epoch': 0.43}
 43%|████▎     | 1014/2382 [3:07:53<4:07:25, 10.85s/it] 43%|████▎     | 1015/2382 [3:08:05<4:10:28, 10.99s/it]                                                       {'loss': 2.1171, 'learning_rate': 0.0006421706631145811, 'epoch': 0.43}
 43%|████▎     | 1015/2382 [3:08:05<4:10:28, 10.99s/it] 43%|████▎     | 1016/2382 [3:08:14<4:01:16, 10.60s/it]                                                       {'loss': 2.0912, 'learning_rate': 0.0006415186016434185, 'epoch': 0.43}
 43%|████▎     | 1016/2382 [3:08:14<4:01:16, 10.60s/it] 43%|████▎     | 1017/2382 [3:08:23<3:49:50, 10.10s/it]                                                       {'loss': 2.2691, 'learning_rate': 0.0006408662784207149, 'epoch': 0.43}
 43%|████▎     | 1017/2382 [3:08:23<3:49:50, 10.10s/it] 43%|████▎     | 1018/2382 [3:08:36<4:09:41, 10.98s/it]                                                       {'loss': 2.0867, 'learning_rate': 0.0006402136946530014, 'epoch': 0.43}
 43%|████▎     | 1018/2382 [3:08:36<4:09:41, 10.98s/it] 43%|████▎     | 1019/2382 [3:08:47<4:09:49, 11.00s/it]                                                       {'loss': 2.149, 'learning_rate': 0.0006395608515472912, 'epoch': 0.43}
 43%|████▎     | 1019/2382 [3:08:47<4:09:49, 11.00s/it] 43%|████▎     | 1020/2382 [3:08:59<4:16:10, 11.29s/it]                                                       {'loss': 2.0426, 'learning_rate': 0.0006389077503110769, 'epoch': 0.43}
 43%|████▎     | 1020/2382 [3:08:59<4:16:10, 11.29s/it] 43%|████▎     | 1021/2382 [3:09:09<4:06:05, 10.85s/it]                                                       {'loss': 2.1311, 'learning_rate': 0.0006382543921523289, 'epoch': 0.43}
 43%|████▎     | 1021/2382 [3:09:09<4:06:05, 10.85s/it] 43%|████▎     | 1022/2382 [3:09:20<4:08:40, 10.97s/it]                                                       {'loss': 1.9427, 'learning_rate': 0.0006376007782794926, 'epoch': 0.43}
 43%|████▎     | 1022/2382 [3:09:20<4:08:40, 10.97s/it] 43%|████▎     | 1023/2382 [3:09:31<4:03:57, 10.77s/it]                                                       {'loss': 2.081, 'learning_rate': 0.0006369469099014862, 'epoch': 0.43}
 43%|████▎     | 1023/2382 [3:09:31<4:03:57, 10.77s/it] 43%|████▎     | 1024/2382 [3:09:41<4:00:04, 10.61s/it]                                                       {'loss': 2.1064, 'learning_rate': 0.0006362927882276989, 'epoch': 0.43}
 43%|████▎     | 1024/2382 [3:09:41<4:00:04, 10.61s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1051 > 1024). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (1359 > 1024). Running this sequence through the model will result in indexing errors
 43%|████▎     | 1025/2382 [3:09:50<3:47:24, 10.06s/it]                                                       {'loss': 1.9749, 'learning_rate': 0.0006356384144679884, 'epoch': 0.43}
 43%|████▎     | 1025/2382 [3:09:50<3:47:24, 10.06s/it] 43%|████▎     | 1026/2382 [3:10:02<4:03:28, 10.77s/it]                                                       {'loss': 2.0595, 'learning_rate': 0.0006349837898326784, 'epoch': 0.43}
 43%|████▎     | 1026/2382 [3:10:02<4:03:28, 10.77s/it] 43%|████▎     | 1027/2382 [3:10:14<4:10:14, 11.08s/it]                                                       {'loss': 2.0918, 'learning_rate': 0.000634328915532557, 'epoch': 0.43}
 43%|████▎     | 1027/2382 [3:10:14<4:10:14, 11.08s/it] 43%|████▎     | 1028/2382 [3:10:24<4:02:21, 10.74s/it]                                                       {'loss': 2.088, 'learning_rate': 0.0006336737927788737, 'epoch': 0.43}
 43%|████▎     | 1028/2382 [3:10:24<4:02:21, 10.74s/it] 43%|████▎     | 1029/2382 [3:10:34<3:58:21, 10.57s/it]                                                       {'loss': 2.1416, 'learning_rate': 0.0006330184227833376, 'epoch': 0.43}
 43%|████▎     | 1029/2382 [3:10:34<3:58:21, 10.57s/it] 43%|████▎     | 1030/2382 [3:10:46<4:10:53, 11.13s/it]                                                       {'loss': 2.042, 'learning_rate': 0.0006323628067581153, 'epoch': 0.43}
 43%|████▎     | 1030/2382 [3:10:46<4:10:53, 11.13s/it] 43%|████▎     | 1031/2382 [3:10:58<4:17:05, 11.42s/it]                                                       {'loss': 2.0795, 'learning_rate': 0.0006317069459158283, 'epoch': 0.43}
 43%|████▎     | 1031/2382 [3:10:58<4:17:05, 11.42s/it] 43%|████▎     | 1032/2382 [3:11:09<4:10:07, 11.12s/it]                                                       {'loss': 2.1279, 'learning_rate': 0.000631050841469551, 'epoch': 0.43}
 43%|████▎     | 1032/2382 [3:11:09<4:10:07, 11.12s/it] 43%|████▎     | 1033/2382 [3:11:21<4:17:28, 11.45s/it]                                                       {'loss': 1.9777, 'learning_rate': 0.0006303944946328085, 'epoch': 0.43}
 43%|████▎     | 1033/2382 [3:11:21<4:17:28, 11.45s/it] 43%|████▎     | 1034/2382 [3:11:33<4:17:55, 11.48s/it]                                                       {'loss': 2.2086, 'learning_rate': 0.0006297379066195737, 'epoch': 0.43}
 43%|████▎     | 1034/2382 [3:11:33<4:17:55, 11.48s/it] 43%|████▎     | 1035/2382 [3:11:44<4:19:31, 11.56s/it]                                                       {'loss': 1.9528, 'learning_rate': 0.0006290810786442661, 'epoch': 0.43}
 43%|████▎     | 1035/2382 [3:11:44<4:19:31, 11.56s/it] 43%|████▎     | 1036/2382 [3:11:56<4:19:45, 11.58s/it]                                                       {'loss': 2.0853, 'learning_rate': 0.0006284240119217488, 'epoch': 0.43}
 43%|████▎     | 1036/2382 [3:11:56<4:19:45, 11.58s/it] 44%|████▎     | 1037/2382 [3:12:08<4:19:36, 11.58s/it]                                                       {'loss': 2.0214, 'learning_rate': 0.0006277667076673266, 'epoch': 0.44}
 44%|████▎     | 1037/2382 [3:12:08<4:19:36, 11.58s/it] 44%|████▎     | 1038/2382 [3:12:19<4:16:58, 11.47s/it]                                                       {'loss': 1.8945, 'learning_rate': 0.0006271091670967436, 'epoch': 0.44}
 44%|████▎     | 1038/2382 [3:12:19<4:16:58, 11.47s/it] 44%|████▎     | 1039/2382 [3:12:30<4:13:30, 11.33s/it]                                                       {'loss': 1.9638, 'learning_rate': 0.0006264513914261807, 'epoch': 0.44}
 44%|████▎     | 1039/2382 [3:12:30<4:13:30, 11.33s/it] 44%|████▎     | 1040/2382 [3:12:39<4:01:16, 10.79s/it]                                                       {'loss': 2.0505, 'learning_rate': 0.0006257933818722543, 'epoch': 0.44}
 44%|████▎     | 1040/2382 [3:12:39<4:01:16, 10.79s/it] 44%|████▎     | 1041/2382 [3:12:52<4:10:29, 11.21s/it]                                                       {'loss': 2.0261, 'learning_rate': 0.0006251351396520129, 'epoch': 0.44}
 44%|████▎     | 1041/2382 [3:12:52<4:10:29, 11.21s/it] 44%|████▎     | 1042/2382 [3:13:07<4:38:29, 12.47s/it]                                                       {'loss': 2.0623, 'learning_rate': 0.000624476665982935, 'epoch': 0.44}
 44%|████▎     | 1042/2382 [3:13:07<4:38:29, 12.47s/it] 44%|████▍     | 1043/2382 [3:13:16<4:15:50, 11.46s/it]                                                       {'loss': 2.0617, 'learning_rate': 0.0006238179620829281, 'epoch': 0.44}
 44%|████▍     | 1043/2382 [3:13:16<4:15:50, 11.46s/it] 44%|████▍     | 1044/2382 [3:13:27<4:11:03, 11.26s/it]                                                       {'loss': 1.9817, 'learning_rate': 0.000623159029170325, 'epoch': 0.44}
 44%|████▍     | 1044/2382 [3:13:27<4:11:03, 11.26s/it] 44%|████▍     | 1045/2382 [3:13:39<4:14:38, 11.43s/it]                                                       {'loss': 2.0911, 'learning_rate': 0.000622499868463882, 'epoch': 0.44}
 44%|████▍     | 1045/2382 [3:13:39<4:14:38, 11.43s/it] 44%|████▍     | 1046/2382 [3:13:50<4:11:13, 11.28s/it]                                                       {'loss': 2.1625, 'learning_rate': 0.0006218404811827767, 'epoch': 0.44}
 44%|████▍     | 1046/2382 [3:13:50<4:11:13, 11.28s/it] 44%|████▍     | 1047/2382 [3:14:01<4:08:39, 11.18s/it]                                                       {'loss': 2.1583, 'learning_rate': 0.0006211808685466063, 'epoch': 0.44}
 44%|████▍     | 1047/2382 [3:14:01<4:08:39, 11.18s/it] 44%|████▍     | 1048/2382 [3:14:11<4:06:34, 11.09s/it]                                                       {'loss': 2.0042, 'learning_rate': 0.0006205210317753842, 'epoch': 0.44}
 44%|████▍     | 1048/2382 [3:14:11<4:06:34, 11.09s/it] 44%|████▍     | 1049/2382 [3:14:21<3:58:14, 10.72s/it]                                                       {'loss': 1.9936, 'learning_rate': 0.0006198609720895384, 'epoch': 0.44}
 44%|████▍     | 1049/2382 [3:14:21<3:58:14, 10.72s/it] 44%|████▍     | 1050/2382 [3:14:34<4:09:58, 11.26s/it]                                                       {'loss': 2.0567, 'learning_rate': 0.0006192006907099098, 'epoch': 0.44}
 44%|████▍     | 1050/2382 [3:14:34<4:09:58, 11.26s/it] 44%|████▍     | 1051/2382 [3:14:43<3:58:42, 10.76s/it]                                                       {'loss': 2.1689, 'learning_rate': 0.0006185401888577488, 'epoch': 0.44}
 44%|████▍     | 1051/2382 [3:14:43<3:58:42, 10.76s/it] 44%|████▍     | 1052/2382 [3:14:54<3:59:47, 10.82s/it]                                                       {'loss': 2.0418, 'learning_rate': 0.0006178794677547138, 'epoch': 0.44}
 44%|████▍     | 1052/2382 [3:14:54<3:59:47, 10.82s/it] 44%|████▍     | 1053/2382 [3:15:06<4:07:55, 11.19s/it]                                                       {'loss': 1.9605, 'learning_rate': 0.0006172185286228684, 'epoch': 0.44}
 44%|████▍     | 1053/2382 [3:15:06<4:07:55, 11.19s/it] 44%|████▍     | 1054/2382 [3:15:19<4:15:23, 11.54s/it]                                                       {'loss': 1.9552, 'learning_rate': 0.0006165573726846797, 'epoch': 0.44}
 44%|████▍     | 1054/2382 [3:15:19<4:15:23, 11.54s/it] 44%|████▍     | 1055/2382 [3:15:29<4:07:59, 11.21s/it]                                                       {'loss': 2.099, 'learning_rate': 0.0006158960011630162, 'epoch': 0.44}
 44%|████▍     | 1055/2382 [3:15:29<4:07:59, 11.21s/it] 44%|████▍     | 1056/2382 [3:15:42<4:15:58, 11.58s/it]                                                       {'loss': 2.0333, 'learning_rate': 0.0006152344152811444, 'epoch': 0.44}
 44%|████▍     | 1056/2382 [3:15:42<4:15:58, 11.58s/it] 44%|████▍     | 1057/2382 [3:15:54<4:19:48, 11.76s/it]                                                       {'loss': 2.1508, 'learning_rate': 0.0006145726162627278, 'epoch': 0.44}
 44%|████▍     | 1057/2382 [3:15:54<4:19:48, 11.76s/it] 44%|████▍     | 1058/2382 [3:16:05<4:17:23, 11.66s/it]                                                       {'loss': 2.0858, 'learning_rate': 0.0006139106053318239, 'epoch': 0.44}
 44%|████▍     | 1058/2382 [3:16:05<4:17:23, 11.66s/it] 44%|████▍     | 1059/2382 [3:16:15<4:04:42, 11.10s/it]                                                       {'loss': 2.0391, 'learning_rate': 0.0006132483837128823, 'epoch': 0.44}
 44%|████▍     | 1059/2382 [3:16:15<4:04:42, 11.10s/it] 45%|████▍     | 1060/2382 [3:16:26<4:04:03, 11.08s/it]                                                       {'loss': 2.0865, 'learning_rate': 0.000612585952630742, 'epoch': 0.44}
 45%|████▍     | 1060/2382 [3:16:26<4:04:03, 11.08s/it] 45%|████▍     | 1061/2382 [3:16:37<4:00:10, 10.91s/it]                                                       {'loss': 2.1978, 'learning_rate': 0.0006119233133106297, 'epoch': 0.45}
 45%|████▍     | 1061/2382 [3:16:37<4:00:10, 10.91s/it] 45%|████▍     | 1062/2382 [3:16:47<3:55:12, 10.69s/it]                                                       {'loss': 1.9677, 'learning_rate': 0.0006112604669781572, 'epoch': 0.45}
 45%|████▍     | 1062/2382 [3:16:47<3:55:12, 10.69s/it] 45%|████▍     | 1063/2382 [3:16:55<3:40:57, 10.05s/it]                                                       {'loss': 2.1661, 'learning_rate': 0.0006105974148593191, 'epoch': 0.45}
 45%|████▍     | 1063/2382 [3:16:55<3:40:57, 10.05s/it] 45%|████▍     | 1064/2382 [3:17:05<3:37:40,  9.91s/it]                                                       {'loss': 2.1622, 'learning_rate': 0.0006099341581804909, 'epoch': 0.45}
 45%|████▍     | 1064/2382 [3:17:05<3:37:40,  9.91s/it] 45%|████▍     | 1065/2382 [3:17:16<3:42:03, 10.12s/it]                                                       {'loss': 2.0495, 'learning_rate': 0.0006092706981684259, 'epoch': 0.45}
 45%|████▍     | 1065/2382 [3:17:16<3:42:03, 10.12s/it] 45%|████▍     | 1066/2382 [3:17:28<3:57:22, 10.82s/it]                                                       {'loss': 1.9958, 'learning_rate': 0.0006086070360502539, 'epoch': 0.45}
 45%|████▍     | 1066/2382 [3:17:28<3:57:22, 10.82s/it] 45%|████▍     | 1067/2382 [3:17:38<3:50:04, 10.50s/it]                                                       {'loss': 2.076, 'learning_rate': 0.0006079431730534786, 'epoch': 0.45}
 45%|████▍     | 1067/2382 [3:17:38<3:50:04, 10.50s/it] 45%|████▍     | 1068/2382 [3:17:49<3:57:37, 10.85s/it]                                                       {'loss': 2.1311, 'learning_rate': 0.0006072791104059748, 'epoch': 0.45}
 45%|████▍     | 1068/2382 [3:17:49<3:57:37, 10.85s/it] 45%|████▍     | 1069/2382 [3:18:01<3:58:54, 10.92s/it]                                                       {'loss': 1.9783, 'learning_rate': 0.000606614849335987, 'epoch': 0.45}
 45%|████▍     | 1069/2382 [3:18:01<3:58:54, 10.92s/it] 45%|████▍     | 1070/2382 [3:18:11<3:57:56, 10.88s/it]                                                       {'loss': 1.994, 'learning_rate': 0.0006059503910721266, 'epoch': 0.45}
 45%|████▍     | 1070/2382 [3:18:11<3:57:56, 10.88s/it] 45%|████▍     | 1071/2382 [3:18:24<4:08:02, 11.35s/it]                                                       {'loss': 2.0322, 'learning_rate': 0.0006052857368433695, 'epoch': 0.45}
 45%|████▍     | 1071/2382 [3:18:24<4:08:02, 11.35s/it] 45%|████▌     | 1072/2382 [3:18:33<3:56:51, 10.85s/it]                                                       {'loss': 2.1231, 'learning_rate': 0.0006046208878790542, 'epoch': 0.45}
 45%|████▌     | 1072/2382 [3:18:33<3:56:51, 10.85s/it] 45%|████▌     | 1073/2382 [3:18:47<4:12:38, 11.58s/it]                                                       {'loss': 2.0797, 'learning_rate': 0.0006039558454088796, 'epoch': 0.45}
 45%|████▌     | 1073/2382 [3:18:47<4:12:38, 11.58s/it] 45%|████▌     | 1074/2382 [3:18:58<4:11:37, 11.54s/it]                                                       {'loss': 1.9927, 'learning_rate': 0.0006032906106629024, 'epoch': 0.45}
 45%|████▌     | 1074/2382 [3:18:58<4:11:37, 11.54s/it] 45%|████▌     | 1075/2382 [3:19:08<3:58:49, 10.96s/it]                                                       {'loss': 2.0579, 'learning_rate': 0.0006026251848715345, 'epoch': 0.45}
 45%|████▌     | 1075/2382 [3:19:08<3:58:49, 10.96s/it] 45%|████▌     | 1076/2382 [3:19:20<4:05:34, 11.28s/it]                                                       {'loss': 1.967, 'learning_rate': 0.0006019595692655415, 'epoch': 0.45}
 45%|████▌     | 1076/2382 [3:19:20<4:05:34, 11.28s/it] 45%|████▌     | 1077/2382 [3:19:31<4:03:00, 11.17s/it]                                                       {'loss': 1.9884, 'learning_rate': 0.0006012937650760405, 'epoch': 0.45}
 45%|████▌     | 1077/2382 [3:19:31<4:03:00, 11.17s/it] 45%|████▌     | 1078/2382 [3:19:41<3:55:28, 10.83s/it]                                                       {'loss': 1.9924, 'learning_rate': 0.0006006277735344967, 'epoch': 0.45}
 45%|████▌     | 1078/2382 [3:19:41<3:55:28, 10.83s/it] 45%|████▌     | 1079/2382 [3:19:54<4:10:01, 11.51s/it]                                                       {'loss': 2.0808, 'learning_rate': 0.0005999615958727219, 'epoch': 0.45}
 45%|████▌     | 1079/2382 [3:19:54<4:10:01, 11.51s/it] 45%|████▌     | 1080/2382 [3:20:06<4:10:51, 11.56s/it]                                                       {'loss': 2.0156, 'learning_rate': 0.0005992952333228728, 'epoch': 0.45}
 45%|████▌     | 1080/2382 [3:20:06<4:10:51, 11.56s/it] 45%|████▌     | 1081/2382 [3:20:17<4:11:44, 11.61s/it]                                                       {'loss': 2.0684, 'learning_rate': 0.0005986286871174474, 'epoch': 0.45}
 45%|████▌     | 1081/2382 [3:20:17<4:11:44, 11.61s/it] 45%|████▌     | 1082/2382 [3:20:27<4:02:11, 11.18s/it]                                                       {'loss': 2.0344, 'learning_rate': 0.0005979619584892833, 'epoch': 0.45}
 45%|████▌     | 1082/2382 [3:20:27<4:02:11, 11.18s/it] 45%|████▌     | 1083/2382 [3:20:36<3:46:22, 10.46s/it]                                                       {'loss': 2.0743, 'learning_rate': 0.0005972950486715563, 'epoch': 0.45}
 45%|████▌     | 1083/2382 [3:20:36<3:46:22, 10.46s/it] 46%|████▌     | 1084/2382 [3:20:46<3:41:46, 10.25s/it]                                                       {'loss': 2.0074, 'learning_rate': 0.0005966279588977767, 'epoch': 0.45}
 46%|████▌     | 1084/2382 [3:20:46<3:41:46, 10.25s/it] 46%|████▌     | 1085/2382 [3:20:58<3:51:39, 10.72s/it]                                                       {'loss': 2.0096, 'learning_rate': 0.0005959606904017877, 'epoch': 0.46}
 46%|████▌     | 1085/2382 [3:20:58<3:51:39, 10.72s/it] 46%|████▌     | 1086/2382 [3:21:10<3:59:20, 11.08s/it]                                                       {'loss': 2.1976, 'learning_rate': 0.0005952932444177631, 'epoch': 0.46}
 46%|████▌     | 1086/2382 [3:21:10<3:59:20, 11.08s/it] 46%|████▌     | 1087/2382 [3:21:21<4:02:53, 11.25s/it]                                                       {'loss': 2.0332, 'learning_rate': 0.0005946256221802051, 'epoch': 0.46}
 46%|████▌     | 1087/2382 [3:21:21<4:02:53, 11.25s/it] 46%|████▌     | 1088/2382 [3:21:33<4:05:55, 11.40s/it]                                                       {'loss': 2.1097, 'learning_rate': 0.0005939578249239419, 'epoch': 0.46}
 46%|████▌     | 1088/2382 [3:21:33<4:05:55, 11.40s/it] 46%|████▌     | 1089/2382 [3:21:45<4:08:44, 11.54s/it]                                                       {'loss': 1.9981, 'learning_rate': 0.0005932898538841254, 'epoch': 0.46}
 46%|████▌     | 1089/2382 [3:21:45<4:08:44, 11.54s/it] 46%|████▌     | 1090/2382 [3:21:58<4:16:00, 11.89s/it]                                                       {'loss': 2.0517, 'learning_rate': 0.0005926217102962285, 'epoch': 0.46}
 46%|████▌     | 1090/2382 [3:21:58<4:16:00, 11.89s/it] 46%|████▌     | 1091/2382 [3:22:07<3:58:53, 11.10s/it]                                                       {'loss': 2.0664, 'learning_rate': 0.0005919533953960439, 'epoch': 0.46}
 46%|████▌     | 1091/2382 [3:22:07<3:58:53, 11.10s/it] 46%|████▌     | 1092/2382 [3:22:18<3:57:00, 11.02s/it]                                                       {'loss': 2.016, 'learning_rate': 0.0005912849104196809, 'epoch': 0.46}
 46%|████▌     | 1092/2382 [3:22:18<3:57:00, 11.02s/it] 46%|████▌     | 1093/2382 [3:22:26<3:40:23, 10.26s/it]                                                       {'loss': 2.0621, 'learning_rate': 0.0005906162566035632, 'epoch': 0.46}
 46%|████▌     | 1093/2382 [3:22:26<3:40:23, 10.26s/it] 46%|████▌     | 1094/2382 [3:22:39<3:54:12, 10.91s/it]                                                       {'loss': 2.0288, 'learning_rate': 0.000589947435184427, 'epoch': 0.46}
 46%|████▌     | 1094/2382 [3:22:39<3:54:12, 10.91s/it] 46%|████▌     | 1095/2382 [3:22:51<4:01:27, 11.26s/it]                                                       {'loss': 1.9732, 'learning_rate': 0.0005892784473993184, 'epoch': 0.46}
 46%|████▌     | 1095/2382 [3:22:51<4:01:27, 11.26s/it] 46%|████▌     | 1096/2382 [3:23:03<4:05:59, 11.48s/it]                                                       {'loss': 2.0721, 'learning_rate': 0.0005886092944855912, 'epoch': 0.46}
 46%|████▌     | 1096/2382 [3:23:03<4:05:59, 11.48s/it] 46%|████▌     | 1097/2382 [3:23:14<4:03:22, 11.36s/it]                                                       {'loss': 2.0167, 'learning_rate': 0.0005879399776809047, 'epoch': 0.46}
 46%|████▌     | 1097/2382 [3:23:14<4:03:22, 11.36s/it] 46%|████▌     | 1098/2382 [3:23:25<4:01:15, 11.27s/it]                                                       {'loss': 2.0407, 'learning_rate': 0.0005872704982232212, 'epoch': 0.46}
 46%|████▌     | 1098/2382 [3:23:25<4:01:15, 11.27s/it] 46%|████▌     | 1099/2382 [3:23:35<3:55:37, 11.02s/it]                                                       {'loss': 1.9974, 'learning_rate': 0.000586600857350804, 'epoch': 0.46}
 46%|████▌     | 1099/2382 [3:23:35<3:55:37, 11.02s/it] 46%|████▌     | 1100/2382 [3:23:46<3:53:20, 10.92s/it]                                                       {'loss': 1.9948, 'learning_rate': 0.000585931056302215, 'epoch': 0.46}
 46%|████▌     | 1100/2382 [3:23:46<3:53:20, 10.92s/it] 46%|████▌     | 1101/2382 [3:23:57<3:53:32, 10.94s/it]                                                       {'loss': 2.0358, 'learning_rate': 0.0005852610963163119, 'epoch': 0.46}
 46%|████▌     | 1101/2382 [3:23:57<3:53:32, 10.94s/it] 46%|████▋     | 1102/2382 [3:24:07<3:45:56, 10.59s/it]                                                       {'loss': 2.0425, 'learning_rate': 0.0005845909786322469, 'epoch': 0.46}
 46%|████▋     | 1102/2382 [3:24:07<3:45:56, 10.59s/it] 46%|████▋     | 1103/2382 [3:24:20<4:02:01, 11.35s/it]                                                       {'loss': 2.0163, 'learning_rate': 0.0005839207044894639, 'epoch': 0.46}
 46%|████▋     | 1103/2382 [3:24:20<4:02:01, 11.35s/it] 46%|████▋     | 1104/2382 [3:24:30<3:55:56, 11.08s/it]                                                       {'loss': 1.9837, 'learning_rate': 0.0005832502751276956, 'epoch': 0.46}
 46%|████▋     | 1104/2382 [3:24:30<3:55:56, 11.08s/it] 46%|████▋     | 1105/2382 [3:24:42<3:57:22, 11.15s/it]                                                       {'loss': 1.9921, 'learning_rate': 0.0005825796917869622, 'epoch': 0.46}
 46%|████▋     | 1105/2382 [3:24:42<3:57:22, 11.15s/it] 46%|████▋     | 1106/2382 [3:24:52<3:49:39, 10.80s/it]                                                       {'loss': 1.9994, 'learning_rate': 0.0005819089557075689, 'epoch': 0.46}
 46%|████▋     | 1106/2382 [3:24:52<3:49:39, 10.80s/it] 46%|████▋     | 1107/2382 [3:25:02<3:44:09, 10.55s/it]                                                       {'loss': 2.181, 'learning_rate': 0.0005812380681301031, 'epoch': 0.46}
 46%|████▋     | 1107/2382 [3:25:02<3:44:09, 10.55s/it] 47%|████▋     | 1108/2382 [3:25:14<3:52:41, 10.96s/it]                                                       {'loss': 2.0508, 'learning_rate': 0.0005805670302954321, 'epoch': 0.46}
 47%|████▋     | 1108/2382 [3:25:14<3:52:41, 10.96s/it] 47%|████▋     | 1109/2382 [3:25:23<3:45:13, 10.62s/it]                                                       {'loss': 2.0064, 'learning_rate': 0.0005798958434447019, 'epoch': 0.47}
 47%|████▋     | 1109/2382 [3:25:23<3:45:13, 10.62s/it] 47%|████▋     | 1110/2382 [3:25:35<3:50:49, 10.89s/it]                                                       {'loss': 2.0159, 'learning_rate': 0.0005792245088193335, 'epoch': 0.47}
 47%|████▋     | 1110/2382 [3:25:35<3:50:49, 10.89s/it] 47%|████▋     | 1111/2382 [3:25:45<3:46:55, 10.71s/it]                                                       {'loss': 2.0583, 'learning_rate': 0.0005785530276610216, 'epoch': 0.47}
 47%|████▋     | 1111/2382 [3:25:45<3:46:55, 10.71s/it] 47%|████▋     | 1112/2382 [3:25:55<3:38:26, 10.32s/it]                                                       {'loss': 2.1179, 'learning_rate': 0.0005778814012117315, 'epoch': 0.47}
 47%|████▋     | 1112/2382 [3:25:55<3:38:26, 10.32s/it] 47%|████▋     | 1113/2382 [3:26:04<3:30:58,  9.98s/it]                                                       {'loss': 2.1423, 'learning_rate': 0.0005772096307136978, 'epoch': 0.47}
 47%|████▋     | 1113/2382 [3:26:04<3:30:58,  9.98s/it] 47%|████▋     | 1114/2382 [3:26:15<3:35:47, 10.21s/it]                                                       {'loss': 1.9925, 'learning_rate': 0.0005765377174094208, 'epoch': 0.47}
 47%|████▋     | 1114/2382 [3:26:15<3:35:47, 10.21s/it] 47%|████▋     | 1115/2382 [3:26:24<3:28:35,  9.88s/it]                                                       {'loss': 2.0332, 'learning_rate': 0.0005758656625416658, 'epoch': 0.47}
 47%|████▋     | 1115/2382 [3:26:24<3:28:35,  9.88s/it] 47%|████▋     | 1116/2382 [3:26:34<3:30:19,  9.97s/it]                                                       {'loss': 2.1395, 'learning_rate': 0.0005751934673534592, 'epoch': 0.47}
 47%|████▋     | 1116/2382 [3:26:34<3:30:19,  9.97s/it] 47%|████▋     | 1117/2382 [3:26:45<3:35:19, 10.21s/it]                                                       {'loss': 2.124, 'learning_rate': 0.0005745211330880871, 'epoch': 0.47}
 47%|████▋     | 1117/2382 [3:26:45<3:35:19, 10.21s/it] 47%|████▋     | 1118/2382 [3:26:58<3:54:21, 11.12s/it]                                                       {'loss': 2.0781, 'learning_rate': 0.0005738486609890934, 'epoch': 0.47}
 47%|████▋     | 1118/2382 [3:26:58<3:54:21, 11.12s/it] 47%|████▋     | 1119/2382 [3:27:12<4:11:22, 11.94s/it]                                                       {'loss': 1.9789, 'learning_rate': 0.0005731760523002761, 'epoch': 0.47}
 47%|████▋     | 1119/2382 [3:27:12<4:11:22, 11.94s/it] 47%|████▋     | 1120/2382 [3:27:21<3:54:32, 11.15s/it]                                                       {'loss': 1.9892, 'learning_rate': 0.0005725033082656862, 'epoch': 0.47}
 47%|████▋     | 1120/2382 [3:27:21<3:54:32, 11.15s/it] 47%|████▋     | 1121/2382 [3:27:32<3:51:12, 11.00s/it]                                                       {'loss': 2.1279, 'learning_rate': 0.0005718304301296252, 'epoch': 0.47}
 47%|████▋     | 1121/2382 [3:27:32<3:51:12, 11.00s/it] 47%|████▋     | 1122/2382 [3:27:43<3:52:50, 11.09s/it]                                                       {'loss': 2.0213, 'learning_rate': 0.0005711574191366427, 'epoch': 0.47}
 47%|████▋     | 1122/2382 [3:27:43<3:52:50, 11.09s/it] 47%|████▋     | 1123/2382 [3:27:54<3:53:43, 11.14s/it]                                                       {'loss': 2.0268, 'learning_rate': 0.0005704842765315334, 'epoch': 0.47}
 47%|████▋     | 1123/2382 [3:27:54<3:53:43, 11.14s/it] 47%|████▋     | 1124/2382 [3:28:06<3:55:13, 11.22s/it]                                                       {'loss': 1.962, 'learning_rate': 0.0005698110035593359, 'epoch': 0.47}
 47%|████▋     | 1124/2382 [3:28:06<3:55:13, 11.22s/it] 47%|████▋     | 1125/2382 [3:28:16<3:48:29, 10.91s/it]                                                       {'loss': 1.9287, 'learning_rate': 0.0005691376014653302, 'epoch': 0.47}
 47%|████▋     | 1125/2382 [3:28:16<3:48:29, 10.91s/it] 47%|████▋     | 1126/2382 [3:28:28<3:54:08, 11.19s/it]                                                       {'loss': 2.058, 'learning_rate': 0.0005684640714950346, 'epoch': 0.47}
 47%|████▋     | 1126/2382 [3:28:28<3:54:08, 11.19s/it] 47%|████▋     | 1127/2382 [3:28:37<3:45:29, 10.78s/it]                                                       {'loss': 2.0697, 'learning_rate': 0.0005677904148942039, 'epoch': 0.47}
 47%|████▋     | 1127/2382 [3:28:37<3:45:29, 10.78s/it] 47%|████▋     | 1128/2382 [3:28:47<3:36:42, 10.37s/it]                                                       {'loss': 2.1365, 'learning_rate': 0.0005671166329088278, 'epoch': 0.47}
 47%|████▋     | 1128/2382 [3:28:47<3:36:42, 10.37s/it] 47%|████▋     | 1129/2382 [3:28:57<3:32:22, 10.17s/it]                                                       {'loss': 2.0062, 'learning_rate': 0.0005664427267851271, 'epoch': 0.47}
 47%|████▋     | 1129/2382 [3:28:57<3:32:22, 10.17s/it] 47%|████▋     | 1130/2382 [3:29:05<3:22:03,  9.68s/it]                                                       {'loss': 2.0425, 'learning_rate': 0.0005657686977695526, 'epoch': 0.47}
 47%|████▋     | 1130/2382 [3:29:05<3:22:03,  9.68s/it] 47%|████▋     | 1131/2382 [3:29:14<3:14:59,  9.35s/it]                                                       {'loss': 2.1361, 'learning_rate': 0.0005650945471087824, 'epoch': 0.47}
 47%|████▋     | 1131/2382 [3:29:14<3:14:59,  9.35s/it] 48%|████▊     | 1132/2382 [3:29:27<3:41:23, 10.63s/it]                                                       {'loss': 2.0198, 'learning_rate': 0.0005644202760497195, 'epoch': 0.48}
 48%|████▊     | 1132/2382 [3:29:27<3:41:23, 10.63s/it] 48%|████▊     | 1133/2382 [3:29:39<3:46:15, 10.87s/it]                                                       {'loss': 2.0693, 'learning_rate': 0.0005637458858394896, 'epoch': 0.48}
 48%|████▊     | 1133/2382 [3:29:39<3:46:15, 10.87s/it] 48%|████▊     | 1134/2382 [3:29:50<3:47:54, 10.96s/it]                                                       {'loss': 2.0609, 'learning_rate': 0.0005630713777254389, 'epoch': 0.48}
 48%|████▊     | 1134/2382 [3:29:50<3:47:54, 10.96s/it] 48%|████▊     | 1135/2382 [3:30:00<3:43:04, 10.73s/it]                                                       {'loss': 1.9631, 'learning_rate': 0.0005623967529551315, 'epoch': 0.48}
 48%|████▊     | 1135/2382 [3:30:00<3:43:04, 10.73s/it] 48%|████▊     | 1136/2382 [3:30:11<3:45:58, 10.88s/it]                                                       {'loss': 2.0399, 'learning_rate': 0.0005617220127763474, 'epoch': 0.48}
 48%|████▊     | 1136/2382 [3:30:11<3:45:58, 10.88s/it] 48%|████▊     | 1137/2382 [3:30:21<3:38:19, 10.52s/it]                                                       {'loss': 2.0369, 'learning_rate': 0.00056104715843708, 'epoch': 0.48}
 48%|████▊     | 1137/2382 [3:30:21<3:38:19, 10.52s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1149 > 1024). Running this sequence through the model will result in indexing errors
 48%|████▊     | 1138/2382 [3:30:31<3:34:55, 10.37s/it]                                                       {'loss': 2.1853, 'learning_rate': 0.0005603721911855337, 'epoch': 0.48}
 48%|████▊     | 1138/2382 [3:30:31<3:34:55, 10.37s/it] 48%|████▊     | 1139/2382 [3:30:45<3:58:29, 11.51s/it]                                                       {'loss': 2.0391, 'learning_rate': 0.0005596971122701221, 'epoch': 0.48}
 48%|████▊     | 1139/2382 [3:30:45<3:58:29, 11.51s/it] 48%|████▊     | 1140/2382 [3:30:55<3:47:54, 11.01s/it]                                                       {'loss': 2.1142, 'learning_rate': 0.0005590219229394652, 'epoch': 0.48}
 48%|████▊     | 1140/2382 [3:30:55<3:47:54, 11.01s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 1024). Running this sequence through the model will result in indexing errors
 48%|████▊     | 1141/2382 [3:31:05<3:41:44, 10.72s/it]                                                       {'loss': 1.9278, 'learning_rate': 0.0005583466244423869, 'epoch': 0.48}
 48%|████▊     | 1141/2382 [3:31:05<3:41:44, 10.72s/it] 48%|████▊     | 1142/2382 [3:31:14<3:27:57, 10.06s/it]                                                       {'loss': 2.2027, 'learning_rate': 0.0005576712180279134, 'epoch': 0.48}
 48%|████▊     | 1142/2382 [3:31:14<3:27:57, 10.06s/it] 48%|████▊     | 1143/2382 [3:31:27<3:47:34, 11.02s/it]                                                       {'loss': 2.0397, 'learning_rate': 0.0005569957049452703, 'epoch': 0.48}
 48%|████▊     | 1143/2382 [3:31:27<3:47:34, 11.02s/it] 48%|████▊     | 1144/2382 [3:31:37<3:41:44, 10.75s/it]                                                       {'loss': 2.1201, 'learning_rate': 0.0005563200864438808, 'epoch': 0.48}
 48%|████▊     | 1144/2382 [3:31:37<3:41:44, 10.75s/it] 48%|████▊     | 1145/2382 [3:31:46<3:33:36, 10.36s/it]                                                       {'loss': 2.0619, 'learning_rate': 0.0005556443637733623, 'epoch': 0.48}
 48%|████▊     | 1145/2382 [3:31:46<3:33:36, 10.36s/it] 48%|████▊     | 1146/2382 [3:31:58<3:42:57, 10.82s/it]                                                       {'loss': 2.0154, 'learning_rate': 0.0005549685381835261, 'epoch': 0.48}
 48%|████▊     | 1146/2382 [3:31:58<3:42:57, 10.82s/it] 48%|████▊     | 1147/2382 [3:32:11<3:51:30, 11.25s/it]                                                       {'loss': 2.0084, 'learning_rate': 0.0005542926109243727, 'epoch': 0.48}
 48%|████▊     | 1147/2382 [3:32:11<3:51:30, 11.25s/it] 48%|████▊     | 1148/2382 [3:32:22<3:54:48, 11.42s/it]                                                       {'loss': 2.181, 'learning_rate': 0.0005536165832460913, 'epoch': 0.48}
 48%|████▊     | 1148/2382 [3:32:22<3:54:48, 11.42s/it] 48%|████▊     | 1149/2382 [3:32:34<3:55:52, 11.48s/it]                                                       {'loss': 2.0174, 'learning_rate': 0.0005529404563990567, 'epoch': 0.48}
 48%|████▊     | 1149/2382 [3:32:34<3:55:52, 11.48s/it] 48%|████▊     | 1150/2382 [3:32:44<3:49:37, 11.18s/it]                                                       {'loss': 2.1397, 'learning_rate': 0.0005522642316338268, 'epoch': 0.48}
 48%|████▊     | 1150/2382 [3:32:44<3:49:37, 11.18s/it] 48%|████▊     | 1151/2382 [3:32:57<3:55:12, 11.46s/it]                                                       {'loss': 2.0341, 'learning_rate': 0.0005515879102011412, 'epoch': 0.48}
 48%|████▊     | 1151/2382 [3:32:57<3:55:12, 11.46s/it] 48%|████▊     | 1152/2382 [3:33:08<3:56:49, 11.55s/it]                                                       {'loss': 2.0882, 'learning_rate': 0.0005509114933519178, 'epoch': 0.48}
 48%|████▊     | 1152/2382 [3:33:08<3:56:49, 11.55s/it] 48%|████▊     | 1153/2382 [3:33:16<3:34:30, 10.47s/it]                                                       {'loss': 2.0275, 'learning_rate': 0.0005502349823372511, 'epoch': 0.48}
 48%|████▊     | 1153/2382 [3:33:16<3:34:30, 10.47s/it] 48%|████▊     | 1154/2382 [3:33:30<3:55:30, 11.51s/it]                                                       {'loss': 2.0597, 'learning_rate': 0.0005495583784084101, 'epoch': 0.48}
 48%|████▊     | 1154/2382 [3:33:30<3:55:30, 11.51s/it] 48%|████▊     | 1155/2382 [3:33:39<3:35:39, 10.55s/it]                                                       {'loss': 2.0935, 'learning_rate': 0.0005488816828168353, 'epoch': 0.48}
 48%|████▊     | 1155/2382 [3:33:39<3:35:39, 10.55s/it] 49%|████▊     | 1156/2382 [3:33:51<3:45:19, 11.03s/it]                                                       {'loss': 2.0015, 'learning_rate': 0.0005482048968141365, 'epoch': 0.49}
 49%|████▊     | 1156/2382 [3:33:51<3:45:19, 11.03s/it] 49%|████▊     | 1157/2382 [3:34:03<3:53:48, 11.45s/it]                                                       {'loss': 2.0268, 'learning_rate': 0.0005475280216520913, 'epoch': 0.49}
 49%|████▊     | 1157/2382 [3:34:03<3:53:48, 11.45s/it] 49%|████▊     | 1158/2382 [3:34:13<3:45:48, 11.07s/it]                                                       {'loss': 1.9687, 'learning_rate': 0.0005468510585826421, 'epoch': 0.49}
 49%|████▊     | 1158/2382 [3:34:13<3:45:48, 11.07s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1976 > 1024). Running this sequence through the model will result in indexing errors
 49%|████▊     | 1159/2382 [3:34:23<3:38:04, 10.70s/it]                                                       {'loss': 2.0539, 'learning_rate': 0.0005461740088578934, 'epoch': 0.49}
 49%|████▊     | 1159/2382 [3:34:23<3:38:04, 10.70s/it] 49%|████▊     | 1160/2382 [3:34:32<3:27:40, 10.20s/it]                                                       {'loss': 2.1143, 'learning_rate': 0.0005454968737301107, 'epoch': 0.49}
 49%|████▊     | 1160/2382 [3:34:32<3:27:40, 10.20s/it] 49%|████▊     | 1161/2382 [3:34:43<3:32:21, 10.44s/it]                                                       {'loss': 2.0347, 'learning_rate': 0.0005448196544517168, 'epoch': 0.49}
 49%|████▊     | 1161/2382 [3:34:43<3:32:21, 10.44s/it] 49%|████▉     | 1162/2382 [3:34:55<3:40:06, 10.83s/it]                                                       {'loss': 1.996, 'learning_rate': 0.0005441423522752904, 'epoch': 0.49}
 49%|████▉     | 1162/2382 [3:34:55<3:40:06, 10.83s/it] 49%|████▉     | 1163/2382 [3:35:04<3:29:45, 10.32s/it]                                                       {'loss': 2.2108, 'learning_rate': 0.000543464968453564, 'epoch': 0.49}
 49%|████▉     | 1163/2382 [3:35:04<3:29:45, 10.32s/it] 49%|████▉     | 1164/2382 [3:35:17<3:42:45, 10.97s/it]                                                       {'loss': 2.0912, 'learning_rate': 0.0005427875042394199, 'epoch': 0.49}
 49%|████▉     | 1164/2382 [3:35:17<3:42:45, 10.97s/it] 49%|████▉     | 1165/2382 [3:35:26<3:31:38, 10.43s/it]                                                       {'loss': 2.1129, 'learning_rate': 0.0005421099608858904, 'epoch': 0.49}
 49%|████▉     | 1165/2382 [3:35:26<3:31:38, 10.43s/it] 49%|████▉     | 1166/2382 [3:35:35<3:22:19,  9.98s/it]                                                       {'loss': 2.0, 'learning_rate': 0.0005414323396461537, 'epoch': 0.49}
 49%|████▉     | 1166/2382 [3:35:35<3:22:19,  9.98s/it] 49%|████▉     | 1167/2382 [3:35:44<3:18:29,  9.80s/it]                                                       {'loss': 2.017, 'learning_rate': 0.0005407546417735316, 'epoch': 0.49}
 49%|████▉     | 1167/2382 [3:35:44<3:18:29,  9.80s/it] 49%|████▉     | 1168/2382 [3:35:54<3:16:15,  9.70s/it]                                                       {'loss': 2.1035, 'learning_rate': 0.0005400768685214882, 'epoch': 0.49}
 49%|████▉     | 1168/2382 [3:35:54<3:16:15,  9.70s/it] 49%|████▉     | 1169/2382 [3:36:07<3:41:35, 10.96s/it]                                                       {'loss': 2.2546, 'learning_rate': 0.0005393990211436272, 'epoch': 0.49}
 49%|████▉     | 1169/2382 [3:36:07<3:41:35, 10.96s/it] 49%|████▉     | 1170/2382 [3:36:20<3:50:41, 11.42s/it]                                                       {'loss': 2.0119, 'learning_rate': 0.0005387211008936885, 'epoch': 0.49}
 49%|████▉     | 1170/2382 [3:36:20<3:50:41, 11.42s/it] 49%|████▉     | 1171/2382 [3:36:28<3:33:22, 10.57s/it]                                                       {'loss': 1.9983, 'learning_rate': 0.0005380431090255476, 'epoch': 0.49}
 49%|████▉     | 1171/2382 [3:36:28<3:33:22, 10.57s/it] 49%|████▉     | 1172/2382 [3:36:39<3:30:58, 10.46s/it]                                                       {'loss': 2.2135, 'learning_rate': 0.0005373650467932121, 'epoch': 0.49}
 49%|████▉     | 1172/2382 [3:36:39<3:30:58, 10.46s/it] 49%|████▉     | 1173/2382 [3:36:48<3:21:14,  9.99s/it]                                                       {'loss': 2.1008, 'learning_rate': 0.00053668691545082, 'epoch': 0.49}
 49%|████▉     | 1173/2382 [3:36:48<3:21:14,  9.99s/it] 49%|████▉     | 1174/2382 [3:36:59<3:30:11, 10.44s/it]                                                       {'loss': 2.0311, 'learning_rate': 0.000536008716252637, 'epoch': 0.49}
 49%|████▉     | 1174/2382 [3:36:59<3:30:11, 10.44s/it] 49%|████▉     | 1175/2382 [3:37:12<3:44:57, 11.18s/it]                                                       {'loss': 2.0704, 'learning_rate': 0.0005353304504530541, 'epoch': 0.49}
 49%|████▉     | 1175/2382 [3:37:12<3:44:57, 11.18s/it] 49%|████▉     | 1176/2382 [3:37:25<3:58:26, 11.86s/it]                                                       {'loss': 2.0809, 'learning_rate': 0.0005346521193065856, 'epoch': 0.49}
 49%|████▉     | 1176/2382 [3:37:25<3:58:26, 11.86s/it] 49%|████▉     | 1177/2382 [3:37:35<3:42:58, 11.10s/it]                                                       {'loss': 2.1005, 'learning_rate': 0.0005339737240678671, 'epoch': 0.49}
 49%|████▉     | 1177/2382 [3:37:35<3:42:58, 11.10s/it] 49%|████▉     | 1178/2382 [3:37:47<3:49:36, 11.44s/it]                                                       {'loss': 2.0001, 'learning_rate': 0.000533295265991652, 'epoch': 0.49}
 49%|████▉     | 1178/2382 [3:37:47<3:49:36, 11.44s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1196 > 1024). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (1247 > 1024). Running this sequence through the model will result in indexing errors
 49%|████▉     | 1179/2382 [3:37:58<3:47:38, 11.35s/it]                                                       {'loss': 2.0655, 'learning_rate': 0.0005326167463328104, 'epoch': 0.49}
 49%|████▉     | 1179/2382 [3:37:58<3:47:38, 11.35s/it] 50%|████▉     | 1180/2382 [3:38:10<3:48:46, 11.42s/it]                                                       {'loss': 2.0182, 'learning_rate': 0.0005319381663463262, 'epoch': 0.5}
 50%|████▉     | 1180/2382 [3:38:10<3:48:46, 11.42s/it] 50%|████▉     | 1181/2382 [3:38:23<3:56:59, 11.84s/it]                                                       {'loss': 1.9973, 'learning_rate': 0.000531259527287295, 'epoch': 0.5}
 50%|████▉     | 1181/2382 [3:38:23<3:56:59, 11.84s/it] 50%|████▉     | 1182/2382 [3:38:33<3:50:01, 11.50s/it]                                                       {'loss': 1.9282, 'learning_rate': 0.0005305808304109215, 'epoch': 0.5}
 50%|████▉     | 1182/2382 [3:38:33<3:50:01, 11.50s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1427 > 1024). Running this sequence through the model will result in indexing errors
 50%|████▉     | 1183/2382 [3:38:45<3:54:15, 11.72s/it]                                                       {'loss': 2.0707, 'learning_rate': 0.0005299020769725172, 'epoch': 0.5}
 50%|████▉     | 1183/2382 [3:38:45<3:54:15, 11.72s/it] 50%|████▉     | 1184/2382 [3:38:54<3:33:23, 10.69s/it]                                                       {'loss': 2.0694, 'learning_rate': 0.0005292232682274985, 'epoch': 0.5}
 50%|████▉     | 1184/2382 [3:38:54<3:33:23, 10.69s/it] 50%|████▉     | 1185/2382 [3:39:06<3:42:49, 11.17s/it]                                                       {'loss': 2.0096, 'learning_rate': 0.000528544405431384, 'epoch': 0.5}
 50%|████▉     | 1185/2382 [3:39:06<3:42:49, 11.17s/it] 50%|████▉     | 1186/2382 [3:39:22<4:08:22, 12.46s/it]                                                       {'loss': 1.9665, 'learning_rate': 0.0005278654898397923, 'epoch': 0.5}
 50%|████▉     | 1186/2382 [3:39:22<4:08:22, 12.46s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1147 > 1024). Running this sequence through the model will result in indexing errors
 50%|████▉     | 1187/2382 [3:39:31<3:50:42, 11.58s/it]                                                       {'loss': 1.9994, 'learning_rate': 0.0005271865227084397, 'epoch': 0.5}
 50%|████▉     | 1187/2382 [3:39:31<3:50:42, 11.58s/it] 50%|████▉     | 1188/2382 [3:39:43<3:54:00, 11.76s/it]                                                       {'loss': 1.9652, 'learning_rate': 0.0005265075052931374, 'epoch': 0.5}
 50%|████▉     | 1188/2382 [3:39:43<3:54:00, 11.76s/it] 50%|████▉     | 1189/2382 [3:39:58<4:10:26, 12.60s/it]                                                       {'loss': 2.0734, 'learning_rate': 0.0005258284388497904, 'epoch': 0.5}
 50%|████▉     | 1189/2382 [3:39:58<4:10:26, 12.60s/it] 50%|████▉     | 1190/2382 [3:40:07<3:52:16, 11.69s/it]                                                       {'loss': 2.0131, 'learning_rate': 0.0005251493246343936, 'epoch': 0.5}
 50%|████▉     | 1190/2382 [3:40:07<3:52:16, 11.69s/it] 50%|█████     | 1191/2382 [3:40:21<4:03:23, 12.26s/it]                                                       {'loss': 2.0613, 'learning_rate': 0.0005244701639030306, 'epoch': 0.5}
 50%|█████     | 1191/2382 [3:40:21<4:03:23, 12.26s/it] 50%|█████     | 1192/2382 [3:40:30<3:44:38, 11.33s/it]                                                       {'loss': 2.1088, 'learning_rate': 0.0005237909579118712, 'epoch': 0.5}
 50%|█████     | 1192/2382 [3:40:30<3:44:38, 11.33s/it] 50%|█████     | 1193/2382 [3:40:41<3:40:11, 11.11s/it]                                                       {'loss': 2.1068, 'learning_rate': 0.0005231117079171687, 'epoch': 0.5}
 50%|█████     | 1193/2382 [3:40:41<3:40:11, 11.11s/it] 50%|█████     | 1194/2382 [3:40:53<3:45:02, 11.37s/it]                                                       {'loss': 1.9358, 'learning_rate': 0.0005224324151752575, 'epoch': 0.5}
 50%|█████     | 1194/2382 [3:40:53<3:45:02, 11.37s/it] 50%|█████     | 1195/2382 [3:41:06<3:58:50, 12.07s/it]                                                       {'loss': 1.9914, 'learning_rate': 0.0005217530809425517, 'epoch': 0.5}
 50%|█████     | 1195/2382 [3:41:06<3:58:50, 12.07s/it] 50%|█████     | 1196/2382 [3:41:23<4:25:01, 13.41s/it]                                                       {'loss': 1.981, 'learning_rate': 0.000521073706475542, 'epoch': 0.5}
 50%|█████     | 1196/2382 [3:41:23<4:25:01, 13.41s/it] 50%|█████     | 1197/2382 [3:41:36<4:21:54, 13.26s/it]                                                       {'loss': 2.0298, 'learning_rate': 0.0005203942930307929, 'epoch': 0.5}
 50%|█████     | 1197/2382 [3:41:36<4:21:54, 13.26s/it] 50%|█████     | 1198/2382 [3:41:48<4:15:14, 12.93s/it]                                                       {'loss': 2.1101, 'learning_rate': 0.0005197148418649416, 'epoch': 0.5}
 50%|█████     | 1198/2382 [3:41:48<4:15:14, 12.93s/it] 50%|█████     | 1199/2382 [3:41:59<4:03:53, 12.37s/it]                                                       {'loss': 2.0305, 'learning_rate': 0.000519035354234695, 'epoch': 0.5}
 50%|█████     | 1199/2382 [3:41:59<4:03:53, 12.37s/it] 50%|█████     | 1200/2382 [3:42:11<4:03:11, 12.34s/it]                                                       {'loss': 2.0545, 'learning_rate': 0.0005183558313968274, 'epoch': 0.5}
 50%|█████     | 1200/2382 [3:42:11<4:03:11, 12.34s/it] 50%|█████     | 1201/2382 [3:42:21<3:47:38, 11.57s/it]                                                       {'loss': 1.9916, 'learning_rate': 0.0005176762746081779, 'epoch': 0.5}
 50%|█████     | 1201/2382 [3:42:21<3:47:38, 11.57s/it] 50%|█████     | 1202/2382 [3:42:32<3:42:36, 11.32s/it]                                                       {'loss': 2.1074, 'learning_rate': 0.0005169966851256488, 'epoch': 0.5}
 50%|█████     | 1202/2382 [3:42:32<3:42:36, 11.32s/it] 51%|█████     | 1203/2382 [3:42:44<3:47:51, 11.60s/it]                                                       {'loss': 2.1196, 'learning_rate': 0.000516317064206203, 'epoch': 0.5}
 51%|█████     | 1203/2382 [3:42:44<3:47:51, 11.60s/it] 51%|█████     | 1204/2382 [3:42:56<3:47:33, 11.59s/it]                                                       {'loss': 2.1223, 'learning_rate': 0.0005156374131068609, 'epoch': 0.51}
 51%|█████     | 1204/2382 [3:42:56<3:47:33, 11.59s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1112 > 1024). Running this sequence through the model will result in indexing errors
 51%|█████     | 1205/2382 [3:43:06<3:38:14, 11.13s/it]                                                       {'loss': 2.089, 'learning_rate': 0.0005149577330846993, 'epoch': 0.51}
 51%|█████     | 1205/2382 [3:43:06<3:38:14, 11.13s/it] 51%|█████     | 1206/2382 [3:43:18<3:43:34, 11.41s/it]                                                       {'loss': 2.0728, 'learning_rate': 0.0005142780253968481, 'epoch': 0.51}
 51%|█████     | 1206/2382 [3:43:18<3:43:34, 11.41s/it] 51%|█████     | 1207/2382 [3:43:29<3:45:03, 11.49s/it]                                                       {'loss': 2.0321, 'learning_rate': 0.0005135982913004888, 'epoch': 0.51}
 51%|█████     | 1207/2382 [3:43:29<3:45:03, 11.49s/it] 51%|█████     | 1208/2382 [3:43:38<3:30:31, 10.76s/it]                                                       {'loss': 2.0663, 'learning_rate': 0.0005129185320528515, 'epoch': 0.51}
 51%|█████     | 1208/2382 [3:43:39<3:30:31, 10.76s/it] 51%|█████     | 1209/2382 [3:43:48<3:25:49, 10.53s/it]                                                       {'loss': 2.0515, 'learning_rate': 0.0005122387489112127, 'epoch': 0.51}
 51%|█████     | 1209/2382 [3:43:48<3:25:49, 10.53s/it] 51%|█████     | 1210/2382 [3:43:58<3:21:54, 10.34s/it]                                                       {'loss': 2.0831, 'learning_rate': 0.0005115589431328931, 'epoch': 0.51}
 51%|█████     | 1210/2382 [3:43:58<3:21:54, 10.34s/it] 51%|█████     | 1211/2382 [3:44:09<3:22:00, 10.35s/it]                                                       {'loss': 1.9466, 'learning_rate': 0.000510879115975256, 'epoch': 0.51}
 51%|█████     | 1211/2382 [3:44:09<3:22:00, 10.35s/it] 51%|█████     | 1212/2382 [3:44:19<3:19:50, 10.25s/it]                                                       {'loss': 2.0856, 'learning_rate': 0.0005101992686957028, 'epoch': 0.51}
 51%|█████     | 1212/2382 [3:44:19<3:19:50, 10.25s/it] 51%|█████     | 1213/2382 [3:44:27<3:08:37,  9.68s/it]                                                       {'loss': 2.0315, 'learning_rate': 0.0005095194025516733, 'epoch': 0.51}
 51%|█████     | 1213/2382 [3:44:27<3:08:37,  9.68s/it] 51%|█████     | 1214/2382 [3:44:38<3:16:58, 10.12s/it]                                                       {'loss': 2.0243, 'learning_rate': 0.0005088395188006422, 'epoch': 0.51}
 51%|█████     | 1214/2382 [3:44:38<3:16:58, 10.12s/it] 51%|█████     | 1215/2382 [3:44:47<3:09:01,  9.72s/it]                                                       {'loss': 2.0586, 'learning_rate': 0.000508159618700116, 'epoch': 0.51}
 51%|█████     | 1215/2382 [3:44:47<3:09:01,  9.72s/it] 51%|█████     | 1216/2382 [3:44:59<3:24:13, 10.51s/it]                                                       {'loss': 2.1018, 'learning_rate': 0.0005074797035076318, 'epoch': 0.51}
 51%|█████     | 1216/2382 [3:44:59<3:24:13, 10.51s/it] 51%|█████     | 1217/2382 [3:45:10<3:22:22, 10.42s/it]                                                       {'loss': 1.9175, 'learning_rate': 0.000506799774480755, 'epoch': 0.51}
 51%|█████     | 1217/2382 [3:45:10<3:22:22, 10.42s/it] 51%|█████     | 1218/2382 [3:45:19<3:17:17, 10.17s/it]                                                       {'loss': 2.0313, 'learning_rate': 0.0005061198328770761, 'epoch': 0.51}
 51%|█████     | 1218/2382 [3:45:19<3:17:17, 10.17s/it] 51%|█████     | 1219/2382 [3:45:29<3:17:34, 10.19s/it]                                                       {'loss': 2.0547, 'learning_rate': 0.0005054398799542088, 'epoch': 0.51}
 51%|█████     | 1219/2382 [3:45:29<3:17:34, 10.19s/it] 51%|█████     | 1220/2382 [3:45:40<3:22:20, 10.45s/it]                                                       {'loss': 2.0654, 'learning_rate': 0.0005047599169697884, 'epoch': 0.51}
 51%|█████     | 1220/2382 [3:45:40<3:22:20, 10.45s/it] 51%|█████▏    | 1221/2382 [3:45:57<3:55:10, 12.15s/it]                                                       {'loss': 2.111, 'learning_rate': 0.000504079945181468, 'epoch': 0.51}
 51%|█████▏    | 1221/2382 [3:45:57<3:55:10, 12.15s/it] 51%|█████▏    | 1222/2382 [3:46:07<3:44:39, 11.62s/it]                                                       {'loss': 2.1795, 'learning_rate': 0.0005033999658469174, 'epoch': 0.51}
 51%|█████▏    | 1222/2382 [3:46:07<3:44:39, 11.62s/it] 51%|█████▏    | 1223/2382 [3:46:21<3:57:58, 12.32s/it]                                                       {'loss': 2.1363, 'learning_rate': 0.0005027199802238204, 'epoch': 0.51}
 51%|█████▏    | 1223/2382 [3:46:21<3:57:58, 12.32s/it] 51%|█████▏    | 1224/2382 [3:46:30<3:41:25, 11.47s/it]                                                       {'loss': 2.0611, 'learning_rate': 0.0005020399895698721, 'epoch': 0.51}
 51%|█████▏    | 1224/2382 [3:46:30<3:41:25, 11.47s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1086 > 1024). Running this sequence through the model will result in indexing errors
 51%|█████▏    | 1225/2382 [3:46:40<3:28:52, 10.83s/it]                                                       {'loss': 2.0296, 'learning_rate': 0.0005013599951427776, 'epoch': 0.51}
 51%|█████▏    | 1225/2382 [3:46:40<3:28:52, 10.83s/it] 51%|█████▏    | 1226/2382 [3:46:50<3:23:40, 10.57s/it]                                                       {'loss': 2.2108, 'learning_rate': 0.0005006799982002482, 'epoch': 0.51}
 51%|█████▏    | 1226/2382 [3:46:50<3:23:40, 10.57s/it] 52%|█████▏    | 1227/2382 [3:46:59<3:13:29, 10.05s/it]                                                       {'loss': 1.9945, 'learning_rate': 0.0005, 'epoch': 0.51}
 52%|█████▏    | 1227/2382 [3:46:59<3:13:29, 10.05s/it] 52%|█████▏    | 1228/2382 [3:47:10<3:22:10, 10.51s/it]                                                       {'loss': 2.0395, 'learning_rate': 0.0004993200017997519, 'epoch': 0.52}
 52%|█████▏    | 1228/2382 [3:47:10<3:22:10, 10.51s/it] 52%|█████▏    | 1229/2382 [3:47:20<3:20:15, 10.42s/it]                                                       {'loss': 1.9016, 'learning_rate': 0.0004986400048572224, 'epoch': 0.52}
 52%|█████▏    | 1229/2382 [3:47:20<3:20:15, 10.42s/it] 52%|█████▏    | 1230/2382 [3:47:33<3:33:37, 11.13s/it]                                                       {'loss': 2.0426, 'learning_rate': 0.000497960010430128, 'epoch': 0.52}
 52%|█████▏    | 1230/2382 [3:47:33<3:33:37, 11.13s/it] 52%|█████▏    | 1231/2382 [3:47:46<3:45:07, 11.74s/it]                                                       {'loss': 2.0948, 'learning_rate': 0.0004972800197761798, 'epoch': 0.52}
 52%|█████▏    | 1231/2382 [3:47:46<3:45:07, 11.74s/it] 52%|█████▏    | 1232/2382 [3:47:58<3:44:34, 11.72s/it]                                                       {'loss': 1.9958, 'learning_rate': 0.0004966000341530827, 'epoch': 0.52}
 52%|█████▏    | 1232/2382 [3:47:58<3:44:34, 11.72s/it] 52%|█████▏    | 1233/2382 [3:48:09<3:41:03, 11.54s/it]                                                       {'loss': 2.0034, 'learning_rate': 0.0004959200548185322, 'epoch': 0.52}
 52%|█████▏    | 1233/2382 [3:48:09<3:41:03, 11.54s/it] 52%|█████▏    | 1234/2382 [3:48:18<3:28:21, 10.89s/it]                                                       {'loss': 2.086, 'learning_rate': 0.0004952400830302117, 'epoch': 0.52}
 52%|█████▏    | 1234/2382 [3:48:18<3:28:21, 10.89s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1043 > 1024). Running this sequence through the model will result in indexing errors
 52%|█████▏    | 1235/2382 [3:48:29<3:26:48, 10.82s/it]                                                       {'loss': 2.0099, 'learning_rate': 0.0004945601200457911, 'epoch': 0.52}
 52%|█████▏    | 1235/2382 [3:48:29<3:26:48, 10.82s/it] 52%|█████▏    | 1236/2382 [3:48:39<3:22:34, 10.61s/it]                                                       {'loss': 2.0621, 'learning_rate': 0.0004938801671229242, 'epoch': 0.52}
 52%|█████▏    | 1236/2382 [3:48:39<3:22:34, 10.61s/it] 52%|█████▏    | 1237/2382 [3:48:49<3:18:23, 10.40s/it]                                                       {'loss': 2.0624, 'learning_rate': 0.0004932002255192452, 'epoch': 0.52}
 52%|█████▏    | 1237/2382 [3:48:49<3:18:23, 10.40s/it] 52%|█████▏    | 1238/2382 [3:48:59<3:14:10, 10.18s/it]                                                       {'loss': 2.0501, 'learning_rate': 0.0004925202964923683, 'epoch': 0.52}
 52%|█████▏    | 1238/2382 [3:48:59<3:14:10, 10.18s/it] 52%|█████▏    | 1239/2382 [3:49:10<3:21:12, 10.56s/it]                                                       {'loss': 2.1413, 'learning_rate': 0.0004918403812998841, 'epoch': 0.52}
 52%|█████▏    | 1239/2382 [3:49:10<3:21:12, 10.56s/it] 52%|█████▏    | 1240/2382 [3:49:20<3:13:17, 10.16s/it]                                                       {'loss': 2.1068, 'learning_rate': 0.000491160481199358, 'epoch': 0.52}
 52%|█████▏    | 1240/2382 [3:49:20<3:13:17, 10.16s/it] 52%|█████▏    | 1241/2382 [3:49:32<3:25:13, 10.79s/it]                                                       {'loss': 2.1115, 'learning_rate': 0.0004904805974483267, 'epoch': 0.52}
 52%|█████▏    | 1241/2382 [3:49:32<3:25:13, 10.79s/it] 52%|█████▏    | 1242/2382 [3:49:42<3:20:42, 10.56s/it]                                                       {'loss': 2.1687, 'learning_rate': 0.0004898007313042975, 'epoch': 0.52}
 52%|█████▏    | 1242/2382 [3:49:42<3:20:42, 10.56s/it] 52%|█████▏    | 1243/2382 [3:49:52<3:17:55, 10.43s/it]                                                       {'loss': 1.9738, 'learning_rate': 0.0004891208840247443, 'epoch': 0.52}
 52%|█████▏    | 1243/2382 [3:49:52<3:17:55, 10.43s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1518 > 1024). Running this sequence through the model will result in indexing errors
 52%|█████▏    | 1244/2382 [3:50:03<3:20:25, 10.57s/it]                                                       {'loss': 2.0326, 'learning_rate': 0.0004884410568671069, 'epoch': 0.52}
 52%|█████▏    | 1244/2382 [3:50:03<3:20:25, 10.57s/it] 52%|█████▏    | 1245/2382 [3:50:15<3:27:23, 10.94s/it]                                                       {'loss': 2.0937, 'learning_rate': 0.0004877612510887874, 'epoch': 0.52}
 52%|█████▏    | 1245/2382 [3:50:15<3:27:23, 10.94s/it] 52%|█████▏    | 1246/2382 [3:50:24<3:20:35, 10.59s/it]                                                       {'loss': 2.0158, 'learning_rate': 0.0004870814679471485, 'epoch': 0.52}
 52%|█████▏    | 1246/2382 [3:50:24<3:20:35, 10.59s/it] 52%|█████▏    | 1247/2382 [3:50:36<3:27:16, 10.96s/it]                                                       {'loss': 2.107, 'learning_rate': 0.00048640170869951115, 'epoch': 0.52}
 52%|█████▏    | 1247/2382 [3:50:36<3:27:16, 10.96s/it] 52%|█████▏    | 1248/2382 [3:50:49<3:38:55, 11.58s/it]                                                       {'loss': 2.0471, 'learning_rate': 0.0004857219746031519, 'epoch': 0.52}
 52%|█████▏    | 1248/2382 [3:50:49<3:38:55, 11.58s/it] 52%|█████▏    | 1249/2382 [3:51:00<3:31:40, 11.21s/it]                                                       {'loss': 2.0342, 'learning_rate': 0.0004850422669153009, 'epoch': 0.52}
 52%|█████▏    | 1249/2382 [3:51:00<3:31:40, 11.21s/it] 52%|█████▏    | 1250/2382 [3:51:10<3:28:32, 11.05s/it]                                                       {'loss': 1.9627, 'learning_rate': 0.0004843625868931392, 'epoch': 0.52}
 52%|█████▏    | 1250/2382 [3:51:10<3:28:32, 11.05s/it] 53%|█████▎    | 1251/2382 [3:51:22<3:32:36, 11.28s/it]                                                       {'loss': 2.0717, 'learning_rate': 0.00048368293579379703, 'epoch': 0.52}
 53%|█████▎    | 1251/2382 [3:51:22<3:32:36, 11.28s/it] 53%|█████▎    | 1252/2382 [3:51:34<3:37:31, 11.55s/it]                                                       {'loss': 2.0886, 'learning_rate': 0.0004830033148743511, 'epoch': 0.53}
 53%|█████▎    | 1252/2382 [3:51:34<3:37:31, 11.55s/it] 53%|█████▎    | 1253/2382 [3:51:44<3:26:51, 10.99s/it]                                                       {'loss': 2.0034, 'learning_rate': 0.00048232372539182207, 'epoch': 0.53}
 53%|█████▎    | 1253/2382 [3:51:44<3:26:51, 10.99s/it] 53%|█████▎    | 1254/2382 [3:51:54<3:21:26, 10.71s/it]                                                       {'loss': 2.0717, 'learning_rate': 0.00048164416860317286, 'epoch': 0.53}
 53%|█████▎    | 1254/2382 [3:51:54<3:21:26, 10.71s/it] 53%|█████▎    | 1255/2382 [3:52:06<3:27:49, 11.06s/it]                                                       {'loss': 1.9572, 'learning_rate': 0.00048096464576530507, 'epoch': 0.53}
 53%|█████▎    | 1255/2382 [3:52:06<3:27:49, 11.06s/it] 53%|█████▎    | 1256/2382 [3:52:16<3:21:34, 10.74s/it]                                                       {'loss': 1.9963, 'learning_rate': 0.00048028515813505854, 'epoch': 0.53}
 53%|█████▎    | 1256/2382 [3:52:16<3:21:34, 10.74s/it] 53%|█████▎    | 1257/2382 [3:52:29<3:34:27, 11.44s/it]                                                       {'loss': 1.9864, 'learning_rate': 0.00047960570696920727, 'epoch': 0.53}
 53%|█████▎    | 1257/2382 [3:52:29<3:34:27, 11.44s/it] 53%|█████▎    | 1258/2382 [3:52:42<3:44:36, 11.99s/it]                                                       {'loss': 2.0559, 'learning_rate': 0.0004789262935244581, 'epoch': 0.53}
 53%|█████▎    | 1258/2382 [3:52:42<3:44:36, 11.99s/it] 53%|█████▎    | 1259/2382 [3:52:53<3:37:18, 11.61s/it]                                                       {'loss': 2.0391, 'learning_rate': 0.0004782469190574483, 'epoch': 0.53}
 53%|█████▎    | 1259/2382 [3:52:53<3:37:18, 11.61s/it] 53%|█████▎    | 1260/2382 [3:53:06<3:42:37, 11.91s/it]                                                       {'loss': 2.0058, 'learning_rate': 0.0004775675848247427, 'epoch': 0.53}
 53%|█████▎    | 1260/2382 [3:53:06<3:42:37, 11.91s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1267 > 1024). Running this sequence through the model will result in indexing errors
 53%|█████▎    | 1261/2382 [3:53:17<3:39:11, 11.73s/it]                                                       {'loss': 2.1019, 'learning_rate': 0.00047688829208283157, 'epoch': 0.53}
 53%|█████▎    | 1261/2382 [3:53:17<3:39:11, 11.73s/it] 53%|█████▎    | 1262/2382 [3:53:26<3:25:34, 11.01s/it]                                                       {'loss': 2.0588, 'learning_rate': 0.0004762090420881289, 'epoch': 0.53}
 53%|█████▎    | 1262/2382 [3:53:26<3:25:34, 11.01s/it] 53%|█████▎    | 1263/2382 [3:53:40<3:39:23, 11.76s/it]                                                       {'loss': 2.0353, 'learning_rate': 0.00047552983609696947, 'epoch': 0.53}
 53%|█████▎    | 1263/2382 [3:53:40<3:39:23, 11.76s/it] 53%|█████▎    | 1264/2382 [3:53:48<3:21:18, 10.80s/it]                                                       {'loss': 2.0986, 'learning_rate': 0.00047485067536560645, 'epoch': 0.53}
 53%|█████▎    | 1264/2382 [3:53:48<3:21:18, 10.80s/it] 53%|█████▎    | 1265/2382 [3:53:58<3:16:52, 10.57s/it]                                                       {'loss': 1.99, 'learning_rate': 0.0004741715611502096, 'epoch': 0.53}
 53%|█████▎    | 1265/2382 [3:53:58<3:16:52, 10.57s/it] 53%|█████▎    | 1266/2382 [3:54:11<3:26:56, 11.13s/it]                                                       {'loss': 1.9374, 'learning_rate': 0.0004734924947068626, 'epoch': 0.53}
 53%|█████▎    | 1266/2382 [3:54:11<3:26:56, 11.13s/it] 53%|█████▎    | 1267/2382 [3:54:21<3:23:30, 10.95s/it]                                                       {'loss': 2.0945, 'learning_rate': 0.0004728134772915605, 'epoch': 0.53}
 53%|█████▎    | 1267/2382 [3:54:21<3:23:30, 10.95s/it] 53%|█████▎    | 1268/2382 [3:54:33<3:29:12, 11.27s/it]                                                       {'loss': 1.9845, 'learning_rate': 0.00047213451016020773, 'epoch': 0.53}
 53%|█████▎    | 1268/2382 [3:54:33<3:29:12, 11.27s/it] 53%|█████▎    | 1269/2382 [3:54:46<3:37:34, 11.73s/it]                                                       {'loss': 2.0124, 'learning_rate': 0.000471455594568616, 'epoch': 0.53}
 53%|█████▎    | 1269/2382 [3:54:46<3:37:34, 11.73s/it] 53%|█████▎    | 1270/2382 [3:54:55<3:21:57, 10.90s/it]                                                       {'loss': 1.9955, 'learning_rate': 0.0004707767317725016, 'epoch': 0.53}
 53%|█████▎    | 1270/2382 [3:54:55<3:21:57, 10.90s/it] 53%|█████▎    | 1271/2382 [3:55:04<3:12:49, 10.41s/it]                                                       {'loss': 2.106, 'learning_rate': 0.0004700979230274829, 'epoch': 0.53}
 53%|█████▎    | 1271/2382 [3:55:04<3:12:49, 10.41s/it] 53%|█████▎    | 1272/2382 [3:55:14<3:07:11, 10.12s/it]                                                       {'loss': 1.9045, 'learning_rate': 0.0004694191695890788, 'epoch': 0.53}
 53%|█████▎    | 1272/2382 [3:55:14<3:07:11, 10.12s/it] 53%|█████▎    | 1273/2382 [3:55:24<3:08:42, 10.21s/it]                                                       {'loss': 2.0238, 'learning_rate': 0.00046874047271270507, 'epoch': 0.53}
 53%|█████▎    | 1273/2382 [3:55:24<3:08:42, 10.21s/it] 53%|█████▎    | 1274/2382 [3:55:36<3:16:00, 10.61s/it]                                                       {'loss': 2.1117, 'learning_rate': 0.00046806183365367396, 'epoch': 0.53}
 53%|█████▎    | 1274/2382 [3:55:36<3:16:00, 10.61s/it] 54%|█████▎    | 1275/2382 [3:55:46<3:12:24, 10.43s/it]                                                       {'loss': 2.0485, 'learning_rate': 0.0004673832536671897, 'epoch': 0.54}
 54%|█████▎    | 1275/2382 [3:55:46<3:12:24, 10.43s/it] 54%|█████▎    | 1276/2382 [3:55:56<3:13:17, 10.49s/it]                                                       {'loss': 1.9494, 'learning_rate': 0.00046670473400834805, 'epoch': 0.54}
 54%|█████▎    | 1276/2382 [3:55:56<3:13:17, 10.49s/it] 54%|█████▎    | 1277/2382 [3:56:11<3:33:21, 11.59s/it]                                                       {'loss': 1.9529, 'learning_rate': 0.000466026275932133, 'epoch': 0.54}
 54%|█████▎    | 1277/2382 [3:56:11<3:33:21, 11.59s/it] 54%|█████▎    | 1278/2382 [3:56:25<3:49:06, 12.45s/it]                                                       {'loss': 1.9361, 'learning_rate': 0.00046534788069341453, 'epoch': 0.54}
 54%|█████▎    | 1278/2382 [3:56:25<3:49:06, 12.45s/it] 54%|█████▎    | 1279/2382 [3:56:34<3:30:58, 11.48s/it]                                                       {'loss': 2.1706, 'learning_rate': 0.00046466954954694605, 'epoch': 0.54}
 54%|█████▎    | 1279/2382 [3:56:34<3:30:58, 11.48s/it] 54%|█████▎    | 1280/2382 [3:56:44<3:21:01, 10.95s/it]                                                       {'loss': 2.1391, 'learning_rate': 0.0004639912837473631, 'epoch': 0.54}
 54%|█████▎    | 1280/2382 [3:56:44<3:21:01, 10.95s/it] 54%|█████▍    | 1281/2382 [3:56:56<3:25:21, 11.19s/it]                                                       {'loss': 2.0803, 'learning_rate': 0.00046331308454918, 'epoch': 0.54}
 54%|█████▍    | 1281/2382 [3:56:56<3:25:21, 11.19s/it] 54%|█████▍    | 1282/2382 [3:57:08<3:30:47, 11.50s/it]                                                       {'loss': 1.9944, 'learning_rate': 0.0004626349532067879, 'epoch': 0.54}
 54%|█████▍    | 1282/2382 [3:57:08<3:30:47, 11.50s/it] 54%|█████▍    | 1283/2382 [3:57:19<3:26:11, 11.26s/it]                                                       {'loss': 2.0356, 'learning_rate': 0.0004619568909744524, 'epoch': 0.54}
 54%|█████▍    | 1283/2382 [3:57:19<3:26:11, 11.26s/it] 54%|█████▍    | 1284/2382 [3:57:29<3:23:55, 11.14s/it]                                                       {'loss': 2.0367, 'learning_rate': 0.00046127889910631167, 'epoch': 0.54}
 54%|█████▍    | 1284/2382 [3:57:29<3:23:55, 11.14s/it] 54%|█████▍    | 1285/2382 [3:57:41<3:24:00, 11.16s/it]                                                       {'loss': 2.0899, 'learning_rate': 0.00046060097885637305, 'epoch': 0.54}
 54%|█████▍    | 1285/2382 [3:57:41<3:24:00, 11.16s/it] 54%|█████▍    | 1286/2382 [3:57:54<3:35:49, 11.82s/it]                                                       {'loss': 1.9155, 'learning_rate': 0.0004599231314785118, 'epoch': 0.54}
 54%|█████▍    | 1286/2382 [3:57:54<3:35:49, 11.82s/it] 54%|█████▍    | 1287/2382 [3:58:07<3:41:08, 12.12s/it]                                                       {'loss': 1.9943, 'learning_rate': 0.0004592453582264684, 'epoch': 0.54}
 54%|█████▍    | 1287/2382 [3:58:07<3:41:08, 12.12s/it] 54%|█████▍    | 1288/2382 [3:58:19<3:39:27, 12.04s/it]                                                       {'loss': 2.0722, 'learning_rate': 0.0004585676603538465, 'epoch': 0.54}
 54%|█████▍    | 1288/2382 [3:58:19<3:39:27, 12.04s/it] 54%|█████▍    | 1289/2382 [3:58:31<3:39:13, 12.03s/it]                                                       {'loss': 2.0621, 'learning_rate': 0.00045789003911410954, 'epoch': 0.54}
 54%|█████▍    | 1289/2382 [3:58:31<3:39:13, 12.03s/it] 54%|█████▍    | 1290/2382 [3:58:41<3:27:10, 11.38s/it]                                                       {'loss': 2.0748, 'learning_rate': 0.0004572124957605803, 'epoch': 0.54}
 54%|█████▍    | 1290/2382 [3:58:41<3:27:10, 11.38s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1815 > 1024). Running this sequence through the model will result in indexing errors
 54%|█████▍    | 1291/2382 [3:58:49<3:09:48, 10.44s/it]                                                       {'loss': 2.0881, 'learning_rate': 0.0004565350315464363, 'epoch': 0.54}
 54%|█████▍    | 1291/2382 [3:58:49<3:09:48, 10.44s/it] 54%|█████▍    | 1292/2382 [3:58:59<3:07:16, 10.31s/it]                                                       {'loss': 2.1228, 'learning_rate': 0.0004558576477247097, 'epoch': 0.54}
 54%|█████▍    | 1292/2382 [3:58:59<3:07:16, 10.31s/it] 54%|█████▍    | 1293/2382 [3:59:09<3:05:42, 10.23s/it]                                                       {'loss': 2.0781, 'learning_rate': 0.0004551803455482833, 'epoch': 0.54}
 54%|█████▍    | 1293/2382 [3:59:09<3:05:42, 10.23s/it] 54%|█████▍    | 1294/2382 [3:59:20<3:13:00, 10.64s/it]                                                       {'loss': 1.9095, 'learning_rate': 0.00045450312626988933, 'epoch': 0.54}
 54%|█████▍    | 1294/2382 [3:59:20<3:13:00, 10.64s/it] 54%|█████▍    | 1295/2382 [3:59:32<3:19:07, 10.99s/it]                                                       {'loss': 1.9425, 'learning_rate': 0.0004538259911421065, 'epoch': 0.54}
 54%|█████▍    | 1295/2382 [3:59:32<3:19:07, 10.99s/it] 54%|█████▍    | 1296/2382 [3:59:41<3:06:25, 10.30s/it]                                                       {'loss': 2.0148, 'learning_rate': 0.00045314894141735803, 'epoch': 0.54}
 54%|█████▍    | 1296/2382 [3:59:41<3:06:25, 10.30s/it] 54%|█████▍    | 1297/2382 [3:59:51<3:06:24, 10.31s/it]                                                       {'loss': 2.0728, 'learning_rate': 0.0004524719783479088, 'epoch': 0.54}
 54%|█████▍    | 1297/2382 [3:59:51<3:06:24, 10.31s/it] 54%|█████▍    | 1298/2382 [4:00:02<3:09:43, 10.50s/it]                                                       {'loss': 1.9706, 'learning_rate': 0.00045179510318586356, 'epoch': 0.54}
 54%|█████▍    | 1298/2382 [4:00:02<3:09:43, 10.50s/it] 55%|█████▍    | 1299/2382 [4:00:14<3:19:06, 11.03s/it]                                                       {'loss': 1.9194, 'learning_rate': 0.00045111831718316485, 'epoch': 0.55}
 55%|█████▍    | 1299/2382 [4:00:14<3:19:06, 11.03s/it] 55%|█████▍    | 1300/2382 [4:00:24<3:10:48, 10.58s/it]                                                       {'loss': 2.0498, 'learning_rate': 0.00045044162159159, 'epoch': 0.55}
 55%|█████▍    | 1300/2382 [4:00:24<3:10:48, 10.58s/it] 55%|█████▍    | 1301/2382 [4:00:35<3:12:20, 10.68s/it]                                                       {'loss': 1.9984, 'learning_rate': 0.00044976501766274884, 'epoch': 0.55}
 55%|█████▍    | 1301/2382 [4:00:35<3:12:20, 10.68s/it] 55%|█████▍    | 1302/2382 [4:00:47<3:21:07, 11.17s/it]                                                       {'loss': 2.1754, 'learning_rate': 0.0004490885066480824, 'epoch': 0.55}
 55%|█████▍    | 1302/2382 [4:00:47<3:21:07, 11.17s/it] 55%|█████▍    | 1303/2382 [4:00:59<3:24:00, 11.34s/it]                                                       {'loss': 2.1113, 'learning_rate': 0.00044841208979885897, 'epoch': 0.55}
 55%|█████▍    | 1303/2382 [4:00:59<3:24:00, 11.34s/it] 55%|█████▍    | 1304/2382 [4:01:11<3:27:59, 11.58s/it]                                                       {'loss': 2.0454, 'learning_rate': 0.00044773576836617336, 'epoch': 0.55}
 55%|█████▍    | 1304/2382 [4:01:11<3:27:59, 11.58s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1371 > 1024). Running this sequence through the model will result in indexing errors
 55%|█████▍    | 1305/2382 [4:01:22<3:22:12, 11.26s/it]                                                       {'loss': 1.9316, 'learning_rate': 0.0004470595436009435, 'epoch': 0.55}
 55%|█████▍    | 1305/2382 [4:01:22<3:22:12, 11.26s/it] 55%|█████▍    | 1306/2382 [4:01:32<3:18:11, 11.05s/it]                                                       {'loss': 2.0717, 'learning_rate': 0.0004463834167539087, 'epoch': 0.55}
 55%|█████▍    | 1306/2382 [4:01:32<3:18:11, 11.05s/it] 55%|█████▍    | 1307/2382 [4:01:43<3:17:24, 11.02s/it]                                                       {'loss': 2.0663, 'learning_rate': 0.0004457073890756273, 'epoch': 0.55}
 55%|█████▍    | 1307/2382 [4:01:43<3:17:24, 11.02s/it] 55%|█████▍    | 1308/2382 [4:01:53<3:11:58, 10.73s/it]                                                       {'loss': 2.0458, 'learning_rate': 0.0004450314618164741, 'epoch': 0.55}
 55%|█████▍    | 1308/2382 [4:01:53<3:11:58, 10.73s/it] 55%|█████▍    | 1309/2382 [4:02:06<3:23:43, 11.39s/it]                                                       {'loss': 1.9525, 'learning_rate': 0.00044435563622663774, 'epoch': 0.55}
 55%|█████▍    | 1309/2382 [4:02:06<3:23:43, 11.39s/it] 55%|█████▍    | 1310/2382 [4:02:15<3:11:25, 10.71s/it]                                                       {'loss': 2.0749, 'learning_rate': 0.00044367991355611936, 'epoch': 0.55}
 55%|█████▍    | 1310/2382 [4:02:15<3:11:25, 10.71s/it] 55%|█████▌    | 1311/2382 [4:02:28<3:20:32, 11.23s/it]                                                       {'loss': 2.0626, 'learning_rate': 0.0004430042950547297, 'epoch': 0.55}
 55%|█████▌    | 1311/2382 [4:02:28<3:20:32, 11.23s/it] 55%|█████▌    | 1312/2382 [4:02:37<3:09:29, 10.63s/it]                                                       {'loss': 2.0328, 'learning_rate': 0.0004423287819720866, 'epoch': 0.55}
 55%|█████▌    | 1312/2382 [4:02:37<3:09:29, 10.63s/it] 55%|█████▌    | 1313/2382 [4:02:48<3:14:00, 10.89s/it]                                                       {'loss': 2.0561, 'learning_rate': 0.000441653375557613, 'epoch': 0.55}
 55%|█████▌    | 1313/2382 [4:02:48<3:14:00, 10.89s/it] 55%|█████▌    | 1314/2382 [4:03:01<3:23:13, 11.42s/it]                                                       {'loss': 1.9684, 'learning_rate': 0.0004409780770605349, 'epoch': 0.55}
 55%|█████▌    | 1314/2382 [4:03:01<3:23:13, 11.42s/it] 55%|█████▌    | 1315/2382 [4:03:13<3:24:25, 11.50s/it]                                                       {'loss': 2.069, 'learning_rate': 0.00044030288772987794, 'epoch': 0.55}
 55%|█████▌    | 1315/2382 [4:03:13<3:24:25, 11.50s/it] 55%|█████▌    | 1316/2382 [4:03:23<3:17:58, 11.14s/it]                                                       {'loss': 2.2419, 'learning_rate': 0.0004396278088144663, 'epoch': 0.55}
 55%|█████▌    | 1316/2382 [4:03:23<3:17:58, 11.14s/it] 55%|█████▌    | 1317/2382 [4:03:36<3:26:42, 11.65s/it]                                                       {'loss': 1.9837, 'learning_rate': 0.00043895284156292004, 'epoch': 0.55}
 55%|█████▌    | 1317/2382 [4:03:36<3:26:42, 11.65s/it] 55%|█████▌    | 1318/2382 [4:03:48<3:26:17, 11.63s/it]                                                       {'loss': 1.9828, 'learning_rate': 0.00043827798722365264, 'epoch': 0.55}
 55%|█████▌    | 1318/2382 [4:03:48<3:26:17, 11.63s/it] 55%|█████▌    | 1319/2382 [4:03:57<3:16:28, 11.09s/it]                                                       {'loss': 2.0688, 'learning_rate': 0.00043760324704486845, 'epoch': 0.55}
 55%|█████▌    | 1319/2382 [4:03:57<3:16:28, 11.09s/it] 55%|█████▌    | 1320/2382 [4:04:10<3:22:30, 11.44s/it]                                                       {'loss': 1.9639, 'learning_rate': 0.00043692862227456125, 'epoch': 0.55}
 55%|█████▌    | 1320/2382 [4:04:10<3:22:30, 11.44s/it] 55%|█████▌    | 1321/2382 [4:04:20<3:14:23, 10.99s/it]                                                       {'loss': 1.9829, 'learning_rate': 0.0004362541141605105, 'epoch': 0.55}
 55%|█████▌    | 1321/2382 [4:04:20<3:14:23, 10.99s/it] 55%|█████▌    | 1322/2382 [4:04:33<3:27:03, 11.72s/it]                                                       {'loss': 2.1148, 'learning_rate': 0.00043557972395028065, 'epoch': 0.55}
 55%|█████▌    | 1322/2382 [4:04:33<3:27:03, 11.72s/it] 56%|█████▌    | 1323/2382 [4:04:42<3:14:15, 11.01s/it]                                                       {'loss': 2.0043, 'learning_rate': 0.0004349054528912177, 'epoch': 0.56}
 56%|█████▌    | 1323/2382 [4:04:42<3:14:15, 11.01s/it] 56%|█████▌    | 1324/2382 [4:04:50<2:54:54,  9.92s/it]                                                       {'loss': 2.1757, 'learning_rate': 0.0004342313022304474, 'epoch': 0.56}
 56%|█████▌    | 1324/2382 [4:04:50<2:54:54,  9.92s/it] 56%|█████▌    | 1325/2382 [4:05:01<3:02:38, 10.37s/it]                                                       {'loss': 1.9887, 'learning_rate': 0.000433557273214873, 'epoch': 0.56}
 56%|█████▌    | 1325/2382 [4:05:01<3:02:38, 10.37s/it] 56%|█████▌    | 1326/2382 [4:05:10<2:55:43,  9.98s/it]                                                       {'loss': 2.1316, 'learning_rate': 0.0004328833670911724, 'epoch': 0.56}
 56%|█████▌    | 1326/2382 [4:05:10<2:55:43,  9.98s/it] 56%|█████▌    | 1327/2382 [4:05:20<2:54:01,  9.90s/it]                                                       {'loss': 1.9985, 'learning_rate': 0.0004322095851057962, 'epoch': 0.56}
 56%|█████▌    | 1327/2382 [4:05:20<2:54:01,  9.90s/it] 56%|█████▌    | 1328/2382 [4:05:29<2:51:32,  9.76s/it]                                                       {'loss': 2.0322, 'learning_rate': 0.00043153592850496555, 'epoch': 0.56}
 56%|█████▌    | 1328/2382 [4:05:29<2:51:32,  9.76s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1043 > 1024). Running this sequence through the model will result in indexing errors
 56%|█████▌    | 1329/2382 [4:05:44<3:14:52, 11.10s/it]                                                       {'loss': 2.1349, 'learning_rate': 0.0004308623985346699, 'epoch': 0.56}
 56%|█████▌    | 1329/2382 [4:05:44<3:14:52, 11.10s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1306 > 1024). Running this sequence through the model will result in indexing errors
 56%|█████▌    | 1330/2382 [4:05:56<3:19:23, 11.37s/it]                                                       {'loss': 2.0697, 'learning_rate': 0.0004301889964406641, 'epoch': 0.56}
 56%|█████▌    | 1330/2382 [4:05:56<3:19:23, 11.37s/it] 56%|█████▌    | 1331/2382 [4:06:05<3:10:57, 10.90s/it]                                                       {'loss': 2.2522, 'learning_rate': 0.00042951572346846666, 'epoch': 0.56}
 56%|█████▌    | 1331/2382 [4:06:05<3:10:57, 10.90s/it] 56%|█████▌    | 1332/2382 [4:06:19<3:27:43, 11.87s/it]                                                       {'loss': 2.0627, 'learning_rate': 0.0004288425808633575, 'epoch': 0.56}
 56%|█████▌    | 1332/2382 [4:06:19<3:27:43, 11.87s/it] 56%|█████▌    | 1333/2382 [4:06:29<3:14:53, 11.15s/it]                                                       {'loss': 2.0331, 'learning_rate': 0.00042816956987037485, 'epoch': 0.56}
 56%|█████▌    | 1333/2382 [4:06:29<3:14:53, 11.15s/it] 56%|█████▌    | 1334/2382 [4:06:39<3:09:48, 10.87s/it]                                                       {'loss': 2.0058, 'learning_rate': 0.00042749669173431385, 'epoch': 0.56}
 56%|█████▌    | 1334/2382 [4:06:39<3:09:48, 10.87s/it] 56%|█████▌    | 1335/2382 [4:06:50<3:09:59, 10.89s/it]                                                       {'loss': 1.9969, 'learning_rate': 0.000426823947699724, 'epoch': 0.56}
 56%|█████▌    | 1335/2382 [4:06:50<3:09:59, 10.89s/it] 56%|█████▌    | 1336/2382 [4:07:01<3:10:24, 10.92s/it]                                                       {'loss': 1.9589, 'learning_rate': 0.00042615133901090663, 'epoch': 0.56}
 56%|█████▌    | 1336/2382 [4:07:01<3:10:24, 10.92s/it] 56%|█████▌    | 1337/2382 [4:07:12<3:12:06, 11.03s/it]                                                       {'loss': 2.0992, 'learning_rate': 0.0004254788669119127, 'epoch': 0.56}
 56%|█████▌    | 1337/2382 [4:07:12<3:12:06, 11.03s/it] 56%|█████▌    | 1338/2382 [4:07:21<3:00:51, 10.39s/it]                                                       {'loss': 2.0518, 'learning_rate': 0.0004248065326465409, 'epoch': 0.56}
 56%|█████▌    | 1338/2382 [4:07:21<3:00:51, 10.39s/it] 56%|█████▌    | 1339/2382 [4:07:31<2:56:39, 10.16s/it]                                                       {'loss': 2.1092, 'learning_rate': 0.00042413433745833423, 'epoch': 0.56}
 56%|█████▌    | 1339/2382 [4:07:31<2:56:39, 10.16s/it] 56%|█████▋    | 1340/2382 [4:07:42<2:59:11, 10.32s/it]                                                       {'loss': 1.9608, 'learning_rate': 0.0004234622825905792, 'epoch': 0.56}
 56%|█████▋    | 1340/2382 [4:07:42<2:59:11, 10.32s/it] 56%|█████▋    | 1341/2382 [4:07:53<3:04:31, 10.64s/it]                                                       {'loss': 2.1223, 'learning_rate': 0.00042279036928630226, 'epoch': 0.56}
 56%|█████▋    | 1341/2382 [4:07:53<3:04:31, 10.64s/it] 56%|█████▋    | 1342/2382 [4:08:05<3:12:46, 11.12s/it]                                                       {'loss': 2.0435, 'learning_rate': 0.0004221185987882684, 'epoch': 0.56}
 56%|█████▋    | 1342/2382 [4:08:05<3:12:46, 11.12s/it] 56%|█████▋    | 1343/2382 [4:08:20<3:32:13, 12.26s/it]                                                       {'loss': 2.1313, 'learning_rate': 0.00042144697233897845, 'epoch': 0.56}
 56%|█████▋    | 1343/2382 [4:08:20<3:32:13, 12.26s/it] 56%|█████▋    | 1344/2382 [4:08:34<3:38:25, 12.63s/it]                                                       {'loss': 1.9413, 'learning_rate': 0.00042077549118066653, 'epoch': 0.56}
 56%|█████▋    | 1344/2382 [4:08:34<3:38:25, 12.63s/it] 56%|█████▋    | 1345/2382 [4:08:48<3:44:56, 13.02s/it]                                                       {'loss': 2.0871, 'learning_rate': 0.00042010415655529827, 'epoch': 0.56}
 56%|█████▋    | 1345/2382 [4:08:48<3:44:56, 13.02s/it] 57%|█████▋    | 1346/2382 [4:09:01<3:45:08, 13.04s/it]                                                       {'loss': 2.0311, 'learning_rate': 0.000419432969704568, 'epoch': 0.56}
 57%|█████▋    | 1346/2382 [4:09:01<3:45:08, 13.04s/it] 57%|█████▋    | 1347/2382 [4:09:10<3:27:17, 12.02s/it]                                                       {'loss': 1.9747, 'learning_rate': 0.0004187619318698971, 'epoch': 0.57}
 57%|█████▋    | 1347/2382 [4:09:10<3:27:17, 12.02s/it] 57%|█████▋    | 1348/2382 [4:09:21<3:18:56, 11.54s/it]                                                       {'loss': 2.0116, 'learning_rate': 0.00041809104429243115, 'epoch': 0.57}
 57%|█████▋    | 1348/2382 [4:09:21<3:18:56, 11.54s/it] 57%|█████▋    | 1349/2382 [4:09:32<3:17:27, 11.47s/it]                                                       {'loss': 2.0194, 'learning_rate': 0.0004174203082130377, 'epoch': 0.57}
 57%|█████▋    | 1349/2382 [4:09:32<3:17:27, 11.47s/it] 57%|█████▋    | 1350/2382 [4:09:42<3:09:34, 11.02s/it]                                                       {'loss': 2.0415, 'learning_rate': 0.00041674972487230455, 'epoch': 0.57}
 57%|█████▋    | 1350/2382 [4:09:42<3:09:34, 11.02s/it] 57%|█████▋    | 1351/2382 [4:09:53<3:10:30, 11.09s/it]                                                       {'loss': 1.9921, 'learning_rate': 0.0004160792955105362, 'epoch': 0.57}
 57%|█████▋    | 1351/2382 [4:09:53<3:10:30, 11.09s/it] 57%|█████▋    | 1352/2382 [4:10:06<3:18:50, 11.58s/it]                                                       {'loss': 2.0836, 'learning_rate': 0.0004154090213677531, 'epoch': 0.57}
 57%|█████▋    | 1352/2382 [4:10:06<3:18:50, 11.58s/it] 57%|█████▋    | 1353/2382 [4:10:18<3:21:32, 11.75s/it]                                                       {'loss': 2.0583, 'learning_rate': 0.0004147389036836881, 'epoch': 0.57}
 57%|█████▋    | 1353/2382 [4:10:18<3:21:32, 11.75s/it] 57%|█████▋    | 1354/2382 [4:10:28<3:13:41, 11.30s/it]                                                       {'loss': 2.0938, 'learning_rate': 0.00041406894369778503, 'epoch': 0.57}
 57%|█████▋    | 1354/2382 [4:10:28<3:13:41, 11.30s/it] 57%|█████▋    | 1355/2382 [4:10:37<3:01:12, 10.59s/it]                                                       {'loss': 2.0124, 'learning_rate': 0.000413399142649196, 'epoch': 0.57}
 57%|█████▋    | 1355/2382 [4:10:37<3:01:12, 10.59s/it] 57%|█████▋    | 1356/2382 [4:10:48<3:00:32, 10.56s/it]                                                       {'loss': 1.9223, 'learning_rate': 0.00041272950177677895, 'epoch': 0.57}
 57%|█████▋    | 1356/2382 [4:10:48<3:00:32, 10.56s/it] 57%|█████▋    | 1357/2382 [4:11:01<3:14:40, 11.40s/it]                                                       {'loss': 1.9777, 'learning_rate': 0.0004120600223190955, 'epoch': 0.57}
 57%|█████▋    | 1357/2382 [4:11:01<3:14:40, 11.40s/it] 57%|█████▋    | 1358/2382 [4:11:13<3:16:59, 11.54s/it]                                                       {'loss': 2.0295, 'learning_rate': 0.00041139070551440886, 'epoch': 0.57}
 57%|█████▋    | 1358/2382 [4:11:13<3:16:59, 11.54s/it] 57%|█████▋    | 1359/2382 [4:11:23<3:08:18, 11.04s/it]                                                       {'loss': 2.0854, 'learning_rate': 0.0004107215526006817, 'epoch': 0.57}
 57%|█████▋    | 1359/2382 [4:11:23<3:08:18, 11.04s/it] 57%|█████▋    | 1360/2382 [4:11:32<2:57:48, 10.44s/it]                                                       {'loss': 2.0624, 'learning_rate': 0.00041005256481557305, 'epoch': 0.57}
 57%|█████▋    | 1360/2382 [4:11:32<2:57:48, 10.44s/it] 57%|█████▋    | 1361/2382 [4:11:44<3:05:56, 10.93s/it]                                                       {'loss': 2.1471, 'learning_rate': 0.00040938374339643694, 'epoch': 0.57}
 57%|█████▋    | 1361/2382 [4:11:44<3:05:56, 10.93s/it] 57%|█████▋    | 1362/2382 [4:11:56<3:12:57, 11.35s/it]                                                       {'loss': 2.0305, 'learning_rate': 0.0004087150895803192, 'epoch': 0.57}
 57%|█████▋    | 1362/2382 [4:11:56<3:12:57, 11.35s/it] 57%|█████▋    | 1363/2382 [4:12:05<2:58:55, 10.54s/it]                                                       {'loss': 2.0183, 'learning_rate': 0.0004080466046039562, 'epoch': 0.57}
 57%|█████▋    | 1363/2382 [4:12:05<2:58:55, 10.54s/it] 57%|█████▋    | 1364/2382 [4:12:17<3:06:20, 10.98s/it]                                                       {'loss': 2.1464, 'learning_rate': 0.0004073782897037716, 'epoch': 0.57}
 57%|█████▋    | 1364/2382 [4:12:17<3:06:20, 10.98s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1069 > 1024). Running this sequence through the model will result in indexing errors
 57%|█████▋    | 1365/2382 [4:12:27<3:02:39, 10.78s/it]                                                       {'loss': 2.1724, 'learning_rate': 0.00040671014611587473, 'epoch': 0.57}
 57%|█████▋    | 1365/2382 [4:12:27<3:02:39, 10.78s/it] 57%|█████▋    | 1366/2382 [4:12:37<2:57:13, 10.47s/it]                                                       {'loss': 2.008, 'learning_rate': 0.0004060421750760581, 'epoch': 0.57}
 57%|█████▋    | 1366/2382 [4:12:37<2:57:13, 10.47s/it] 57%|█████▋    | 1367/2382 [4:12:48<2:57:22, 10.48s/it]                                                       {'loss': 2.103, 'learning_rate': 0.0004053743778197951, 'epoch': 0.57}
 57%|█████▋    | 1367/2382 [4:12:48<2:57:22, 10.48s/it] 57%|█████▋    | 1368/2382 [4:12:59<3:01:50, 10.76s/it]                                                       {'loss': 1.907, 'learning_rate': 0.0004047067555822371, 'epoch': 0.57}
 57%|█████▋    | 1368/2382 [4:12:59<3:01:50, 10.76s/it] 57%|█████▋    | 1369/2382 [4:13:09<2:57:57, 10.54s/it]                                                       {'loss': 2.032, 'learning_rate': 0.00040403930959821244, 'epoch': 0.57}
 57%|█████▋    | 1369/2382 [4:13:09<2:57:57, 10.54s/it] 58%|█████▊    | 1370/2382 [4:13:20<2:58:09, 10.56s/it]                                                       {'loss': 1.896, 'learning_rate': 0.0004033720411022235, 'epoch': 0.57}
 58%|█████▊    | 1370/2382 [4:13:20<2:58:09, 10.56s/it] 58%|█████▊    | 1371/2382 [4:13:31<3:02:55, 10.86s/it]                                                       {'loss': 2.0455, 'learning_rate': 0.0004027049513284437, 'epoch': 0.58}
 58%|█████▊    | 1371/2382 [4:13:31<3:02:55, 10.86s/it] 58%|█████▊    | 1372/2382 [4:13:40<2:54:49, 10.39s/it]                                                       {'loss': 2.0218, 'learning_rate': 0.00040203804151071665, 'epoch': 0.58}
 58%|█████▊    | 1372/2382 [4:13:40<2:54:49, 10.39s/it] 58%|█████▊    | 1373/2382 [4:13:49<2:47:58,  9.99s/it]                                                       {'loss': 2.111, 'learning_rate': 0.0004013713128825529, 'epoch': 0.58}
 58%|█████▊    | 1373/2382 [4:13:49<2:47:58,  9.99s/it] 58%|█████▊    | 1374/2382 [4:13:59<2:47:15,  9.96s/it]                                                       {'loss': 1.9572, 'learning_rate': 0.00040070476667712743, 'epoch': 0.58}
 58%|█████▊    | 1374/2382 [4:13:59<2:47:15,  9.96s/it] 58%|█████▊    | 1375/2382 [4:14:11<2:53:39, 10.35s/it]                                                       {'loss': 1.9996, 'learning_rate': 0.00040003840412727816, 'epoch': 0.58}
 58%|█████▊    | 1375/2382 [4:14:11<2:53:39, 10.35s/it] 58%|█████▊    | 1376/2382 [4:14:20<2:51:06, 10.21s/it]                                                       {'loss': 2.0011, 'learning_rate': 0.0003993722264655034, 'epoch': 0.58}
 58%|█████▊    | 1376/2382 [4:14:20<2:51:06, 10.21s/it] 58%|█████▊    | 1377/2382 [4:14:35<3:14:24, 11.61s/it]                                                       {'loss': 1.9168, 'learning_rate': 0.0003987062349239596, 'epoch': 0.58}
 58%|█████▊    | 1377/2382 [4:14:35<3:14:24, 11.61s/it] 58%|█████▊    | 1378/2382 [4:14:45<3:03:03, 10.94s/it]                                                       {'loss': 2.108, 'learning_rate': 0.0003980404307344584, 'epoch': 0.58}
 58%|█████▊    | 1378/2382 [4:14:45<3:03:03, 10.94s/it] 58%|█████▊    | 1379/2382 [4:14:55<2:57:58, 10.65s/it]                                                       {'loss': 1.9409, 'learning_rate': 0.00039737481512846574, 'epoch': 0.58}
 58%|█████▊    | 1379/2382 [4:14:55<2:57:58, 10.65s/it] 58%|█████▊    | 1380/2382 [4:15:05<2:57:26, 10.62s/it]                                                       {'loss': 2.1372, 'learning_rate': 0.00039670938933709774, 'epoch': 0.58}
 58%|█████▊    | 1380/2382 [4:15:05<2:57:26, 10.62s/it] 58%|█████▊    | 1381/2382 [4:15:19<3:13:02, 11.57s/it]                                                       {'loss': 1.9818, 'learning_rate': 0.0003960441545911204, 'epoch': 0.58}
 58%|█████▊    | 1381/2382 [4:15:19<3:13:02, 11.57s/it] 58%|█████▊    | 1382/2382 [4:15:30<3:08:45, 11.33s/it]                                                       {'loss': 2.0196, 'learning_rate': 0.0003953791121209458, 'epoch': 0.58}
 58%|█████▊    | 1382/2382 [4:15:30<3:08:45, 11.33s/it] 58%|█████▊    | 1383/2382 [4:15:40<3:02:46, 10.98s/it]                                                       {'loss': 1.9576, 'learning_rate': 0.00039471426315663055, 'epoch': 0.58}
 58%|█████▊    | 1383/2382 [4:15:40<3:02:46, 10.98s/it] 58%|█████▊    | 1384/2382 [4:15:51<3:00:50, 10.87s/it]                                                       {'loss': 2.0566, 'learning_rate': 0.0003940496089278735, 'epoch': 0.58}
 58%|█████▊    | 1384/2382 [4:15:51<3:00:50, 10.87s/it] 58%|█████▊    | 1385/2382 [4:16:00<2:51:40, 10.33s/it]                                                       {'loss': 1.9861, 'learning_rate': 0.0003933851506640131, 'epoch': 0.58}
 58%|█████▊    | 1385/2382 [4:16:00<2:51:40, 10.33s/it] 58%|█████▊    | 1386/2382 [4:16:10<2:52:16, 10.38s/it]                                                       {'loss': 1.8938, 'learning_rate': 0.00039272088959402534, 'epoch': 0.58}
 58%|█████▊    | 1386/2382 [4:16:10<2:52:16, 10.38s/it] 58%|█████▊    | 1387/2382 [4:16:20<2:51:43, 10.35s/it]                                                       {'loss': 2.0522, 'learning_rate': 0.00039205682694652157, 'epoch': 0.58}
 58%|█████▊    | 1387/2382 [4:16:20<2:51:43, 10.35s/it] 58%|█████▊    | 1388/2382 [4:16:35<3:13:46, 11.70s/it]                                                       {'loss': 1.9982, 'learning_rate': 0.0003913929639497462, 'epoch': 0.58}
 58%|█████▊    | 1388/2382 [4:16:35<3:13:46, 11.70s/it] 58%|█████▊    | 1389/2382 [4:16:47<3:15:37, 11.82s/it]                                                       {'loss': 1.963, 'learning_rate': 0.0003907293018315742, 'epoch': 0.58}
 58%|█████▊    | 1389/2382 [4:16:47<3:15:37, 11.82s/it] 58%|█████▊    | 1390/2382 [4:16:59<3:14:17, 11.75s/it]                                                       {'loss': 2.0245, 'learning_rate': 0.0003900658418195091, 'epoch': 0.58}
 58%|█████▊    | 1390/2382 [4:16:59<3:14:17, 11.75s/it] 58%|█████▊    | 1391/2382 [4:17:09<3:04:09, 11.15s/it]                                                       {'loss': 2.0407, 'learning_rate': 0.00038940258514068093, 'epoch': 0.58}
 58%|█████▊    | 1391/2382 [4:17:09<3:04:09, 11.15s/it] 58%|█████▊    | 1392/2382 [4:17:20<3:03:22, 11.11s/it]                                                       {'loss': 2.1269, 'learning_rate': 0.00038873953302184284, 'epoch': 0.58}
 58%|█████▊    | 1392/2382 [4:17:20<3:03:22, 11.11s/it] 58%|█████▊    | 1393/2382 [4:17:35<3:22:16, 12.27s/it]                                                       {'loss': 2.0249, 'learning_rate': 0.0003880766866893704, 'epoch': 0.58}
 58%|█████▊    | 1393/2382 [4:17:35<3:22:16, 12.27s/it] 59%|█████▊    | 1394/2382 [4:17:45<3:14:32, 11.81s/it]                                                       {'loss': 1.9135, 'learning_rate': 0.00038741404736925813, 'epoch': 0.59}
 59%|█████▊    | 1394/2382 [4:17:45<3:14:32, 11.81s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1211 > 1024). Running this sequence through the model will result in indexing errors
 59%|█████▊    | 1395/2382 [4:17:58<3:19:24, 12.12s/it]                                                       {'loss': 2.0426, 'learning_rate': 0.00038675161628711776, 'epoch': 0.59}
 59%|█████▊    | 1395/2382 [4:17:58<3:19:24, 12.12s/it] 59%|█████▊    | 1396/2382 [4:18:07<3:00:30, 10.98s/it]                                                       {'loss': 2.2265, 'learning_rate': 0.0003860893946681762, 'epoch': 0.59}
 59%|█████▊    | 1396/2382 [4:18:07<3:00:30, 10.98s/it] 59%|█████▊    | 1397/2382 [4:18:18<3:03:12, 11.16s/it]                                                       {'loss': 2.098, 'learning_rate': 0.00038542738373727235, 'epoch': 0.59}
 59%|█████▊    | 1397/2382 [4:18:18<3:03:12, 11.16s/it] 59%|█████▊    | 1398/2382 [4:18:29<3:01:00, 11.04s/it]                                                       {'loss': 1.9906, 'learning_rate': 0.00038476558471885577, 'epoch': 0.59}
 59%|█████▊    | 1398/2382 [4:18:29<3:01:00, 11.04s/it] 59%|█████▊    | 1399/2382 [4:18:38<2:53:21, 10.58s/it]                                                       {'loss': 1.9818, 'learning_rate': 0.00038410399883698394, 'epoch': 0.59}
 59%|█████▊    | 1399/2382 [4:18:39<2:53:21, 10.58s/it] 59%|█████▉    | 1400/2382 [4:18:50<2:58:10, 10.89s/it]                                                       {'loss': 2.0475, 'learning_rate': 0.0003834426273153204, 'epoch': 0.59}
 59%|█████▉    | 1400/2382 [4:18:50<2:58:10, 10.89s/it] 59%|█████▉    | 1401/2382 [4:19:01<2:59:50, 11.00s/it]                                                       {'loss': 2.0226, 'learning_rate': 0.0003827814713771318, 'epoch': 0.59}
 59%|█████▉    | 1401/2382 [4:19:01<2:59:50, 11.00s/it] 59%|█████▉    | 1402/2382 [4:19:13<3:03:28, 11.23s/it]                                                       {'loss': 1.9384, 'learning_rate': 0.0003821205322452863, 'epoch': 0.59}
 59%|█████▉    | 1402/2382 [4:19:13<3:03:28, 11.23s/it] 59%|█████▉    | 1403/2382 [4:19:22<2:52:20, 10.56s/it]                                                       {'loss': 2.0414, 'learning_rate': 0.0003814598111422513, 'epoch': 0.59}
 59%|█████▉    | 1403/2382 [4:19:22<2:52:20, 10.56s/it] 59%|█████▉    | 1404/2382 [4:19:31<2:42:19,  9.96s/it]                                                       {'loss': 2.1393, 'learning_rate': 0.0003807993092900903, 'epoch': 0.59}
 59%|█████▉    | 1404/2382 [4:19:31<2:42:19,  9.96s/it] 59%|█████▉    | 1405/2382 [4:19:43<2:54:46, 10.73s/it]                                                       {'loss': 2.2015, 'learning_rate': 0.0003801390279104617, 'epoch': 0.59}
 59%|█████▉    | 1405/2382 [4:19:43<2:54:46, 10.73s/it] 59%|█████▉    | 1406/2382 [4:19:54<2:56:37, 10.86s/it]                                                       {'loss': 1.9828, 'learning_rate': 0.000379478968224616, 'epoch': 0.59}
 59%|█████▉    | 1406/2382 [4:19:54<2:56:37, 10.86s/it] 59%|█████▉    | 1407/2382 [4:20:05<2:56:25, 10.86s/it]                                                       {'loss': 2.0666, 'learning_rate': 0.00037881913145339387, 'epoch': 0.59}
 59%|█████▉    | 1407/2382 [4:20:05<2:56:25, 10.86s/it] 59%|█████▉    | 1408/2382 [4:20:14<2:46:03, 10.23s/it]                                                       {'loss': 2.0957, 'learning_rate': 0.0003781595188172233, 'epoch': 0.59}
 59%|█████▉    | 1408/2382 [4:20:14<2:46:03, 10.23s/it] 59%|█████▉    | 1409/2382 [4:20:24<2:43:42, 10.09s/it]                                                       {'loss': 2.0659, 'learning_rate': 0.0003775001315361183, 'epoch': 0.59}
 59%|█████▉    | 1409/2382 [4:20:24<2:43:42, 10.09s/it] 59%|█████▉    | 1410/2382 [4:20:33<2:38:19,  9.77s/it]                                                       {'loss': 1.9859, 'learning_rate': 0.00037684097082967515, 'epoch': 0.59}
 59%|█████▉    | 1410/2382 [4:20:33<2:38:19,  9.77s/it] 59%|█████▉    | 1411/2382 [4:20:45<2:50:31, 10.54s/it]                                                       {'loss': 2.1927, 'learning_rate': 0.000376182037917072, 'epoch': 0.59}
 59%|█████▉    | 1411/2382 [4:20:45<2:50:31, 10.54s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1060 > 1024). Running this sequence through the model will result in indexing errors
 59%|█████▉    | 1412/2382 [4:20:56<2:54:24, 10.79s/it]                                                       {'loss': 2.0757, 'learning_rate': 0.00037552333401706504, 'epoch': 0.59}
 59%|█████▉    | 1412/2382 [4:20:56<2:54:24, 10.79s/it] 59%|█████▉    | 1413/2382 [4:21:07<2:52:01, 10.65s/it]                                                       {'loss': 2.0336, 'learning_rate': 0.0003748648603479873, 'epoch': 0.59}
 59%|█████▉    | 1413/2382 [4:21:07<2:52:01, 10.65s/it] 59%|█████▉    | 1414/2382 [4:21:15<2:41:18, 10.00s/it]                                                       {'loss': 2.0437, 'learning_rate': 0.00037420661812774574, 'epoch': 0.59}
 59%|█████▉    | 1414/2382 [4:21:15<2:41:18, 10.00s/it] 59%|█████▉    | 1415/2382 [4:21:28<2:53:22, 10.76s/it]                                                       {'loss': 2.0952, 'learning_rate': 0.00037354860857381945, 'epoch': 0.59}
 59%|█████▉    | 1415/2382 [4:21:28<2:53:22, 10.76s/it] 59%|█████▉    | 1416/2382 [4:21:38<2:48:10, 10.45s/it]                                                       {'loss': 1.9249, 'learning_rate': 0.00037289083290325663, 'epoch': 0.59}
 59%|█████▉    | 1416/2382 [4:21:38<2:48:10, 10.45s/it] 59%|█████▉    | 1417/2382 [4:21:49<2:50:29, 10.60s/it]                                                       {'loss': 2.0937, 'learning_rate': 0.0003722332923326735, 'epoch': 0.59}
 59%|█████▉    | 1417/2382 [4:21:49<2:50:29, 10.60s/it] 60%|█████▉    | 1418/2382 [4:22:00<2:54:43, 10.87s/it]                                                       {'loss': 1.923, 'learning_rate': 0.00037157598807825134, 'epoch': 0.6}
 60%|█████▉    | 1418/2382 [4:22:00<2:54:43, 10.87s/it] 60%|█████▉    | 1419/2382 [4:22:12<2:57:51, 11.08s/it]                                                       {'loss': 1.9653, 'learning_rate': 0.000370918921355734, 'epoch': 0.6}
 60%|█████▉    | 1419/2382 [4:22:12<2:57:51, 11.08s/it] 60%|█████▉    | 1420/2382 [4:22:24<3:03:09, 11.42s/it]                                                       {'loss': 1.9807, 'learning_rate': 0.0003702620933804263, 'epoch': 0.6}
 60%|█████▉    | 1420/2382 [4:22:24<3:03:09, 11.42s/it] 60%|█████▉    | 1421/2382 [4:22:36<3:06:14, 11.63s/it]                                                       {'loss': 1.969, 'learning_rate': 0.0003696055053671916, 'epoch': 0.6}
 60%|█████▉    | 1421/2382 [4:22:36<3:06:14, 11.63s/it] 60%|█████▉    | 1422/2382 [4:22:49<3:12:22, 12.02s/it]                                                       {'loss': 1.9222, 'learning_rate': 0.00036894915853044906, 'epoch': 0.6}
 60%|█████▉    | 1422/2382 [4:22:49<3:12:22, 12.02s/it] 60%|█████▉    | 1423/2382 [4:23:00<3:06:29, 11.67s/it]                                                       {'loss': 2.0107, 'learning_rate': 0.00036829305408417166, 'epoch': 0.6}
 60%|█████▉    | 1423/2382 [4:23:00<3:06:29, 11.67s/it] 60%|█████▉    | 1424/2382 [4:23:13<3:14:08, 12.16s/it]                                                       {'loss': 1.9545, 'learning_rate': 0.0003676371932418847, 'epoch': 0.6}
 60%|█████▉    | 1424/2382 [4:23:13<3:14:08, 12.16s/it] 60%|█████▉    | 1425/2382 [4:23:24<3:06:33, 11.70s/it]                                                       {'loss': 1.9842, 'learning_rate': 0.0003669815772166625, 'epoch': 0.6}
 60%|█████▉    | 1425/2382 [4:23:24<3:06:33, 11.70s/it] 60%|█████▉    | 1426/2382 [4:23:35<3:06:57, 11.73s/it]                                                       {'loss': 1.9468, 'learning_rate': 0.00036632620722112637, 'epoch': 0.6}
 60%|█████▉    | 1426/2382 [4:23:35<3:06:57, 11.73s/it] 60%|█████▉    | 1427/2382 [4:23:48<3:12:13, 12.08s/it]                                                       {'loss': 1.943, 'learning_rate': 0.0003656710844674431, 'epoch': 0.6}
 60%|█████▉    | 1427/2382 [4:23:48<3:12:13, 12.08s/it] 60%|█████▉    | 1428/2382 [4:24:01<3:14:57, 12.26s/it]                                                       {'loss': 2.0776, 'learning_rate': 0.00036501621016732155, 'epoch': 0.6}
 60%|█████▉    | 1428/2382 [4:24:01<3:14:57, 12.26s/it] 60%|█████▉    | 1429/2382 [4:24:11<3:06:09, 11.72s/it]                                                       {'loss': 2.0899, 'learning_rate': 0.0003643615855320117, 'epoch': 0.6}
 60%|█████▉    | 1429/2382 [4:24:11<3:06:09, 11.72s/it] 60%|██████    | 1430/2382 [4:24:23<3:05:31, 11.69s/it]                                                       {'loss': 2.0922, 'learning_rate': 0.00036370721177230114, 'epoch': 0.6}
 60%|██████    | 1430/2382 [4:24:23<3:05:31, 11.69s/it] 60%|██████    | 1431/2382 [4:24:35<3:06:00, 11.74s/it]                                                       {'loss': 2.1123, 'learning_rate': 0.00036305309009851384, 'epoch': 0.6}
 60%|██████    | 1431/2382 [4:24:35<3:06:00, 11.74s/it] 60%|██████    | 1432/2382 [4:24:46<3:02:44, 11.54s/it]                                                       {'loss': 2.0663, 'learning_rate': 0.00036239922172050747, 'epoch': 0.6}
 60%|██████    | 1432/2382 [4:24:46<3:02:44, 11.54s/it] 60%|██████    | 1433/2382 [4:24:56<2:56:08, 11.14s/it]                                                       {'loss': 1.9538, 'learning_rate': 0.0003617456078476712, 'epoch': 0.6}
 60%|██████    | 1433/2382 [4:24:56<2:56:08, 11.14s/it] 60%|██████    | 1434/2382 [4:25:06<2:51:27, 10.85s/it]                                                       {'loss': 2.0484, 'learning_rate': 0.00036109224968892316, 'epoch': 0.6}
 60%|██████    | 1434/2382 [4:25:06<2:51:27, 10.85s/it] 60%|██████    | 1435/2382 [4:25:16<2:43:54, 10.38s/it]                                                       {'loss': 2.0044, 'learning_rate': 0.0003604391484527089, 'epoch': 0.6}
 60%|██████    | 1435/2382 [4:25:16<2:43:54, 10.38s/it] 60%|██████    | 1436/2382 [4:25:29<2:56:02, 11.17s/it]                                                       {'loss': 2.0058, 'learning_rate': 0.0003597863053469987, 'epoch': 0.6}
 60%|██████    | 1436/2382 [4:25:29<2:56:02, 11.17s/it] 60%|██████    | 1437/2382 [4:25:41<3:01:07, 11.50s/it]                                                       {'loss': 2.0447, 'learning_rate': 0.0003591337215792851, 'epoch': 0.6}
 60%|██████    | 1437/2382 [4:25:41<3:01:07, 11.50s/it] 60%|██████    | 1438/2382 [4:25:53<3:03:28, 11.66s/it]                                                       {'loss': 2.1117, 'learning_rate': 0.0003584813983565815, 'epoch': 0.6}
 60%|██████    | 1438/2382 [4:25:53<3:03:28, 11.66s/it] 60%|██████    | 1439/2382 [4:26:05<3:03:21, 11.67s/it]                                                       {'loss': 1.9664, 'learning_rate': 0.00035782933688541913, 'epoch': 0.6}
 60%|██████    | 1439/2382 [4:26:05<3:03:21, 11.67s/it] 60%|██████    | 1440/2382 [4:26:14<2:53:50, 11.07s/it]                                                       {'loss': 2.0044, 'learning_rate': 0.0003571775383718447, 'epoch': 0.6}
 60%|██████    | 1440/2382 [4:26:14<2:53:50, 11.07s/it] 60%|██████    | 1441/2382 [4:26:27<3:00:14, 11.49s/it]                                                       {'loss': 1.9984, 'learning_rate': 0.00035652600402141923, 'epoch': 0.6}
 60%|██████    | 1441/2382 [4:26:27<3:00:14, 11.49s/it] 61%|██████    | 1442/2382 [4:26:37<2:52:35, 11.02s/it]                                                       {'loss': 2.0107, 'learning_rate': 0.00035587473503921455, 'epoch': 0.61}
 61%|██████    | 1442/2382 [4:26:37<2:52:35, 11.02s/it] 61%|██████    | 1443/2382 [4:26:48<2:54:53, 11.18s/it]                                                       {'loss': 2.1467, 'learning_rate': 0.00035522373262981223, 'epoch': 0.61}
 61%|██████    | 1443/2382 [4:26:48<2:54:53, 11.18s/it] 61%|██████    | 1444/2382 [4:26:58<2:49:29, 10.84s/it]                                                       {'loss': 1.9928, 'learning_rate': 0.00035457299799730046, 'epoch': 0.61}
 61%|██████    | 1444/2382 [4:26:58<2:49:29, 10.84s/it] 61%|██████    | 1445/2382 [4:27:09<2:46:06, 10.64s/it]                                                       {'loss': 2.0807, 'learning_rate': 0.00035392253234527225, 'epoch': 0.61}
 61%|██████    | 1445/2382 [4:27:09<2:46:06, 10.64s/it] 61%|██████    | 1446/2382 [4:27:19<2:47:04, 10.71s/it]                                                       {'loss': 2.0244, 'learning_rate': 0.00035327233687682273, 'epoch': 0.61}
 61%|██████    | 1446/2382 [4:27:19<2:47:04, 10.71s/it] 61%|██████    | 1447/2382 [4:27:30<2:46:49, 10.71s/it]                                                       {'loss': 1.9978, 'learning_rate': 0.00035262241279454787, 'epoch': 0.61}
 61%|██████    | 1447/2382 [4:27:30<2:46:49, 10.71s/it] 61%|██████    | 1448/2382 [4:27:41<2:49:25, 10.88s/it]                                                       {'loss': 2.0589, 'learning_rate': 0.0003519727613005416, 'epoch': 0.61}
 61%|██████    | 1448/2382 [4:27:41<2:49:25, 10.88s/it] 61%|██████    | 1449/2382 [4:27:53<2:50:27, 10.96s/it]                                                       {'loss': 2.024, 'learning_rate': 0.00035132338359639316, 'epoch': 0.61}
 61%|██████    | 1449/2382 [4:27:53<2:50:27, 10.96s/it] 61%|██████    | 1450/2382 [4:28:04<2:53:29, 11.17s/it]                                                       {'loss': 2.0035, 'learning_rate': 0.000350674280883186, 'epoch': 0.61}
 61%|██████    | 1450/2382 [4:28:04<2:53:29, 11.17s/it] 61%|██████    | 1451/2382 [4:28:16<2:54:06, 11.22s/it]                                                       {'loss': 2.0313, 'learning_rate': 0.00035002545436149473, 'epoch': 0.61}
 61%|██████    | 1451/2382 [4:28:16<2:54:06, 11.22s/it] 61%|██████    | 1452/2382 [4:28:26<2:49:45, 10.95s/it]                                                       {'loss': 2.0574, 'learning_rate': 0.000349376905231383, 'epoch': 0.61}
 61%|██████    | 1452/2382 [4:28:26<2:49:45, 10.95s/it] 61%|██████    | 1453/2382 [4:28:37<2:49:31, 10.95s/it]                                                       {'loss': 2.0123, 'learning_rate': 0.00034872863469240136, 'epoch': 0.61}
 61%|██████    | 1453/2382 [4:28:37<2:49:31, 10.95s/it] 61%|██████    | 1454/2382 [4:28:46<2:41:26, 10.44s/it]                                                       {'loss': 2.0381, 'learning_rate': 0.00034808064394358526, 'epoch': 0.61}
 61%|██████    | 1454/2382 [4:28:46<2:41:26, 10.44s/it] 61%|██████    | 1455/2382 [4:28:57<2:41:32, 10.46s/it]                                                       {'loss': 2.0435, 'learning_rate': 0.00034743293418345277, 'epoch': 0.61}
 61%|██████    | 1455/2382 [4:28:57<2:41:32, 10.46s/it] 61%|██████    | 1456/2382 [4:29:09<2:49:20, 10.97s/it]                                                       {'loss': 1.9873, 'learning_rate': 0.00034678550661000195, 'epoch': 0.61}
 61%|██████    | 1456/2382 [4:29:09<2:49:20, 10.97s/it] 61%|██████    | 1457/2382 [4:29:18<2:41:26, 10.47s/it]                                                       {'loss': 2.0672, 'learning_rate': 0.0003461383624207092, 'epoch': 0.61}
 61%|██████    | 1457/2382 [4:29:18<2:41:26, 10.47s/it] 61%|██████    | 1458/2382 [4:29:30<2:46:08, 10.79s/it]                                                       {'loss': 2.1025, 'learning_rate': 0.00034549150281252633, 'epoch': 0.61}
 61%|██████    | 1458/2382 [4:29:30<2:46:08, 10.79s/it] 61%|██████▏   | 1459/2382 [4:29:42<2:52:30, 11.21s/it]                                                       {'loss': 2.1665, 'learning_rate': 0.00034484492898187934, 'epoch': 0.61}
 61%|██████▏   | 1459/2382 [4:29:42<2:52:30, 11.21s/it] 61%|██████▏   | 1460/2382 [4:29:56<3:05:27, 12.07s/it]                                                       {'loss': 1.9688, 'learning_rate': 0.0003441986421246653, 'epoch': 0.61}
 61%|██████▏   | 1460/2382 [4:29:56<3:05:27, 12.07s/it] 61%|██████▏   | 1461/2382 [4:30:07<3:00:52, 11.78s/it]                                                       {'loss': 1.9496, 'learning_rate': 0.0003435526434362506, 'epoch': 0.61}
 61%|██████▏   | 1461/2382 [4:30:07<3:00:52, 11.78s/it] 61%|██████▏   | 1462/2382 [4:30:16<2:48:45, 11.01s/it]                                                       {'loss': 2.1143, 'learning_rate': 0.00034290693411146876, 'epoch': 0.61}
 61%|██████▏   | 1462/2382 [4:30:16<2:48:45, 11.01s/it] 61%|██████▏   | 1463/2382 [4:30:27<2:48:41, 11.01s/it]                                                       {'loss': 2.0728, 'learning_rate': 0.000342261515344618, 'epoch': 0.61}
 61%|██████▏   | 1463/2382 [4:30:27<2:48:41, 11.01s/it] 61%|██████▏   | 1464/2382 [4:30:41<2:59:52, 11.76s/it]                                                       {'loss': 2.0118, 'learning_rate': 0.00034161638832945886, 'epoch': 0.61}
 61%|██████▏   | 1464/2382 [4:30:41<2:59:52, 11.76s/it] 62%|██████▏   | 1465/2382 [4:30:52<2:58:07, 11.65s/it]                                                       {'loss': 1.9382, 'learning_rate': 0.00034097155425921255, 'epoch': 0.61}
 62%|██████▏   | 1465/2382 [4:30:52<2:58:07, 11.65s/it] 62%|██████▏   | 1466/2382 [4:31:01<2:46:06, 10.88s/it]                                                       {'loss': 2.0875, 'learning_rate': 0.0003403270143265587, 'epoch': 0.62}
 62%|██████▏   | 1466/2382 [4:31:01<2:46:06, 10.88s/it] 62%|██████▏   | 1467/2382 [4:31:11<2:43:07, 10.70s/it]                                                       {'loss': 2.1282, 'learning_rate': 0.0003396827697236322, 'epoch': 0.62}
 62%|██████▏   | 1467/2382 [4:31:11<2:43:07, 10.70s/it] 62%|██████▏   | 1468/2382 [4:31:22<2:41:23, 10.59s/it]                                                       {'loss': 2.0706, 'learning_rate': 0.00033903882164202243, 'epoch': 0.62}
 62%|██████▏   | 1468/2382 [4:31:22<2:41:23, 10.59s/it] 62%|██████▏   | 1469/2382 [4:31:36<2:55:59, 11.57s/it]                                                       {'loss': 2.0317, 'learning_rate': 0.00033839517127277007, 'epoch': 0.62}
 62%|██████▏   | 1469/2382 [4:31:36<2:55:59, 11.57s/it] 62%|██████▏   | 1470/2382 [4:31:48<2:59:32, 11.81s/it]                                                       {'loss': 2.0604, 'learning_rate': 0.00033775181980636484, 'epoch': 0.62}
 62%|██████▏   | 1470/2382 [4:31:48<2:59:32, 11.81s/it] 62%|██████▏   | 1471/2382 [4:31:58<2:49:38, 11.17s/it]                                                       {'loss': 2.0871, 'learning_rate': 0.0003371087684327438, 'epoch': 0.62}
 62%|██████▏   | 1471/2382 [4:31:58<2:49:38, 11.17s/it] 62%|██████▏   | 1472/2382 [4:32:12<3:05:26, 12.23s/it]                                                       {'loss': 1.9375, 'learning_rate': 0.0003364660183412892, 'epoch': 0.62}
 62%|██████▏   | 1472/2382 [4:32:12<3:05:26, 12.23s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1774 > 1024). Running this sequence through the model will result in indexing errors
 62%|██████▏   | 1473/2382 [4:32:21<2:47:59, 11.09s/it]                                                       {'loss': 1.9806, 'learning_rate': 0.0003358235707208259, 'epoch': 0.62}
 62%|██████▏   | 1473/2382 [4:32:21<2:47:59, 11.09s/it] 62%|██████▏   | 1474/2382 [4:32:33<2:51:42, 11.35s/it]                                                       {'loss': 1.8953, 'learning_rate': 0.00033518142675961917, 'epoch': 0.62}
 62%|██████▏   | 1474/2382 [4:32:33<2:51:42, 11.35s/it] 62%|██████▏   | 1475/2382 [4:32:42<2:41:09, 10.66s/it]                                                       {'loss': 2.1555, 'learning_rate': 0.00033453958764537297, 'epoch': 0.62}
 62%|██████▏   | 1475/2382 [4:32:42<2:41:09, 10.66s/it] 62%|██████▏   | 1476/2382 [4:32:51<2:34:42, 10.25s/it]                                                       {'loss': 2.1129, 'learning_rate': 0.0003338980545652267, 'epoch': 0.62}
 62%|██████▏   | 1476/2382 [4:32:51<2:34:42, 10.25s/it] 62%|██████▏   | 1477/2382 [4:33:00<2:30:38,  9.99s/it]                                                       {'loss': 1.9942, 'learning_rate': 0.00033325682870575477, 'epoch': 0.62}
 62%|██████▏   | 1477/2382 [4:33:00<2:30:38,  9.99s/it] 62%|██████▏   | 1478/2382 [4:33:11<2:31:07, 10.03s/it]                                                       {'loss': 2.084, 'learning_rate': 0.0003326159112529624, 'epoch': 0.62}
 62%|██████▏   | 1478/2382 [4:33:11<2:31:07, 10.03s/it] 62%|██████▏   | 1479/2382 [4:33:22<2:36:48, 10.42s/it]                                                       {'loss': 2.0496, 'learning_rate': 0.00033197530339228485, 'epoch': 0.62}
 62%|██████▏   | 1479/2382 [4:33:22<2:36:48, 10.42s/it] 62%|██████▏   | 1480/2382 [4:33:32<2:34:03, 10.25s/it]                                                       {'loss': 2.0368, 'learning_rate': 0.00033133500630858504, 'epoch': 0.62}
 62%|██████▏   | 1480/2382 [4:33:32<2:34:03, 10.25s/it] 62%|██████▏   | 1481/2382 [4:33:46<2:49:50, 11.31s/it]                                                       {'loss': 1.9803, 'learning_rate': 0.00033069502118615037, 'epoch': 0.62}
 62%|██████▏   | 1481/2382 [4:33:46<2:49:50, 11.31s/it] 62%|██████▏   | 1482/2382 [4:33:54<2:38:03, 10.54s/it]                                                       {'loss': 2.0823, 'learning_rate': 0.00033005534920869175, 'epoch': 0.62}
 62%|██████▏   | 1482/2382 [4:33:54<2:38:03, 10.54s/it] 62%|██████▏   | 1483/2382 [4:34:05<2:38:38, 10.59s/it]                                                       {'loss': 2.0578, 'learning_rate': 0.00032941599155934055, 'epoch': 0.62}
 62%|██████▏   | 1483/2382 [4:34:05<2:38:38, 10.59s/it] 62%|██████▏   | 1484/2382 [4:34:14<2:32:47, 10.21s/it]                                                       {'loss': 2.0789, 'learning_rate': 0.00032877694942064716, 'epoch': 0.62}
 62%|██████▏   | 1484/2382 [4:34:14<2:32:47, 10.21s/it] 62%|██████▏   | 1485/2382 [4:34:26<2:41:10, 10.78s/it]                                                       {'loss': 2.0393, 'learning_rate': 0.00032813822397457826, 'epoch': 0.62}
 62%|██████▏   | 1485/2382 [4:34:26<2:41:10, 10.78s/it] 62%|██████▏   | 1486/2382 [4:34:38<2:45:17, 11.07s/it]                                                       {'loss': 2.0085, 'learning_rate': 0.0003274998164025148, 'epoch': 0.62}
 62%|██████▏   | 1486/2382 [4:34:38<2:45:17, 11.07s/it] 62%|██████▏   | 1487/2382 [4:34:50<2:46:23, 11.15s/it]                                                       {'loss': 2.1072, 'learning_rate': 0.0003268617278852494, 'epoch': 0.62}
 62%|██████▏   | 1487/2382 [4:34:50<2:46:23, 11.15s/it] 62%|██████▏   | 1488/2382 [4:35:01<2:48:23, 11.30s/it]                                                       {'loss': 2.0392, 'learning_rate': 0.0003262239596029849, 'epoch': 0.62}
 62%|██████▏   | 1488/2382 [4:35:01<2:48:23, 11.30s/it] 63%|██████▎   | 1489/2382 [4:35:11<2:42:47, 10.94s/it]                                                       {'loss': 1.9831, 'learning_rate': 0.0003255865127353321, 'epoch': 0.62}
 63%|██████▎   | 1489/2382 [4:35:11<2:42:47, 10.94s/it] 63%|██████▎   | 1490/2382 [4:35:24<2:50:34, 11.47s/it]                                                       {'loss': 2.1609, 'learning_rate': 0.0003249493884613069, 'epoch': 0.63}
 63%|██████▎   | 1490/2382 [4:35:24<2:50:34, 11.47s/it] 63%|██████▎   | 1491/2382 [4:35:34<2:45:47, 11.16s/it]                                                       {'loss': 2.1544, 'learning_rate': 0.0003243125879593286, 'epoch': 0.63}
 63%|██████▎   | 1491/2382 [4:35:34<2:45:47, 11.16s/it] 63%|██████▎   | 1492/2382 [4:35:46<2:48:52, 11.39s/it]                                                       {'loss': 2.0949, 'learning_rate': 0.00032367611240721793, 'epoch': 0.63}
 63%|██████▎   | 1492/2382 [4:35:46<2:48:52, 11.39s/it] 63%|██████▎   | 1493/2382 [4:35:56<2:41:19, 10.89s/it]                                                       {'loss': 2.0418, 'learning_rate': 0.00032303996298219416, 'epoch': 0.63}
 63%|██████▎   | 1493/2382 [4:35:56<2:41:19, 10.89s/it] 63%|██████▎   | 1494/2382 [4:36:07<2:40:36, 10.85s/it]                                                       {'loss': 2.059, 'learning_rate': 0.00032240414086087357, 'epoch': 0.63}
 63%|██████▎   | 1494/2382 [4:36:07<2:40:36, 10.85s/it] 63%|██████▎   | 1495/2382 [4:36:21<2:53:17, 11.72s/it]                                                       {'loss': 1.9939, 'learning_rate': 0.0003217686472192671, 'epoch': 0.63}
 63%|██████▎   | 1495/2382 [4:36:21<2:53:17, 11.72s/it] 63%|██████▎   | 1496/2382 [4:36:32<2:49:48, 11.50s/it]                                                       {'loss': 1.9898, 'learning_rate': 0.00032113348323277837, 'epoch': 0.63}
 63%|██████▎   | 1496/2382 [4:36:32<2:49:48, 11.50s/it] 63%|██████▎   | 1497/2382 [4:36:43<2:47:32, 11.36s/it]                                                       {'loss': 2.0848, 'learning_rate': 0.0003204986500762006, 'epoch': 0.63}
 63%|██████▎   | 1497/2382 [4:36:43<2:47:32, 11.36s/it] 63%|██████▎   | 1498/2382 [4:36:53<2:41:04, 10.93s/it]                                                       {'loss': 1.8947, 'learning_rate': 0.000319864148923716, 'epoch': 0.63}
 63%|██████▎   | 1498/2382 [4:36:53<2:41:04, 10.93s/it] 63%|██████▎   | 1499/2382 [4:37:02<2:35:14, 10.55s/it]                                                       {'loss': 2.0803, 'learning_rate': 0.00031922998094889175, 'epoch': 0.63}
 63%|██████▎   | 1499/2382 [4:37:02<2:35:14, 10.55s/it] 63%|██████▎   | 1500/2382 [4:37:12<2:32:56, 10.40s/it]                                                       {'loss': 1.9777, 'learning_rate': 0.00031859614732467957, 'epoch': 0.63}
 63%|██████▎   | 1500/2382 [4:37:12<2:32:56, 10.40s/it] 63%|██████▎   | 1501/2382 [4:37:23<2:34:25, 10.52s/it]                                                       {'loss': 1.9449, 'learning_rate': 0.0003179626492234123, 'epoch': 0.63}
 63%|██████▎   | 1501/2382 [4:37:23<2:34:25, 10.52s/it] 63%|██████▎   | 1502/2382 [4:37:34<2:35:13, 10.58s/it]                                                       {'loss': 2.0745, 'learning_rate': 0.0003173294878168025, 'epoch': 0.63}
 63%|██████▎   | 1502/2382 [4:37:34<2:35:13, 10.58s/it] 63%|██████▎   | 1503/2382 [4:37:46<2:43:11, 11.14s/it]                                                       {'loss': 2.0219, 'learning_rate': 0.0003166966642759398, 'epoch': 0.63}
 63%|██████▎   | 1503/2382 [4:37:46<2:43:11, 11.14s/it] 63%|██████▎   | 1504/2382 [4:37:58<2:45:55, 11.34s/it]                                                       {'loss': 2.0659, 'learning_rate': 0.0003160641797712891, 'epoch': 0.63}
 63%|██████▎   | 1504/2382 [4:37:58<2:45:55, 11.34s/it] 63%|██████▎   | 1505/2382 [4:38:09<2:45:19, 11.31s/it]                                                       {'loss': 2.0341, 'learning_rate': 0.0003154320354726878, 'epoch': 0.63}
 63%|██████▎   | 1505/2382 [4:38:09<2:45:19, 11.31s/it] 63%|██████▎   | 1506/2382 [4:38:20<2:43:24, 11.19s/it]                                                       {'loss': 2.0839, 'learning_rate': 0.0003148002325493445, 'epoch': 0.63}
 63%|██████▎   | 1506/2382 [4:38:20<2:43:24, 11.19s/it] 63%|██████▎   | 1507/2382 [4:38:33<2:48:26, 11.55s/it]                                                       {'loss': 2.0402, 'learning_rate': 0.0003141687721698363, 'epoch': 0.63}
 63%|██████▎   | 1507/2382 [4:38:33<2:48:26, 11.55s/it] 63%|██████▎   | 1508/2382 [4:38:43<2:43:32, 11.23s/it]                                                       {'loss': 1.9142, 'learning_rate': 0.00031353765550210655, 'epoch': 0.63}
 63%|██████▎   | 1508/2382 [4:38:43<2:43:32, 11.23s/it] 63%|██████▎   | 1509/2382 [4:38:55<2:46:47, 11.46s/it]                                                       {'loss': 1.9294, 'learning_rate': 0.0003129068837134631, 'epoch': 0.63}
 63%|██████▎   | 1509/2382 [4:38:55<2:46:47, 11.46s/it] 63%|██████▎   | 1510/2382 [4:39:06<2:45:07, 11.36s/it]                                                       {'loss': 2.0747, 'learning_rate': 0.0003122764579705759, 'epoch': 0.63}
 63%|██████▎   | 1510/2382 [4:39:06<2:45:07, 11.36s/it] 63%|██████▎   | 1511/2382 [4:39:16<2:39:47, 11.01s/it]                                                       {'loss': 2.0374, 'learning_rate': 0.0003116463794394746, 'epoch': 0.63}
 63%|██████▎   | 1511/2382 [4:39:16<2:39:47, 11.01s/it] 63%|██████▎   | 1512/2382 [4:39:26<2:34:01, 10.62s/it]                                                       {'loss': 2.0718, 'learning_rate': 0.0003110166492855468, 'epoch': 0.63}
 63%|██████▎   | 1512/2382 [4:39:26<2:34:01, 10.62s/it] 64%|██████▎   | 1513/2382 [4:39:37<2:35:27, 10.73s/it]                                                       {'loss': 2.0087, 'learning_rate': 0.00031038726867353586, 'epoch': 0.63}
 64%|██████▎   | 1513/2382 [4:39:37<2:35:27, 10.73s/it] 64%|██████▎   | 1514/2382 [4:39:46<2:28:11, 10.24s/it]                                                       {'loss': 2.1641, 'learning_rate': 0.0003097582387675385, 'epoch': 0.64}
 64%|██████▎   | 1514/2382 [4:39:46<2:28:11, 10.24s/it] 64%|██████▎   | 1515/2382 [4:39:58<2:36:02, 10.80s/it]                                                       {'loss': 1.9874, 'learning_rate': 0.00030912956073100286, 'epoch': 0.64}
 64%|██████▎   | 1515/2382 [4:39:58<2:36:02, 10.80s/it] 64%|██████▎   | 1516/2382 [4:40:09<2:34:59, 10.74s/it]                                                       {'loss': 2.0073, 'learning_rate': 0.00030850123572672626, 'epoch': 0.64}
 64%|██████▎   | 1516/2382 [4:40:09<2:34:59, 10.74s/it] 64%|██████▎   | 1517/2382 [4:40:18<2:26:32, 10.16s/it]                                                       {'loss': 1.9781, 'learning_rate': 0.00030787326491685284, 'epoch': 0.64}
 64%|██████▎   | 1517/2382 [4:40:18<2:26:32, 10.16s/it] 64%|██████▎   | 1518/2382 [4:40:28<2:28:50, 10.34s/it]                                                       {'loss': 2.0787, 'learning_rate': 0.00030724564946287204, 'epoch': 0.64}
 64%|██████▎   | 1518/2382 [4:40:28<2:28:50, 10.34s/it] 64%|██████▍   | 1519/2382 [4:40:38<2:23:30,  9.98s/it]                                                       {'loss': 1.9279, 'learning_rate': 0.00030661839052561546, 'epoch': 0.64}
 64%|██████▍   | 1519/2382 [4:40:38<2:23:30,  9.98s/it] 64%|██████▍   | 1520/2382 [4:40:48<2:25:34, 10.13s/it]                                                       {'loss': 2.0862, 'learning_rate': 0.0003059914892652559, 'epoch': 0.64}
 64%|██████▍   | 1520/2382 [4:40:48<2:25:34, 10.13s/it] 64%|██████▍   | 1521/2382 [4:41:00<2:35:03, 10.81s/it]                                                       {'loss': 2.0389, 'learning_rate': 0.0003053649468413043, 'epoch': 0.64}
 64%|██████▍   | 1521/2382 [4:41:00<2:35:03, 10.81s/it] 64%|██████▍   | 1522/2382 [4:41:10<2:28:48, 10.38s/it]                                                       {'loss': 2.0159, 'learning_rate': 0.00030473876441260785, 'epoch': 0.64}
 64%|██████▍   | 1522/2382 [4:41:10<2:28:48, 10.38s/it] 64%|██████▍   | 1523/2382 [4:41:19<2:24:24, 10.09s/it]                                                       {'loss': 1.9665, 'learning_rate': 0.00030411294313734805, 'epoch': 0.64}
 64%|██████▍   | 1523/2382 [4:41:19<2:24:24, 10.09s/it] 64%|██████▍   | 1524/2382 [4:41:31<2:29:37, 10.46s/it]                                                       {'loss': 2.0337, 'learning_rate': 0.0003034874841730382, 'epoch': 0.64}
 64%|██████▍   | 1524/2382 [4:41:31<2:29:37, 10.46s/it] 64%|██████▍   | 1525/2382 [4:41:40<2:23:37, 10.06s/it]                                                       {'loss': 2.0866, 'learning_rate': 0.00030286238867652184, 'epoch': 0.64}
 64%|██████▍   | 1525/2382 [4:41:40<2:23:37, 10.06s/it] 64%|██████▍   | 1526/2382 [4:41:50<2:23:51, 10.08s/it]                                                       {'loss': 2.006, 'learning_rate': 0.00030223765780396973, 'epoch': 0.64}
 64%|██████▍   | 1526/2382 [4:41:50<2:23:51, 10.08s/it] 64%|██████▍   | 1527/2382 [4:41:59<2:18:31,  9.72s/it]                                                       {'loss': 2.1092, 'learning_rate': 0.00030161329271087865, 'epoch': 0.64}
 64%|██████▍   | 1527/2382 [4:41:59<2:18:31,  9.72s/it] 64%|██████▍   | 1528/2382 [4:42:11<2:28:10, 10.41s/it]                                                       {'loss': 2.0795, 'learning_rate': 0.00030098929455206903, 'epoch': 0.64}
 64%|██████▍   | 1528/2382 [4:42:11<2:28:10, 10.41s/it] 64%|██████▍   | 1529/2382 [4:42:21<2:26:06, 10.28s/it]                                                       {'loss': 2.0192, 'learning_rate': 0.0003003656644816817, 'epoch': 0.64}
 64%|██████▍   | 1529/2382 [4:42:21<2:26:06, 10.28s/it] 64%|██████▍   | 1530/2382 [4:42:33<2:34:01, 10.85s/it]                                                       {'loss': 2.0358, 'learning_rate': 0.00029974240365317754, 'epoch': 0.64}
 64%|██████▍   | 1530/2382 [4:42:33<2:34:01, 10.85s/it] 64%|██████▍   | 1531/2382 [4:42:43<2:30:17, 10.60s/it]                                                       {'loss': 2.0451, 'learning_rate': 0.0002991195132193342, 'epoch': 0.64}
 64%|██████▍   | 1531/2382 [4:42:43<2:30:17, 10.60s/it] 64%|██████▍   | 1532/2382 [4:42:54<2:34:29, 10.91s/it]                                                       {'loss': 1.8692, 'learning_rate': 0.0002984969943322442, 'epoch': 0.64}
 64%|██████▍   | 1532/2382 [4:42:54<2:34:29, 10.91s/it] 64%|██████▍   | 1533/2382 [4:43:06<2:38:22, 11.19s/it]                                                       {'loss': 2.0779, 'learning_rate': 0.0002978748481433131, 'epoch': 0.64}
 64%|██████▍   | 1533/2382 [4:43:06<2:38:22, 11.19s/it] 64%|██████▍   | 1534/2382 [4:43:19<2:43:02, 11.54s/it]                                                       {'loss': 2.0397, 'learning_rate': 0.000297253075803257, 'epoch': 0.64}
 64%|██████▍   | 1534/2382 [4:43:19<2:43:02, 11.54s/it] 64%|██████▍   | 1535/2382 [4:43:31<2:47:05, 11.84s/it]                                                       {'loss': 2.0656, 'learning_rate': 0.0002966316784621, 'epoch': 0.64}
 64%|██████▍   | 1535/2382 [4:43:31<2:47:05, 11.84s/it] 64%|██████▍   | 1536/2382 [4:43:42<2:43:16, 11.58s/it]                                                       {'loss': 1.9808, 'learning_rate': 0.0002960106572691733, 'epoch': 0.64}
 64%|██████▍   | 1536/2382 [4:43:42<2:43:16, 11.58s/it] 65%|██████▍   | 1537/2382 [4:43:54<2:42:21, 11.53s/it]                                                       {'loss': 2.0449, 'learning_rate': 0.0002953900133731123, 'epoch': 0.65}
 65%|██████▍   | 1537/2382 [4:43:54<2:42:21, 11.53s/it] 65%|██████▍   | 1538/2382 [4:44:06<2:47:51, 11.93s/it]                                                       {'loss': 1.9421, 'learning_rate': 0.0002947697479218543, 'epoch': 0.65}
 65%|██████▍   | 1538/2382 [4:44:06<2:47:51, 11.93s/it] 65%|██████▍   | 1539/2382 [4:44:21<3:00:10, 12.82s/it]                                                       {'loss': 1.9842, 'learning_rate': 0.0002941498620626366, 'epoch': 0.65}
 65%|██████▍   | 1539/2382 [4:44:21<3:00:10, 12.82s/it] 65%|██████▍   | 1540/2382 [4:44:32<2:50:56, 12.18s/it]                                                       {'loss': 2.1246, 'learning_rate': 0.0002935303569419949, 'epoch': 0.65}
 65%|██████▍   | 1540/2382 [4:44:32<2:50:56, 12.18s/it] 65%|██████▍   | 1541/2382 [4:44:43<2:44:26, 11.73s/it]                                                       {'loss': 2.1645, 'learning_rate': 0.0002929112337057601, 'epoch': 0.65}
 65%|██████▍   | 1541/2382 [4:44:43<2:44:26, 11.73s/it] 65%|██████▍   | 1542/2382 [4:44:54<2:42:14, 11.59s/it]                                                       {'loss': 2.0786, 'learning_rate': 0.0002922924934990568, 'epoch': 0.65}
 65%|██████▍   | 1542/2382 [4:44:54<2:42:14, 11.59s/it] 65%|██████▍   | 1543/2382 [4:45:04<2:34:27, 11.05s/it]                                                       {'loss': 2.0237, 'learning_rate': 0.00029167413746630176, 'epoch': 0.65}
 65%|██████▍   | 1543/2382 [4:45:04<2:34:27, 11.05s/it] 65%|██████▍   | 1544/2382 [4:45:16<2:38:31, 11.35s/it]                                                       {'loss': 1.9604, 'learning_rate': 0.0002910561667512005, 'epoch': 0.65}
 65%|██████▍   | 1544/2382 [4:45:16<2:38:31, 11.35s/it] 65%|██████▍   | 1545/2382 [4:45:26<2:32:52, 10.96s/it]                                                       {'loss': 2.0971, 'learning_rate': 0.00029043858249674616, 'epoch': 0.65}
 65%|██████▍   | 1545/2382 [4:45:26<2:32:52, 10.96s/it] 65%|██████▍   | 1546/2382 [4:45:41<2:50:00, 12.20s/it]                                                       {'loss': 1.9454, 'learning_rate': 0.0002898213858452173, 'epoch': 0.65}
 65%|██████▍   | 1546/2382 [4:45:41<2:50:00, 12.20s/it] 65%|██████▍   | 1547/2382 [4:45:53<2:50:52, 12.28s/it]                                                       {'loss': 1.9066, 'learning_rate': 0.00028920457793817506, 'epoch': 0.65}
 65%|██████▍   | 1547/2382 [4:45:53<2:50:52, 12.28s/it] 65%|██████▍   | 1548/2382 [4:46:02<2:36:57, 11.29s/it]                                                       {'loss': 2.0744, 'learning_rate': 0.00028858815991646185, 'epoch': 0.65}
 65%|██████▍   | 1548/2382 [4:46:02<2:36:57, 11.29s/it] 65%|██████▌   | 1549/2382 [4:46:15<2:40:23, 11.55s/it]                                                       {'loss': 1.9075, 'learning_rate': 0.00028797213292019926, 'epoch': 0.65}
 65%|██████▌   | 1549/2382 [4:46:15<2:40:23, 11.55s/it] 65%|██████▌   | 1550/2382 [4:46:25<2:36:43, 11.30s/it]                                                       {'loss': 2.0577, 'learning_rate': 0.00028735649808878485, 'epoch': 0.65}
 65%|██████▌   | 1550/2382 [4:46:25<2:36:43, 11.30s/it] 65%|██████▌   | 1551/2382 [4:46:35<2:31:05, 10.91s/it]                                                       {'loss': 2.0375, 'learning_rate': 0.0002867412565608915, 'epoch': 0.65}
 65%|██████▌   | 1551/2382 [4:46:35<2:31:05, 10.91s/it] 65%|██████▌   | 1552/2382 [4:46:45<2:25:35, 10.52s/it]                                                       {'loss': 2.1158, 'learning_rate': 0.0002861264094744647, 'epoch': 0.65}
 65%|██████▌   | 1552/2382 [4:46:45<2:25:35, 10.52s/it] 65%|██████▌   | 1553/2382 [4:46:55<2:21:53, 10.27s/it]                                                       {'loss': 1.9908, 'learning_rate': 0.00028551195796671963, 'epoch': 0.65}
 65%|██████▌   | 1553/2382 [4:46:55<2:21:53, 10.27s/it] 65%|██████▌   | 1554/2382 [4:47:07<2:30:24, 10.90s/it]                                                       {'loss': 2.0406, 'learning_rate': 0.0002848979031741406, 'epoch': 0.65}
 65%|██████▌   | 1554/2382 [4:47:07<2:30:24, 10.90s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 1024). Running this sequence through the model will result in indexing errors
 65%|██████▌   | 1555/2382 [4:47:17<2:27:37, 10.71s/it]                                                       {'loss': 2.0874, 'learning_rate': 0.00028428424623247787, 'epoch': 0.65}
 65%|██████▌   | 1555/2382 [4:47:17<2:27:37, 10.71s/it] 65%|██████▌   | 1556/2382 [4:47:28<2:28:51, 10.81s/it]                                                       {'loss': 2.0502, 'learning_rate': 0.00028367098827674573, 'epoch': 0.65}
 65%|██████▌   | 1556/2382 [4:47:28<2:28:51, 10.81s/it] 65%|██████▌   | 1557/2382 [4:47:39<2:27:25, 10.72s/it]                                                       {'loss': 2.0366, 'learning_rate': 0.00028305813044122096, 'epoch': 0.65}
 65%|██████▌   | 1557/2382 [4:47:39<2:27:25, 10.72s/it] 65%|██████▌   | 1558/2382 [4:47:49<2:25:50, 10.62s/it]                                                       {'loss': 2.1262, 'learning_rate': 0.00028244567385943964, 'epoch': 0.65}
 65%|██████▌   | 1558/2382 [4:47:49<2:25:50, 10.62s/it] 65%|██████▌   | 1559/2382 [4:48:01<2:30:07, 10.94s/it]                                                       {'loss': 1.9333, 'learning_rate': 0.0002818336196641959, 'epoch': 0.65}
 65%|██████▌   | 1559/2382 [4:48:01<2:30:07, 10.94s/it] 65%|██████▌   | 1560/2382 [4:48:13<2:33:18, 11.19s/it]                                                       {'loss': 2.0887, 'learning_rate': 0.0002812219689875397, 'epoch': 0.65}
 65%|██████▌   | 1560/2382 [4:48:13<2:33:18, 11.19s/it] 66%|██████▌   | 1561/2382 [4:48:24<2:34:43, 11.31s/it]                                                       {'loss': 1.9676, 'learning_rate': 0.00028061072296077484, 'epoch': 0.66}
 66%|██████▌   | 1561/2382 [4:48:24<2:34:43, 11.31s/it] 66%|██████▌   | 1562/2382 [4:48:35<2:30:53, 11.04s/it]                                                       {'loss': 2.1314, 'learning_rate': 0.00027999988271445645, 'epoch': 0.66}
 66%|██████▌   | 1562/2382 [4:48:35<2:30:53, 11.04s/it] 66%|██████▌   | 1563/2382 [4:48:44<2:23:23, 10.51s/it]                                                       {'loss': 1.9506, 'learning_rate': 0.0002793894493783892, 'epoch': 0.66}
 66%|██████▌   | 1563/2382 [4:48:44<2:23:23, 10.51s/it] 66%|██████▌   | 1564/2382 [4:48:54<2:23:20, 10.51s/it]                                                       {'loss': 2.0776, 'learning_rate': 0.0002787794240816254, 'epoch': 0.66}
 66%|██████▌   | 1564/2382 [4:48:54<2:23:20, 10.51s/it] 66%|██████▌   | 1565/2382 [4:49:05<2:23:01, 10.50s/it]                                                       {'loss': 2.0102, 'learning_rate': 0.000278169807952462, 'epoch': 0.66}
 66%|██████▌   | 1565/2382 [4:49:05<2:23:01, 10.50s/it] 66%|██████▌   | 1566/2382 [4:49:15<2:19:41, 10.27s/it]                                                       {'loss': 2.0978, 'learning_rate': 0.00027756060211843957, 'epoch': 0.66}
 66%|██████▌   | 1566/2382 [4:49:15<2:19:41, 10.27s/it] 66%|██████▌   | 1567/2382 [4:49:27<2:28:18, 10.92s/it]                                                       {'loss': 2.1346, 'learning_rate': 0.0002769518077063399, 'epoch': 0.66}
 66%|██████▌   | 1567/2382 [4:49:27<2:28:18, 10.92s/it] 66%|██████▌   | 1568/2382 [4:49:38<2:29:30, 11.02s/it]                                                       {'loss': 2.029, 'learning_rate': 0.00027634342584218364, 'epoch': 0.66}
 66%|██████▌   | 1568/2382 [4:49:38<2:29:30, 11.02s/it] 66%|██████▌   | 1569/2382 [4:49:50<2:32:32, 11.26s/it]                                                       {'loss': 1.8988, 'learning_rate': 0.00027573545765122853, 'epoch': 0.66}
 66%|██████▌   | 1569/2382 [4:49:50<2:32:32, 11.26s/it] 66%|██████▌   | 1570/2382 [4:50:02<2:36:04, 11.53s/it]                                                       {'loss': 1.9428, 'learning_rate': 0.0002751279042579672, 'epoch': 0.66}
 66%|██████▌   | 1570/2382 [4:50:02<2:36:04, 11.53s/it] 66%|██████▌   | 1571/2382 [4:50:15<2:39:36, 11.81s/it]                                                       {'loss': 2.0211, 'learning_rate': 0.0002745207667861246, 'epoch': 0.66}
 66%|██████▌   | 1571/2382 [4:50:15<2:39:36, 11.81s/it] 66%|██████▌   | 1572/2382 [4:50:27<2:39:30, 11.82s/it]                                                       {'loss': 1.94, 'learning_rate': 0.00027391404635865725, 'epoch': 0.66}
 66%|██████▌   | 1572/2382 [4:50:27<2:39:30, 11.82s/it] 66%|██████▌   | 1573/2382 [4:50:37<2:34:23, 11.45s/it]                                                       {'loss': 2.0115, 'learning_rate': 0.0002733077440977494, 'epoch': 0.66}
 66%|██████▌   | 1573/2382 [4:50:37<2:34:23, 11.45s/it] 66%|██████▌   | 1574/2382 [4:50:48<2:32:36, 11.33s/it]                                                       {'loss': 2.0529, 'learning_rate': 0.0002727018611248125, 'epoch': 0.66}
 66%|██████▌   | 1574/2382 [4:50:48<2:32:36, 11.33s/it] 66%|██████▌   | 1575/2382 [4:51:00<2:32:34, 11.34s/it]                                                       {'loss': 2.159, 'learning_rate': 0.0002720963985604822, 'epoch': 0.66}
 66%|██████▌   | 1575/2382 [4:51:00<2:32:34, 11.34s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1791 > 1024). Running this sequence through the model will result in indexing errors
 66%|██████▌   | 1576/2382 [4:51:09<2:25:13, 10.81s/it]                                                       {'loss': 2.0486, 'learning_rate': 0.00027149135752461696, 'epoch': 0.66}
 66%|██████▌   | 1576/2382 [4:51:09<2:25:13, 10.81s/it] 66%|██████▌   | 1577/2382 [4:51:22<2:31:53, 11.32s/it]                                                       {'loss': 2.0068, 'learning_rate': 0.0002708867391362948, 'epoch': 0.66}
 66%|██████▌   | 1577/2382 [4:51:22<2:31:53, 11.32s/it] 66%|██████▌   | 1578/2382 [4:51:32<2:27:57, 11.04s/it]                                                       {'loss': 2.0135, 'learning_rate': 0.0002702825445138127, 'epoch': 0.66}
 66%|██████▌   | 1578/2382 [4:51:32<2:27:57, 11.04s/it] 66%|██████▋   | 1579/2382 [4:51:41<2:18:48, 10.37s/it]                                                       {'loss': 2.0547, 'learning_rate': 0.00026967877477468395, 'epoch': 0.66}
 66%|██████▋   | 1579/2382 [4:51:41<2:18:48, 10.37s/it] 66%|██████▋   | 1580/2382 [4:51:52<2:23:18, 10.72s/it]                                                       {'loss': 2.0183, 'learning_rate': 0.00026907543103563516, 'epoch': 0.66}
 66%|██████▋   | 1580/2382 [4:51:52<2:23:18, 10.72s/it] 66%|██████▋   | 1581/2382 [4:52:06<2:34:36, 11.58s/it]                                                       {'loss': 1.8855, 'learning_rate': 0.0002684725144126056, 'epoch': 0.66}
 66%|██████▋   | 1581/2382 [4:52:06<2:34:36, 11.58s/it] 66%|██████▋   | 1582/2382 [4:52:14<2:21:26, 10.61s/it]                                                       {'loss': 2.0568, 'learning_rate': 0.0002678700260207449, 'epoch': 0.66}
 66%|██████▋   | 1582/2382 [4:52:14<2:21:26, 10.61s/it] 66%|██████▋   | 1583/2382 [4:52:24<2:15:23, 10.17s/it]                                                       {'loss': 2.0772, 'learning_rate': 0.0002672679669744097, 'epoch': 0.66}
 66%|██████▋   | 1583/2382 [4:52:24<2:15:23, 10.17s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1218 > 1024). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (1377 > 1024). Running this sequence through the model will result in indexing errors
 66%|██████▋   | 1584/2382 [4:52:34<2:16:06, 10.23s/it]                                                       {'loss': 2.0788, 'learning_rate': 0.00026666633838716316, 'epoch': 0.66}
 66%|██████▋   | 1584/2382 [4:52:34<2:16:06, 10.23s/it] 67%|██████▋   | 1585/2382 [4:52:45<2:19:28, 10.50s/it]                                                       {'loss': 2.0154, 'learning_rate': 0.00026606514137177226, 'epoch': 0.67}
 67%|██████▋   | 1585/2382 [4:52:45<2:19:28, 10.50s/it] 67%|██████▋   | 1586/2382 [4:52:55<2:17:35, 10.37s/it]                                                       {'loss': 2.0131, 'learning_rate': 0.0002654643770402058, 'epoch': 0.67}
 67%|██████▋   | 1586/2382 [4:52:55<2:17:35, 10.37s/it] 67%|██████▋   | 1587/2382 [4:53:08<2:25:57, 11.02s/it]                                                       {'loss': 1.9892, 'learning_rate': 0.0002648640465036316, 'epoch': 0.67}
 67%|██████▋   | 1587/2382 [4:53:08<2:25:57, 11.02s/it] 67%|██████▋   | 1588/2382 [4:53:16<2:14:25, 10.16s/it]                                                       {'loss': 2.1862, 'learning_rate': 0.00026426415087241623, 'epoch': 0.67}
 67%|██████▋   | 1588/2382 [4:53:16<2:14:25, 10.16s/it] 67%|██████▋   | 1589/2382 [4:53:26<2:16:03, 10.29s/it]                                                       {'loss': 2.0783, 'learning_rate': 0.0002636646912561208, 'epoch': 0.67}
 67%|██████▋   | 1589/2382 [4:53:26<2:16:03, 10.29s/it] 67%|██████▋   | 1590/2382 [4:53:37<2:16:21, 10.33s/it]                                                       {'loss': 2.065, 'learning_rate': 0.0002630656687635007, 'epoch': 0.67}
 67%|██████▋   | 1590/2382 [4:53:37<2:16:21, 10.33s/it] 67%|██████▋   | 1591/2382 [4:53:47<2:16:34, 10.36s/it]                                                       {'loss': 2.0838, 'learning_rate': 0.00026246708450250255, 'epoch': 0.67}
 67%|██████▋   | 1591/2382 [4:53:47<2:16:34, 10.36s/it] 67%|██████▋   | 1592/2382 [4:54:00<2:27:15, 11.18s/it]                                                       {'loss': 2.0293, 'learning_rate': 0.0002618689395802624, 'epoch': 0.67}
 67%|██████▋   | 1592/2382 [4:54:00<2:27:15, 11.18s/it] 67%|██████▋   | 1593/2382 [4:54:10<2:20:15, 10.67s/it]                                                       {'loss': 2.0002, 'learning_rate': 0.00026127123510310407, 'epoch': 0.67}
 67%|██████▋   | 1593/2382 [4:54:10<2:20:15, 10.67s/it] 67%|██████▋   | 1594/2382 [4:54:18<2:10:51,  9.96s/it]                                                       {'loss': 2.0144, 'learning_rate': 0.000260673972176536, 'epoch': 0.67}
 67%|██████▋   | 1594/2382 [4:54:18<2:10:51,  9.96s/it] 67%|██████▋   | 1595/2382 [4:54:28<2:10:44,  9.97s/it]                                                       {'loss': 2.0185, 'learning_rate': 0.0002600771519052506, 'epoch': 0.67}
 67%|██████▋   | 1595/2382 [4:54:28<2:10:44,  9.97s/it] 67%|██████▋   | 1596/2382 [4:54:39<2:14:14, 10.25s/it]                                                       {'loss': 2.0006, 'learning_rate': 0.0002594807753931211, 'epoch': 0.67}
 67%|██████▋   | 1596/2382 [4:54:39<2:14:14, 10.25s/it] 67%|██████▋   | 1597/2382 [4:54:48<2:09:41,  9.91s/it]                                                       {'loss': 2.0084, 'learning_rate': 0.00025888484374320033, 'epoch': 0.67}
 67%|██████▋   | 1597/2382 [4:54:48<2:09:41,  9.91s/it] 67%|██████▋   | 1598/2382 [4:55:02<2:26:35, 11.22s/it]                                                       {'loss': 1.8995, 'learning_rate': 0.000258289358057718, 'epoch': 0.67}
 67%|██████▋   | 1598/2382 [4:55:02<2:26:35, 11.22s/it] 67%|██████▋   | 1599/2382 [4:55:12<2:20:28, 10.76s/it]                                                       {'loss': 2.0351, 'learning_rate': 0.00025769431943807933, 'epoch': 0.67}
 67%|██████▋   | 1599/2382 [4:55:12<2:20:28, 10.76s/it] 67%|██████▋   | 1600/2382 [4:55:27<2:36:41, 12.02s/it]                                                       {'loss': 2.0192, 'learning_rate': 0.0002570997289848625, 'epoch': 0.67}
 67%|██████▋   | 1600/2382 [4:55:27<2:36:41, 12.02s/it] 67%|██████▋   | 1601/2382 [4:55:38<2:31:36, 11.65s/it]                                                       {'loss': 1.9205, 'learning_rate': 0.00025650558779781636, 'epoch': 0.67}
 67%|██████▋   | 1601/2382 [4:55:38<2:31:36, 11.65s/it] 67%|██████▋   | 1602/2382 [4:55:47<2:22:11, 10.94s/it]                                                       {'loss': 2.0715, 'learning_rate': 0.00025591189697585947, 'epoch': 0.67}
 67%|██████▋   | 1602/2382 [4:55:47<2:22:11, 10.94s/it] 67%|██████▋   | 1603/2382 [4:55:59<2:25:07, 11.18s/it]                                                       {'loss': 1.9014, 'learning_rate': 0.0002553186576170767, 'epoch': 0.67}
 67%|██████▋   | 1603/2382 [4:55:59<2:25:07, 11.18s/it] 67%|██████▋   | 1604/2382 [4:56:11<2:30:16, 11.59s/it]                                                       {'loss': 1.974, 'learning_rate': 0.00025472587081871854, 'epoch': 0.67}
 67%|██████▋   | 1604/2382 [4:56:11<2:30:16, 11.59s/it] 67%|██████▋   | 1605/2382 [4:56:21<2:21:27, 10.92s/it]                                                       {'loss': 2.0577, 'learning_rate': 0.00025413353767719804, 'epoch': 0.67}
 67%|██████▋   | 1605/2382 [4:56:21<2:21:27, 10.92s/it] 67%|██████▋   | 1606/2382 [4:56:33<2:26:41, 11.34s/it]                                                       {'loss': 1.9282, 'learning_rate': 0.0002535416592880896, 'epoch': 0.67}
 67%|██████▋   | 1606/2382 [4:56:33<2:26:41, 11.34s/it] 67%|██████▋   | 1607/2382 [4:56:44<2:24:48, 11.21s/it]                                                       {'loss': 2.1152, 'learning_rate': 0.0002529502367461257, 'epoch': 0.67}
 67%|██████▋   | 1607/2382 [4:56:44<2:24:48, 11.21s/it] 68%|██████▊   | 1608/2382 [4:56:56<2:27:30, 11.43s/it]                                                       {'loss': 2.0035, 'learning_rate': 0.0002523592711451964, 'epoch': 0.67}
 68%|██████▊   | 1608/2382 [4:56:56<2:27:30, 11.43s/it] 68%|██████▊   | 1609/2382 [4:57:08<2:30:13, 11.66s/it]                                                       {'loss': 2.0084, 'learning_rate': 0.00025176876357834664, 'epoch': 0.68}
 68%|██████▊   | 1609/2382 [4:57:08<2:30:13, 11.66s/it] 68%|██████▊   | 1610/2382 [4:57:17<2:20:16, 10.90s/it]                                                       {'loss': 2.2084, 'learning_rate': 0.0002511787151377735, 'epoch': 0.68}
 68%|██████▊   | 1610/2382 [4:57:17<2:20:16, 10.90s/it] 68%|██████▊   | 1611/2382 [4:57:29<2:23:10, 11.14s/it]                                                       {'loss': 2.0548, 'learning_rate': 0.0002505891269148256, 'epoch': 0.68}
 68%|██████▊   | 1611/2382 [4:57:29<2:23:10, 11.14s/it] 68%|██████▊   | 1612/2382 [4:57:40<2:21:22, 11.02s/it]                                                       {'loss': 2.1262, 'learning_rate': 0.0002500000000000001, 'epoch': 0.68}
 68%|██████▊   | 1612/2382 [4:57:40<2:21:22, 11.02s/it] 68%|██████▊   | 1613/2382 [4:57:50<2:19:10, 10.86s/it]                                                       {'loss': 2.0487, 'learning_rate': 0.0002494113354829406, 'epoch': 0.68}
 68%|██████▊   | 1613/2382 [4:57:50<2:19:10, 10.86s/it] 68%|██████▊   | 1614/2382 [4:58:02<2:23:11, 11.19s/it]                                                       {'loss': 2.0349, 'learning_rate': 0.00024882313445243585, 'epoch': 0.68}
 68%|██████▊   | 1614/2382 [4:58:02<2:23:11, 11.19s/it] 68%|██████▊   | 1615/2382 [4:58:14<2:25:23, 11.37s/it]                                                       {'loss': 2.1051, 'learning_rate': 0.00024823539799641726, 'epoch': 0.68}
 68%|██████▊   | 1615/2382 [4:58:14<2:25:23, 11.37s/it] 68%|██████▊   | 1616/2382 [4:58:24<2:20:01, 10.97s/it]                                                       {'loss': 2.1978, 'learning_rate': 0.00024764812720195714, 'epoch': 0.68}
 68%|██████▊   | 1616/2382 [4:58:24<2:20:01, 10.97s/it] 68%|██████▊   | 1617/2382 [4:58:34<2:15:21, 10.62s/it]                                                       {'loss': 1.9484, 'learning_rate': 0.0002470613231552661, 'epoch': 0.68}
 68%|██████▊   | 1617/2382 [4:58:34<2:15:21, 10.62s/it] 68%|██████▊   | 1618/2382 [4:58:44<2:13:01, 10.45s/it]                                                       {'loss': 2.0619, 'learning_rate': 0.0002464749869416914, 'epoch': 0.68}
 68%|██████▊   | 1618/2382 [4:58:44<2:13:01, 10.45s/it] 68%|██████▊   | 1619/2382 [4:58:53<2:06:36,  9.96s/it]                                                       {'loss': 2.0501, 'learning_rate': 0.00024588911964571554, 'epoch': 0.68}
 68%|██████▊   | 1619/2382 [4:58:53<2:06:36,  9.96s/it] 68%|██████▊   | 1620/2382 [4:59:02<2:04:43,  9.82s/it]                                                       {'loss': 2.0001, 'learning_rate': 0.0002453037223509534, 'epoch': 0.68}
 68%|██████▊   | 1620/2382 [4:59:02<2:04:43,  9.82s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1348 > 1024). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (1549 > 1024). Running this sequence through the model will result in indexing errors
 68%|██████▊   | 1621/2382 [4:59:13<2:07:17, 10.04s/it]                                                       {'loss': 2.0849, 'learning_rate': 0.0002447187961401506, 'epoch': 0.68}
 68%|██████▊   | 1621/2382 [4:59:13<2:07:17, 10.04s/it] 68%|██████▊   | 1622/2382 [4:59:24<2:13:29, 10.54s/it]                                                       {'loss': 2.0042, 'learning_rate': 0.00024413434209518138, 'epoch': 0.68}
 68%|██████▊   | 1622/2382 [4:59:24<2:13:29, 10.54s/it] 68%|██████▊   | 1623/2382 [4:59:35<2:12:16, 10.46s/it]                                                       {'loss': 1.9598, 'learning_rate': 0.000243550361297047, 'epoch': 0.68}
 68%|██████▊   | 1623/2382 [4:59:35<2:12:16, 10.46s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1167 > 1024). Running this sequence through the model will result in indexing errors
 68%|██████▊   | 1624/2382 [4:59:45<2:10:18, 10.31s/it]                                                       {'loss': 2.1086, 'learning_rate': 0.00024296685482587282, 'epoch': 0.68}
 68%|██████▊   | 1624/2382 [4:59:45<2:10:18, 10.31s/it] 68%|██████▊   | 1625/2382 [4:59:55<2:09:24, 10.26s/it]                                                       {'loss': 2.0712, 'learning_rate': 0.00024238382376090713, 'epoch': 0.68}
 68%|██████▊   | 1625/2382 [4:59:55<2:09:24, 10.26s/it] 68%|██████▊   | 1626/2382 [5:00:07<2:17:15, 10.89s/it]                                                       {'loss': 2.0566, 'learning_rate': 0.00024180126918051909, 'epoch': 0.68}
 68%|██████▊   | 1626/2382 [5:00:07<2:17:15, 10.89s/it] 68%|██████▊   | 1627/2382 [5:00:18<2:15:13, 10.75s/it]                                                       {'loss': 2.0598, 'learning_rate': 0.00024121919216219646, 'epoch': 0.68}
 68%|██████▊   | 1627/2382 [5:00:18<2:15:13, 10.75s/it] 68%|██████▊   | 1628/2382 [5:00:28<2:14:08, 10.67s/it]                                                       {'loss': 2.011, 'learning_rate': 0.00024063759378254373, 'epoch': 0.68}
 68%|██████▊   | 1628/2382 [5:00:28<2:14:08, 10.67s/it] 68%|██████▊   | 1629/2382 [5:00:39<2:15:14, 10.78s/it]                                                       {'loss': 2.1908, 'learning_rate': 0.00024005647511728023, 'epoch': 0.68}
 68%|██████▊   | 1629/2382 [5:00:39<2:15:14, 10.78s/it] 68%|██████▊   | 1630/2382 [5:00:51<2:20:56, 11.25s/it]                                                       {'loss': 1.9435, 'learning_rate': 0.00023947583724123745, 'epoch': 0.68}
 68%|██████▊   | 1630/2382 [5:00:51<2:20:56, 11.25s/it] 68%|██████▊   | 1631/2382 [5:01:05<2:28:24, 11.86s/it]                                                       {'loss': 2.0748, 'learning_rate': 0.00023889568122835837, 'epoch': 0.68}
 68%|██████▊   | 1631/2382 [5:01:05<2:28:24, 11.86s/it] 69%|██████▊   | 1632/2382 [5:01:13<2:16:17, 10.90s/it]                                                       {'loss': 2.179, 'learning_rate': 0.00023831600815169408, 'epoch': 0.68}
 69%|██████▊   | 1632/2382 [5:01:13<2:16:17, 10.90s/it] 69%|██████▊   | 1633/2382 [5:01:27<2:25:52, 11.69s/it]                                                       {'loss': 2.0139, 'learning_rate': 0.00023773681908340283, 'epoch': 0.69}
 69%|██████▊   | 1633/2382 [5:01:27<2:25:52, 11.69s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1055 > 1024). Running this sequence through the model will result in indexing errors
 69%|██████▊   | 1634/2382 [5:01:38<2:24:34, 11.60s/it]                                                       {'loss': 2.0409, 'learning_rate': 0.0002371581150947476, 'epoch': 0.69}
 69%|██████▊   | 1634/2382 [5:01:38<2:24:34, 11.60s/it] 69%|██████▊   | 1635/2382 [5:01:50<2:23:36, 11.53s/it]                                                       {'loss': 1.928, 'learning_rate': 0.0002365798972560943, 'epoch': 0.69}
 69%|██████▊   | 1635/2382 [5:01:50<2:23:36, 11.53s/it] 69%|██████▊   | 1636/2382 [5:02:00<2:17:10, 11.03s/it]                                                       {'loss': 2.0685, 'learning_rate': 0.0002360021666369091, 'epoch': 0.69}
 69%|██████▊   | 1636/2382 [5:02:00<2:17:10, 11.03s/it] 69%|██████▊   | 1637/2382 [5:02:13<2:25:02, 11.68s/it]                                                       {'loss': 2.0075, 'learning_rate': 0.0002354249243057575, 'epoch': 0.69}
 69%|██████▊   | 1637/2382 [5:02:13<2:25:02, 11.68s/it] 69%|██████▉   | 1638/2382 [5:02:24<2:23:31, 11.57s/it]                                                       {'loss': 1.9929, 'learning_rate': 0.00023484817133030206, 'epoch': 0.69}
 69%|██████▉   | 1638/2382 [5:02:24<2:23:31, 11.57s/it] 69%|██████▉   | 1639/2382 [5:02:35<2:21:30, 11.43s/it]                                                       {'loss': 2.0146, 'learning_rate': 0.0002342719087772995, 'epoch': 0.69}
 69%|██████▉   | 1639/2382 [5:02:35<2:21:30, 11.43s/it] 69%|██████▉   | 1640/2382 [5:02:50<2:32:57, 12.37s/it]                                                       {'loss': 1.9978, 'learning_rate': 0.00023369613771260007, 'epoch': 0.69}
 69%|██████▉   | 1640/2382 [5:02:50<2:32:57, 12.37s/it] 69%|██████▉   | 1641/2382 [5:03:00<2:24:30, 11.70s/it]                                                       {'loss': 2.2262, 'learning_rate': 0.000233120859201145, 'epoch': 0.69}
 69%|██████▉   | 1641/2382 [5:03:00<2:24:30, 11.70s/it] 69%|██████▉   | 1642/2382 [5:03:10<2:17:56, 11.18s/it]                                                       {'loss': 2.0374, 'learning_rate': 0.0002325460743069639, 'epoch': 0.69}
 69%|██████▉   | 1642/2382 [5:03:10<2:17:56, 11.18s/it] 69%|██████▉   | 1643/2382 [5:03:19<2:09:06, 10.48s/it]                                                       {'loss': 1.9688, 'learning_rate': 0.00023197178409317394, 'epoch': 0.69}
 69%|██████▉   | 1643/2382 [5:03:19<2:09:06, 10.48s/it] 69%|██████▉   | 1644/2382 [5:03:30<2:11:32, 10.69s/it]                                                       {'loss': 2.0192, 'learning_rate': 0.00023139798962197716, 'epoch': 0.69}
 69%|██████▉   | 1644/2382 [5:03:30<2:11:32, 10.69s/it] 69%|██████▉   | 1645/2382 [5:03:46<2:30:35, 12.26s/it]                                                       {'loss': 1.9853, 'learning_rate': 0.00023082469195465893, 'epoch': 0.69}
 69%|██████▉   | 1645/2382 [5:03:46<2:30:35, 12.26s/it] 69%|██████▉   | 1646/2382 [5:03:56<2:22:02, 11.58s/it]                                                       {'loss': 1.9465, 'learning_rate': 0.00023025189215158509, 'epoch': 0.69}
 69%|██████▉   | 1646/2382 [5:03:56<2:22:02, 11.58s/it] 69%|██████▉   | 1647/2382 [5:04:10<2:30:08, 12.26s/it]                                                       {'loss': 2.0639, 'learning_rate': 0.0002296795912722014, 'epoch': 0.69}
 69%|██████▉   | 1647/2382 [5:04:10<2:30:08, 12.26s/it] 69%|██████▉   | 1648/2382 [5:04:24<2:39:23, 13.03s/it]                                                       {'loss': 1.9494, 'learning_rate': 0.00022910779037503003, 'epoch': 0.69}
 69%|██████▉   | 1648/2382 [5:04:24<2:39:23, 13.03s/it] 69%|██████▉   | 1649/2382 [5:04:35<2:28:45, 12.18s/it]                                                       {'loss': 2.0496, 'learning_rate': 0.00022853649051766918, 'epoch': 0.69}
 69%|██████▉   | 1649/2382 [5:04:35<2:28:45, 12.18s/it] 69%|██████▉   | 1650/2382 [5:04:47<2:28:15, 12.15s/it]                                                       {'loss': 2.1063, 'learning_rate': 0.00022796569275678973, 'epoch': 0.69}
 69%|██████▉   | 1650/2382 [5:04:47<2:28:15, 12.15s/it] 69%|██████▉   | 1651/2382 [5:04:57<2:23:00, 11.74s/it]                                                       {'loss': 2.1741, 'learning_rate': 0.00022739539814813425, 'epoch': 0.69}
 69%|██████▉   | 1651/2382 [5:04:57<2:23:00, 11.74s/it] 69%|██████▉   | 1652/2382 [5:05:08<2:18:28, 11.38s/it]                                                       {'loss': 2.0638, 'learning_rate': 0.00022682560774651457, 'epoch': 0.69}
 69%|██████▉   | 1652/2382 [5:05:08<2:18:28, 11.38s/it] 69%|██████▉   | 1653/2382 [5:05:19<2:16:29, 11.23s/it]                                                       {'loss': 1.9508, 'learning_rate': 0.00022625632260581002, 'epoch': 0.69}
 69%|██████▉   | 1653/2382 [5:05:19<2:16:29, 11.23s/it] 69%|██████▉   | 1654/2382 [5:05:31<2:19:41, 11.51s/it]                                                       {'loss': 2.0887, 'learning_rate': 0.00022568754377896516, 'epoch': 0.69}
 69%|██████▉   | 1654/2382 [5:05:31<2:19:41, 11.51s/it] 69%|██████▉   | 1655/2382 [5:05:42<2:16:11, 11.24s/it]                                                       {'loss': 2.0434, 'learning_rate': 0.00022511927231798812, 'epoch': 0.69}
 69%|██████▉   | 1655/2382 [5:05:42<2:16:11, 11.24s/it] 70%|██████▉   | 1656/2382 [5:05:52<2:13:57, 11.07s/it]                                                       {'loss': 2.0119, 'learning_rate': 0.0002245515092739488, 'epoch': 0.69}
 70%|██████▉   | 1656/2382 [5:05:52<2:13:57, 11.07s/it] 70%|██████▉   | 1657/2382 [5:06:04<2:16:29, 11.30s/it]                                                       {'loss': 2.0039, 'learning_rate': 0.00022398425569697666, 'epoch': 0.7}
 70%|██████▉   | 1657/2382 [5:06:04<2:16:29, 11.30s/it] 70%|██████▉   | 1658/2382 [5:06:15<2:15:03, 11.19s/it]                                                       {'loss': 1.9774, 'learning_rate': 0.00022341751263625886, 'epoch': 0.7}
 70%|██████▉   | 1658/2382 [5:06:15<2:15:03, 11.19s/it] 70%|██████▉   | 1659/2382 [5:06:25<2:10:32, 10.83s/it]                                                       {'loss': 1.9851, 'learning_rate': 0.00022285128114003856, 'epoch': 0.7}
 70%|██████▉   | 1659/2382 [5:06:25<2:10:32, 10.83s/it] 70%|██████▉   | 1660/2382 [5:06:37<2:13:50, 11.12s/it]                                                       {'loss': 2.0137, 'learning_rate': 0.00022228556225561204, 'epoch': 0.7}
 70%|██████▉   | 1660/2382 [5:06:37<2:13:50, 11.12s/it] 70%|██████▉   | 1661/2382 [5:06:46<2:06:17, 10.51s/it]                                                       {'loss': 2.1618, 'learning_rate': 0.00022172035702932823, 'epoch': 0.7}
 70%|██████▉   | 1661/2382 [5:06:46<2:06:17, 10.51s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1159 > 1024). Running this sequence through the model will result in indexing errors
 70%|██████▉   | 1662/2382 [5:06:59<2:14:44, 11.23s/it]                                                       {'loss': 1.9994, 'learning_rate': 0.00022115566650658536, 'epoch': 0.7}
 70%|██████▉   | 1662/2382 [5:06:59<2:14:44, 11.23s/it] 70%|██████▉   | 1663/2382 [5:07:09<2:12:06, 11.02s/it]                                                       {'loss': 2.0798, 'learning_rate': 0.00022059149173183013, 'epoch': 0.7}
 70%|██████▉   | 1663/2382 [5:07:09<2:12:06, 11.02s/it] 70%|██████▉   | 1664/2382 [5:07:20<2:11:57, 11.03s/it]                                                       {'loss': 2.094, 'learning_rate': 0.00022002783374855517, 'epoch': 0.7}
 70%|██████▉   | 1664/2382 [5:07:20<2:11:57, 11.03s/it] 70%|██████▉   | 1665/2382 [5:07:32<2:15:05, 11.30s/it]                                                       {'loss': 2.1088, 'learning_rate': 0.00021946469359929743, 'epoch': 0.7}
 70%|██████▉   | 1665/2382 [5:07:32<2:15:05, 11.30s/it] 70%|██████▉   | 1666/2382 [5:07:44<2:14:18, 11.26s/it]                                                       {'loss': 2.0215, 'learning_rate': 0.00021890207232563554, 'epoch': 0.7}
 70%|██████▉   | 1666/2382 [5:07:44<2:14:18, 11.26s/it] 70%|██████▉   | 1667/2382 [5:07:52<2:04:28, 10.45s/it]                                                       {'loss': 2.0458, 'learning_rate': 0.00021833997096818897, 'epoch': 0.7}
 70%|██████▉   | 1667/2382 [5:07:52<2:04:28, 10.45s/it] 70%|███████   | 1668/2382 [5:08:04<2:08:14, 10.78s/it]                                                       {'loss': 1.9755, 'learning_rate': 0.00021777839056661552, 'epoch': 0.7}
 70%|███████   | 1668/2382 [5:08:04<2:08:14, 10.78s/it] 70%|███████   | 1669/2382 [5:08:13<2:03:16, 10.37s/it]                                                       {'loss': 2.0644, 'learning_rate': 0.00021721733215960892, 'epoch': 0.7}
 70%|███████   | 1669/2382 [5:08:13<2:03:16, 10.37s/it] 70%|███████   | 1670/2382 [5:08:22<1:57:54,  9.94s/it]                                                       {'loss': 2.1005, 'learning_rate': 0.00021665679678489804, 'epoch': 0.7}
 70%|███████   | 1670/2382 [5:08:22<1:57:54,  9.94s/it] 70%|███████   | 1671/2382 [5:08:32<1:56:32,  9.83s/it]                                                       {'loss': 2.0261, 'learning_rate': 0.00021609678547924416, 'epoch': 0.7}
 70%|███████   | 1671/2382 [5:08:32<1:56:32,  9.83s/it] 70%|███████   | 1672/2382 [5:08:43<2:00:31, 10.19s/it]                                                       {'loss': 2.0614, 'learning_rate': 0.0002155372992784389, 'epoch': 0.7}
 70%|███████   | 1672/2382 [5:08:43<2:00:31, 10.19s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1304 > 1024). Running this sequence through the model will result in indexing errors
 70%|███████   | 1673/2382 [5:08:53<2:00:17, 10.18s/it]                                                       {'loss': 2.061, 'learning_rate': 0.00021497833921730315, 'epoch': 0.7}
 70%|███████   | 1673/2382 [5:08:53<2:00:17, 10.18s/it] 70%|███████   | 1674/2382 [5:09:02<1:57:08,  9.93s/it]                                                       {'loss': 2.0122, 'learning_rate': 0.00021441990632968438, 'epoch': 0.7}
 70%|███████   | 1674/2382 [5:09:02<1:57:08,  9.93s/it] 70%|███████   | 1675/2382 [5:09:12<1:57:20,  9.96s/it]                                                       {'loss': 2.0482, 'learning_rate': 0.00021386200164845526, 'epoch': 0.7}
 70%|███████   | 1675/2382 [5:09:12<1:57:20,  9.96s/it] 70%|███████   | 1676/2382 [5:09:22<1:58:02, 10.03s/it]                                                       {'loss': 2.0759, 'learning_rate': 0.00021330462620551094, 'epoch': 0.7}
 70%|███████   | 1676/2382 [5:09:22<1:58:02, 10.03s/it] 70%|███████   | 1677/2382 [5:09:34<2:04:20, 10.58s/it]                                                       {'loss': 1.9808, 'learning_rate': 0.0002127477810317685, 'epoch': 0.7}
 70%|███████   | 1677/2382 [5:09:34<2:04:20, 10.58s/it] 70%|███████   | 1678/2382 [5:09:49<2:20:28, 11.97s/it]                                                       {'loss': 2.1523, 'learning_rate': 0.0002121914671571633, 'epoch': 0.7}
 70%|███████   | 1678/2382 [5:09:49<2:20:28, 11.97s/it] 70%|███████   | 1679/2382 [5:10:00<2:13:48, 11.42s/it]                                                       {'loss': 2.0882, 'learning_rate': 0.00021163568561064882, 'epoch': 0.7}
 70%|███████   | 1679/2382 [5:10:00<2:13:48, 11.42s/it] 71%|███████   | 1680/2382 [5:10:12<2:16:36, 11.68s/it]                                                       {'loss': 1.9895, 'learning_rate': 0.00021108043742019356, 'epoch': 0.71}
 71%|███████   | 1680/2382 [5:10:12<2:16:36, 11.68s/it] 71%|███████   | 1681/2382 [5:10:22<2:09:56, 11.12s/it]                                                       {'loss': 2.08, 'learning_rate': 0.00021052572361277968, 'epoch': 0.71}
 71%|███████   | 1681/2382 [5:10:22<2:09:56, 11.12s/it] 71%|███████   | 1682/2382 [5:10:32<2:07:03, 10.89s/it]                                                       {'loss': 2.0216, 'learning_rate': 0.00020997154521440098, 'epoch': 0.71}
 71%|███████   | 1682/2382 [5:10:32<2:07:03, 10.89s/it] 71%|███████   | 1683/2382 [5:10:42<2:04:45, 10.71s/it]                                                       {'loss': 2.0955, 'learning_rate': 0.0002094179032500607, 'epoch': 0.71}
 71%|███████   | 1683/2382 [5:10:42<2:04:45, 10.71s/it] 71%|███████   | 1684/2382 [5:10:54<2:07:00, 10.92s/it]                                                       {'loss': 1.9867, 'learning_rate': 0.00020886479874377, 'epoch': 0.71}
 71%|███████   | 1684/2382 [5:10:54<2:07:00, 10.92s/it] 71%|███████   | 1685/2382 [5:11:06<2:09:55, 11.18s/it]                                                       {'loss': 2.0516, 'learning_rate': 0.00020831223271854611, 'epoch': 0.71}
 71%|███████   | 1685/2382 [5:11:06<2:09:55, 11.18s/it] 71%|███████   | 1686/2382 [5:11:15<2:02:52, 10.59s/it]                                                       {'loss': 2.1556, 'learning_rate': 0.00020776020619641024, 'epoch': 0.71}
 71%|███████   | 1686/2382 [5:11:15<2:02:52, 10.59s/it] 71%|███████   | 1687/2382 [5:11:27<2:08:39, 11.11s/it]                                                       {'loss': 1.9698, 'learning_rate': 0.00020720872019838567, 'epoch': 0.71}
 71%|███████   | 1687/2382 [5:11:27<2:08:39, 11.11s/it] 71%|███████   | 1688/2382 [5:11:37<2:05:06, 10.82s/it]                                                       {'loss': 1.9644, 'learning_rate': 0.00020665777574449608, 'epoch': 0.71}
 71%|███████   | 1688/2382 [5:11:37<2:05:06, 10.82s/it] 71%|███████   | 1689/2382 [5:11:49<2:09:41, 11.23s/it]                                                       {'loss': 1.9467, 'learning_rate': 0.00020610737385376348, 'epoch': 0.71}
 71%|███████   | 1689/2382 [5:11:49<2:09:41, 11.23s/it] 71%|███████   | 1690/2382 [5:12:00<2:06:17, 10.95s/it]                                                       {'loss': 1.9663, 'learning_rate': 0.000205557515544206, 'epoch': 0.71}
 71%|███████   | 1690/2382 [5:12:00<2:06:17, 10.95s/it] 71%|███████   | 1691/2382 [5:12:11<2:07:12, 11.05s/it]                                                       {'loss': 2.0238, 'learning_rate': 0.00020500820183283697, 'epoch': 0.71}
 71%|███████   | 1691/2382 [5:12:11<2:07:12, 11.05s/it] 71%|███████   | 1692/2382 [5:12:20<1:59:50, 10.42s/it]                                                       {'loss': 1.9658, 'learning_rate': 0.00020445943373566177, 'epoch': 0.71}
 71%|███████   | 1692/2382 [5:12:20<1:59:50, 10.42s/it] 71%|███████   | 1693/2382 [5:12:31<2:03:02, 10.72s/it]                                                       {'loss': 2.0619, 'learning_rate': 0.00020391121226767724, 'epoch': 0.71}
 71%|███████   | 1693/2382 [5:12:31<2:03:02, 10.72s/it] 71%|███████   | 1694/2382 [5:12:42<2:01:16, 10.58s/it]                                                       {'loss': 2.1399, 'learning_rate': 0.00020336353844286877, 'epoch': 0.71}
 71%|███████   | 1694/2382 [5:12:42<2:01:16, 10.58s/it] 71%|███████   | 1695/2382 [5:12:54<2:06:33, 11.05s/it]                                                       {'loss': 1.9594, 'learning_rate': 0.00020281641327420918, 'epoch': 0.71}
 71%|███████   | 1695/2382 [5:12:54<2:06:33, 11.05s/it] 71%|███████   | 1696/2382 [5:13:06<2:11:40, 11.52s/it]                                                       {'loss': 2.162, 'learning_rate': 0.00020226983777365604, 'epoch': 0.71}
 71%|███████   | 1696/2382 [5:13:06<2:11:40, 11.52s/it] 71%|███████   | 1697/2382 [5:13:17<2:09:06, 11.31s/it]                                                       {'loss': 1.9514, 'learning_rate': 0.0002017238129521506, 'epoch': 0.71}
 71%|███████   | 1697/2382 [5:13:17<2:09:06, 11.31s/it] 71%|███████▏  | 1698/2382 [5:13:27<2:03:21, 10.82s/it]                                                       {'loss': 2.0776, 'learning_rate': 0.00020117833981961563, 'epoch': 0.71}
 71%|███████▏  | 1698/2382 [5:13:27<2:03:21, 10.82s/it] 71%|███████▏  | 1699/2382 [5:13:37<2:01:47, 10.70s/it]                                                       {'loss': 1.9941, 'learning_rate': 0.00020063341938495312, 'epoch': 0.71}
 71%|███████▏  | 1699/2382 [5:13:37<2:01:47, 10.70s/it] 71%|███████▏  | 1700/2382 [5:13:47<1:57:56, 10.38s/it]                                                       {'loss': 2.2013, 'learning_rate': 0.00020008905265604316, 'epoch': 0.71}
 71%|███████▏  | 1700/2382 [5:13:47<1:57:56, 10.38s/it] 71%|███████▏  | 1701/2382 [5:13:58<2:00:26, 10.61s/it]                                                       {'loss': 1.9364, 'learning_rate': 0.00019954524063974172, 'epoch': 0.71}
 71%|███████▏  | 1701/2382 [5:13:58<2:00:26, 10.61s/it] 71%|███████▏  | 1702/2382 [5:14:09<2:00:05, 10.60s/it]                                                       {'loss': 2.1596, 'learning_rate': 0.00019900198434187838, 'epoch': 0.71}
 71%|███████▏  | 1702/2382 [5:14:09<2:00:05, 10.60s/it] 71%|███████▏  | 1703/2382 [5:14:19<1:59:57, 10.60s/it]                                                       {'loss': 1.9803, 'learning_rate': 0.00019845928476725522, 'epoch': 0.71}
 71%|███████▏  | 1703/2382 [5:14:19<1:59:57, 10.60s/it] 72%|███████▏  | 1704/2382 [5:14:30<1:59:11, 10.55s/it]                                                       {'loss': 1.9715, 'learning_rate': 0.00019791714291964463, 'epoch': 0.72}
 72%|███████▏  | 1704/2382 [5:14:30<1:59:11, 10.55s/it] 72%|███████▏  | 1705/2382 [5:14:42<2:04:57, 11.08s/it]                                                       {'loss': 2.0701, 'learning_rate': 0.0001973755598017874, 'epoch': 0.72}
 72%|███████▏  | 1705/2382 [5:14:42<2:04:57, 11.08s/it] 72%|███████▏  | 1706/2382 [5:14:53<2:05:04, 11.10s/it]                                                       {'loss': 2.0659, 'learning_rate': 0.00019683453641539052, 'epoch': 0.72}
 72%|███████▏  | 1706/2382 [5:14:53<2:05:04, 11.10s/it] 72%|███████▏  | 1707/2382 [5:15:03<1:59:51, 10.65s/it]                                                       {'loss': 2.0451, 'learning_rate': 0.0001962940737611264, 'epoch': 0.72}
 72%|███████▏  | 1707/2382 [5:15:03<1:59:51, 10.65s/it] 72%|███████▏  | 1708/2382 [5:15:13<1:59:36, 10.65s/it]                                                       {'loss': 2.0981, 'learning_rate': 0.0001957541728386295, 'epoch': 0.72}
 72%|███████▏  | 1708/2382 [5:15:13<1:59:36, 10.65s/it] 72%|███████▏  | 1709/2382 [5:15:24<2:00:22, 10.73s/it]                                                       {'loss': 2.1278, 'learning_rate': 0.00019521483464649597, 'epoch': 0.72}
 72%|███████▏  | 1709/2382 [5:15:24<2:00:22, 10.73s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1675 > 1024). Running this sequence through the model will result in indexing errors
 72%|███████▏  | 1710/2382 [5:15:37<2:06:11, 11.27s/it]                                                       {'loss': 2.0034, 'learning_rate': 0.0001946760601822809, 'epoch': 0.72}
 72%|███████▏  | 1710/2382 [5:15:37<2:06:11, 11.27s/it] 72%|███████▏  | 1711/2382 [5:15:50<2:13:56, 11.98s/it]                                                       {'loss': 2.0268, 'learning_rate': 0.00019413785044249677, 'epoch': 0.72}
 72%|███████▏  | 1711/2382 [5:15:50<2:13:56, 11.98s/it] 72%|███████▏  | 1712/2382 [5:16:03<2:15:49, 12.16s/it]                                                       {'loss': 1.9716, 'learning_rate': 0.00019360020642261155, 'epoch': 0.72}
 72%|███████▏  | 1712/2382 [5:16:03<2:15:49, 12.16s/it] 72%|███████▏  | 1713/2382 [5:16:13<2:07:39, 11.45s/it]                                                       {'loss': 2.1645, 'learning_rate': 0.00019306312911704683, 'epoch': 0.72}
 72%|███████▏  | 1713/2382 [5:16:13<2:07:39, 11.45s/it] 72%|███████▏  | 1714/2382 [5:16:24<2:05:48, 11.30s/it]                                                       {'loss': 1.9985, 'learning_rate': 0.00019252661951917567, 'epoch': 0.72}
 72%|███████▏  | 1714/2382 [5:16:24<2:05:48, 11.30s/it] 72%|███████▏  | 1715/2382 [5:16:34<2:00:57, 10.88s/it]                                                       {'loss': 2.1265, 'learning_rate': 0.00019199067862132164, 'epoch': 0.72}
 72%|███████▏  | 1715/2382 [5:16:34<2:00:57, 10.88s/it] 72%|███████▏  | 1716/2382 [5:16:47<2:09:02, 11.63s/it]                                                       {'loss': 1.8991, 'learning_rate': 0.00019145530741475632, 'epoch': 0.72}
 72%|███████▏  | 1716/2382 [5:16:47<2:09:02, 11.63s/it] 72%|███████▏  | 1717/2382 [5:16:57<2:03:08, 11.11s/it]                                                       {'loss': 2.0568, 'learning_rate': 0.00019092050688969737, 'epoch': 0.72}
 72%|███████▏  | 1717/2382 [5:16:57<2:03:08, 11.11s/it] 72%|███████▏  | 1718/2382 [5:17:07<1:59:53, 10.83s/it]                                                       {'loss': 1.9929, 'learning_rate': 0.00019038627803530712, 'epoch': 0.72}
 72%|███████▏  | 1718/2382 [5:17:07<1:59:53, 10.83s/it] 72%|███████▏  | 1719/2382 [5:17:18<1:59:49, 10.84s/it]                                                       {'loss': 2.1617, 'learning_rate': 0.0001898526218396907, 'epoch': 0.72}
 72%|███████▏  | 1719/2382 [5:17:18<1:59:49, 10.84s/it] 72%|███████▏  | 1720/2382 [5:17:28<1:55:53, 10.50s/it]                                                       {'loss': 2.046, 'learning_rate': 0.00018931953928989366, 'epoch': 0.72}
 72%|███████▏  | 1720/2382 [5:17:28<1:55:53, 10.50s/it] 72%|███████▏  | 1721/2382 [5:17:38<1:53:34, 10.31s/it]                                                       {'loss': 2.0629, 'learning_rate': 0.00018878703137190046, 'epoch': 0.72}
 72%|███████▏  | 1721/2382 [5:17:38<1:53:34, 10.31s/it] 72%|███████▏  | 1722/2382 [5:17:49<1:56:00, 10.55s/it]                                                       {'loss': 2.0504, 'learning_rate': 0.00018825509907063325, 'epoch': 0.72}
 72%|███████▏  | 1722/2382 [5:17:49<1:56:00, 10.55s/it] 72%|███████▏  | 1723/2382 [5:18:00<1:59:25, 10.87s/it]                                                       {'loss': 2.0098, 'learning_rate': 0.0001877237433699493, 'epoch': 0.72}
 72%|███████▏  | 1723/2382 [5:18:00<1:59:25, 10.87s/it] 72%|███████▏  | 1724/2382 [5:18:13<2:04:43, 11.37s/it]                                                       {'loss': 2.0786, 'learning_rate': 0.00018719296525263924, 'epoch': 0.72}
 72%|███████▏  | 1724/2382 [5:18:13<2:04:43, 11.37s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (2371 > 1024). Running this sequence through the model will result in indexing errors
 72%|███████▏  | 1725/2382 [5:18:23<1:59:54, 10.95s/it]                                                       {'loss': 2.1362, 'learning_rate': 0.0001866627657004258, 'epoch': 0.72}
 72%|███████▏  | 1725/2382 [5:18:23<1:59:54, 10.95s/it] 72%|███████▏  | 1726/2382 [5:18:37<2:09:48, 11.87s/it]                                                       {'loss': 2.1036, 'learning_rate': 0.00018613314569396088, 'epoch': 0.72}
 72%|███████▏  | 1726/2382 [5:18:37<2:09:48, 11.87s/it] 73%|███████▎  | 1727/2382 [5:18:49<2:10:18, 11.94s/it]                                                       {'loss': 1.9489, 'learning_rate': 0.00018560410621282542, 'epoch': 0.72}
 73%|███████▎  | 1727/2382 [5:18:49<2:10:18, 11.94s/it] 73%|███████▎  | 1728/2382 [5:18:59<2:05:40, 11.53s/it]                                                       {'loss': 2.0727, 'learning_rate': 0.00018507564823552563, 'epoch': 0.73}
 73%|███████▎  | 1728/2382 [5:18:59<2:05:40, 11.53s/it] 73%|███████▎  | 1729/2382 [5:19:10<2:03:13, 11.32s/it]                                                       {'loss': 2.0721, 'learning_rate': 0.0001845477727394929, 'epoch': 0.73}
 73%|███████▎  | 1729/2382 [5:19:10<2:03:13, 11.32s/it] 73%|███████▎  | 1730/2382 [5:19:21<2:01:34, 11.19s/it]                                                       {'loss': 2.0591, 'learning_rate': 0.00018402048070108106, 'epoch': 0.73}
 73%|███████▎  | 1730/2382 [5:19:21<2:01:34, 11.19s/it] 73%|███████▎  | 1731/2382 [5:19:31<1:56:06, 10.70s/it]                                                       {'loss': 2.0926, 'learning_rate': 0.00018349377309556487, 'epoch': 0.73}
 73%|███████▎  | 1731/2382 [5:19:31<1:56:06, 10.70s/it] 73%|███████▎  | 1732/2382 [5:19:42<1:56:20, 10.74s/it]                                                       {'loss': 2.0727, 'learning_rate': 0.00018296765089713767, 'epoch': 0.73}
 73%|███████▎  | 1732/2382 [5:19:42<1:56:20, 10.74s/it] 73%|███████▎  | 1733/2382 [5:19:52<1:55:55, 10.72s/it]                                                       {'loss': 1.9232, 'learning_rate': 0.00018244211507891062, 'epoch': 0.73}
 73%|███████▎  | 1733/2382 [5:19:52<1:55:55, 10.72s/it] 73%|███████▎  | 1734/2382 [5:20:07<2:09:15, 11.97s/it]                                                       {'loss': 2.0291, 'learning_rate': 0.00018191716661291013, 'epoch': 0.73}
 73%|███████▎  | 1734/2382 [5:20:07<2:09:15, 11.97s/it] 73%|███████▎  | 1735/2382 [5:20:20<2:11:44, 12.22s/it]                                                       {'loss': 2.0499, 'learning_rate': 0.00018139280647007594, 'epoch': 0.73}
 73%|███████▎  | 1735/2382 [5:20:20<2:11:44, 12.22s/it] 73%|███████▎  | 1736/2382 [5:20:30<2:04:45, 11.59s/it]                                                       {'loss': 2.0463, 'learning_rate': 0.00018086903562025998, 'epoch': 0.73}
 73%|███████▎  | 1736/2382 [5:20:30<2:04:45, 11.59s/it] 73%|███████▎  | 1737/2382 [5:20:43<2:07:54, 11.90s/it]                                                       {'loss': 2.1292, 'learning_rate': 0.00018034585503222438, 'epoch': 0.73}
 73%|███████▎  | 1737/2382 [5:20:43<2:07:54, 11.90s/it] 73%|███████▎  | 1738/2382 [5:20:55<2:08:42, 11.99s/it]                                                       {'loss': 2.0676, 'learning_rate': 0.0001798232656736389, 'epoch': 0.73}
 73%|███████▎  | 1738/2382 [5:20:55<2:08:42, 11.99s/it] 73%|███████▎  | 1739/2382 [5:21:05<2:02:31, 11.43s/it]                                                       {'loss': 1.9833, 'learning_rate': 0.0001793012685110803, 'epoch': 0.73}
 73%|███████▎  | 1739/2382 [5:21:05<2:02:31, 11.43s/it] 73%|███████▎  | 1740/2382 [5:21:15<1:57:36, 10.99s/it]                                                       {'loss': 2.0459, 'learning_rate': 0.00017877986451002992, 'epoch': 0.73}
 73%|███████▎  | 1740/2382 [5:21:15<1:57:36, 10.99s/it] 73%|███████▎  | 1741/2382 [5:21:27<2:01:09, 11.34s/it]                                                       {'loss': 1.9831, 'learning_rate': 0.0001782590546348719, 'epoch': 0.73}
 73%|███████▎  | 1741/2382 [5:21:27<2:01:09, 11.34s/it] 73%|███████▎  | 1742/2382 [5:21:36<1:52:58, 10.59s/it]                                                       {'loss': 1.9508, 'learning_rate': 0.00017773883984889178, 'epoch': 0.73}
 73%|███████▎  | 1742/2382 [5:21:36<1:52:58, 10.59s/it] 73%|███████▎  | 1743/2382 [5:21:45<1:48:32, 10.19s/it]                                                       {'loss': 2.0733, 'learning_rate': 0.00017721922111427386, 'epoch': 0.73}
 73%|███████▎  | 1743/2382 [5:21:45<1:48:32, 10.19s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1030 > 1024). Running this sequence through the model will result in indexing errors
 73%|███████▎  | 1744/2382 [5:21:59<2:00:13, 11.31s/it]                                                       {'loss': 1.8855, 'learning_rate': 0.00017670019939210026, 'epoch': 0.73}
 73%|███████▎  | 1744/2382 [5:21:59<2:00:13, 11.31s/it] 73%|███████▎  | 1745/2382 [5:22:09<1:54:49, 10.82s/it]                                                       {'loss': 2.075, 'learning_rate': 0.00017618177564234904, 'epoch': 0.73}
 73%|███████▎  | 1745/2382 [5:22:09<1:54:49, 10.82s/it] 73%|███████▎  | 1746/2382 [5:22:21<1:57:35, 11.09s/it]                                                       {'loss': 2.1439, 'learning_rate': 0.0001756639508238922, 'epoch': 0.73}
 73%|███████▎  | 1746/2382 [5:22:21<1:57:35, 11.09s/it] 73%|███████▎  | 1747/2382 [5:22:31<1:55:32, 10.92s/it]                                                       {'loss': 2.0721, 'learning_rate': 0.00017514672589449376, 'epoch': 0.73}
 73%|███████▎  | 1747/2382 [5:22:31<1:55:32, 10.92s/it] 73%|███████▎  | 1748/2382 [5:22:43<1:57:45, 11.14s/it]                                                       {'loss': 2.0484, 'learning_rate': 0.00017463010181080867, 'epoch': 0.73}
 73%|███████▎  | 1748/2382 [5:22:43<1:57:45, 11.14s/it] 73%|███████▎  | 1749/2382 [5:22:54<1:58:55, 11.27s/it]                                                       {'loss': 1.9579, 'learning_rate': 0.00017411407952837977, 'epoch': 0.73}
 73%|███████▎  | 1749/2382 [5:22:54<1:58:55, 11.27s/it] 73%|███████▎  | 1750/2382 [5:23:03<1:51:15, 10.56s/it]                                                       {'loss': 2.1069, 'learning_rate': 0.00017359866000163758, 'epoch': 0.73}
 73%|███████▎  | 1750/2382 [5:23:03<1:51:15, 10.56s/it] 74%|███████▎  | 1751/2382 [5:23:16<1:58:18, 11.25s/it]                                                       {'loss': 1.9764, 'learning_rate': 0.00017308384418389722, 'epoch': 0.73}
 74%|███████▎  | 1751/2382 [5:23:16<1:58:18, 11.25s/it] 74%|███████▎  | 1752/2382 [5:23:30<2:05:59, 12.00s/it]                                                       {'loss': 1.9833, 'learning_rate': 0.0001725696330273575, 'epoch': 0.74}
 74%|███████▎  | 1752/2382 [5:23:30<2:05:59, 12.00s/it] 74%|███████▎  | 1753/2382 [5:23:41<2:03:36, 11.79s/it]                                                       {'loss': 2.0257, 'learning_rate': 0.0001720560274830988, 'epoch': 0.74}
 74%|███████▎  | 1753/2382 [5:23:41<2:03:36, 11.79s/it] 74%|███████▎  | 1754/2382 [5:23:51<1:57:26, 11.22s/it]                                                       {'loss': 2.1224, 'learning_rate': 0.00017154302850108156, 'epoch': 0.74}
 74%|███████▎  | 1754/2382 [5:23:51<1:57:26, 11.22s/it] 74%|███████▎  | 1755/2382 [5:24:07<2:13:23, 12.76s/it]                                                       {'loss': 1.9919, 'learning_rate': 0.00017103063703014372, 'epoch': 0.74}
 74%|███████▎  | 1755/2382 [5:24:07<2:13:23, 12.76s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 1024). Running this sequence through the model will result in indexing errors
 74%|███████▎  | 1756/2382 [5:24:17<2:03:43, 11.86s/it]                                                       {'loss': 2.1261, 'learning_rate': 0.00017051885401800015, 'epoch': 0.74}
 74%|███████▎  | 1756/2382 [5:24:17<2:03:43, 11.86s/it] 74%|███████▍  | 1757/2382 [5:24:26<1:55:16, 11.07s/it]                                                       {'loss': 2.0727, 'learning_rate': 0.00017000768041124039, 'epoch': 0.74}
 74%|███████▍  | 1757/2382 [5:24:26<1:55:16, 11.07s/it] 74%|███████▍  | 1758/2382 [5:24:39<1:59:43, 11.51s/it]                                                       {'loss': 2.0055, 'learning_rate': 0.00016949711715532606, 'epoch': 0.74}
 74%|███████▍  | 1758/2382 [5:24:39<1:59:43, 11.51s/it] 74%|███████▍  | 1759/2382 [5:24:49<1:55:06, 11.09s/it]                                                       {'loss': 1.9449, 'learning_rate': 0.00016898716519459073, 'epoch': 0.74}
 74%|███████▍  | 1759/2382 [5:24:49<1:55:06, 11.09s/it] 74%|███████▍  | 1760/2382 [5:25:00<1:54:35, 11.05s/it]                                                       {'loss': 1.9935, 'learning_rate': 0.0001684778254722371, 'epoch': 0.74}
 74%|███████▍  | 1760/2382 [5:25:00<1:54:35, 11.05s/it] 74%|███████▍  | 1761/2382 [5:25:11<1:54:00, 11.02s/it]                                                       {'loss': 2.0608, 'learning_rate': 0.00016796909893033502, 'epoch': 0.74}
 74%|███████▍  | 1761/2382 [5:25:11<1:54:00, 11.02s/it] 74%|███████▍  | 1762/2382 [5:25:27<2:10:38, 12.64s/it]                                                       {'loss': 2.0382, 'learning_rate': 0.00016746098650982072, 'epoch': 0.74}
 74%|███████▍  | 1762/2382 [5:25:27<2:10:38, 12.64s/it] 74%|███████▍  | 1763/2382 [5:25:40<2:09:30, 12.55s/it]                                                       {'loss': 2.0676, 'learning_rate': 0.0001669534891504944, 'epoch': 0.74}
 74%|███████▍  | 1763/2382 [5:25:40<2:09:30, 12.55s/it] 74%|███████▍  | 1764/2382 [5:25:56<2:19:49, 13.58s/it]                                                       {'loss': 2.0681, 'learning_rate': 0.00016644660779101885, 'epoch': 0.74}
 74%|███████▍  | 1764/2382 [5:25:56<2:19:49, 13.58s/it] 74%|███████▍  | 1765/2382 [5:26:05<2:08:03, 12.45s/it]                                                       {'loss': 2.0133, 'learning_rate': 0.00016594034336891688, 'epoch': 0.74}
 74%|███████▍  | 1765/2382 [5:26:05<2:08:03, 12.45s/it] 74%|███████▍  | 1766/2382 [5:26:18<2:07:49, 12.45s/it]                                                       {'loss': 2.017, 'learning_rate': 0.00016543469682057105, 'epoch': 0.74}
 74%|███████▍  | 1766/2382 [5:26:18<2:07:49, 12.45s/it] 74%|███████▍  | 1767/2382 [5:26:26<1:55:43, 11.29s/it]                                                       {'loss': 2.0987, 'learning_rate': 0.00016492966908122033, 'epoch': 0.74}
 74%|███████▍  | 1767/2382 [5:26:26<1:55:43, 11.29s/it] 74%|███████▍  | 1768/2382 [5:26:37<1:53:47, 11.12s/it]                                                       {'loss': 1.8747, 'learning_rate': 0.0001644252610849597, 'epoch': 0.74}
 74%|███████▍  | 1768/2382 [5:26:37<1:53:47, 11.12s/it] 74%|███████▍  | 1769/2382 [5:26:48<1:52:03, 10.97s/it]                                                       {'loss': 2.0171, 'learning_rate': 0.0001639214737647377, 'epoch': 0.74}
 74%|███████▍  | 1769/2382 [5:26:48<1:52:03, 10.97s/it] 74%|███████▍  | 1770/2382 [5:26:59<1:53:15, 11.10s/it]                                                       {'loss': 1.9598, 'learning_rate': 0.0001634183080523548, 'epoch': 0.74}
 74%|███████▍  | 1770/2382 [5:26:59<1:53:15, 11.10s/it] 74%|███████▍  | 1771/2382 [5:27:12<1:58:25, 11.63s/it]                                                       {'loss': 2.0627, 'learning_rate': 0.00016291576487846205, 'epoch': 0.74}
 74%|███████▍  | 1771/2382 [5:27:12<1:58:25, 11.63s/it] 74%|███████▍  | 1772/2382 [5:27:24<1:57:52, 11.59s/it]                                                       {'loss': 2.0437, 'learning_rate': 0.00016241384517255852, 'epoch': 0.74}
 74%|███████▍  | 1772/2382 [5:27:24<1:57:52, 11.59s/it] 74%|███████▍  | 1773/2382 [5:27:34<1:54:27, 11.28s/it]                                                       {'loss': 2.0009, 'learning_rate': 0.00016191254986299043, 'epoch': 0.74}
 74%|███████▍  | 1773/2382 [5:27:34<1:54:27, 11.28s/it] 74%|███████▍  | 1774/2382 [5:27:45<1:53:21, 11.19s/it]                                                       {'loss': 1.9735, 'learning_rate': 0.0001614118798769491, 'epoch': 0.74}
 74%|███████▍  | 1774/2382 [5:27:45<1:53:21, 11.19s/it] 75%|███████▍  | 1775/2382 [5:27:56<1:51:05, 10.98s/it]                                                       {'loss': 2.0512, 'learning_rate': 0.00016091183614046933, 'epoch': 0.74}
 75%|███████▍  | 1775/2382 [5:27:56<1:51:05, 10.98s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1957 > 1024). Running this sequence through the model will result in indexing errors
 75%|███████▍  | 1776/2382 [5:28:06<1:47:54, 10.68s/it]                                                       {'loss': 2.1611, 'learning_rate': 0.0001604124195784276, 'epoch': 0.75}
 75%|███████▍  | 1776/2382 [5:28:06<1:47:54, 10.68s/it] 75%|███████▍  | 1777/2382 [5:28:18<1:52:34, 11.17s/it]                                                       {'loss': 2.1638, 'learning_rate': 0.0001599136311145402, 'epoch': 0.75}
 75%|███████▍  | 1777/2382 [5:28:18<1:52:34, 11.17s/it] 75%|███████▍  | 1778/2382 [5:28:29<1:51:17, 11.05s/it]                                                       {'loss': 2.045, 'learning_rate': 0.00015941547167136211, 'epoch': 0.75}
 75%|███████▍  | 1778/2382 [5:28:29<1:51:17, 11.05s/it] 75%|███████▍  | 1779/2382 [5:28:38<1:44:24, 10.39s/it]                                                       {'loss': 2.0514, 'learning_rate': 0.0001589179421702842, 'epoch': 0.75}
 75%|███████▍  | 1779/2382 [5:28:38<1:44:24, 10.39s/it] 75%|███████▍  | 1780/2382 [5:28:49<1:47:19, 10.70s/it]                                                       {'loss': 2.1421, 'learning_rate': 0.00015842104353153285, 'epoch': 0.75}
 75%|███████▍  | 1780/2382 [5:28:49<1:47:19, 10.70s/it] 75%|███████▍  | 1781/2382 [5:29:00<1:49:27, 10.93s/it]                                                       {'loss': 1.8981, 'learning_rate': 0.00015792477667416716, 'epoch': 0.75}
 75%|███████▍  | 1781/2382 [5:29:00<1:49:27, 10.93s/it] 75%|███████▍  | 1782/2382 [5:29:10<1:45:50, 10.58s/it]                                                       {'loss': 2.0243, 'learning_rate': 0.00015742914251607793, 'epoch': 0.75}
 75%|███████▍  | 1782/2382 [5:29:10<1:45:50, 10.58s/it] 75%|███████▍  | 1783/2382 [5:29:20<1:42:40, 10.28s/it]                                                       {'loss': 2.1008, 'learning_rate': 0.00015693414197398564, 'epoch': 0.75}
 75%|███████▍  | 1783/2382 [5:29:20<1:42:40, 10.28s/it] 75%|███████▍  | 1784/2382 [5:29:31<1:44:04, 10.44s/it]                                                       {'loss': 2.0095, 'learning_rate': 0.00015643977596343917, 'epoch': 0.75}
 75%|███████▍  | 1784/2382 [5:29:31<1:44:04, 10.44s/it] 75%|███████▍  | 1785/2382 [5:29:43<1:49:06, 10.97s/it]                                                       {'loss': 2.0589, 'learning_rate': 0.000155946045398813, 'epoch': 0.75}
 75%|███████▍  | 1785/2382 [5:29:43<1:49:06, 10.97s/it] 75%|███████▍  | 1786/2382 [5:29:53<1:46:59, 10.77s/it]                                                       {'loss': 2.1502, 'learning_rate': 0.0001554529511933071, 'epoch': 0.75}
 75%|███████▍  | 1786/2382 [5:29:53<1:46:59, 10.77s/it] 75%|███████▌  | 1787/2382 [5:30:07<1:56:31, 11.75s/it]                                                       {'loss': 2.0443, 'learning_rate': 0.0001549604942589441, 'epoch': 0.75}
 75%|███████▌  | 1787/2382 [5:30:07<1:56:31, 11.75s/it] 75%|███████▌  | 1788/2382 [5:30:17<1:50:13, 11.13s/it]                                                       {'loss': 2.1408, 'learning_rate': 0.00015446867550656767, 'epoch': 0.75}
 75%|███████▌  | 1788/2382 [5:30:17<1:50:13, 11.13s/it] 75%|███████▌  | 1789/2382 [5:30:27<1:47:27, 10.87s/it]                                                       {'loss': 1.897, 'learning_rate': 0.00015397749584584165, 'epoch': 0.75}
 75%|███████▌  | 1789/2382 [5:30:27<1:47:27, 10.87s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1348 > 1024). Running this sequence through the model will result in indexing errors
 75%|███████▌  | 1790/2382 [5:30:40<1:53:26, 11.50s/it]                                                       {'loss': 2.0905, 'learning_rate': 0.00015348695618524756, 'epoch': 0.75}
 75%|███████▌  | 1790/2382 [5:30:40<1:53:26, 11.50s/it] 75%|███████▌  | 1791/2382 [5:30:51<1:51:16, 11.30s/it]                                                       {'loss': 1.9687, 'learning_rate': 0.00015299705743208292, 'epoch': 0.75}
 75%|███████▌  | 1791/2382 [5:30:51<1:51:16, 11.30s/it] 75%|███████▌  | 1792/2382 [5:31:04<1:55:45, 11.77s/it]                                                       {'loss': 1.9517, 'learning_rate': 0.00015250780049246026, 'epoch': 0.75}
 75%|███████▌  | 1792/2382 [5:31:04<1:55:45, 11.77s/it] 75%|███████▌  | 1793/2382 [5:31:14<1:50:08, 11.22s/it]                                                       {'loss': 1.9976, 'learning_rate': 0.0001520191862713049, 'epoch': 0.75}
 75%|███████▌  | 1793/2382 [5:31:14<1:50:08, 11.22s/it] 75%|███████▌  | 1794/2382 [5:31:25<1:50:33, 11.28s/it]                                                       {'loss': 2.0363, 'learning_rate': 0.00015153121567235335, 'epoch': 0.75}
 75%|███████▌  | 1794/2382 [5:31:25<1:50:33, 11.28s/it] 75%|███████▌  | 1795/2382 [5:31:37<1:53:33, 11.61s/it]                                                       {'loss': 2.0499, 'learning_rate': 0.00015104388959815142, 'epoch': 0.75}
 75%|███████▌  | 1795/2382 [5:31:37<1:53:33, 11.61s/it] 75%|███████▌  | 1796/2382 [5:31:50<1:55:37, 11.84s/it]                                                       {'loss': 2.0661, 'learning_rate': 0.00015055720895005342, 'epoch': 0.75}
 75%|███████▌  | 1796/2382 [5:31:50<1:55:37, 11.84s/it] 75%|███████▌  | 1797/2382 [5:32:04<2:01:48, 12.49s/it]                                                       {'loss': 1.9855, 'learning_rate': 0.00015007117462821919, 'epoch': 0.75}
 75%|███████▌  | 1797/2382 [5:32:04<2:01:48, 12.49s/it] 75%|███████▌  | 1798/2382 [5:32:14<1:53:48, 11.69s/it]                                                       {'loss': 2.054, 'learning_rate': 0.0001495857875316136, 'epoch': 0.75}
 75%|███████▌  | 1798/2382 [5:32:14<1:53:48, 11.69s/it] 76%|███████▌  | 1799/2382 [5:32:29<2:04:16, 12.79s/it]                                                       {'loss': 2.0064, 'learning_rate': 0.00014910104855800428, 'epoch': 0.75}
 76%|███████▌  | 1799/2382 [5:32:29<2:04:16, 12.79s/it] 76%|███████▌  | 1800/2382 [5:32:41<2:00:54, 12.47s/it]                                                       {'loss': 2.0789, 'learning_rate': 0.0001486169586039602, 'epoch': 0.76}
 76%|███████▌  | 1800/2382 [5:32:41<2:00:54, 12.47s/it] 76%|███████▌  | 1801/2382 [5:32:51<1:55:19, 11.91s/it]                                                       {'loss': 1.997, 'learning_rate': 0.0001481335185648498, 'epoch': 0.76}
 76%|███████▌  | 1801/2382 [5:32:51<1:55:19, 11.91s/it] 76%|███████▌  | 1802/2382 [5:33:01<1:47:31, 11.12s/it]                                                       {'loss': 2.0125, 'learning_rate': 0.00014765072933483947, 'epoch': 0.76}
 76%|███████▌  | 1802/2382 [5:33:01<1:47:31, 11.12s/it] 76%|███████▌  | 1803/2382 [5:33:10<1:42:04, 10.58s/it]                                                       {'loss': 2.0476, 'learning_rate': 0.00014716859180689162, 'epoch': 0.76}
 76%|███████▌  | 1803/2382 [5:33:10<1:42:04, 10.58s/it] 76%|███████▌  | 1804/2382 [5:33:21<1:44:29, 10.85s/it]                                                       {'loss': 1.9963, 'learning_rate': 0.00014668710687276365, 'epoch': 0.76}
 76%|███████▌  | 1804/2382 [5:33:21<1:44:29, 10.85s/it] 76%|███████▌  | 1805/2382 [5:33:35<1:50:44, 11.52s/it]                                                       {'loss': 1.9549, 'learning_rate': 0.00014620627542300584, 'epoch': 0.76}
 76%|███████▌  | 1805/2382 [5:33:35<1:50:44, 11.52s/it] 76%|███████▌  | 1806/2382 [5:33:48<1:57:13, 12.21s/it]                                                       {'loss': 1.9435, 'learning_rate': 0.00014572609834695972, 'epoch': 0.76}
 76%|███████▌  | 1806/2382 [5:33:48<1:57:13, 12.21s/it] 76%|███████▌  | 1807/2382 [5:34:00<1:56:28, 12.15s/it]                                                       {'loss': 1.9327, 'learning_rate': 0.00014524657653275654, 'epoch': 0.76}
 76%|███████▌  | 1807/2382 [5:34:00<1:56:28, 12.15s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1393 > 1024). Running this sequence through the model will result in indexing errors
 76%|███████▌  | 1808/2382 [5:34:12<1:54:35, 11.98s/it]                                                       {'loss': 1.9855, 'learning_rate': 0.00014476771086731566, 'epoch': 0.76}
 76%|███████▌  | 1808/2382 [5:34:12<1:54:35, 11.98s/it] 76%|███████▌  | 1809/2382 [5:34:21<1:46:59, 11.20s/it]                                                       {'loss': 2.143, 'learning_rate': 0.00014428950223634263, 'epoch': 0.76}
 76%|███████▌  | 1809/2382 [5:34:21<1:46:59, 11.20s/it] 76%|███████▌  | 1810/2382 [5:34:32<1:44:50, 11.00s/it]                                                       {'loss': 2.1085, 'learning_rate': 0.00014381195152432768, 'epoch': 0.76}
 76%|███████▌  | 1810/2382 [5:34:32<1:44:50, 11.00s/it] 76%|███████▌  | 1811/2382 [5:34:41<1:40:27, 10.56s/it]                                                       {'loss': 2.0461, 'learning_rate': 0.00014333505961454452, 'epoch': 0.76}
 76%|███████▌  | 1811/2382 [5:34:41<1:40:27, 10.56s/it] 76%|███████▌  | 1812/2382 [5:34:51<1:38:17, 10.35s/it]                                                       {'loss': 2.028, 'learning_rate': 0.00014285882738904822, 'epoch': 0.76}
 76%|███████▌  | 1812/2382 [5:34:51<1:38:17, 10.35s/it] 76%|███████▌  | 1813/2382 [5:35:03<1:42:40, 10.83s/it]                                                       {'loss': 2.028, 'learning_rate': 0.0001423832557286735, 'epoch': 0.76}
 76%|███████▌  | 1813/2382 [5:35:03<1:42:40, 10.83s/it] 76%|███████▌  | 1814/2382 [5:35:15<1:44:20, 11.02s/it]                                                       {'loss': 2.0097, 'learning_rate': 0.0001419083455130337, 'epoch': 0.76}
 76%|███████▌  | 1814/2382 [5:35:15<1:44:20, 11.02s/it] 76%|███████▌  | 1815/2382 [5:35:25<1:42:10, 10.81s/it]                                                       {'loss': 2.0397, 'learning_rate': 0.0001414340976205183, 'epoch': 0.76}
 76%|███████▌  | 1815/2382 [5:35:25<1:42:10, 10.81s/it] 76%|███████▌  | 1816/2382 [5:35:36<1:42:00, 10.81s/it]                                                       {'loss': 2.0682, 'learning_rate': 0.00014096051292829205, 'epoch': 0.76}
 76%|███████▌  | 1816/2382 [5:35:36<1:42:00, 10.81s/it] 76%|███████▋  | 1817/2382 [5:35:46<1:39:36, 10.58s/it]                                                       {'loss': 1.9567, 'learning_rate': 0.0001404875923122928, 'epoch': 0.76}
 76%|███████▋  | 1817/2382 [5:35:46<1:39:36, 10.58s/it] 76%|███████▋  | 1818/2382 [5:35:56<1:37:14, 10.34s/it]                                                       {'loss': 1.9535, 'learning_rate': 0.00014001533664723047, 'epoch': 0.76}
 76%|███████▋  | 1818/2382 [5:35:56<1:37:14, 10.34s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1103 > 1024). Running this sequence through the model will result in indexing errors
 76%|███████▋  | 1819/2382 [5:36:07<1:39:07, 10.56s/it]                                                       {'loss': 1.9858, 'learning_rate': 0.00013954374680658484, 'epoch': 0.76}
 76%|███████▋  | 1819/2382 [5:36:07<1:39:07, 10.56s/it] 76%|███████▋  | 1820/2382 [5:36:17<1:38:20, 10.50s/it]                                                       {'loss': 2.0034, 'learning_rate': 0.0001390728236626045, 'epoch': 0.76}
 76%|███████▋  | 1820/2382 [5:36:17<1:38:20, 10.50s/it] 76%|███████▋  | 1821/2382 [5:36:27<1:35:53, 10.26s/it]                                                       {'loss': 2.0837, 'learning_rate': 0.00013860256808630427, 'epoch': 0.76}
 76%|███████▋  | 1821/2382 [5:36:27<1:35:53, 10.26s/it] 76%|███████▋  | 1822/2382 [5:36:37<1:36:41, 10.36s/it]                                                       {'loss': 2.1078, 'learning_rate': 0.0001381329809474649, 'epoch': 0.76}
 76%|███████▋  | 1822/2382 [5:36:37<1:36:41, 10.36s/it] 77%|███████▋  | 1823/2382 [5:36:49<1:39:02, 10.63s/it]                                                       {'loss': 1.9231, 'learning_rate': 0.0001376640631146307, 'epoch': 0.77}
 77%|███████▋  | 1823/2382 [5:36:49<1:39:02, 10.63s/it] 77%|███████▋  | 1824/2382 [5:37:05<1:54:58, 12.36s/it]                                                       {'loss': 2.0001, 'learning_rate': 0.00013719581545510763, 'epoch': 0.77}
 77%|███████▋  | 1824/2382 [5:37:05<1:54:58, 12.36s/it] 77%|███████▋  | 1825/2382 [5:37:22<2:08:32, 13.85s/it]                                                       {'loss': 1.9625, 'learning_rate': 0.00013672823883496244, 'epoch': 0.77}
 77%|███████▋  | 1825/2382 [5:37:22<2:08:32, 13.85s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1133 > 1024). Running this sequence through the model will result in indexing errors
 77%|███████▋  | 1826/2382 [5:37:35<2:03:48, 13.36s/it]                                                       {'loss': 2.0058, 'learning_rate': 0.00013626133411902093, 'epoch': 0.77}
 77%|███████▋  | 1826/2382 [5:37:35<2:03:48, 13.36s/it] 77%|███████▋  | 1827/2382 [5:37:46<1:59:34, 12.93s/it]                                                       {'loss': 2.1204, 'learning_rate': 0.0001357951021708655, 'epoch': 0.77}
 77%|███████▋  | 1827/2382 [5:37:46<1:59:34, 12.93s/it] 77%|███████▋  | 1828/2382 [5:37:57<1:51:59, 12.13s/it]                                                       {'loss': 1.9622, 'learning_rate': 0.00013532954385283481, 'epoch': 0.77}
 77%|███████▋  | 1828/2382 [5:37:57<1:51:59, 12.13s/it] 77%|███████▋  | 1829/2382 [5:38:08<1:49:41, 11.90s/it]                                                       {'loss': 2.0754, 'learning_rate': 0.00013486466002602133, 'epoch': 0.77}
 77%|███████▋  | 1829/2382 [5:38:08<1:49:41, 11.90s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1097 > 1024). Running this sequence through the model will result in indexing errors
 77%|███████▋  | 1830/2382 [5:38:19<1:47:14, 11.66s/it]                                                       {'loss': 2.0332, 'learning_rate': 0.00013440045155027014, 'epoch': 0.77}
 77%|███████▋  | 1830/2382 [5:38:19<1:47:14, 11.66s/it] 77%|███████▋  | 1831/2382 [5:38:28<1:40:04, 10.90s/it]                                                       {'loss': 2.0508, 'learning_rate': 0.00013393691928417688, 'epoch': 0.77}
 77%|███████▋  | 1831/2382 [5:38:28<1:40:04, 10.90s/it] 77%|███████▋  | 1832/2382 [5:38:39<1:38:26, 10.74s/it]                                                       {'loss': 2.1269, 'learning_rate': 0.00013347406408508694, 'epoch': 0.77}
 77%|███████▋  | 1832/2382 [5:38:39<1:38:26, 10.74s/it] 77%|███████▋  | 1833/2382 [5:38:51<1:41:19, 11.07s/it]                                                       {'loss': 2.061, 'learning_rate': 0.00013301188680909287, 'epoch': 0.77}
 77%|███████▋  | 1833/2382 [5:38:51<1:41:19, 11.07s/it] 77%|███████▋  | 1834/2382 [5:39:00<1:37:49, 10.71s/it]                                                       {'loss': 2.0717, 'learning_rate': 0.00013255038831103382, 'epoch': 0.77}
 77%|███████▋  | 1834/2382 [5:39:00<1:37:49, 10.71s/it] 77%|███████▋  | 1835/2382 [5:39:12<1:39:48, 10.95s/it]                                                       {'loss': 2.0285, 'learning_rate': 0.0001320895694444932, 'epoch': 0.77}
 77%|███████▋  | 1835/2382 [5:39:12<1:39:48, 10.95s/it] 77%|███████▋  | 1836/2382 [5:39:24<1:43:10, 11.34s/it]                                                       {'loss': 1.9102, 'learning_rate': 0.00013162943106179747, 'epoch': 0.77}
 77%|███████▋  | 1836/2382 [5:39:24<1:43:10, 11.34s/it] 77%|███████▋  | 1837/2382 [5:39:34<1:39:07, 10.91s/it]                                                       {'loss': 1.9958, 'learning_rate': 0.0001311699740140146, 'epoch': 0.77}
 77%|███████▋  | 1837/2382 [5:39:34<1:39:07, 10.91s/it] 77%|███████▋  | 1838/2382 [5:39:44<1:34:54, 10.47s/it]                                                       {'loss': 2.0609, 'learning_rate': 0.00013071119915095226, 'epoch': 0.77}
 77%|███████▋  | 1838/2382 [5:39:44<1:34:54, 10.47s/it] 77%|███████▋  | 1839/2382 [5:39:53<1:31:39, 10.13s/it]                                                       {'loss': 2.0769, 'learning_rate': 0.00013025310732115618, 'epoch': 0.77}
 77%|███████▋  | 1839/2382 [5:39:53<1:31:39, 10.13s/it] 77%|███████▋  | 1840/2382 [5:40:03<1:32:45, 10.27s/it]                                                       {'loss': 1.9696, 'learning_rate': 0.00012979569937190887, 'epoch': 0.77}
 77%|███████▋  | 1840/2382 [5:40:03<1:32:45, 10.27s/it] 77%|███████▋  | 1841/2382 [5:40:13<1:31:46, 10.18s/it]                                                       {'loss': 1.984, 'learning_rate': 0.00012933897614922813, 'epoch': 0.77}
 77%|███████▋  | 1841/2382 [5:40:13<1:31:46, 10.18s/it] 77%|███████▋  | 1842/2382 [5:40:25<1:34:40, 10.52s/it]                                                       {'loss': 1.9627, 'learning_rate': 0.00012888293849786504, 'epoch': 0.77}
 77%|███████▋  | 1842/2382 [5:40:25<1:34:40, 10.52s/it] 77%|███████▋  | 1843/2382 [5:40:36<1:35:17, 10.61s/it]                                                       {'loss': 2.2001, 'learning_rate': 0.00012842758726130281, 'epoch': 0.77}
 77%|███████▋  | 1843/2382 [5:40:36<1:35:17, 10.61s/it] 77%|███████▋  | 1844/2382 [5:40:47<1:38:09, 10.95s/it]                                                       {'loss': 2.0551, 'learning_rate': 0.00012797292328175524, 'epoch': 0.77}
 77%|███████▋  | 1844/2382 [5:40:47<1:38:09, 10.95s/it] 77%|███████▋  | 1845/2382 [5:40:57<1:36:01, 10.73s/it]                                                       {'loss': 2.0633, 'learning_rate': 0.00012751894740016434, 'epoch': 0.77}
 77%|███████▋  | 1845/2382 [5:40:57<1:36:01, 10.73s/it] 77%|███████▋  | 1846/2382 [5:41:13<1:48:44, 12.17s/it]                                                       {'loss': 1.9986, 'learning_rate': 0.00012706566045620027, 'epoch': 0.77}
 77%|███████▋  | 1846/2382 [5:41:13<1:48:44, 12.17s/it] 78%|███████▊  | 1847/2382 [5:41:26<1:50:01, 12.34s/it]                                                       {'loss': 2.0261, 'learning_rate': 0.00012661306328825818, 'epoch': 0.78}
 78%|███████▊  | 1847/2382 [5:41:26<1:50:01, 12.34s/it] 78%|███████▊  | 1848/2382 [5:41:37<1:46:36, 11.98s/it]                                                       {'loss': 1.983, 'learning_rate': 0.00012616115673345785, 'epoch': 0.78}
 78%|███████▊  | 1848/2382 [5:41:37<1:46:36, 11.98s/it] 78%|███████▊  | 1849/2382 [5:41:48<1:43:13, 11.62s/it]                                                       {'loss': 2.1424, 'learning_rate': 0.0001257099416276416, 'epoch': 0.78}
 78%|███████▊  | 1849/2382 [5:41:48<1:43:13, 11.62s/it] 78%|███████▊  | 1850/2382 [5:41:56<1:35:22, 10.76s/it]                                                       {'loss': 1.9878, 'learning_rate': 0.00012525941880537307, 'epoch': 0.78}
 78%|███████▊  | 1850/2382 [5:41:56<1:35:22, 10.76s/it] 78%|███████▊  | 1851/2382 [5:42:08<1:37:56, 11.07s/it]                                                       {'loss': 1.9899, 'learning_rate': 0.0001248095890999349, 'epoch': 0.78}
 78%|███████▊  | 1851/2382 [5:42:08<1:37:56, 11.07s/it] 78%|███████▊  | 1852/2382 [5:42:19<1:36:23, 10.91s/it]                                                       {'loss': 2.0385, 'learning_rate': 0.00012436045334332825, 'epoch': 0.78}
 78%|███████▊  | 1852/2382 [5:42:19<1:36:23, 10.91s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1135 > 1024). Running this sequence through the model will result in indexing errors
 78%|███████▊  | 1853/2382 [5:42:31<1:38:30, 11.17s/it]                                                       {'loss': 2.1053, 'learning_rate': 0.00012391201236627074, 'epoch': 0.78}
 78%|███████▊  | 1853/2382 [5:42:31<1:38:30, 11.17s/it] 78%|███████▊  | 1854/2382 [5:42:42<1:38:50, 11.23s/it]                                                       {'loss': 1.902, 'learning_rate': 0.00012346426699819457, 'epoch': 0.78}
 78%|███████▊  | 1854/2382 [5:42:42<1:38:50, 11.23s/it] 78%|███████▊  | 1855/2382 [5:42:53<1:36:57, 11.04s/it]                                                       {'loss': 2.0383, 'learning_rate': 0.00012301721806724564, 'epoch': 0.78}
 78%|███████▊  | 1855/2382 [5:42:53<1:36:57, 11.04s/it] 78%|███████▊  | 1856/2382 [5:43:04<1:39:02, 11.30s/it]                                                       {'loss': 2.1089, 'learning_rate': 0.0001225708664002818, 'epoch': 0.78}
 78%|███████▊  | 1856/2382 [5:43:04<1:39:02, 11.30s/it] 78%|███████▊  | 1857/2382 [5:43:15<1:37:51, 11.18s/it]                                                       {'loss': 2.0647, 'learning_rate': 0.00012212521282287093, 'epoch': 0.78}
 78%|███████▊  | 1857/2382 [5:43:15<1:37:51, 11.18s/it] 78%|███████▊  | 1858/2382 [5:43:26<1:37:03, 11.11s/it]                                                       {'loss': 1.9287, 'learning_rate': 0.0001216802581592899, 'epoch': 0.78}
 78%|███████▊  | 1858/2382 [5:43:26<1:37:03, 11.11s/it] 78%|███████▊  | 1859/2382 [5:43:37<1:36:42, 11.09s/it]                                                       {'loss': 2.0088, 'learning_rate': 0.00012123600323252294, 'epoch': 0.78}
 78%|███████▊  | 1859/2382 [5:43:37<1:36:42, 11.09s/it] 78%|███████▊  | 1860/2382 [5:43:48<1:36:30, 11.09s/it]                                                       {'loss': 2.0977, 'learning_rate': 0.00012079244886426016, 'epoch': 0.78}
 78%|███████▊  | 1860/2382 [5:43:48<1:36:30, 11.09s/it] 78%|███████▊  | 1861/2382 [5:44:01<1:39:12, 11.42s/it]                                                       {'loss': 2.1707, 'learning_rate': 0.00012034959587489542, 'epoch': 0.78}
 78%|███████▊  | 1861/2382 [5:44:01<1:39:12, 11.42s/it] 78%|███████▊  | 1862/2382 [5:44:11<1:36:37, 11.15s/it]                                                       {'loss': 1.9589, 'learning_rate': 0.00011990744508352603, 'epoch': 0.78}
 78%|███████▊  | 1862/2382 [5:44:11<1:36:37, 11.15s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1266 > 1024). Running this sequence through the model will result in indexing errors
 78%|███████▊  | 1863/2382 [5:44:24<1:40:35, 11.63s/it]                                                       {'loss': 2.0182, 'learning_rate': 0.00011946599730794972, 'epoch': 0.78}
 78%|███████▊  | 1863/2382 [5:44:24<1:40:35, 11.63s/it] 78%|███████▊  | 1864/2382 [5:44:34<1:36:15, 11.15s/it]                                                       {'loss': 1.9344, 'learning_rate': 0.00011902525336466464, 'epoch': 0.78}
 78%|███████▊  | 1864/2382 [5:44:34<1:36:15, 11.15s/it] 78%|███████▊  | 1865/2382 [5:44:47<1:40:49, 11.70s/it]                                                       {'loss': 1.9859, 'learning_rate': 0.00011858521406886675, 'epoch': 0.78}
 78%|███████▊  | 1865/2382 [5:44:47<1:40:49, 11.70s/it] 78%|███████▊  | 1866/2382 [5:44:57<1:36:34, 11.23s/it]                                                       {'loss': 2.1804, 'learning_rate': 0.00011814588023444878, 'epoch': 0.78}
 78%|███████▊  | 1866/2382 [5:44:57<1:36:34, 11.23s/it] 78%|███████▊  | 1867/2382 [5:45:09<1:38:21, 11.46s/it]                                                       {'loss': 1.9986, 'learning_rate': 0.0001177072526739989, 'epoch': 0.78}
 78%|███████▊  | 1867/2382 [5:45:09<1:38:21, 11.46s/it] 78%|███████▊  | 1868/2382 [5:45:19<1:35:24, 11.14s/it]                                                       {'loss': 2.0921, 'learning_rate': 0.00011726933219879854, 'epoch': 0.78}
 78%|███████▊  | 1868/2382 [5:45:19<1:35:24, 11.14s/it] 78%|███████▊  | 1869/2382 [5:45:34<1:45:03, 12.29s/it]                                                       {'loss': 1.9844, 'learning_rate': 0.00011683211961882134, 'epoch': 0.78}
 78%|███████▊  | 1869/2382 [5:45:34<1:45:03, 12.29s/it] 79%|███████▊  | 1870/2382 [5:45:46<1:44:09, 12.21s/it]                                                       {'loss': 1.9607, 'learning_rate': 0.000116395615742732, 'epoch': 0.78}
 79%|███████▊  | 1870/2382 [5:45:46<1:44:09, 12.21s/it] 79%|███████▊  | 1871/2382 [5:45:59<1:45:14, 12.36s/it]                                                       {'loss': 2.0814, 'learning_rate': 0.00011595982137788402, 'epoch': 0.79}
 79%|███████▊  | 1871/2382 [5:45:59<1:45:14, 12.36s/it] 79%|███████▊  | 1872/2382 [5:46:11<1:44:06, 12.25s/it]                                                       {'loss': 2.0121, 'learning_rate': 0.00011552473733031893, 'epoch': 0.79}
 79%|███████▊  | 1872/2382 [5:46:11<1:44:06, 12.25s/it] 79%|███████▊  | 1873/2382 [5:46:23<1:42:17, 12.06s/it]                                                       {'loss': 1.9567, 'learning_rate': 0.00011509036440476439, 'epoch': 0.79}
 79%|███████▊  | 1873/2382 [5:46:23<1:42:17, 12.06s/it] 79%|███████▊  | 1874/2382 [5:46:32<1:34:34, 11.17s/it]                                                       {'loss': 2.054, 'learning_rate': 0.00011465670340463241, 'epoch': 0.79}
 79%|███████▊  | 1874/2382 [5:46:32<1:34:34, 11.17s/it] 79%|███████▊  | 1875/2382 [5:46:45<1:38:31, 11.66s/it]                                                       {'loss': 1.9689, 'learning_rate': 0.00011422375513201854, 'epoch': 0.79}
 79%|███████▊  | 1875/2382 [5:46:45<1:38:31, 11.66s/it] 79%|███████▉  | 1876/2382 [5:46:56<1:38:29, 11.68s/it]                                                       {'loss': 2.0523, 'learning_rate': 0.00011379152038770029, 'epoch': 0.79}
 79%|███████▉  | 1876/2382 [5:46:56<1:38:29, 11.68s/it] 79%|███████▉  | 1877/2382 [5:47:05<1:30:40, 10.77s/it]                                                       {'loss': 2.0357, 'learning_rate': 0.00011335999997113489, 'epoch': 0.79}
 79%|███████▉  | 1877/2382 [5:47:05<1:30:40, 10.77s/it] 79%|███████▉  | 1878/2382 [5:47:15<1:27:27, 10.41s/it]                                                       {'loss': 2.1169, 'learning_rate': 0.00011292919468045875, 'epoch': 0.79}
 79%|███████▉  | 1878/2382 [5:47:15<1:27:27, 10.41s/it] 79%|███████▉  | 1879/2382 [5:47:28<1:34:29, 11.27s/it]                                                       {'loss': 1.9688, 'learning_rate': 0.00011249910531248564, 'epoch': 0.79}
 79%|███████▉  | 1879/2382 [5:47:28<1:34:29, 11.27s/it] 79%|███████▉  | 1880/2382 [5:47:39<1:32:53, 11.10s/it]                                                       {'loss': 1.9452, 'learning_rate': 0.00011206973266270476, 'epoch': 0.79}
 79%|███████▉  | 1880/2382 [5:47:39<1:32:53, 11.10s/it] 79%|███████▉  | 1881/2382 [5:47:49<1:30:27, 10.83s/it]                                                       {'loss': 2.0695, 'learning_rate': 0.00011164107752528002, 'epoch': 0.79}
 79%|███████▉  | 1881/2382 [5:47:49<1:30:27, 10.83s/it] 79%|███████▉  | 1882/2382 [5:48:02<1:35:40, 11.48s/it]                                                       {'loss': 1.9988, 'learning_rate': 0.00011121314069304811, 'epoch': 0.79}
 79%|███████▉  | 1882/2382 [5:48:02<1:35:40, 11.48s/it] 79%|███████▉  | 1883/2382 [5:48:14<1:36:12, 11.57s/it]                                                       {'loss': 1.9678, 'learning_rate': 0.00011078592295751738, 'epoch': 0.79}
 79%|███████▉  | 1883/2382 [5:48:14<1:36:12, 11.57s/it] 79%|███████▉  | 1884/2382 [5:48:27<1:41:39, 12.25s/it]                                                       {'loss': 1.9878, 'learning_rate': 0.00011035942510886565, 'epoch': 0.79}
 79%|███████▉  | 1884/2382 [5:48:27<1:41:39, 12.25s/it] 79%|███████▉  | 1885/2382 [5:48:36<1:33:09, 11.25s/it]                                                       {'loss': 2.0434, 'learning_rate': 0.0001099336479359398, 'epoch': 0.79}
 79%|███████▉  | 1885/2382 [5:48:36<1:33:09, 11.25s/it] 79%|███████▉  | 1886/2382 [5:48:45<1:27:52, 10.63s/it]                                                       {'loss': 2.111, 'learning_rate': 0.00010950859222625314, 'epoch': 0.79}
 79%|███████▉  | 1886/2382 [5:48:45<1:27:52, 10.63s/it] 79%|███████▉  | 1887/2382 [5:48:56<1:27:09, 10.56s/it]                                                       {'loss': 2.0715, 'learning_rate': 0.0001090842587659851, 'epoch': 0.79}
 79%|███████▉  | 1887/2382 [5:48:56<1:27:09, 10.56s/it] 79%|███████▉  | 1888/2382 [5:49:07<1:29:34, 10.88s/it]                                                       {'loss': 1.9461, 'learning_rate': 0.00010866064833997914, 'epoch': 0.79}
 79%|███████▉  | 1888/2382 [5:49:07<1:29:34, 10.88s/it] 79%|███████▉  | 1889/2382 [5:49:19<1:32:11, 11.22s/it]                                                       {'loss': 1.9827, 'learning_rate': 0.00010823776173174116, 'epoch': 0.79}
 79%|███████▉  | 1889/2382 [5:49:19<1:32:11, 11.22s/it] 79%|███████▉  | 1890/2382 [5:49:31<1:31:37, 11.17s/it]                                                       {'loss': 2.0066, 'learning_rate': 0.00010781559972343869, 'epoch': 0.79}
 79%|███████▉  | 1890/2382 [5:49:31<1:31:37, 11.17s/it] 79%|███████▉  | 1891/2382 [5:49:40<1:27:26, 10.69s/it]                                                       {'loss': 2.0107, 'learning_rate': 0.00010739416309589867, 'epoch': 0.79}
 79%|███████▉  | 1891/2382 [5:49:40<1:27:26, 10.69s/it] 79%|███████▉  | 1892/2382 [5:49:49<1:23:46, 10.26s/it]                                                       {'loss': 2.0762, 'learning_rate': 0.00010697345262860636, 'epoch': 0.79}
 79%|███████▉  | 1892/2382 [5:49:49<1:23:46, 10.26s/it] 79%|███████▉  | 1893/2382 [5:50:01<1:26:05, 10.56s/it]                                                       {'loss': 2.0028, 'learning_rate': 0.0001065534690997042, 'epoch': 0.79}
 79%|███████▉  | 1893/2382 [5:50:01<1:26:05, 10.56s/it] 80%|███████▉  | 1894/2382 [5:50:11<1:25:56, 10.57s/it]                                                       {'loss': 1.9831, 'learning_rate': 0.00010613421328599005, 'epoch': 0.79}
 80%|███████▉  | 1894/2382 [5:50:11<1:25:56, 10.57s/it] 80%|███████▉  | 1895/2382 [5:50:22<1:26:26, 10.65s/it]                                                       {'loss': 1.9954, 'learning_rate': 0.00010571568596291559, 'epoch': 0.8}
 80%|███████▉  | 1895/2382 [5:50:22<1:26:26, 10.65s/it] 80%|███████▉  | 1896/2382 [5:50:33<1:26:36, 10.69s/it]                                                       {'loss': 2.0888, 'learning_rate': 0.00010529788790458534, 'epoch': 0.8}
 80%|███████▉  | 1896/2382 [5:50:33<1:26:36, 10.69s/it] 80%|███████▉  | 1897/2382 [5:50:43<1:25:42, 10.60s/it]                                                       {'loss': 1.95, 'learning_rate': 0.00010488081988375492, 'epoch': 0.8}
 80%|███████▉  | 1897/2382 [5:50:43<1:25:42, 10.60s/it] 80%|███████▉  | 1898/2382 [5:50:56<1:29:48, 11.13s/it]                                                       {'loss': 2.0079, 'learning_rate': 0.00010446448267182951, 'epoch': 0.8}
 80%|███████▉  | 1898/2382 [5:50:56<1:29:48, 11.13s/it] 80%|███████▉  | 1899/2382 [5:51:07<1:29:49, 11.16s/it]                                                       {'loss': 1.9112, 'learning_rate': 0.0001040488770388625, 'epoch': 0.8}
 80%|███████▉  | 1899/2382 [5:51:07<1:29:49, 11.16s/it] 80%|███████▉  | 1900/2382 [5:51:18<1:29:33, 11.15s/it]                                                       {'loss': 1.9884, 'learning_rate': 0.00010363400375355464, 'epoch': 0.8}
 80%|███████▉  | 1900/2382 [5:51:18<1:29:33, 11.15s/it] 80%|███████▉  | 1901/2382 [5:51:32<1:35:54, 11.96s/it]                                                       {'loss': 2.0366, 'learning_rate': 0.00010321986358325169, 'epoch': 0.8}
 80%|███████▉  | 1901/2382 [5:51:32<1:35:54, 11.96s/it] 80%|███████▉  | 1902/2382 [5:51:42<1:30:50, 11.35s/it]                                                       {'loss': 1.9728, 'learning_rate': 0.00010280645729394367, 'epoch': 0.8}
 80%|███████▉  | 1902/2382 [5:51:42<1:30:50, 11.35s/it] 80%|███████▉  | 1903/2382 [5:51:58<1:41:42, 12.74s/it]                                                       {'loss': 2.064, 'learning_rate': 0.0001023937856502633, 'epoch': 0.8}
 80%|███████▉  | 1903/2382 [5:51:58<1:41:42, 12.74s/it] 80%|███████▉  | 1904/2382 [5:52:09<1:37:09, 12.20s/it]                                                       {'loss': 1.9266, 'learning_rate': 0.00010198184941548405, 'epoch': 0.8}
 80%|███████▉  | 1904/2382 [5:52:09<1:37:09, 12.20s/it] 80%|███████▉  | 1905/2382 [5:52:20<1:34:22, 11.87s/it]                                                       {'loss': 2.089, 'learning_rate': 0.00010157064935151988, 'epoch': 0.8}
 80%|███████▉  | 1905/2382 [5:52:20<1:34:22, 11.87s/it] 80%|████████  | 1906/2382 [5:52:31<1:32:07, 11.61s/it]                                                       {'loss': 1.9492, 'learning_rate': 0.00010116018621892236, 'epoch': 0.8}
 80%|████████  | 1906/2382 [5:52:31<1:32:07, 11.61s/it] 80%|████████  | 1907/2382 [5:52:40<1:27:09, 11.01s/it]                                                       {'loss': 2.1605, 'learning_rate': 0.00010075046077688066, 'epoch': 0.8}
 80%|████████  | 1907/2382 [5:52:40<1:27:09, 11.01s/it] 80%|████████  | 1908/2382 [5:52:51<1:26:29, 10.95s/it]                                                       {'loss': 2.0092, 'learning_rate': 0.00010034147378321923, 'epoch': 0.8}
 80%|████████  | 1908/2382 [5:52:51<1:26:29, 10.95s/it] 80%|████████  | 1909/2382 [5:53:01<1:23:29, 10.59s/it]                                                       {'loss': 2.0941, 'learning_rate': 9.993322599439691e-05, 'epoch': 0.8}
 80%|████████  | 1909/2382 [5:53:01<1:23:29, 10.59s/it] 80%|████████  | 1910/2382 [5:53:11<1:22:32, 10.49s/it]                                                       {'loss': 2.0256, 'learning_rate': 9.952571816550494e-05, 'epoch': 0.8}
 80%|████████  | 1910/2382 [5:53:11<1:22:32, 10.49s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1237 > 1024). Running this sequence through the model will result in indexing errors
 80%|████████  | 1911/2382 [5:53:21<1:20:30, 10.25s/it]                                                       {'loss': 1.9602, 'learning_rate': 9.911895105026625e-05, 'epoch': 0.8}
 80%|████████  | 1911/2382 [5:53:21<1:20:30, 10.25s/it] 80%|████████  | 1912/2382 [5:53:34<1:27:09, 11.13s/it]                                                       {'loss': 1.9214, 'learning_rate': 9.871292540103377e-05, 'epoch': 0.8}
 80%|████████  | 1912/2382 [5:53:34<1:27:09, 11.13s/it] 80%|████████  | 1913/2382 [5:53:44<1:23:48, 10.72s/it]                                                       {'loss': 1.9156, 'learning_rate': 9.830764196878872e-05, 'epoch': 0.8}
 80%|████████  | 1913/2382 [5:53:44<1:23:48, 10.72s/it] 80%|████████  | 1914/2382 [5:53:53<1:20:42, 10.35s/it]                                                       {'loss': 1.9605, 'learning_rate': 9.790310150313974e-05, 'epoch': 0.8}
 80%|████████  | 1914/2382 [5:53:53<1:20:42, 10.35s/it] 80%|████████  | 1915/2382 [5:54:04<1:21:29, 10.47s/it]                                                       {'loss': 1.9497, 'learning_rate': 9.749930475232155e-05, 'epoch': 0.8}
 80%|████████  | 1915/2382 [5:54:04<1:21:29, 10.47s/it] 80%|████████  | 1916/2382 [5:54:16<1:24:51, 10.93s/it]                                                       {'loss': 1.9133, 'learning_rate': 9.70962524631926e-05, 'epoch': 0.8}
 80%|████████  | 1916/2382 [5:54:16<1:24:51, 10.93s/it] 80%|████████  | 1917/2382 [5:54:28<1:27:23, 11.28s/it]                                                       {'loss': 1.9692, 'learning_rate': 9.6693945381235e-05, 'epoch': 0.8}
 80%|████████  | 1917/2382 [5:54:28<1:27:23, 11.28s/it] 81%|████████  | 1918/2382 [5:54:39<1:26:51, 11.23s/it]                                                       {'loss': 1.9671, 'learning_rate': 9.629238425055231e-05, 'epoch': 0.8}
 81%|████████  | 1918/2382 [5:54:39<1:26:51, 11.23s/it] 81%|████████  | 1919/2382 [5:54:50<1:25:56, 11.14s/it]                                                       {'loss': 1.9675, 'learning_rate': 9.58915698138686e-05, 'epoch': 0.81}
 81%|████████  | 1919/2382 [5:54:50<1:25:56, 11.14s/it] 81%|████████  | 1920/2382 [5:55:03<1:29:25, 11.61s/it]                                                       {'loss': 2.0513, 'learning_rate': 9.549150281252633e-05, 'epoch': 0.81}
 81%|████████  | 1920/2382 [5:55:03<1:29:25, 11.61s/it] 81%|████████  | 1921/2382 [5:55:15<1:29:11, 11.61s/it]                                                       {'loss': 2.044, 'learning_rate': 9.509218398648617e-05, 'epoch': 0.81}
 81%|████████  | 1921/2382 [5:55:15<1:29:11, 11.61s/it] 81%|████████  | 1922/2382 [5:55:25<1:25:27, 11.15s/it]                                                       {'loss': 2.0675, 'learning_rate': 9.46936140743243e-05, 'epoch': 0.81}
 81%|████████  | 1922/2382 [5:55:25<1:25:27, 11.15s/it] 81%|████████  | 1923/2382 [5:55:38<1:31:09, 11.92s/it]                                                       {'loss': 2.1455, 'learning_rate': 9.429579381323233e-05, 'epoch': 0.81}
 81%|████████  | 1923/2382 [5:55:38<1:31:09, 11.92s/it] 81%|████████  | 1924/2382 [5:55:51<1:31:47, 12.03s/it]                                                       {'loss': 2.0361, 'learning_rate': 9.389872393901499e-05, 'epoch': 0.81}
 81%|████████  | 1924/2382 [5:55:51<1:31:47, 12.03s/it] 81%|████████  | 1925/2382 [5:56:06<1:39:46, 13.10s/it]                                                       {'loss': 1.9431, 'learning_rate': 9.350240518608922e-05, 'epoch': 0.81}
 81%|████████  | 1925/2382 [5:56:06<1:39:46, 13.10s/it] 81%|████████  | 1926/2382 [5:56:17<1:34:44, 12.47s/it]                                                       {'loss': 1.9022, 'learning_rate': 9.31068382874825e-05, 'epoch': 0.81}
 81%|████████  | 1926/2382 [5:56:17<1:34:44, 12.47s/it] 81%|████████  | 1927/2382 [5:56:30<1:36:15, 12.69s/it]                                                       {'loss': 1.925, 'learning_rate': 9.271202397483213e-05, 'epoch': 0.81}
 81%|████████  | 1927/2382 [5:56:30<1:36:15, 12.69s/it] 81%|████████  | 1928/2382 [5:56:41<1:32:14, 12.19s/it]                                                       {'loss': 2.0888, 'learning_rate': 9.231796297838297e-05, 'epoch': 0.81}
 81%|████████  | 1928/2382 [5:56:41<1:32:14, 12.19s/it] 81%|████████  | 1929/2382 [5:56:52<1:28:46, 11.76s/it]                                                       {'loss': 2.1263, 'learning_rate': 9.192465602698651e-05, 'epoch': 0.81}
 81%|████████  | 1929/2382 [5:56:52<1:28:46, 11.76s/it] 81%|████████  | 1930/2382 [5:57:04<1:28:26, 11.74s/it]                                                       {'loss': 2.1117, 'learning_rate': 9.153210384809995e-05, 'epoch': 0.81}
 81%|████████  | 1930/2382 [5:57:04<1:28:26, 11.74s/it] 81%|████████  | 1931/2382 [5:57:14<1:25:40, 11.40s/it]                                                       {'loss': 1.9274, 'learning_rate': 9.114030716778432e-05, 'epoch': 0.81}
 81%|████████  | 1931/2382 [5:57:14<1:25:40, 11.40s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1343 > 1024). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (1070 > 1024). Running this sequence through the model will result in indexing errors
 81%|████████  | 1932/2382 [5:57:26<1:24:41, 11.29s/it]                                                       {'loss': 1.9531, 'learning_rate': 9.074926671070321e-05, 'epoch': 0.81}
 81%|████████  | 1932/2382 [5:57:26<1:24:41, 11.29s/it] 81%|████████  | 1933/2382 [5:57:36<1:23:12, 11.12s/it]                                                       {'loss': 2.0124, 'learning_rate': 9.03589832001217e-05, 'epoch': 0.81}
 81%|████████  | 1933/2382 [5:57:36<1:23:12, 11.12s/it] 81%|████████  | 1934/2382 [5:57:46<1:20:50, 10.83s/it]                                                       {'loss': 2.0816, 'learning_rate': 8.996945735790446e-05, 'epoch': 0.81}
 81%|████████  | 1934/2382 [5:57:46<1:20:50, 10.83s/it] 81%|████████  | 1935/2382 [5:57:57<1:19:55, 10.73s/it]                                                       {'loss': 1.9376, 'learning_rate': 8.958068990451524e-05, 'epoch': 0.81}
 81%|████████  | 1935/2382 [5:57:57<1:19:55, 10.73s/it] 81%|████████▏ | 1936/2382 [5:58:07<1:18:31, 10.56s/it]                                                       {'loss': 1.9697, 'learning_rate': 8.919268155901456e-05, 'epoch': 0.81}
 81%|████████▏ | 1936/2382 [5:58:07<1:18:31, 10.56s/it] 81%|████████▏ | 1937/2382 [5:58:17<1:17:44, 10.48s/it]                                                       {'loss': 2.0541, 'learning_rate': 8.88054330390593e-05, 'epoch': 0.81}
 81%|████████▏ | 1937/2382 [5:58:17<1:17:44, 10.48s/it] 81%|████████▏ | 1938/2382 [5:58:26<1:13:55,  9.99s/it]                                                       {'loss': 2.0762, 'learning_rate': 8.841894506090098e-05, 'epoch': 0.81}
 81%|████████▏ | 1938/2382 [5:58:26<1:13:55,  9.99s/it] 81%|████████▏ | 1939/2382 [5:58:39<1:20:40, 10.93s/it]                                                       {'loss': 2.0265, 'learning_rate': 8.803321833938432e-05, 'epoch': 0.81}
 81%|████████▏ | 1939/2382 [5:58:39<1:20:40, 10.93s/it] 81%|████████▏ | 1940/2382 [5:58:50<1:20:47, 10.97s/it]                                                       {'loss': 2.0146, 'learning_rate': 8.764825358794587e-05, 'epoch': 0.81}
 81%|████████▏ | 1940/2382 [5:58:50<1:20:47, 10.97s/it] 81%|████████▏ | 1941/2382 [5:59:02<1:22:03, 11.16s/it]                                                       {'loss': 2.0462, 'learning_rate': 8.7264051518613e-05, 'epoch': 0.81}
 81%|████████▏ | 1941/2382 [5:59:02<1:22:03, 11.16s/it] 82%|████████▏ | 1942/2382 [5:59:13<1:22:03, 11.19s/it]                                                       {'loss': 2.0961, 'learning_rate': 8.688061284200266e-05, 'epoch': 0.81}
 82%|████████▏ | 1942/2382 [5:59:13<1:22:03, 11.19s/it] 82%|████████▏ | 1943/2382 [5:59:24<1:21:51, 11.19s/it]                                                       {'loss': 2.0805, 'learning_rate': 8.649793826731922e-05, 'epoch': 0.82}
 82%|████████▏ | 1943/2382 [5:59:24<1:21:51, 11.19s/it] 82%|████████▏ | 1944/2382 [5:59:34<1:17:10, 10.57s/it]                                                       {'loss': 1.9707, 'learning_rate': 8.611602850235445e-05, 'epoch': 0.82}
 82%|████████▏ | 1944/2382 [5:59:34<1:17:10, 10.57s/it] 82%|████████▏ | 1945/2382 [5:59:45<1:19:29, 10.91s/it]                                                       {'loss': 1.9923, 'learning_rate': 8.573488425348519e-05, 'epoch': 0.82}
 82%|████████▏ | 1945/2382 [5:59:45<1:19:29, 10.91s/it] 82%|████████▏ | 1946/2382 [5:59:55<1:17:42, 10.69s/it]                                                       {'loss': 1.969, 'learning_rate': 8.535450622567231e-05, 'epoch': 0.82}
 82%|████████▏ | 1946/2382 [5:59:55<1:17:42, 10.69s/it] 82%|████████▏ | 1947/2382 [6:00:05<1:15:23, 10.40s/it]                                                       {'loss': 2.0266, 'learning_rate': 8.49748951224597e-05, 'epoch': 0.82}
 82%|████████▏ | 1947/2382 [6:00:05<1:15:23, 10.40s/it] 82%|████████▏ | 1948/2382 [6:00:18<1:21:10, 11.22s/it]                                                       {'loss': 2.0123, 'learning_rate': 8.459605164597267e-05, 'epoch': 0.82}
 82%|████████▏ | 1948/2382 [6:00:18<1:21:10, 11.22s/it] 82%|████████▏ | 1949/2382 [6:00:27<1:15:29, 10.46s/it]                                                       {'loss': 1.9637, 'learning_rate': 8.421797649691681e-05, 'epoch': 0.82}
 82%|████████▏ | 1949/2382 [6:00:27<1:15:29, 10.46s/it] 82%|████████▏ | 1950/2382 [6:00:36<1:12:48, 10.11s/it]                                                       {'loss': 2.0464, 'learning_rate': 8.384067037457638e-05, 'epoch': 0.82}
 82%|████████▏ | 1950/2382 [6:00:36<1:12:48, 10.11s/it] 82%|████████▏ | 1951/2382 [6:00:47<1:14:01, 10.31s/it]                                                       {'loss': 2.0847, 'learning_rate': 8.346413397681352e-05, 'epoch': 0.82}
 82%|████████▏ | 1951/2382 [6:00:47<1:14:01, 10.31s/it] 82%|████████▏ | 1952/2382 [6:00:58<1:16:09, 10.63s/it]                                                       {'loss': 2.0467, 'learning_rate': 8.308836800006647e-05, 'epoch': 0.82}
 82%|████████▏ | 1952/2382 [6:00:58<1:16:09, 10.63s/it] 82%|████████▏ | 1953/2382 [6:01:11<1:21:03, 11.34s/it]                                                       {'loss': 1.9775, 'learning_rate': 8.271337313934868e-05, 'epoch': 0.82}
 82%|████████▏ | 1953/2382 [6:01:11<1:21:03, 11.34s/it] 82%|████████▏ | 1954/2382 [6:01:23<1:21:25, 11.41s/it]                                                       {'loss': 1.9585, 'learning_rate': 8.233915008824733e-05, 'epoch': 0.82}
 82%|████████▏ | 1954/2382 [6:01:23<1:21:25, 11.41s/it] 82%|████████▏ | 1955/2382 [6:01:32<1:15:40, 10.63s/it]                                                       {'loss': 2.0783, 'learning_rate': 8.196569953892202e-05, 'epoch': 0.82}
 82%|████████▏ | 1955/2382 [6:01:32<1:15:40, 10.63s/it] 82%|████████▏ | 1956/2382 [6:01:43<1:15:51, 10.68s/it]                                                       {'loss': 2.1308, 'learning_rate': 8.159302218210368e-05, 'epoch': 0.82}
 82%|████████▏ | 1956/2382 [6:01:43<1:15:51, 10.68s/it] 82%|████████▏ | 1957/2382 [6:01:53<1:14:23, 10.50s/it]                                                       {'loss': 2.0475, 'learning_rate': 8.122111870709286e-05, 'epoch': 0.82}
 82%|████████▏ | 1957/2382 [6:01:53<1:14:23, 10.50s/it] 82%|████████▏ | 1958/2382 [6:02:06<1:19:28, 11.25s/it]                                                       {'loss': 1.9251, 'learning_rate': 8.084998980175878e-05, 'epoch': 0.82}
 82%|████████▏ | 1958/2382 [6:02:06<1:19:28, 11.25s/it] 82%|████████▏ | 1959/2382 [6:02:16<1:18:11, 11.09s/it]                                                       {'loss': 2.083, 'learning_rate': 8.047963615253833e-05, 'epoch': 0.82}
 82%|████████▏ | 1959/2382 [6:02:16<1:18:11, 11.09s/it] 82%|████████▏ | 1960/2382 [6:02:25<1:13:30, 10.45s/it]                                                       {'loss': 2.0202, 'learning_rate': 8.011005844443425e-05, 'epoch': 0.82}
 82%|████████▏ | 1960/2382 [6:02:25<1:13:30, 10.45s/it] 82%|████████▏ | 1961/2382 [6:02:37<1:16:15, 10.87s/it]                                                       {'loss': 1.996, 'learning_rate': 7.974125736101418e-05, 'epoch': 0.82}
 82%|████████▏ | 1961/2382 [6:02:37<1:16:15, 10.87s/it] 82%|████████▏ | 1962/2382 [6:02:48<1:15:00, 10.72s/it]                                                       {'loss': 2.0574, 'learning_rate': 7.937323358440934e-05, 'epoch': 0.82}
 82%|████████▏ | 1962/2382 [6:02:48<1:15:00, 10.72s/it] 82%|████████▏ | 1963/2382 [6:03:00<1:18:11, 11.20s/it]                                                       {'loss': 2.046, 'learning_rate': 7.900598779531331e-05, 'epoch': 0.82}
 82%|████████▏ | 1963/2382 [6:03:00<1:18:11, 11.20s/it] 82%|████████▏ | 1964/2382 [6:03:11<1:17:07, 11.07s/it]                                                       {'loss': 1.9596, 'learning_rate': 7.863952067298042e-05, 'epoch': 0.82}
 82%|████████▏ | 1964/2382 [6:03:11<1:17:07, 11.07s/it] 82%|████████▏ | 1965/2382 [6:03:19<1:12:13, 10.39s/it]                                                       {'loss': 2.0485, 'learning_rate': 7.827383289522516e-05, 'epoch': 0.82}
 82%|████████▏ | 1965/2382 [6:03:19<1:12:13, 10.39s/it] 83%|████████▎ | 1966/2382 [6:03:32<1:17:16, 11.15s/it]                                                       {'loss': 1.9269, 'learning_rate': 7.790892513842019e-05, 'epoch': 0.83}
 83%|████████▎ | 1966/2382 [6:03:32<1:17:16, 11.15s/it] 83%|████████▎ | 1967/2382 [6:03:43<1:15:15, 10.88s/it]                                                       {'loss': 2.08, 'learning_rate': 7.75447980774957e-05, 'epoch': 0.83}
 83%|████████▎ | 1967/2382 [6:03:43<1:15:15, 10.88s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1990 > 1024). Running this sequence through the model will result in indexing errors
 83%|████████▎ | 1968/2382 [6:03:54<1:15:55, 11.00s/it]                                                       {'loss': 2.1379, 'learning_rate': 7.718145238593793e-05, 'epoch': 0.83}
 83%|████████▎ | 1968/2382 [6:03:54<1:15:55, 11.00s/it] 83%|████████▎ | 1969/2382 [6:04:07<1:20:49, 11.74s/it]                                                       {'loss': 1.9947, 'learning_rate': 7.681888873578785e-05, 'epoch': 0.83}
 83%|████████▎ | 1969/2382 [6:04:07<1:20:49, 11.74s/it] 83%|████████▎ | 1970/2382 [6:04:19<1:19:36, 11.59s/it]                                                       {'loss': 2.09, 'learning_rate': 7.645710779763981e-05, 'epoch': 0.83}
 83%|████████▎ | 1970/2382 [6:04:19<1:19:36, 11.59s/it] 83%|████████▎ | 1971/2382 [6:04:31<1:21:04, 11.84s/it]                                                       {'loss': 1.9265, 'learning_rate': 7.609611024064062e-05, 'epoch': 0.83}
 83%|████████▎ | 1971/2382 [6:04:31<1:21:04, 11.84s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1476 > 1024). Running this sequence through the model will result in indexing errors
 83%|████████▎ | 1972/2382 [6:04:41<1:17:07, 11.29s/it]                                                       {'loss': 2.1595, 'learning_rate': 7.573589673248832e-05, 'epoch': 0.83}
 83%|████████▎ | 1972/2382 [6:04:41<1:17:07, 11.29s/it] 83%|████████▎ | 1973/2382 [6:04:52<1:17:09, 11.32s/it]                                                       {'loss': 1.9464, 'learning_rate': 7.537646793943032e-05, 'epoch': 0.83}
 83%|████████▎ | 1973/2382 [6:04:52<1:17:09, 11.32s/it] 83%|████████▎ | 1974/2382 [6:05:03<1:16:06, 11.19s/it]                                                       {'loss': 2.0827, 'learning_rate': 7.501782452626305e-05, 'epoch': 0.83}
 83%|████████▎ | 1974/2382 [6:05:03<1:16:06, 11.19s/it] 83%|████████▎ | 1975/2382 [6:05:13<1:12:18, 10.66s/it]                                                       {'loss': 1.9668, 'learning_rate': 7.465996715633027e-05, 'epoch': 0.83}
 83%|████████▎ | 1975/2382 [6:05:13<1:12:18, 10.66s/it] 83%|████████▎ | 1976/2382 [6:05:23<1:11:08, 10.51s/it]                                                       {'loss': 1.9616, 'learning_rate': 7.430289649152156e-05, 'epoch': 0.83}
 83%|████████▎ | 1976/2382 [6:05:23<1:11:08, 10.51s/it] 83%|████████▎ | 1977/2382 [6:05:32<1:08:14, 10.11s/it]                                                       {'loss': 2.067, 'learning_rate': 7.394661319227175e-05, 'epoch': 0.83}
 83%|████████▎ | 1977/2382 [6:05:32<1:08:14, 10.11s/it] 83%|████████▎ | 1978/2382 [6:05:44<1:11:25, 10.61s/it]                                                       {'loss': 2.0833, 'learning_rate': 7.359111791755917e-05, 'epoch': 0.83}
 83%|████████▎ | 1978/2382 [6:05:44<1:11:25, 10.61s/it] 83%|████████▎ | 1979/2382 [6:05:53<1:08:06, 10.14s/it]                                                       {'loss': 2.0998, 'learning_rate': 7.323641132490494e-05, 'epoch': 0.83}
 83%|████████▎ | 1979/2382 [6:05:53<1:08:06, 10.14s/it] 83%|████████▎ | 1980/2382 [6:06:04<1:09:02, 10.31s/it]                                                       {'loss': 1.9342, 'learning_rate': 7.288249407037084e-05, 'epoch': 0.83}
 83%|████████▎ | 1980/2382 [6:06:04<1:09:02, 10.31s/it] 83%|████████▎ | 1981/2382 [6:06:16<1:12:18, 10.82s/it]                                                       {'loss': 2.0266, 'learning_rate': 7.252936680855942e-05, 'epoch': 0.83}
 83%|████████▎ | 1981/2382 [6:06:16<1:12:18, 10.82s/it] 83%|████████▎ | 1982/2382 [6:06:28<1:16:14, 11.44s/it]                                                       {'loss': 1.9587, 'learning_rate': 7.217703019261135e-05, 'epoch': 0.83}
 83%|████████▎ | 1982/2382 [6:06:28<1:16:14, 11.44s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1061 > 1024). Running this sequence through the model will result in indexing errors
 83%|████████▎ | 1983/2382 [6:06:42<1:19:29, 11.95s/it]                                                       {'loss': 1.9047, 'learning_rate': 7.182548487420554e-05, 'epoch': 0.83}
 83%|████████▎ | 1983/2382 [6:06:42<1:19:29, 11.95s/it] 83%|████████▎ | 1984/2382 [6:06:56<1:25:00, 12.82s/it]                                                       {'loss': 1.9783, 'learning_rate': 7.147473150355693e-05, 'epoch': 0.83}
 83%|████████▎ | 1984/2382 [6:06:56<1:25:00, 12.82s/it] 83%|████████▎ | 1985/2382 [6:07:08<1:21:49, 12.37s/it]                                                       {'loss': 1.9594, 'learning_rate': 7.112477072941598e-05, 'epoch': 0.83}
 83%|████████▎ | 1985/2382 [6:07:08<1:21:49, 12.37s/it] 83%|████████▎ | 1986/2382 [6:07:16<1:14:10, 11.24s/it]                                                       {'loss': 2.0561, 'learning_rate': 7.077560319906695e-05, 'epoch': 0.83}
 83%|████████▎ | 1986/2382 [6:07:16<1:14:10, 11.24s/it] 83%|████████▎ | 1987/2382 [6:07:30<1:19:10, 12.03s/it]                                                       {'loss': 2.0555, 'learning_rate': 7.042722955832703e-05, 'epoch': 0.83}
 83%|████████▎ | 1987/2382 [6:07:30<1:19:10, 12.03s/it] 83%|████████▎ | 1988/2382 [6:07:43<1:20:31, 12.26s/it]                                                       {'loss': 1.8594, 'learning_rate': 7.007965045154474e-05, 'epoch': 0.83}
 83%|████████▎ | 1988/2382 [6:07:43<1:20:31, 12.26s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 1024). Running this sequence through the model will result in indexing errors
 84%|████████▎ | 1989/2382 [6:07:53<1:14:49, 11.42s/it]                                                       {'loss': 2.0377, 'learning_rate': 6.973286652159949e-05, 'epoch': 0.83}
 84%|████████▎ | 1989/2382 [6:07:53<1:14:49, 11.42s/it] 84%|████████▎ | 1990/2382 [6:08:03<1:13:42, 11.28s/it]                                                       {'loss': 1.9976, 'learning_rate': 6.938687840989971e-05, 'epoch': 0.84}
 84%|████████▎ | 1990/2382 [6:08:03<1:13:42, 11.28s/it] 84%|████████▎ | 1991/2382 [6:08:12<1:08:14, 10.47s/it]                                                       {'loss': 2.0716, 'learning_rate': 6.904168675638195e-05, 'epoch': 0.84}
 84%|████████▎ | 1991/2382 [6:08:12<1:08:14, 10.47s/it] 84%|████████▎ | 1992/2382 [6:08:23<1:08:01, 10.47s/it]                                                       {'loss': 2.0929, 'learning_rate': 6.86972921995096e-05, 'epoch': 0.84}
 84%|████████▎ | 1992/2382 [6:08:23<1:08:01, 10.47s/it] 84%|████████▎ | 1993/2382 [6:08:35<1:11:23, 11.01s/it]                                                       {'loss': 2.0592, 'learning_rate': 6.835369537627178e-05, 'epoch': 0.84}
 84%|████████▎ | 1993/2382 [6:08:35<1:11:23, 11.01s/it] 84%|████████▎ | 1994/2382 [6:08:45<1:09:30, 10.75s/it]                                                       {'loss': 2.0688, 'learning_rate': 6.801089692218215e-05, 'epoch': 0.84}
 84%|████████▎ | 1994/2382 [6:08:45<1:09:30, 10.75s/it] 84%|████████▍ | 1995/2382 [6:08:58<1:13:00, 11.32s/it]                                                       {'loss': 2.0281, 'learning_rate': 6.766889747127742e-05, 'epoch': 0.84}
 84%|████████▍ | 1995/2382 [6:08:58<1:13:00, 11.32s/it] 84%|████████▍ | 1996/2382 [6:09:11<1:17:39, 12.07s/it]                                                       {'loss': 1.9396, 'learning_rate': 6.73276976561169e-05, 'epoch': 0.84}
 84%|████████▍ | 1996/2382 [6:09:11<1:17:39, 12.07s/it] 84%|████████▍ | 1997/2382 [6:09:24<1:17:33, 12.09s/it]                                                       {'loss': 1.974, 'learning_rate': 6.698729810778065e-05, 'epoch': 0.84}
 84%|████████▍ | 1997/2382 [6:09:24<1:17:33, 12.09s/it] 84%|████████▍ | 1998/2382 [6:09:33<1:13:01, 11.41s/it]                                                       {'loss': 1.9763, 'learning_rate': 6.664769945586885e-05, 'epoch': 0.84}
 84%|████████▍ | 1998/2382 [6:09:33<1:13:01, 11.41s/it] 84%|████████▍ | 1999/2382 [6:09:47<1:16:21, 11.96s/it]                                                       {'loss': 1.9903, 'learning_rate': 6.630890232849984e-05, 'epoch': 0.84}
 84%|████████▍ | 1999/2382 [6:09:47<1:16:21, 11.96s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1494 > 1024). Running this sequence through the model will result in indexing errors
 84%|████████▍ | 2000/2382 [6:09:59<1:17:04, 12.11s/it]                                                       {'loss': 1.9257, 'learning_rate': 6.597090735230987e-05, 'epoch': 0.84}
 84%|████████▍ | 2000/2382 [6:09:59<1:17:04, 12.11s/it] 84%|████████▍ | 2001/2382 [6:10:08<1:11:24, 11.24s/it]                                                       {'loss': 2.0799, 'learning_rate': 6.563371515245154e-05, 'epoch': 0.84}
 84%|████████▍ | 2001/2382 [6:10:08<1:11:24, 11.24s/it] 84%|████████▍ | 2002/2382 [6:10:18<1:09:00, 10.90s/it]                                                       {'loss': 2.0266, 'learning_rate': 6.529732635259234e-05, 'epoch': 0.84}
 84%|████████▍ | 2002/2382 [6:10:18<1:09:00, 10.90s/it] 84%|████████▍ | 2003/2382 [6:10:28<1:06:28, 10.52s/it]                                                       {'loss': 1.9519, 'learning_rate': 6.496174157491408e-05, 'epoch': 0.84}
 84%|████████▍ | 2003/2382 [6:10:28<1:06:28, 10.52s/it] 84%|████████▍ | 2004/2382 [6:10:41<1:11:11, 11.30s/it]                                                       {'loss': 2.0389, 'learning_rate': 6.462696144011149e-05, 'epoch': 0.84}
 84%|████████▍ | 2004/2382 [6:10:41<1:11:11, 11.30s/it] 84%|████████▍ | 2005/2382 [6:10:55<1:15:10, 11.97s/it]                                                       {'loss': 2.0569, 'learning_rate': 6.429298656739069e-05, 'epoch': 0.84}
 84%|████████▍ | 2005/2382 [6:10:55<1:15:10, 11.97s/it] 84%|████████▍ | 2006/2382 [6:11:04<1:09:27, 11.08s/it]                                                       {'loss': 2.0506, 'learning_rate': 6.395981757446867e-05, 'epoch': 0.84}
 84%|████████▍ | 2006/2382 [6:11:04<1:09:27, 11.08s/it] 84%|████████▍ | 2007/2382 [6:11:13<1:05:45, 10.52s/it]                                                       {'loss': 2.0294, 'learning_rate': 6.362745507757189e-05, 'epoch': 0.84}
 84%|████████▍ | 2007/2382 [6:11:13<1:05:45, 10.52s/it] 84%|████████▍ | 2008/2382 [6:11:22<1:03:06, 10.12s/it]                                                       {'loss': 2.0695, 'learning_rate': 6.329589969143517e-05, 'epoch': 0.84}
 84%|████████▍ | 2008/2382 [6:11:22<1:03:06, 10.12s/it] 84%|████████▍ | 2009/2382 [6:11:34<1:05:38, 10.56s/it]                                                       {'loss': 2.0474, 'learning_rate': 6.296515202930014e-05, 'epoch': 0.84}
 84%|████████▍ | 2009/2382 [6:11:34<1:05:38, 10.56s/it] 84%|████████▍ | 2010/2382 [6:11:44<1:05:49, 10.62s/it]                                                       {'loss': 2.1086, 'learning_rate': 6.2635212702915e-05, 'epoch': 0.84}
 84%|████████▍ | 2010/2382 [6:11:44<1:05:49, 10.62s/it] 84%|████████▍ | 2011/2382 [6:11:55<1:05:57, 10.67s/it]                                                       {'loss': 1.9991, 'learning_rate': 6.230608232253226e-05, 'epoch': 0.84}
 84%|████████▍ | 2011/2382 [6:11:55<1:05:57, 10.67s/it] 84%|████████▍ | 2012/2382 [6:12:05<1:03:47, 10.34s/it]                                                       {'loss': 1.9888, 'learning_rate': 6.197776149690871e-05, 'epoch': 0.84}
 84%|████████▍ | 2012/2382 [6:12:05<1:03:47, 10.34s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1143 > 1024). Running this sequence through the model will result in indexing errors
 85%|████████▍ | 2013/2382 [6:12:15<1:02:31, 10.17s/it]                                                       {'loss': 1.9501, 'learning_rate': 6.165025083330356e-05, 'epoch': 0.84}
 85%|████████▍ | 2013/2382 [6:12:15<1:02:31, 10.17s/it] 85%|████████▍ | 2014/2382 [6:12:24<1:00:33,  9.87s/it]                                                       {'loss': 2.0575, 'learning_rate': 6.132355093747765e-05, 'epoch': 0.85}
 85%|████████▍ | 2014/2382 [6:12:24<1:00:33,  9.87s/it] 85%|████████▍ | 2015/2382 [6:12:35<1:03:26, 10.37s/it]                                                       {'loss': 2.0035, 'learning_rate': 6.099766241369231e-05, 'epoch': 0.85}
 85%|████████▍ | 2015/2382 [6:12:35<1:03:26, 10.37s/it] 85%|████████▍ | 2016/2382 [6:12:47<1:05:33, 10.75s/it]                                                       {'loss': 2.04, 'learning_rate': 6.0672585864707806e-05, 'epoch': 0.85}
 85%|████████▍ | 2016/2382 [6:12:47<1:05:33, 10.75s/it] 85%|████████▍ | 2017/2382 [6:12:57<1:04:22, 10.58s/it]                                                       {'loss': 1.9928, 'learning_rate': 6.034832189178302e-05, 'epoch': 0.85}
 85%|████████▍ | 2017/2382 [6:12:57<1:04:22, 10.58s/it] 85%|████████▍ | 2018/2382 [6:13:07<1:03:08, 10.41s/it]                                                       {'loss': 2.0339, 'learning_rate': 6.002487109467347e-05, 'epoch': 0.85}
 85%|████████▍ | 2018/2382 [6:13:07<1:03:08, 10.41s/it] 85%|████████▍ | 2019/2382 [6:13:17<1:01:39, 10.19s/it]                                                       {'loss': 2.0971, 'learning_rate': 5.9702234071631e-05, 'epoch': 0.85}
 85%|████████▍ | 2019/2382 [6:13:17<1:01:39, 10.19s/it] 85%|████████▍ | 2020/2382 [6:13:28<1:02:30, 10.36s/it]                                                       {'loss': 1.9623, 'learning_rate': 5.9380411419402206e-05, 'epoch': 0.85}
 85%|████████▍ | 2020/2382 [6:13:28<1:02:30, 10.36s/it] 85%|████████▍ | 2021/2382 [6:13:38<1:03:08, 10.49s/it]                                                       {'loss': 2.052, 'learning_rate': 5.905940373322732e-05, 'epoch': 0.85}
 85%|████████▍ | 2021/2382 [6:13:38<1:03:08, 10.49s/it] 85%|████████▍ | 2022/2382 [6:13:50<1:05:49, 10.97s/it]                                                       {'loss': 2.0797, 'learning_rate': 5.8739211606839427e-05, 'epoch': 0.85}
 85%|████████▍ | 2022/2382 [6:13:50<1:05:49, 10.97s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1416 > 1024). Running this sequence through the model will result in indexing errors
 85%|████████▍ | 2023/2382 [6:14:01<1:04:11, 10.73s/it]                                                       {'loss': 1.9237, 'learning_rate': 5.841983563246278e-05, 'epoch': 0.85}
 85%|████████▍ | 2023/2382 [6:14:01<1:04:11, 10.73s/it] 85%|████████▍ | 2024/2382 [6:14:10<1:01:34, 10.32s/it]                                                       {'loss': 2.1611, 'learning_rate': 5.810127640081259e-05, 'epoch': 0.85}
 85%|████████▍ | 2024/2382 [6:14:10<1:01:34, 10.32s/it] 85%|████████▌ | 2025/2382 [6:14:24<1:07:14, 11.30s/it]                                                       {'loss': 2.012, 'learning_rate': 5.778353450109286e-05, 'epoch': 0.85}
 85%|████████▌ | 2025/2382 [6:14:24<1:07:14, 11.30s/it] 85%|████████▌ | 2026/2382 [6:14:35<1:06:48, 11.26s/it]                                                       {'loss': 1.9908, 'learning_rate': 5.746661052099639e-05, 'epoch': 0.85}
 85%|████████▌ | 2026/2382 [6:14:35<1:06:48, 11.26s/it] 85%|████████▌ | 2027/2382 [6:14:46<1:06:56, 11.31s/it]                                                       {'loss': 1.9681, 'learning_rate': 5.7150505046702884e-05, 'epoch': 0.85}
 85%|████████▌ | 2027/2382 [6:14:46<1:06:56, 11.31s/it] 85%|████████▌ | 2028/2382 [6:14:57<1:06:38, 11.29s/it]                                                       {'loss': 1.9424, 'learning_rate': 5.683521866287833e-05, 'epoch': 0.85}
 85%|████████▌ | 2028/2382 [6:14:57<1:06:38, 11.29s/it] 85%|████████▌ | 2029/2382 [6:15:11<1:09:49, 11.87s/it]                                                       {'loss': 2.0064, 'learning_rate': 5.652075195267337e-05, 'epoch': 0.85}
 85%|████████▌ | 2029/2382 [6:15:11<1:09:49, 11.87s/it] 85%|████████▌ | 2030/2382 [6:15:22<1:08:33, 11.68s/it]                                                       {'loss': 2.064, 'learning_rate': 5.6207105497722956e-05, 'epoch': 0.85}
 85%|████████▌ | 2030/2382 [6:15:22<1:08:33, 11.68s/it] 85%|████████▌ | 2031/2382 [6:15:32<1:06:04, 11.29s/it]                                                       {'loss': 2.0305, 'learning_rate': 5.589427987814483e-05, 'epoch': 0.85}
 85%|████████▌ | 2031/2382 [6:15:32<1:06:04, 11.29s/it] 85%|████████▌ | 2032/2382 [6:15:46<1:09:24, 11.90s/it]                                                       {'loss': 2.001, 'learning_rate': 5.5582275672538315e-05, 'epoch': 0.85}
 85%|████████▌ | 2032/2382 [6:15:46<1:09:24, 11.90s/it] 85%|████████▌ | 2033/2382 [6:15:56<1:07:03, 11.53s/it]                                                       {'loss': 2.0536, 'learning_rate': 5.527109345798365e-05, 'epoch': 0.85}
 85%|████████▌ | 2033/2382 [6:15:56<1:07:03, 11.53s/it] 85%|████████▌ | 2034/2382 [6:16:07<1:06:03, 11.39s/it]                                                       {'loss': 1.9449, 'learning_rate': 5.4960733810040797e-05, 'epoch': 0.85}
 85%|████████▌ | 2034/2382 [6:16:07<1:06:03, 11.39s/it] 85%|████████▌ | 2035/2382 [6:16:19<1:06:09, 11.44s/it]                                                       {'loss': 1.9632, 'learning_rate': 5.465119730274798e-05, 'epoch': 0.85}
 85%|████████▌ | 2035/2382 [6:16:19<1:06:09, 11.44s/it] 85%|████████▌ | 2036/2382 [6:16:31<1:07:07, 11.64s/it]                                                       {'loss': 2.0334, 'learning_rate': 5.434248450862123e-05, 'epoch': 0.85}
 85%|████████▌ | 2036/2382 [6:16:31<1:07:07, 11.64s/it] 86%|████████▌ | 2037/2382 [6:16:41<1:03:58, 11.13s/it]                                                       {'loss': 2.1252, 'learning_rate': 5.403459599865307e-05, 'epoch': 0.85}
 86%|████████▌ | 2037/2382 [6:16:41<1:03:58, 11.13s/it] 86%|████████▌ | 2038/2382 [6:16:52<1:03:47, 11.13s/it]                                                       {'loss': 1.9961, 'learning_rate': 5.372753234231137e-05, 'epoch': 0.86}
 86%|████████▌ | 2038/2382 [6:16:52<1:03:47, 11.13s/it] 86%|████████▌ | 2039/2382 [6:17:05<1:07:19, 11.78s/it]                                                       {'loss': 2.0826, 'learning_rate': 5.34212941075381e-05, 'epoch': 0.86}
 86%|████████▌ | 2039/2382 [6:17:05<1:07:19, 11.78s/it] 86%|████████▌ | 2040/2382 [6:17:18<1:08:24, 12.00s/it]                                                       {'loss': 1.9557, 'learning_rate': 5.3115881860749005e-05, 'epoch': 0.86}
 86%|████████▌ | 2040/2382 [6:17:18<1:08:24, 12.00s/it] 86%|████████▌ | 2041/2382 [6:17:32<1:11:06, 12.51s/it]                                                       {'loss': 1.9868, 'learning_rate': 5.2811296166831666e-05, 'epoch': 0.86}
 86%|████████▌ | 2041/2382 [6:17:32<1:11:06, 12.51s/it] 86%|████████▌ | 2042/2382 [6:17:41<1:05:56, 11.64s/it]                                                       {'loss': 2.0135, 'learning_rate': 5.250753758914506e-05, 'epoch': 0.86}
 86%|████████▌ | 2042/2382 [6:17:41<1:05:56, 11.64s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1049 > 1024). Running this sequence through the model will result in indexing errors
 86%|████████▌ | 2043/2382 [6:17:53<1:05:18, 11.56s/it]                                                       {'loss': 1.9917, 'learning_rate': 5.2204606689518485e-05, 'epoch': 0.86}
 86%|████████▌ | 2043/2382 [6:17:53<1:05:18, 11.56s/it] 86%|████████▌ | 2044/2382 [6:18:06<1:07:37, 12.00s/it]                                                       {'loss': 1.9981, 'learning_rate': 5.190250402825014e-05, 'epoch': 0.86}
 86%|████████▌ | 2044/2382 [6:18:06<1:07:37, 12.00s/it] 86%|████████▌ | 2045/2382 [6:18:16<1:04:08, 11.42s/it]                                                       {'loss': 2.0178, 'learning_rate': 5.160123016410645e-05, 'epoch': 0.86}
 86%|████████▌ | 2045/2382 [6:18:16<1:04:08, 11.42s/it] 86%|████████▌ | 2046/2382 [6:18:27<1:03:32, 11.35s/it]                                                       {'loss': 2.0624, 'learning_rate': 5.130078565432089e-05, 'epoch': 0.86}
 86%|████████▌ | 2046/2382 [6:18:27<1:03:32, 11.35s/it] 86%|████████▌ | 2047/2382 [6:18:37<1:01:04, 10.94s/it]                                                       {'loss': 2.0826, 'learning_rate': 5.100117105459279e-05, 'epoch': 0.86}
 86%|████████▌ | 2047/2382 [6:18:37<1:01:04, 10.94s/it] 86%|████████▌ | 2048/2382 [6:18:49<1:02:17, 11.19s/it]                                                       {'loss': 2.055, 'learning_rate': 5.0702386919086685e-05, 'epoch': 0.86}
 86%|████████▌ | 2048/2382 [6:18:49<1:02:17, 11.19s/it] 86%|████████▌ | 2049/2382 [6:18:58<59:48, 10.78s/it]                                                       {'loss': 1.9497, 'learning_rate': 5.040443380043114e-05, 'epoch': 0.86}
 86%|████████▌ | 2049/2382 [6:18:58<59:48, 10.78s/it] 86%|████████▌ | 2050/2382 [6:19:09<59:10, 10.69s/it]                                                     {'loss': 2.0142, 'learning_rate': 5.010731224971748e-05, 'epoch': 0.86}
 86%|████████▌ | 2050/2382 [6:19:09<59:10, 10.69s/it] 86%|████████▌ | 2051/2382 [6:19:20<59:12, 10.73s/it]                                                     {'loss': 2.0156, 'learning_rate': 4.981102281649913e-05, 'epoch': 0.86}
 86%|████████▌ | 2051/2382 [6:19:20<59:12, 10.73s/it] 86%|████████▌ | 2052/2382 [6:19:29<55:56, 10.17s/it]                                                     {'loss': 1.9624, 'learning_rate': 4.9515566048790485e-05, 'epoch': 0.86}
 86%|████████▌ | 2052/2382 [6:19:29<55:56, 10.17s/it] 86%|████████▌ | 2053/2382 [6:19:40<58:37, 10.69s/it]                                                     {'loss': 1.9827, 'learning_rate': 4.922094249306558e-05, 'epoch': 0.86}
 86%|████████▌ | 2053/2382 [6:19:40<58:37, 10.69s/it] 86%|████████▌ | 2054/2382 [6:19:51<58:15, 10.66s/it]                                                     {'loss': 2.119, 'learning_rate': 4.892715269425746e-05, 'epoch': 0.86}
 86%|████████▌ | 2054/2382 [6:19:51<58:15, 10.66s/it] 86%|████████▋ | 2055/2382 [6:20:04<1:01:35, 11.30s/it]                                                       {'loss': 1.9635, 'learning_rate': 4.863419719575724e-05, 'epoch': 0.86}
 86%|████████▋ | 2055/2382 [6:20:04<1:01:35, 11.30s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1333 > 1024). Running this sequence through the model will result in indexing errors
 86%|████████▋ | 2056/2382 [6:20:13<58:34, 10.78s/it]                                                       {'loss': 2.0601, 'learning_rate': 4.834207653941269e-05, 'epoch': 0.86}
 86%|████████▋ | 2056/2382 [6:20:13<58:34, 10.78s/it] 86%|████████▋ | 2057/2382 [6:20:26<1:01:29, 11.35s/it]                                                       {'loss': 2.0269, 'learning_rate': 4.805079126552769e-05, 'epoch': 0.86}
 86%|████████▋ | 2057/2382 [6:20:26<1:01:29, 11.35s/it] 86%|████████▋ | 2058/2382 [6:20:38<1:02:35, 11.59s/it]                                                       {'loss': 1.9698, 'learning_rate': 4.7760341912860936e-05, 'epoch': 0.86}
 86%|████████▋ | 2058/2382 [6:20:38<1:02:35, 11.59s/it] 86%|████████▋ | 2059/2382 [6:20:50<1:02:54, 11.68s/it]                                                       {'loss': 2.0719, 'learning_rate': 4.74707290186247e-05, 'epoch': 0.86}
 86%|████████▋ | 2059/2382 [6:20:50<1:02:54, 11.68s/it] 86%|████████▋ | 2060/2382 [6:21:01<1:01:28, 11.45s/it]                                                       {'loss': 2.0006, 'learning_rate': 4.7181953118484556e-05, 'epoch': 0.86}
 86%|████████▋ | 2060/2382 [6:21:01<1:01:28, 11.45s/it] 87%|████████▋ | 2061/2382 [6:21:11<59:05, 11.05s/it]                                                       {'loss': 2.1359, 'learning_rate': 4.689401474655791e-05, 'epoch': 0.86}
 87%|████████▋ | 2061/2382 [6:21:11<59:05, 11.05s/it] 87%|████████▋ | 2062/2382 [6:21:23<1:00:26, 11.33s/it]                                                       {'loss': 2.0402, 'learning_rate': 4.6606914435412815e-05, 'epoch': 0.87}
 87%|████████▋ | 2062/2382 [6:21:23<1:00:26, 11.33s/it] 87%|████████▋ | 2063/2382 [6:21:35<1:00:49, 11.44s/it]                                                       {'loss': 2.0695, 'learning_rate': 4.632065271606756e-05, 'epoch': 0.87}
 87%|████████▋ | 2063/2382 [6:21:35<1:00:49, 11.44s/it] 87%|████████▋ | 2064/2382 [6:21:43<55:31, 10.48s/it]                                                       {'loss': 2.0437, 'learning_rate': 4.603523011798932e-05, 'epoch': 0.87}
 87%|████████▋ | 2064/2382 [6:21:43<55:31, 10.48s/it] 87%|████████▋ | 2065/2382 [6:21:54<55:37, 10.53s/it]                                                     {'loss': 2.0114, 'learning_rate': 4.5750647169092995e-05, 'epoch': 0.87}
 87%|████████▋ | 2065/2382 [6:21:54<55:37, 10.53s/it] 87%|████████▋ | 2066/2382 [6:22:03<54:00, 10.25s/it]                                                     {'loss': 2.0637, 'learning_rate': 4.546690439574081e-05, 'epoch': 0.87}
 87%|████████▋ | 2066/2382 [6:22:03<54:00, 10.25s/it] 87%|████████▋ | 2067/2382 [6:22:15<56:34, 10.78s/it]                                                     {'loss': 2.007, 'learning_rate': 4.518400232274078e-05, 'epoch': 0.87}
 87%|████████▋ | 2067/2382 [6:22:15<56:34, 10.78s/it] 87%|████████▋ | 2068/2382 [6:22:27<57:11, 10.93s/it]                                                     {'loss': 1.9989, 'learning_rate': 4.49019414733462e-05, 'epoch': 0.87}
 87%|████████▋ | 2068/2382 [6:22:27<57:11, 10.93s/it] 87%|████████▋ | 2069/2382 [6:22:37<55:47, 10.69s/it]                                                     {'loss': 2.0679, 'learning_rate': 4.462072236925413e-05, 'epoch': 0.87}
 87%|████████▋ | 2069/2382 [6:22:37<55:47, 10.69s/it] 87%|████████▋ | 2070/2382 [6:22:48<56:53, 10.94s/it]                                                     {'loss': 1.8984, 'learning_rate': 4.434034553060501e-05, 'epoch': 0.87}
 87%|████████▋ | 2070/2382 [6:22:48<56:53, 10.94s/it] 87%|████████▋ | 2071/2382 [6:22:59<56:49, 10.96s/it]                                                     {'loss': 2.0047, 'learning_rate': 4.4060811475981234e-05, 'epoch': 0.87}
 87%|████████▋ | 2071/2382 [6:22:59<56:49, 10.96s/it] 87%|████████▋ | 2072/2382 [6:23:12<58:45, 11.37s/it]                                                     {'loss': 1.9281, 'learning_rate': 4.378212072240656e-05, 'epoch': 0.87}
 87%|████████▋ | 2072/2382 [6:23:12<58:45, 11.37s/it] 87%|████████▋ | 2073/2382 [6:23:21<56:11, 10.91s/it]                                                     {'loss': 2.0961, 'learning_rate': 4.3504273785344936e-05, 'epoch': 0.87}
 87%|████████▋ | 2073/2382 [6:23:21<56:11, 10.91s/it] 87%|████████▋ | 2074/2382 [6:23:30<52:05, 10.15s/it]                                                     {'loss': 2.0137, 'learning_rate': 4.322727117869951e-05, 'epoch': 0.87}
 87%|████████▋ | 2074/2382 [6:23:30<52:05, 10.15s/it] 87%|████████▋ | 2075/2382 [6:23:39<50:59,  9.97s/it]                                                     {'loss': 2.0753, 'learning_rate': 4.2951113414812e-05, 'epoch': 0.87}
 87%|████████▋ | 2075/2382 [6:23:39<50:59,  9.97s/it] 87%|████████▋ | 2076/2382 [6:23:49<49:59,  9.80s/it]                                                     {'loss': 2.0285, 'learning_rate': 4.2675801004461165e-05, 'epoch': 0.87}
 87%|████████▋ | 2076/2382 [6:23:49<49:59,  9.80s/it] 87%|████████▋ | 2077/2382 [6:24:00<51:28, 10.13s/it]                                                     {'loss': 2.125, 'learning_rate': 4.240133445686234e-05, 'epoch': 0.87}
 87%|████████▋ | 2077/2382 [6:24:00<51:28, 10.13s/it] 87%|████████▋ | 2078/2382 [6:24:10<52:11, 10.30s/it]                                                     {'loss': 1.9971, 'learning_rate': 4.212771427966649e-05, 'epoch': 0.87}
 87%|████████▋ | 2078/2382 [6:24:10<52:11, 10.30s/it] 87%|████████▋ | 2079/2382 [6:24:20<50:43, 10.05s/it]                                                     {'loss': 1.9412, 'learning_rate': 4.1854940978959034e-05, 'epoch': 0.87}
 87%|████████▋ | 2079/2382 [6:24:20<50:43, 10.05s/it] 87%|████████▋ | 2080/2382 [6:24:31<51:41, 10.27s/it]                                                     {'loss': 2.0556, 'learning_rate': 4.158301505925904e-05, 'epoch': 0.87}
 87%|████████▋ | 2080/2382 [6:24:31<51:41, 10.27s/it] 87%|████████▋ | 2081/2382 [6:24:41<51:33, 10.28s/it]                                                     {'loss': 2.0037, 'learning_rate': 4.1311937023518264e-05, 'epoch': 0.87}
 87%|████████▋ | 2081/2382 [6:24:41<51:33, 10.28s/it] 87%|████████▋ | 2082/2382 [6:24:52<52:52, 10.58s/it]                                                     {'loss': 2.0136, 'learning_rate': 4.1041707373120354e-05, 'epoch': 0.87}
 87%|████████▋ | 2082/2382 [6:24:52<52:52, 10.58s/it] 87%|████████▋ | 2083/2382 [6:25:04<54:18, 10.90s/it]                                                     {'loss': 2.1975, 'learning_rate': 4.077232660787944e-05, 'epoch': 0.87}
 87%|████████▋ | 2083/2382 [6:25:04<54:18, 10.90s/it] 87%|████████▋ | 2084/2382 [6:25:15<54:28, 10.97s/it]                                                     {'loss': 2.0092, 'learning_rate': 4.0503795226039805e-05, 'epoch': 0.87}
 87%|████████▋ | 2084/2382 [6:25:15<54:28, 10.97s/it] 88%|████████▊ | 2085/2382 [6:25:25<52:41, 10.64s/it]                                                     {'loss': 2.0613, 'learning_rate': 4.0236113724274713e-05, 'epoch': 0.87}
 88%|████████▊ | 2085/2382 [6:25:25<52:41, 10.64s/it] 88%|████████▊ | 2086/2382 [6:25:35<52:09, 10.57s/it]                                                     {'loss': 2.0652, 'learning_rate': 3.996928259768551e-05, 'epoch': 0.88}
 88%|████████▊ | 2086/2382 [6:25:35<52:09, 10.57s/it] 88%|████████▊ | 2087/2382 [6:25:47<53:38, 10.91s/it]                                                     {'loss': 1.9686, 'learning_rate': 3.9703302339800686e-05, 'epoch': 0.88}
 88%|████████▊ | 2087/2382 [6:25:47<53:38, 10.91s/it] 88%|████████▊ | 2088/2382 [6:26:02<59:03, 12.05s/it]                                                     {'loss': 2.0263, 'learning_rate': 3.9438173442575e-05, 'epoch': 0.88}
 88%|████████▊ | 2088/2382 [6:26:02<59:03, 12.05s/it] 88%|████████▊ | 2089/2382 [6:26:14<58:34, 11.99s/it]                                                     {'loss': 1.9464, 'learning_rate': 3.9173896396388295e-05, 'epoch': 0.88}
 88%|████████▊ | 2089/2382 [6:26:14<58:34, 11.99s/it] 88%|████████▊ | 2090/2382 [6:26:22<53:16, 10.95s/it]                                                     {'loss': 2.0073, 'learning_rate': 3.8910471690045243e-05, 'epoch': 0.88}
 88%|████████▊ | 2090/2382 [6:26:22<53:16, 10.95s/it] 88%|████████▊ | 2091/2382 [6:26:34<54:12, 11.18s/it]                                                     {'loss': 1.996, 'learning_rate': 3.8647899810773713e-05, 'epoch': 0.88}
 88%|████████▊ | 2091/2382 [6:26:34<54:12, 11.18s/it] 88%|████████▊ | 2092/2382 [6:26:44<52:54, 10.95s/it]                                                     {'loss': 1.9854, 'learning_rate': 3.8386181244224274e-05, 'epoch': 0.88}
 88%|████████▊ | 2092/2382 [6:26:44<52:54, 10.95s/it] 88%|████████▊ | 2093/2382 [6:26:56<53:50, 11.18s/it]                                                     {'loss': 2.0329, 'learning_rate': 3.8125316474469317e-05, 'epoch': 0.88}
 88%|████████▊ | 2093/2382 [6:26:56<53:50, 11.18s/it] 88%|████████▊ | 2094/2382 [6:27:09<56:05, 11.69s/it]                                                     {'loss': 2.0652, 'learning_rate': 3.786530598400206e-05, 'epoch': 0.88}
 88%|████████▊ | 2094/2382 [6:27:09<56:05, 11.69s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1641 > 1024). Running this sequence through the model will result in indexing errors
 88%|████████▊ | 2095/2382 [6:27:19<54:32, 11.40s/it]                                                     {'loss': 2.0635, 'learning_rate': 3.760615025373543e-05, 'epoch': 0.88}
 88%|████████▊ | 2095/2382 [6:27:19<54:32, 11.40s/it] 88%|████████▊ | 2096/2382 [6:27:29<51:02, 10.71s/it]                                                     {'loss': 2.0322, 'learning_rate': 3.734784976300165e-05, 'epoch': 0.88}
 88%|████████▊ | 2096/2382 [6:27:29<51:02, 10.71s/it] 88%|████████▊ | 2097/2382 [6:27:37<47:53, 10.08s/it]                                                     {'loss': 2.0337, 'learning_rate': 3.709040498955102e-05, 'epoch': 0.88}
 88%|████████▊ | 2097/2382 [6:27:37<47:53, 10.08s/it] 88%|████████▊ | 2098/2382 [6:27:49<49:29, 10.46s/it]                                                     {'loss': 1.9838, 'learning_rate': 3.683381640955097e-05, 'epoch': 0.88}
 88%|████████▊ | 2098/2382 [6:27:49<49:29, 10.46s/it] 88%|████████▊ | 2099/2382 [6:28:00<50:40, 10.74s/it]                                                     {'loss': 2.1216, 'learning_rate': 3.6578084497585484e-05, 'epoch': 0.88}
 88%|████████▊ | 2099/2382 [6:28:00<50:40, 10.74s/it] 88%|████████▊ | 2100/2382 [6:28:09<48:41, 10.36s/it]                                                     {'loss': 2.1039, 'learning_rate': 3.632320972665415e-05, 'epoch': 0.88}
 88%|████████▊ | 2100/2382 [6:28:09<48:41, 10.36s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1702 > 1024). Running this sequence through the model will result in indexing errors
 88%|████████▊ | 2101/2382 [6:28:22<51:50, 11.07s/it]                                                     {'loss': 2.0711, 'learning_rate': 3.6069192568170926e-05, 'epoch': 0.88}
 88%|████████▊ | 2101/2382 [6:28:22<51:50, 11.07s/it] 88%|████████▊ | 2102/2382 [6:28:33<51:51, 11.11s/it]                                                     {'loss': 2.0093, 'learning_rate': 3.5816033491963716e-05, 'epoch': 0.88}
 88%|████████▊ | 2102/2382 [6:28:33<51:51, 11.11s/it] 88%|████████▊ | 2103/2382 [6:28:44<50:23, 10.84s/it]                                                     {'loss': 1.9579, 'learning_rate': 3.5563732966273245e-05, 'epoch': 0.88}
 88%|████████▊ | 2103/2382 [6:28:44<50:23, 10.84s/it] 88%|████████▊ | 2104/2382 [6:28:55<51:28, 11.11s/it]                                                     {'loss': 2.0171, 'learning_rate': 3.53122914577525e-05, 'epoch': 0.88}
 88%|████████▊ | 2104/2382 [6:28:55<51:28, 11.11s/it] 88%|████████▊ | 2105/2382 [6:29:06<50:10, 10.87s/it]                                                     {'loss': 2.0085, 'learning_rate': 3.5061709431465195e-05, 'epoch': 0.88}
 88%|████████▊ | 2105/2382 [6:29:06<50:10, 10.87s/it] 88%|████████▊ | 2106/2382 [6:29:18<51:27, 11.19s/it]                                                     {'loss': 2.0674, 'learning_rate': 3.4811987350885807e-05, 'epoch': 0.88}
 88%|████████▊ | 2106/2382 [6:29:18<51:27, 11.19s/it] 88%|████████▊ | 2107/2382 [6:29:30<52:39, 11.49s/it]                                                     {'loss': 1.9518, 'learning_rate': 3.456312567789793e-05, 'epoch': 0.88}
 88%|████████▊ | 2107/2382 [6:29:30<52:39, 11.49s/it] 88%|████████▊ | 2108/2382 [6:29:39<48:54, 10.71s/it]                                                     {'loss': 1.9822, 'learning_rate': 3.431512487279392e-05, 'epoch': 0.88}
 88%|████████▊ | 2108/2382 [6:29:39<48:54, 10.71s/it] 89%|████████▊ | 2109/2382 [6:29:49<48:31, 10.67s/it]                                                     {'loss': 1.9897, 'learning_rate': 3.406798539427386e-05, 'epoch': 0.89}
 89%|████████▊ | 2109/2382 [6:29:49<48:31, 10.67s/it] 89%|████████▊ | 2110/2382 [6:29:59<47:06, 10.39s/it]                                                     {'loss': 2.1064, 'learning_rate': 3.38217076994447e-05, 'epoch': 0.89}
 89%|████████▊ | 2110/2382 [6:29:59<47:06, 10.39s/it] 89%|████████▊ | 2111/2382 [6:30:10<48:17, 10.69s/it]                                                     {'loss': 2.0971, 'learning_rate': 3.357629224381964e-05, 'epoch': 0.89}
 89%|████████▊ | 2111/2382 [6:30:10<48:17, 10.69s/it] 89%|████████▊ | 2112/2382 [6:30:22<49:16, 10.95s/it]                                                     {'loss': 2.1249, 'learning_rate': 3.3331739481316624e-05, 'epoch': 0.89}
 89%|████████▊ | 2112/2382 [6:30:22<49:16, 10.95s/it] 89%|████████▊ | 2113/2382 [6:30:33<49:26, 11.03s/it]                                                     {'loss': 2.0452, 'learning_rate': 3.308804986425851e-05, 'epoch': 0.89}
 89%|████████▊ | 2113/2382 [6:30:33<49:26, 11.03s/it] 89%|████████▊ | 2114/2382 [6:30:41<45:33, 10.20s/it]                                                     {'loss': 2.1501, 'learning_rate': 3.284522384337124e-05, 'epoch': 0.89}
 89%|████████▊ | 2114/2382 [6:30:41<45:33, 10.20s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1458 > 1024). Running this sequence through the model will result in indexing errors
 89%|████████▉ | 2115/2382 [6:30:52<45:51, 10.31s/it]                                                     {'loss': 2.0929, 'learning_rate': 3.260326186778373e-05, 'epoch': 0.89}
 89%|████████▉ | 2115/2382 [6:30:52<45:51, 10.31s/it] 89%|████████▉ | 2116/2382 [6:31:04<48:32, 10.95s/it]                                                     {'loss': 2.024, 'learning_rate': 3.23621643850267e-05, 'epoch': 0.89}
 89%|████████▉ | 2116/2382 [6:31:04<48:32, 10.95s/it] 89%|████████▉ | 2117/2382 [6:31:16<49:12, 11.14s/it]                                                     {'loss': 2.1025, 'learning_rate': 3.212193184103196e-05, 'epoch': 0.89}
 89%|████████▉ | 2117/2382 [6:31:16<49:12, 11.14s/it] 89%|████████▉ | 2118/2382 [6:31:26<47:38, 10.83s/it]                                                     {'loss': 2.0496, 'learning_rate': 3.18825646801314e-05, 'epoch': 0.89}
 89%|████████▉ | 2118/2382 [6:31:26<47:38, 10.83s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 1024). Running this sequence through the model will result in indexing errors
 89%|████████▉ | 2119/2382 [6:31:36<46:58, 10.72s/it]                                                     {'loss': 1.9962, 'learning_rate': 3.164406334505637e-05, 'epoch': 0.89}
 89%|████████▉ | 2119/2382 [6:31:36<46:58, 10.72s/it] 89%|████████▉ | 2120/2382 [6:31:49<49:03, 11.24s/it]                                                     {'loss': 2.0841, 'learning_rate': 3.14064282769369e-05, 'epoch': 0.89}
 89%|████████▉ | 2120/2382 [6:31:49<49:03, 11.24s/it] 89%|████████▉ | 2121/2382 [6:31:59<46:56, 10.79s/it]                                                     {'loss': 2.0265, 'learning_rate': 3.116965991530052e-05, 'epoch': 0.89}
 89%|████████▉ | 2121/2382 [6:31:59<46:56, 10.79s/it] 89%|████████▉ | 2122/2382 [6:32:08<45:22, 10.47s/it]                                                     {'loss': 2.059, 'learning_rate': 3.093375869807202e-05, 'epoch': 0.89}
 89%|████████▉ | 2122/2382 [6:32:08<45:22, 10.47s/it] 89%|████████▉ | 2123/2382 [6:32:21<47:30, 11.01s/it]                                                     {'loss': 1.999, 'learning_rate': 3.069872506157212e-05, 'epoch': 0.89}
 89%|████████▉ | 2123/2382 [6:32:21<47:30, 11.01s/it] 89%|████████▉ | 2124/2382 [6:32:31<46:10, 10.74s/it]                                                     {'loss': 2.0499, 'learning_rate': 3.0464559440517015e-05, 'epoch': 0.89}
 89%|████████▉ | 2124/2382 [6:32:31<46:10, 10.74s/it] 89%|████████▉ | 2125/2382 [6:32:41<45:07, 10.53s/it]                                                     {'loss': 2.0593, 'learning_rate': 3.0231262268017256e-05, 'epoch': 0.89}
 89%|████████▉ | 2125/2382 [6:32:41<45:07, 10.53s/it] 89%|████████▉ | 2126/2382 [6:32:53<46:38, 10.93s/it]                                                     {'loss': 2.0826, 'learning_rate': 2.9998833975577233e-05, 'epoch': 0.89}
 89%|████████▉ | 2126/2382 [6:32:53<46:38, 10.93s/it] 89%|████████▉ | 2127/2382 [6:33:05<48:03, 11.31s/it]                                                     {'loss': 1.9329, 'learning_rate': 2.9767274993094283e-05, 'epoch': 0.89}
 89%|████████▉ | 2127/2382 [6:33:05<48:03, 11.31s/it] 89%|████████▉ | 2128/2382 [6:33:17<49:13, 11.63s/it]                                                     {'loss': 2.0, 'learning_rate': 2.953658574885776e-05, 'epoch': 0.89}
 89%|████████▉ | 2128/2382 [6:33:17<49:13, 11.63s/it] 89%|████████▉ | 2129/2382 [6:33:27<46:58, 11.14s/it]                                                     {'loss': 2.0687, 'learning_rate': 2.9306766669548458e-05, 'epoch': 0.89}
 89%|████████▉ | 2129/2382 [6:33:27<46:58, 11.14s/it] 89%|████████▉ | 2130/2382 [6:33:37<44:34, 10.61s/it]                                                     {'loss': 2.072, 'learning_rate': 2.9077818180237692e-05, 'epoch': 0.89}
 89%|████████▉ | 2130/2382 [6:33:37<44:34, 10.61s/it] 89%|████████▉ | 2131/2382 [6:33:47<44:41, 10.68s/it]                                                     {'loss': 2.0396, 'learning_rate': 2.8849740704386563e-05, 'epoch': 0.89}
 89%|████████▉ | 2131/2382 [6:33:47<44:41, 10.68s/it] 90%|████████▉ | 2132/2382 [6:33:57<42:41, 10.25s/it]                                                     {'loss': 1.9974, 'learning_rate': 2.862253466384507e-05, 'epoch': 0.89}
 90%|████████▉ | 2132/2382 [6:33:57<42:41, 10.25s/it] 90%|████████▉ | 2133/2382 [6:34:06<41:47, 10.07s/it]                                                     {'loss': 2.0816, 'learning_rate': 2.8396200478851497e-05, 'epoch': 0.9}
 90%|████████▉ | 2133/2382 [6:34:06<41:47, 10.07s/it] 90%|████████▉ | 2134/2382 [6:34:19<45:01, 10.89s/it]                                                     {'loss': 1.9615, 'learning_rate': 2.8170738568031707e-05, 'epoch': 0.9}
 90%|████████▉ | 2134/2382 [6:34:19<45:01, 10.89s/it] 90%|████████▉ | 2135/2382 [6:34:29<43:54, 10.67s/it]                                                     {'loss': 1.9211, 'learning_rate': 2.7946149348397788e-05, 'epoch': 0.9}
 90%|████████▉ | 2135/2382 [6:34:29<43:54, 10.67s/it] 90%|████████▉ | 2136/2382 [6:34:42<46:32, 11.35s/it]                                                     {'loss': 2.0865, 'learning_rate': 2.7722433235348065e-05, 'epoch': 0.9}
 90%|████████▉ | 2136/2382 [6:34:42<46:32, 11.35s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1056 > 1024). Running this sequence through the model will result in indexing errors
 90%|████████▉ | 2137/2382 [6:34:53<46:05, 11.29s/it]                                                     {'loss': 2.1558, 'learning_rate': 2.7499590642665774e-05, 'epoch': 0.9}
 90%|████████▉ | 2137/2382 [6:34:53<46:05, 11.29s/it] 90%|████████▉ | 2138/2382 [6:35:06<47:01, 11.56s/it]                                                     {'loss': 1.9419, 'learning_rate': 2.727762198251871e-05, 'epoch': 0.9}
 90%|████████▉ | 2138/2382 [6:35:06<47:01, 11.56s/it] 90%|████████▉ | 2139/2382 [6:35:15<44:23, 10.96s/it]                                                     {'loss': 2.0306, 'learning_rate': 2.705652766545802e-05, 'epoch': 0.9}
 90%|████████▉ | 2139/2382 [6:35:15<44:23, 10.96s/it] 90%|████████▉ | 2140/2382 [6:35:27<45:14, 11.22s/it]                                                     {'loss': 2.0916, 'learning_rate': 2.683630810041787e-05, 'epoch': 0.9}
 90%|████████▉ | 2140/2382 [6:35:27<45:14, 11.22s/it] 90%|████████▉ | 2141/2382 [6:35:37<44:02, 10.97s/it]                                                     {'loss': 2.035, 'learning_rate': 2.6616963694714392e-05, 'epoch': 0.9}
 90%|████████▉ | 2141/2382 [6:35:37<44:02, 10.97s/it] 90%|████████▉ | 2142/2382 [6:35:48<43:29, 10.87s/it]                                                     {'loss': 2.006, 'learning_rate': 2.6398494854045054e-05, 'epoch': 0.9}
 90%|████████▉ | 2142/2382 [6:35:48<43:29, 10.87s/it] 90%|████████▉ | 2143/2382 [6:35:58<42:41, 10.72s/it]                                                     {'loss': 2.0323, 'learning_rate': 2.6180901982487683e-05, 'epoch': 0.9}
 90%|████████▉ | 2143/2382 [6:35:58<42:41, 10.72s/it] 90%|█████████ | 2144/2382 [6:36:09<42:46, 10.78s/it]                                                     {'loss': 2.1013, 'learning_rate': 2.596418548250029e-05, 'epoch': 0.9}
 90%|█████████ | 2144/2382 [6:36:09<42:46, 10.78s/it] 90%|█████████ | 2145/2382 [6:36:23<45:45, 11.58s/it]                                                     {'loss': 1.9123, 'learning_rate': 2.5748345754919688e-05, 'epoch': 0.9}
 90%|█████████ | 2145/2382 [6:36:23<45:45, 11.58s/it] 90%|█████████ | 2146/2382 [6:36:35<46:39, 11.86s/it]                                                     {'loss': 2.1158, 'learning_rate': 2.55333831989612e-05, 'epoch': 0.9}
 90%|█████████ | 2146/2382 [6:36:35<46:39, 11.86s/it] 90%|█████████ | 2147/2382 [6:36:44<42:11, 10.77s/it]                                                     {'loss': 2.0469, 'learning_rate': 2.531929821221768e-05, 'epoch': 0.9}
 90%|█████████ | 2147/2382 [6:36:44<42:11, 10.77s/it] 90%|█████████ | 2148/2382 [6:36:54<41:34, 10.66s/it]                                                     {'loss': 1.9632, 'learning_rate': 2.5106091190658597e-05, 'epoch': 0.9}
 90%|█████████ | 2148/2382 [6:36:54<41:34, 10.66s/it] 90%|█████████ | 2149/2382 [6:37:09<46:41, 12.02s/it]                                                     {'loss': 2.036, 'learning_rate': 2.4893762528630015e-05, 'epoch': 0.9}
 90%|█████████ | 2149/2382 [6:37:09<46:41, 12.02s/it] 90%|█████████ | 2150/2382 [6:37:26<52:12, 13.50s/it]                                                     {'loss': 2.0673, 'learning_rate': 2.46823126188529e-05, 'epoch': 0.9}
 90%|█████████ | 2150/2382 [6:37:26<52:12, 13.50s/it] 90%|█████████ | 2151/2382 [6:37:37<48:32, 12.61s/it]                                                     {'loss': 2.049, 'learning_rate': 2.4471741852423235e-05, 'epoch': 0.9}
 90%|█████████ | 2151/2382 [6:37:37<48:32, 12.61s/it] 90%|█████████ | 2152/2382 [6:37:48<46:42, 12.18s/it]                                                     {'loss': 2.0826, 'learning_rate': 2.4262050618810815e-05, 'epoch': 0.9}
 90%|█████████ | 2152/2382 [6:37:48<46:42, 12.18s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1099 > 1024). Running this sequence through the model will result in indexing errors
 90%|█████████ | 2153/2382 [6:38:00<46:34, 12.20s/it]                                                     {'loss': 2.0359, 'learning_rate': 2.4053239305858676e-05, 'epoch': 0.9}
 90%|█████████ | 2153/2382 [6:38:00<46:34, 12.20s/it] 90%|█████████ | 2154/2382 [6:38:13<47:42, 12.55s/it]                                                     {'loss': 1.9192, 'learning_rate': 2.384530829978232e-05, 'epoch': 0.9}
 90%|█████████ | 2154/2382 [6:38:13<47:42, 12.55s/it] 90%|█████████ | 2155/2382 [6:38:27<48:09, 12.73s/it]                                                     {'loss': 2.0323, 'learning_rate': 2.363825798516911e-05, 'epoch': 0.9}
 90%|█████████ | 2155/2382 [6:38:27<48:09, 12.73s/it] 91%|█████████ | 2156/2382 [6:38:38<46:06, 12.24s/it]                                                     {'loss': 1.9005, 'learning_rate': 2.3432088744977487e-05, 'epoch': 0.9}
 91%|█████████ | 2156/2382 [6:38:38<46:06, 12.24s/it] 91%|█████████ | 2157/2382 [6:38:48<43:21, 11.56s/it]                                                     {'loss': 2.1729, 'learning_rate': 2.32268009605362e-05, 'epoch': 0.91}
 91%|█████████ | 2157/2382 [6:38:48<43:21, 11.56s/it] 91%|█████████ | 2158/2382 [6:38:59<42:51, 11.48s/it]                                                     {'loss': 2.0566, 'learning_rate': 2.3022395011543685e-05, 'epoch': 0.91}
 91%|█████████ | 2158/2382 [6:38:59<42:51, 11.48s/it] 91%|█████████ | 2159/2382 [6:39:10<41:53, 11.27s/it]                                                     {'loss': 1.9286, 'learning_rate': 2.281887127606741e-05, 'epoch': 0.91}
 91%|█████████ | 2159/2382 [6:39:10<41:53, 11.27s/it] 91%|█████████ | 2160/2382 [6:39:21<41:35, 11.24s/it]                                                     {'loss': 2.2234, 'learning_rate': 2.261623013054298e-05, 'epoch': 0.91}
 91%|█████████ | 2160/2382 [6:39:21<41:35, 11.24s/it] 91%|█████████ | 2161/2382 [6:39:31<40:19, 10.95s/it]                                                     {'loss': 2.1242, 'learning_rate': 2.241447194977364e-05, 'epoch': 0.91}
 91%|█████████ | 2161/2382 [6:39:31<40:19, 10.95s/it] 91%|█████████ | 2162/2382 [6:39:41<38:53, 10.61s/it]                                                     {'loss': 2.0125, 'learning_rate': 2.2213597106929607e-05, 'epoch': 0.91}
 91%|█████████ | 2162/2382 [6:39:41<38:53, 10.61s/it] 91%|█████████ | 2163/2382 [6:39:52<38:48, 10.63s/it]                                                     {'loss': 2.1158, 'learning_rate': 2.201360597354718e-05, 'epoch': 0.91}
 91%|█████████ | 2163/2382 [6:39:52<38:48, 10.63s/it] 91%|█████████ | 2164/2382 [6:40:02<38:33, 10.61s/it]                                                     {'loss': 2.0471, 'learning_rate': 2.181449891952819e-05, 'epoch': 0.91}
 91%|█████████ | 2164/2382 [6:40:02<38:33, 10.61s/it] 91%|█████████ | 2165/2382 [6:40:11<36:56, 10.22s/it]                                                     {'loss': 2.0403, 'learning_rate': 2.1616276313139227e-05, 'epoch': 0.91}
 91%|█████████ | 2165/2382 [6:40:11<36:56, 10.22s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1441 > 1024). Running this sequence through the model will result in indexing errors
 91%|█████████ | 2166/2382 [6:40:22<37:09, 10.32s/it]                                                     {'loss': 2.074, 'learning_rate': 2.1418938521010955e-05, 'epoch': 0.91}
 91%|█████████ | 2166/2382 [6:40:22<37:09, 10.32s/it] 91%|█████████ | 2167/2382 [6:40:33<37:40, 10.51s/it]                                                     {'loss': 2.0113, 'learning_rate': 2.1222485908137746e-05, 'epoch': 0.91}
 91%|█████████ | 2167/2382 [6:40:33<37:40, 10.51s/it] 91%|█████████ | 2168/2382 [6:40:43<37:24, 10.49s/it]                                                     {'loss': 1.9971, 'learning_rate': 2.1026918837876497e-05, 'epoch': 0.91}
 91%|█████████ | 2168/2382 [6:40:43<37:24, 10.49s/it] 91%|█████████ | 2169/2382 [6:40:56<39:36, 11.16s/it]                                                     {'loss': 2.2174, 'learning_rate': 2.0832237671946363e-05, 'epoch': 0.91}
 91%|█████████ | 2169/2382 [6:40:56<39:36, 11.16s/it] 91%|█████████ | 2170/2382 [6:41:06<37:37, 10.65s/it]                                                     {'loss': 2.0302, 'learning_rate': 2.0638442770427867e-05, 'epoch': 0.91}
 91%|█████████ | 2170/2382 [6:41:06<37:37, 10.65s/it] 91%|█████████ | 2171/2382 [6:41:16<37:15, 10.59s/it]                                                     {'loss': 2.0331, 'learning_rate': 2.0445534491762395e-05, 'epoch': 0.91}
 91%|█████████ | 2171/2382 [6:41:16<37:15, 10.59s/it] 91%|█████████ | 2172/2382 [6:41:28<38:29, 11.00s/it]                                                     {'loss': 2.0029, 'learning_rate': 2.025351319275137e-05, 'epoch': 0.91}
 91%|█████████ | 2172/2382 [6:41:28<38:29, 11.00s/it] 91%|█████████ | 2173/2382 [6:41:39<38:24, 11.02s/it]                                                     {'loss': 1.9764, 'learning_rate': 2.0062379228555526e-05, 'epoch': 0.91}
 91%|█████████ | 2173/2382 [6:41:39<38:24, 11.02s/it] 91%|█████████▏| 2174/2382 [6:41:49<37:19, 10.76s/it]                                                     {'loss': 1.994, 'learning_rate': 1.9872132952694632e-05, 'epoch': 0.91}
 91%|█████████▏| 2174/2382 [6:41:49<37:19, 10.76s/it] 91%|█████████▏| 2175/2382 [6:42:00<36:56, 10.71s/it]                                                     {'loss': 2.0339, 'learning_rate': 1.968277471704649e-05, 'epoch': 0.91}
 91%|█████████▏| 2175/2382 [6:42:00<36:56, 10.71s/it] 91%|█████████▏| 2176/2382 [6:42:11<36:54, 10.75s/it]                                                     {'loss': 2.0862, 'learning_rate': 1.9494304871846447e-05, 'epoch': 0.91}
 91%|█████████▏| 2176/2382 [6:42:11<36:54, 10.75s/it] 91%|█████████▏| 2177/2382 [6:42:21<36:01, 10.54s/it]                                                     {'loss': 1.9854, 'learning_rate': 1.9306723765686595e-05, 'epoch': 0.91}
 91%|█████████▏| 2177/2382 [6:42:21<36:01, 10.54s/it] 91%|█████████▏| 2178/2382 [6:42:31<35:57, 10.57s/it]                                                     {'loss': 1.995, 'learning_rate': 1.9120031745515298e-05, 'epoch': 0.91}
 91%|█████████▏| 2178/2382 [6:42:31<35:57, 10.57s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1227 > 1024). Running this sequence through the model will result in indexing errors
 91%|█████████▏| 2179/2382 [6:42:42<36:02, 10.65s/it]                                                     {'loss': 2.0718, 'learning_rate': 1.893422915663645e-05, 'epoch': 0.91}
 91%|█████████▏| 2179/2382 [6:42:42<36:02, 10.65s/it] 92%|█████████▏| 2180/2382 [6:42:53<36:16, 10.77s/it]                                                     {'loss': 1.947, 'learning_rate': 1.8749316342708823e-05, 'epoch': 0.91}
 92%|█████████▏| 2180/2382 [6:42:53<36:16, 10.77s/it] 92%|█████████▏| 2181/2382 [6:43:06<37:36, 11.22s/it]                                                     {'loss': 2.0052, 'learning_rate': 1.8565293645745495e-05, 'epoch': 0.92}
 92%|█████████▏| 2181/2382 [6:43:06<37:36, 11.22s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1121 > 1024). Running this sequence through the model will result in indexing errors
 92%|█████████▏| 2182/2382 [6:43:17<37:37, 11.29s/it]                                                     {'loss': 2.1521, 'learning_rate': 1.8382161406113208e-05, 'epoch': 0.92}
 92%|█████████▏| 2182/2382 [6:43:17<37:37, 11.29s/it] 92%|█████████▏| 2183/2382 [6:43:26<35:14, 10.62s/it]                                                     {'loss': 2.1184, 'learning_rate': 1.8199919962531843e-05, 'epoch': 0.92}
 92%|█████████▏| 2183/2382 [6:43:26<35:14, 10.62s/it] 92%|█████████▏| 2184/2382 [6:43:36<34:31, 10.46s/it]                                                     {'loss': 2.0031, 'learning_rate': 1.801856965207338e-05, 'epoch': 0.92}
 92%|█████████▏| 2184/2382 [6:43:36<34:31, 10.46s/it] 92%|█████████▏| 2185/2382 [6:43:47<34:51, 10.62s/it]                                                     {'loss': 2.0662, 'learning_rate': 1.7838110810161788e-05, 'epoch': 0.92}
 92%|█████████▏| 2185/2382 [6:43:47<34:51, 10.62s/it] 92%|█████████▏| 2186/2382 [6:43:58<34:41, 10.62s/it]                                                     {'loss': 2.0437, 'learning_rate': 1.765854377057219e-05, 'epoch': 0.92}
 92%|█████████▏| 2186/2382 [6:43:58<34:41, 10.62s/it] 92%|█████████▏| 2187/2382 [6:44:08<34:20, 10.57s/it]                                                     {'loss': 2.0169, 'learning_rate': 1.747986886543007e-05, 'epoch': 0.92}
 92%|█████████▏| 2187/2382 [6:44:08<34:20, 10.57s/it] 92%|█████████▏| 2188/2382 [6:44:22<36:52, 11.40s/it]                                                     {'loss': 1.9829, 'learning_rate': 1.7302086425210973e-05, 'epoch': 0.92}
 92%|█████████▏| 2188/2382 [6:44:22<36:52, 11.40s/it] 92%|█████████▏| 2189/2382 [6:44:32<35:46, 11.12s/it]                                                     {'loss': 1.989, 'learning_rate': 1.7125196778739804e-05, 'epoch': 0.92}
 92%|█████████▏| 2189/2382 [6:44:32<35:46, 11.12s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1311 > 1024). Running this sequence through the model will result in indexing errors
 92%|█████████▏| 2190/2382 [6:44:43<35:32, 11.11s/it]                                                     {'loss': 2.0427, 'learning_rate': 1.6949200253189966e-05, 'epoch': 0.92}
 92%|█████████▏| 2190/2382 [6:44:43<35:32, 11.11s/it] 92%|█████████▏| 2191/2382 [6:44:52<33:25, 10.50s/it]                                                     {'loss': 2.0214, 'learning_rate': 1.677409717408307e-05, 'epoch': 0.92}
 92%|█████████▏| 2191/2382 [6:44:52<33:25, 10.50s/it] 92%|█████████▏| 2192/2382 [6:45:05<35:12, 11.12s/it]                                                     {'loss': 1.969, 'learning_rate': 1.659988786528821e-05, 'epoch': 0.92}
 92%|█████████▏| 2192/2382 [6:45:05<35:12, 11.12s/it] 92%|█████████▏| 2193/2382 [6:45:15<34:26, 10.93s/it]                                                     {'loss': 1.9838, 'learning_rate': 1.6426572649021475e-05, 'epoch': 0.92}
 92%|█████████▏| 2193/2382 [6:45:15<34:26, 10.93s/it] 92%|█████████▏| 2194/2382 [6:45:27<34:44, 11.09s/it]                                                     {'loss': 1.9642, 'learning_rate': 1.6254151845844943e-05, 'epoch': 0.92}
 92%|█████████▏| 2194/2382 [6:45:27<34:44, 11.09s/it] 92%|█████████▏| 2195/2382 [6:45:38<34:52, 11.19s/it]                                                     {'loss': 1.96, 'learning_rate': 1.608262577466679e-05, 'epoch': 0.92}
 92%|█████████▏| 2195/2382 [6:45:38<34:52, 11.19s/it] 92%|█████████▏| 2196/2382 [6:45:50<34:51, 11.25s/it]                                                     {'loss': 1.9628, 'learning_rate': 1.5911994752739965e-05, 'epoch': 0.92}
 92%|█████████▏| 2196/2382 [6:45:50<34:51, 11.25s/it] 92%|█████████▏| 2197/2382 [6:45:59<33:06, 10.74s/it]                                                     {'loss': 2.0153, 'learning_rate': 1.5742259095662127e-05, 'epoch': 0.92}
 92%|█████████▏| 2197/2382 [6:45:59<33:06, 10.74s/it] 92%|█████████▏| 2198/2382 [6:46:12<34:41, 11.31s/it]                                                     {'loss': 2.0059, 'learning_rate': 1.557341911737481e-05, 'epoch': 0.92}
 92%|█████████▏| 2198/2382 [6:46:12<34:41, 11.31s/it] 92%|█████████▏| 2199/2382 [6:46:21<32:36, 10.69s/it]                                                     {'loss': 2.0426, 'learning_rate': 1.5405475130162992e-05, 'epoch': 0.92}
 92%|█████████▏| 2199/2382 [6:46:21<32:36, 10.69s/it] 92%|█████████▏| 2200/2382 [6:46:33<33:33, 11.06s/it]                                                     {'loss': 2.0876, 'learning_rate': 1.5238427444654367e-05, 'epoch': 0.92}
 92%|█████████▏| 2200/2382 [6:46:33<33:33, 11.06s/it] 92%|█████████▏| 2201/2382 [6:46:42<31:38, 10.49s/it]                                                     {'loss': 2.0626, 'learning_rate': 1.5072276369818783e-05, 'epoch': 0.92}
 92%|█████████▏| 2201/2382 [6:46:42<31:38, 10.49s/it] 92%|█████████▏| 2202/2382 [6:46:56<34:48, 11.60s/it]                                                     {'loss': 1.9543, 'learning_rate': 1.4907022212967803e-05, 'epoch': 0.92}
 92%|█████████▏| 2202/2382 [6:46:56<34:48, 11.60s/it] 92%|█████████▏| 2203/2382 [6:47:07<33:51, 11.35s/it]                                                     {'loss': 2.1632, 'learning_rate': 1.4742665279753986e-05, 'epoch': 0.92}
 92%|█████████▏| 2203/2382 [6:47:07<33:51, 11.35s/it] 93%|█████████▎| 2204/2382 [6:47:18<33:37, 11.33s/it]                                                     {'loss': 2.0779, 'learning_rate': 1.4579205874170554e-05, 'epoch': 0.92}
 93%|█████████▎| 2204/2382 [6:47:18<33:37, 11.33s/it] 93%|█████████▎| 2205/2382 [6:47:33<36:27, 12.36s/it]                                                     {'loss': 1.9175, 'learning_rate': 1.4416644298550497e-05, 'epoch': 0.93}
 93%|█████████▎| 2205/2382 [6:47:33<36:27, 12.36s/it] 93%|█████████▎| 2206/2382 [6:47:46<36:37, 12.48s/it]                                                     {'loss': 1.985, 'learning_rate': 1.4254980853566246e-05, 'epoch': 0.93}
 93%|█████████▎| 2206/2382 [6:47:46<36:37, 12.48s/it] 93%|█████████▎| 2207/2382 [6:47:56<34:09, 11.71s/it]                                                     {'loss': 2.0191, 'learning_rate': 1.4094215838229174e-05, 'epoch': 0.93}
 93%|█████████▎| 2207/2382 [6:47:56<34:09, 11.71s/it] 93%|█████████▎| 2208/2382 [6:48:05<31:53, 11.00s/it]                                                     {'loss': 2.1482, 'learning_rate': 1.3934349549888647e-05, 'epoch': 0.93}
 93%|█████████▎| 2208/2382 [6:48:05<31:53, 11.00s/it] 93%|█████████▎| 2209/2382 [6:48:17<32:31, 11.28s/it]                                                     {'loss': 1.9424, 'learning_rate': 1.3775382284232084e-05, 'epoch': 0.93}
 93%|█████████▎| 2209/2382 [6:48:17<32:31, 11.28s/it] 93%|█████████▎| 2210/2382 [6:48:27<31:27, 10.98s/it]                                                     {'loss': 2.0022, 'learning_rate': 1.3617314335283792e-05, 'epoch': 0.93}
 93%|█████████▎| 2210/2382 [6:48:27<31:27, 10.98s/it] 93%|█████████▎| 2211/2382 [6:48:40<32:33, 11.42s/it]                                                     {'loss': 2.0176, 'learning_rate': 1.3460145995404849e-05, 'epoch': 0.93}
 93%|█████████▎| 2211/2382 [6:48:40<32:33, 11.42s/it] 93%|█████████▎| 2212/2382 [6:48:50<30:59, 10.94s/it]                                                     {'loss': 2.0734, 'learning_rate': 1.3303877555292442e-05, 'epoch': 0.93}
 93%|█████████▎| 2212/2382 [6:48:50<30:59, 10.94s/it] 93%|█████████▎| 2213/2382 [6:49:01<30:55, 10.98s/it]                                                     {'loss': 2.0774, 'learning_rate': 1.3148509303979372e-05, 'epoch': 0.93}
 93%|█████████▎| 2213/2382 [6:49:01<30:55, 10.98s/it] 93%|█████████▎| 2214/2382 [6:49:10<29:40, 10.60s/it]                                                     {'loss': 2.1597, 'learning_rate': 1.2994041528833267e-05, 'epoch': 0.93}
 93%|█████████▎| 2214/2382 [6:49:10<29:40, 10.60s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1159 > 1024). Running this sequence through the model will result in indexing errors
 93%|█████████▎| 2215/2382 [6:49:21<29:14, 10.51s/it]                                                     {'loss': 1.9348, 'learning_rate': 1.2840474515556311e-05, 'epoch': 0.93}
 93%|█████████▎| 2215/2382 [6:49:21<29:14, 10.51s/it] 93%|█████████▎| 2216/2382 [6:49:29<27:24,  9.91s/it]                                                     {'loss': 2.1653, 'learning_rate': 1.2687808548184798e-05, 'epoch': 0.93}
 93%|█████████▎| 2216/2382 [6:49:29<27:24,  9.91s/it] 93%|█████████▎| 2217/2382 [6:49:41<28:58, 10.54s/it]                                                     {'loss': 1.9727, 'learning_rate': 1.2536043909088191e-05, 'epoch': 0.93}
 93%|█████████▎| 2217/2382 [6:49:41<28:58, 10.54s/it] 93%|█████████▎| 2218/2382 [6:49:53<29:59, 10.98s/it]                                                     {'loss': 2.165, 'learning_rate': 1.2385180878969115e-05, 'epoch': 0.93}
 93%|█████████▎| 2218/2382 [6:49:53<29:59, 10.98s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1165 > 1024). Running this sequence through the model will result in indexing errors
 93%|█████████▎| 2219/2382 [6:50:04<29:36, 10.90s/it]                                                     {'loss': 1.9947, 'learning_rate': 1.2235219736862534e-05, 'epoch': 0.93}
 93%|█████████▎| 2219/2382 [6:50:04<29:36, 10.90s/it] 93%|█████████▎| 2220/2382 [6:50:13<27:54, 10.34s/it]                                                     {'loss': 2.1, 'learning_rate': 1.2086160760135078e-05, 'epoch': 0.93}
 93%|█████████▎| 2220/2382 [6:50:13<27:54, 10.34s/it] 93%|█████████▎| 2221/2382 [6:50:23<27:34, 10.28s/it]                                                     {'loss': 2.0224, 'learning_rate': 1.1938004224484989e-05, 'epoch': 0.93}
 93%|█████████▎| 2221/2382 [6:50:23<27:34, 10.28s/it] 93%|█████████▎| 2222/2382 [6:50:33<26:49, 10.06s/it]                                                     {'loss': 2.0501, 'learning_rate': 1.1790750403941231e-05, 'epoch': 0.93}
 93%|█████████▎| 2222/2382 [6:50:33<26:49, 10.06s/it] 93%|█████████▎| 2223/2382 [6:50:44<27:21, 10.33s/it]                                                     {'loss': 2.1035, 'learning_rate': 1.1644399570863273e-05, 'epoch': 0.93}
 93%|█████████▎| 2223/2382 [6:50:44<27:21, 10.33s/it] 93%|█████████▎| 2224/2382 [6:50:55<27:44, 10.53s/it]                                                     {'loss': 2.0679, 'learning_rate': 1.1498951995940144e-05, 'epoch': 0.93}
 93%|█████████▎| 2224/2382 [6:50:55<27:44, 10.53s/it] 93%|█████████▎| 2225/2382 [6:51:05<27:33, 10.53s/it]                                                     {'loss': 2.0906, 'learning_rate': 1.1354407948190536e-05, 'epoch': 0.93}
 93%|█████████▎| 2225/2382 [6:51:05<27:33, 10.53s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1186 > 1024). Running this sequence through the model will result in indexing errors
 93%|█████████▎| 2226/2382 [6:51:17<28:08, 10.83s/it]                                                     {'loss': 2.0031, 'learning_rate': 1.1210767694961654e-05, 'epoch': 0.93}
 93%|█████████▎| 2226/2382 [6:51:17<28:08, 10.83s/it] 93%|█████████▎| 2227/2382 [6:51:27<27:17, 10.57s/it]                                                     {'loss': 2.062, 'learning_rate': 1.1068031501929366e-05, 'epoch': 0.93}
 93%|█████████▎| 2227/2382 [6:51:27<27:17, 10.57s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1122 > 1024). Running this sequence through the model will result in indexing errors
 94%|█████████▎| 2228/2382 [6:51:36<26:39, 10.38s/it]                                                     {'loss': 1.9664, 'learning_rate': 1.0926199633097156e-05, 'epoch': 0.94}
 94%|█████████▎| 2228/2382 [6:51:36<26:39, 10.38s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1443 > 1024). Running this sequence through the model will result in indexing errors
 94%|█████████▎| 2229/2382 [6:51:46<26:01, 10.20s/it]                                                     {'loss': 1.9982, 'learning_rate': 1.0785272350796127e-05, 'epoch': 0.94}
 94%|█████████▎| 2229/2382 [6:51:46<26:01, 10.20s/it] 94%|█████████▎| 2230/2382 [6:51:56<25:40, 10.13s/it]                                                     {'loss': 2.0049, 'learning_rate': 1.0645249915683997e-05, 'epoch': 0.94}
 94%|█████████▎| 2230/2382 [6:51:56<25:40, 10.13s/it] 94%|█████████▎| 2231/2382 [6:52:09<27:49, 11.05s/it]                                                     {'loss': 1.9973, 'learning_rate': 1.0506132586745098e-05, 'epoch': 0.94}
 94%|█████████▎| 2231/2382 [6:52:09<27:49, 11.05s/it] 94%|█████████▎| 2232/2382 [6:52:19<26:13, 10.49s/it]                                                     {'loss': 2.1609, 'learning_rate': 1.0367920621289494e-05, 'epoch': 0.94}
 94%|█████████▎| 2232/2382 [6:52:19<26:13, 10.49s/it] 94%|█████████▎| 2233/2382 [6:52:31<27:29, 11.07s/it]                                                     {'loss': 2.0143, 'learning_rate': 1.023061427495281e-05, 'epoch': 0.94}
 94%|█████████▎| 2233/2382 [6:52:31<27:29, 11.07s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1030 > 1024). Running this sequence through the model will result in indexing errors
 94%|█████████▍| 2234/2382 [6:52:42<26:54, 10.91s/it]                                                     {'loss': 2.0342, 'learning_rate': 1.0094213801695729e-05, 'epoch': 0.94}
 94%|█████████▍| 2234/2382 [6:52:42<26:54, 10.91s/it] 94%|█████████▍| 2235/2382 [6:52:54<27:50, 11.36s/it]                                                     {'loss': 2.0329, 'learning_rate': 9.958719453803277e-06, 'epoch': 0.94}
 94%|█████████▍| 2235/2382 [6:52:54<27:50, 11.36s/it] 94%|█████████▍| 2236/2382 [6:53:05<27:18, 11.22s/it]                                                     {'loss': 2.0286, 'learning_rate': 9.824131481884658e-06, 'epoch': 0.94}
 94%|█████████▍| 2236/2382 [6:53:05<27:18, 11.22s/it] 94%|█████████▍| 2237/2382 [6:53:15<26:19, 10.89s/it]                                                     {'loss': 1.9288, 'learning_rate': 9.690450134872519e-06, 'epoch': 0.94}
 94%|█████████▍| 2237/2382 [6:53:15<26:19, 10.89s/it] 94%|█████████▍| 2238/2382 [6:53:25<25:25, 10.59s/it]                                                     {'loss': 2.0561, 'learning_rate': 9.557675660022746e-06, 'epoch': 0.94}
 94%|█████████▍| 2238/2382 [6:53:25<25:25, 10.59s/it] 94%|█████████▍| 2239/2382 [6:53:35<25:12, 10.58s/it]                                                     {'loss': 1.9802, 'learning_rate': 9.42580830291373e-06, 'epoch': 0.94}
 94%|█████████▍| 2239/2382 [6:53:35<25:12, 10.58s/it] 94%|█████████▍| 2240/2382 [6:53:46<24:50, 10.50s/it]                                                     {'loss': 2.0543, 'learning_rate': 9.294848307446201e-06, 'epoch': 0.94}
 94%|█████████▍| 2240/2382 [6:53:46<24:50, 10.50s/it] 94%|█████████▍| 2241/2382 [6:53:56<24:41, 10.51s/it]                                                     {'loss': 2.0634, 'learning_rate': 9.164795915842572e-06, 'epoch': 0.94}
 94%|█████████▍| 2241/2382 [6:53:56<24:41, 10.51s/it] 94%|█████████▍| 2242/2382 [6:54:08<25:35, 10.97s/it]                                                     {'loss': 2.1029, 'learning_rate': 9.035651368646646e-06, 'epoch': 0.94}
 94%|█████████▍| 2242/2382 [6:54:08<25:35, 10.97s/it] 94%|█████████▍| 2243/2382 [6:54:19<25:13, 10.89s/it]                                                     {'loss': 2.0925, 'learning_rate': 8.907414904723022e-06, 'epoch': 0.94}
 94%|█████████▍| 2243/2382 [6:54:19<25:13, 10.89s/it] 94%|█████████▍| 2244/2382 [6:54:32<26:38, 11.58s/it]                                                     {'loss': 2.0077, 'learning_rate': 8.780086761256634e-06, 'epoch': 0.94}
 94%|█████████▍| 2244/2382 [6:54:32<26:38, 11.58s/it] 94%|█████████▍| 2245/2382 [6:54:44<26:53, 11.78s/it]                                                     {'loss': 2.0014, 'learning_rate': 8.653667173752544e-06, 'epoch': 0.94}
 94%|█████████▍| 2245/2382 [6:54:44<26:53, 11.78s/it] 94%|█████████▍| 2246/2382 [6:54:56<26:14, 11.58s/it]                                                     {'loss': 2.0325, 'learning_rate': 8.528156376035324e-06, 'epoch': 0.94}
 94%|█████████▍| 2246/2382 [6:54:56<26:14, 11.58s/it] 94%|█████████▍| 2247/2382 [6:55:07<25:58, 11.55s/it]                                                     {'loss': 1.9541, 'learning_rate': 8.403554600248498e-06, 'epoch': 0.94}
 94%|█████████▍| 2247/2382 [6:55:07<25:58, 11.55s/it] 94%|█████████▍| 2248/2382 [6:55:19<25:49, 11.57s/it]                                                     {'loss': 2.021, 'learning_rate': 8.27986207685455e-06, 'epoch': 0.94}
 94%|█████████▍| 2248/2382 [6:55:19<25:49, 11.57s/it] 94%|█████████▍| 2249/2382 [6:55:27<23:47, 10.74s/it]                                                     {'loss': 2.042, 'learning_rate': 8.157079034633974e-06, 'epoch': 0.94}
 94%|█████████▍| 2249/2382 [6:55:27<23:47, 10.74s/it] 94%|█████████▍| 2250/2382 [6:55:39<24:11, 10.99s/it]                                                     {'loss': 2.0015, 'learning_rate': 8.035205700685167e-06, 'epoch': 0.94}
 94%|█████████▍| 2250/2382 [6:55:39<24:11, 10.99s/it] 95%|█████████▍| 2251/2382 [6:55:50<23:38, 10.83s/it]                                                     {'loss': 1.9337, 'learning_rate': 7.914242300424034e-06, 'epoch': 0.94}
 95%|█████████▍| 2251/2382 [6:55:50<23:38, 10.83s/it] 95%|█████████▍| 2252/2382 [6:55:58<22:08, 10.22s/it]                                                     {'loss': 2.0832, 'learning_rate': 7.794189057583333e-06, 'epoch': 0.95}
 95%|█████████▍| 2252/2382 [6:55:58<22:08, 10.22s/it] 95%|█████████▍| 2253/2382 [6:56:07<20:46,  9.66s/it]                                                     {'loss': 1.942, 'learning_rate': 7.675046194212553e-06, 'epoch': 0.95}
 95%|█████████▍| 2253/2382 [6:56:07<20:46,  9.66s/it] 95%|█████████▍| 2254/2382 [6:56:18<21:23, 10.03s/it]                                                     {'loss': 1.9702, 'learning_rate': 7.5568139306771975e-06, 'epoch': 0.95}
 95%|█████████▍| 2254/2382 [6:56:18<21:23, 10.03s/it] 95%|█████████▍| 2255/2382 [6:56:27<21:05,  9.97s/it]                                                     {'loss': 2.0719, 'learning_rate': 7.439492485658617e-06, 'epoch': 0.95}
 95%|█████████▍| 2255/2382 [6:56:27<21:05,  9.97s/it] 95%|█████████▍| 2256/2382 [6:56:37<21:00, 10.00s/it]                                                     {'loss': 2.0962, 'learning_rate': 7.323082076153509e-06, 'epoch': 0.95}
 95%|█████████▍| 2256/2382 [6:56:37<21:00, 10.00s/it] 95%|█████████▍| 2257/2382 [6:56:47<20:25,  9.80s/it]                                                     {'loss': 2.0459, 'learning_rate': 7.207582917473532e-06, 'epoch': 0.95}
 95%|█████████▍| 2257/2382 [6:56:47<20:25,  9.80s/it] 95%|█████████▍| 2258/2382 [6:56:59<21:49, 10.56s/it]                                                     {'loss': 2.015, 'learning_rate': 7.092995223244858e-06, 'epoch': 0.95}
 95%|█████████▍| 2258/2382 [6:56:59<21:49, 10.56s/it] 95%|█████████▍| 2259/2382 [6:57:08<20:28,  9.98s/it]                                                     {'loss': 2.1819, 'learning_rate': 6.979319205407953e-06, 'epoch': 0.95}
 95%|█████████▍| 2259/2382 [6:57:08<20:28,  9.98s/it] 95%|█████████▍| 2260/2382 [6:57:19<21:06, 10.38s/it]                                                     {'loss': 1.9798, 'learning_rate': 6.866555074216962e-06, 'epoch': 0.95}
 95%|█████████▍| 2260/2382 [6:57:19<21:06, 10.38s/it] 95%|█████████▍| 2261/2382 [6:57:30<21:29, 10.66s/it]                                                     {'loss': 2.1001, 'learning_rate': 6.754703038239329e-06, 'epoch': 0.95}
 95%|█████████▍| 2261/2382 [6:57:30<21:29, 10.66s/it] 95%|█████████▍| 2262/2382 [6:57:41<21:08, 10.57s/it]                                                     {'loss': 1.9282, 'learning_rate': 6.6437633043555655e-06, 'epoch': 0.95}
 95%|█████████▍| 2262/2382 [6:57:41<21:08, 10.57s/it] 95%|█████████▌| 2263/2382 [6:57:53<21:56, 11.06s/it]                                                     {'loss': 2.0537, 'learning_rate': 6.533736077758867e-06, 'epoch': 0.95}
 95%|█████████▌| 2263/2382 [6:57:53<21:56, 11.06s/it] 95%|█████████▌| 2264/2382 [6:58:02<20:21, 10.35s/it]                                                     {'loss': 1.9979, 'learning_rate': 6.424621561954613e-06, 'epoch': 0.95}
 95%|█████████▌| 2264/2382 [6:58:02<20:21, 10.35s/it] 95%|█████████▌| 2265/2382 [6:58:13<20:52, 10.71s/it]                                                     {'loss': 1.9631, 'learning_rate': 6.316419958760089e-06, 'epoch': 0.95}
 95%|█████████▌| 2265/2382 [6:58:13<20:52, 10.71s/it] 95%|█████████▌| 2266/2382 [6:58:24<20:32, 10.63s/it]                                                     {'loss': 1.9509, 'learning_rate': 6.2091314683039304e-06, 'epoch': 0.95}
 95%|█████████▌| 2266/2382 [6:58:24<20:32, 10.63s/it] 95%|█████████▌| 2267/2382 [6:58:33<19:51, 10.36s/it]                                                     {'loss': 2.0683, 'learning_rate': 6.102756289025957e-06, 'epoch': 0.95}
 95%|█████████▌| 2267/2382 [6:58:33<19:51, 10.36s/it] 95%|█████████▌| 2268/2382 [6:58:45<20:13, 10.64s/it]                                                     {'loss': 2.0509, 'learning_rate': 5.997294617676841e-06, 'epoch': 0.95}
 95%|█████████▌| 2268/2382 [6:58:45<20:13, 10.64s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1205 > 1024). Running this sequence through the model will result in indexing errors
 95%|█████████▌| 2269/2382 [6:58:57<20:45, 11.03s/it]                                                     {'loss': 2.0046, 'learning_rate': 5.892746649317438e-06, 'epoch': 0.95}
 95%|█████████▌| 2269/2382 [6:58:57<20:45, 11.03s/it] 95%|█████████▌| 2270/2382 [6:59:04<18:30,  9.91s/it]                                                     {'loss': 2.139, 'learning_rate': 5.789112577318789e-06, 'epoch': 0.95}
 95%|█████████▌| 2270/2382 [6:59:04<18:30,  9.91s/it] 95%|█████████▌| 2271/2382 [6:59:13<18:10,  9.82s/it]                                                     {'loss': 2.0788, 'learning_rate': 5.686392593361567e-06, 'epoch': 0.95}
 95%|█████████▌| 2271/2382 [6:59:13<18:10,  9.82s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1409 > 1024). Running this sequence through the model will result in indexing errors
 95%|█████████▌| 2272/2382 [6:59:23<17:58,  9.81s/it]                                                     {'loss': 2.0778, 'learning_rate': 5.5845868874357386e-06, 'epoch': 0.95}
 95%|█████████▌| 2272/2382 [6:59:23<17:58,  9.81s/it] 95%|█████████▌| 2273/2382 [6:59:32<17:24,  9.58s/it]                                                     {'loss': 2.0933, 'learning_rate': 5.483695647840181e-06, 'epoch': 0.95}
 95%|█████████▌| 2273/2382 [6:59:32<17:24,  9.58s/it] 95%|█████████▌| 2274/2382 [6:59:45<18:55, 10.52s/it]                                                     {'loss': 2.0702, 'learning_rate': 5.383719061182457e-06, 'epoch': 0.95}
 95%|█████████▌| 2274/2382 [6:59:45<18:55, 10.52s/it] 96%|█████████▌| 2275/2382 [6:59:56<18:59, 10.65s/it]                                                     {'loss': 1.9614, 'learning_rate': 5.284657312378427e-06, 'epoch': 0.95}
 96%|█████████▌| 2275/2382 [6:59:56<18:59, 10.65s/it] 96%|█████████▌| 2276/2382 [7:00:08<19:23, 10.97s/it]                                                     {'loss': 2.1268, 'learning_rate': 5.186510584651693e-06, 'epoch': 0.96}
 96%|█████████▌| 2276/2382 [7:00:08<19:23, 10.97s/it] 96%|█████████▌| 2277/2382 [7:00:18<18:35, 10.63s/it]                                                     {'loss': 2.0159, 'learning_rate': 5.089279059533658e-06, 'epoch': 0.96}
 96%|█████████▌| 2277/2382 [7:00:18<18:35, 10.63s/it] 96%|█████████▌| 2278/2382 [7:00:27<17:56, 10.35s/it]                                                     {'loss': 2.0411, 'learning_rate': 4.992962916862853e-06, 'epoch': 0.96}
 96%|█████████▌| 2278/2382 [7:00:27<17:56, 10.35s/it] 96%|█████████▌| 2279/2382 [7:00:37<17:14, 10.05s/it]                                                     {'loss': 1.9665, 'learning_rate': 4.897562334784722e-06, 'epoch': 0.96}
 96%|█████████▌| 2279/2382 [7:00:37<17:14, 10.05s/it] 96%|█████████▌| 2280/2382 [7:00:46<16:54,  9.95s/it]                                                     {'loss': 2.0709, 'learning_rate': 4.803077489751395e-06, 'epoch': 0.96}
 96%|█████████▌| 2280/2382 [7:00:46<16:54,  9.95s/it] 96%|█████████▌| 2281/2382 [7:00:57<17:06, 10.17s/it]                                                     {'loss': 2.0597, 'learning_rate': 4.709508556521136e-06, 'epoch': 0.96}
 96%|█████████▌| 2281/2382 [7:00:57<17:06, 10.17s/it] 96%|█████████▌| 2282/2382 [7:01:07<16:49, 10.10s/it]                                                     {'loss': 2.0359, 'learning_rate': 4.6168557081582855e-06, 'epoch': 0.96}
 96%|█████████▌| 2282/2382 [7:01:07<16:49, 10.10s/it] 96%|█████████▌| 2283/2382 [7:01:19<17:47, 10.79s/it]                                                     {'loss': 2.0197, 'learning_rate': 4.52511911603265e-06, 'epoch': 0.96}
 96%|█████████▌| 2283/2382 [7:01:19<17:47, 10.79s/it] 96%|█████████▌| 2284/2382 [7:01:32<18:20, 11.23s/it]                                                     {'loss': 1.9538, 'learning_rate': 4.434298949819449e-06, 'epoch': 0.96}
 96%|█████████▌| 2284/2382 [7:01:32<18:20, 11.23s/it] 96%|█████████▌| 2285/2382 [7:01:42<17:44, 10.98s/it]                                                     {'loss': 2.0604, 'learning_rate': 4.344395377498811e-06, 'epoch': 0.96}
 96%|█████████▌| 2285/2382 [7:01:42<17:44, 10.98s/it] 96%|█████████▌| 2286/2382 [7:01:54<18:02, 11.28s/it]                                                     {'loss': 2.0663, 'learning_rate': 4.255408565355612e-06, 'epoch': 0.96}
 96%|█████████▌| 2286/2382 [7:01:54<18:02, 11.28s/it] 96%|█████████▌| 2287/2382 [7:02:02<16:29, 10.41s/it]                                                     {'loss': 2.0462, 'learning_rate': 4.167338677979026e-06, 'epoch': 0.96}
 96%|█████████▌| 2287/2382 [7:02:02<16:29, 10.41s/it] 96%|█████████▌| 2288/2382 [7:02:16<17:53, 11.42s/it]                                                     {'loss': 2.0154, 'learning_rate': 4.080185878262421e-06, 'epoch': 0.96}
 96%|█████████▌| 2288/2382 [7:02:16<17:53, 11.42s/it] 96%|█████████▌| 2289/2382 [7:02:28<17:45, 11.46s/it]                                                     {'loss': 1.9618, 'learning_rate': 3.99395032740274e-06, 'epoch': 0.96}
 96%|█████████▌| 2289/2382 [7:02:28<17:45, 11.46s/it] 96%|█████████▌| 2290/2382 [7:02:37<16:48, 10.96s/it]                                                     {'loss': 1.9816, 'learning_rate': 3.908632184900562e-06, 'epoch': 0.96}
 96%|█████████▌| 2290/2382 [7:02:37<16:48, 10.96s/it] 96%|█████████▌| 2291/2382 [7:02:49<17:01, 11.22s/it]                                                     {'loss': 2.0954, 'learning_rate': 3.8242316085594916e-06, 'epoch': 0.96}
 96%|█████████▌| 2291/2382 [7:02:49<17:01, 11.22s/it] 96%|█████████▌| 2292/2382 [7:03:01<17:15, 11.51s/it]                                                     {'loss': 2.023, 'learning_rate': 3.7407487544861563e-06, 'epoch': 0.96}
 96%|█████████▌| 2292/2382 [7:03:01<17:15, 11.51s/it] 96%|█████████▋| 2293/2382 [7:03:11<16:07, 10.87s/it]                                                     {'loss': 2.0873, 'learning_rate': 3.6581837770895965e-06, 'epoch': 0.96}
 96%|█████████▋| 2293/2382 [7:03:11<16:07, 10.87s/it] 96%|█████████▋| 2294/2382 [7:03:21<15:30, 10.57s/it]                                                     {'loss': 1.9869, 'learning_rate': 3.576536829081323e-06, 'epoch': 0.96}
 96%|█████████▋| 2294/2382 [7:03:21<15:30, 10.57s/it] 96%|█████████▋| 2295/2382 [7:03:31<15:14, 10.51s/it]                                                     {'loss': 1.9739, 'learning_rate': 3.4958080614748145e-06, 'epoch': 0.96}
 96%|█████████▋| 2295/2382 [7:03:31<15:14, 10.51s/it] 96%|█████████▋| 2296/2382 [7:03:42<15:03, 10.51s/it]                                                     {'loss': 1.9911, 'learning_rate': 3.4159976235852984e-06, 'epoch': 0.96}
 96%|█████████▋| 2296/2382 [7:03:42<15:03, 10.51s/it] 96%|█████████▋| 2297/2382 [7:03:54<15:40, 11.07s/it]                                                     {'loss': 2.0379, 'learning_rate': 3.3371056630293604e-06, 'epoch': 0.96}
 96%|█████████▋| 2297/2382 [7:03:54<15:40, 11.07s/it] 96%|█████████▋| 2298/2382 [7:04:03<14:35, 10.42s/it]                                                     {'loss': 2.0794, 'learning_rate': 3.2591323257248896e-06, 'epoch': 0.96}
 96%|█████████▋| 2298/2382 [7:04:03<14:35, 10.42s/it] 97%|█████████▋| 2299/2382 [7:04:13<14:19, 10.36s/it]                                                     {'loss': 2.0198, 'learning_rate': 3.1820777558907444e-06, 'epoch': 0.96}
 97%|█████████▋| 2299/2382 [7:04:13<14:19, 10.36s/it] 97%|█████████▋| 2300/2382 [7:04:23<14:08, 10.35s/it]                                                     {'loss': 1.9397, 'learning_rate': 3.1059420960462548e-06, 'epoch': 0.97}
 97%|█████████▋| 2300/2382 [7:04:23<14:08, 10.35s/it] 97%|█████████▋| 2301/2382 [7:04:37<15:18, 11.34s/it]                                                     {'loss': 2.0199, 'learning_rate': 3.030725487011388e-06, 'epoch': 0.97}
 97%|█████████▋| 2301/2382 [7:04:37<15:18, 11.34s/it] 97%|█████████▋| 2302/2382 [7:04:48<15:03, 11.30s/it]                                                     {'loss': 2.0951, 'learning_rate': 2.956428067906025e-06, 'epoch': 0.97}
 97%|█████████▋| 2302/2382 [7:04:48<15:03, 11.30s/it] 97%|█████████▋| 2303/2382 [7:04:58<14:22, 10.91s/it]                                                     {'loss': 1.9502, 'learning_rate': 2.8830499761500207e-06, 'epoch': 0.97}
 97%|█████████▋| 2303/2382 [7:04:58<14:22, 10.91s/it] 97%|█████████▋| 2304/2382 [7:05:11<14:42, 11.32s/it]                                                     {'loss': 2.0317, 'learning_rate': 2.8105913474628653e-06, 'epoch': 0.97}
 97%|█████████▋| 2304/2382 [7:05:11<14:42, 11.32s/it] 97%|█████████▋| 2305/2382 [7:05:20<13:49, 10.77s/it]                                                     {'loss': 2.0571, 'learning_rate': 2.739052315863355e-06, 'epoch': 0.97}
 97%|█████████▋| 2305/2382 [7:05:20<13:49, 10.77s/it] 97%|█████████▋| 2306/2382 [7:05:34<14:50, 11.72s/it]                                                     {'loss': 2.0017, 'learning_rate': 2.6684330136694245e-06, 'epoch': 0.97}
 97%|█████████▋| 2306/2382 [7:05:34<14:50, 11.72s/it] 97%|█████████▋| 2307/2382 [7:05:45<14:31, 11.63s/it]                                                     {'loss': 1.9582, 'learning_rate': 2.5987335714979797e-06, 'epoch': 0.97}
 97%|█████████▋| 2307/2382 [7:05:45<14:31, 11.63s/it] 97%|█████████▋| 2308/2382 [7:05:55<13:45, 11.15s/it]                                                     {'loss': 2.0408, 'learning_rate': 2.529954118264455e-06, 'epoch': 0.97}
 97%|█████████▋| 2308/2382 [7:05:55<13:45, 11.15s/it] 97%|█████████▋| 2309/2382 [7:06:04<12:46, 10.50s/it]                                                     {'loss': 2.1234, 'learning_rate': 2.4620947811827e-06, 'epoch': 0.97}
 97%|█████████▋| 2309/2382 [7:06:04<12:46, 10.50s/it] 97%|█████████▋| 2310/2382 [7:06:15<12:30, 10.43s/it]                                                     {'loss': 1.9922, 'learning_rate': 2.395155685764705e-06, 'epoch': 0.97}
 97%|█████████▋| 2310/2382 [7:06:15<12:30, 10.43s/it] 97%|█████████▋| 2311/2382 [7:06:25<12:13, 10.32s/it]                                                     {'loss': 1.9261, 'learning_rate': 2.329136955820488e-06, 'epoch': 0.97}
 97%|█████████▋| 2311/2382 [7:06:25<12:13, 10.32s/it] 97%|█████████▋| 2312/2382 [7:06:36<12:16, 10.52s/it]                                                     {'loss': 2.1111, 'learning_rate': 2.2640387134577057e-06, 'epoch': 0.97}
 97%|█████████▋| 2312/2382 [7:06:36<12:16, 10.52s/it] 97%|█████████▋| 2313/2382 [7:06:45<11:46, 10.24s/it]                                                     {'loss': 2.0528, 'learning_rate': 2.199861079081433e-06, 'epoch': 0.97}
 97%|█████████▋| 2313/2382 [7:06:45<11:46, 10.24s/it] 97%|█████████▋| 2314/2382 [7:06:56<11:49, 10.43s/it]                                                     {'loss': 1.9724, 'learning_rate': 2.136604171394052e-06, 'epoch': 0.97}
 97%|█████████▋| 2314/2382 [7:06:56<11:49, 10.43s/it] 97%|█████████▋| 2315/2382 [7:07:08<12:03, 10.80s/it]                                                     {'loss': 2.0054, 'learning_rate': 2.0742681073950276e-06, 'epoch': 0.97}
 97%|█████████▋| 2315/2382 [7:07:08<12:03, 10.80s/it] 97%|█████████▋| 2316/2382 [7:07:17<11:21, 10.33s/it]                                                     {'loss': 2.0335, 'learning_rate': 2.012853002380466e-06, 'epoch': 0.97}
 97%|█████████▋| 2316/2382 [7:07:17<11:21, 10.33s/it] 97%|█████████▋| 2317/2382 [7:07:27<10:54, 10.07s/it]                                                     {'loss': 1.9402, 'learning_rate': 1.9523589699433354e-06, 'epoch': 0.97}
 97%|█████████▋| 2317/2382 [7:07:27<10:54, 10.07s/it] 97%|█████████▋| 2318/2382 [7:07:38<11:15, 10.55s/it]                                                     {'loss': 1.9741, 'learning_rate': 1.8927861219728005e-06, 'epoch': 0.97}
 97%|█████████▋| 2318/2382 [7:07:38<11:15, 10.55s/it] 97%|█████████▋| 2319/2382 [7:07:48<10:44, 10.23s/it]                                                     {'loss': 1.9713, 'learning_rate': 1.8341345686543331e-06, 'epoch': 0.97}
 97%|█████████▋| 2319/2382 [7:07:48<10:44, 10.23s/it] 97%|█████████▋| 2320/2382 [7:07:58<10:33, 10.21s/it]                                                     {'loss': 1.9937, 'learning_rate': 1.776404418469213e-06, 'epoch': 0.97}
 97%|█████████▋| 2320/2382 [7:07:58<10:33, 10.21s/it] 97%|█████████▋| 2321/2382 [7:08:08<10:17, 10.13s/it]                                                     {'loss': 2.0853, 'learning_rate': 1.7195957781946382e-06, 'epoch': 0.97}
 97%|█████████▋| 2321/2382 [7:08:08<10:17, 10.13s/it] 97%|█████████▋| 2322/2382 [7:08:20<10:45, 10.76s/it]                                                     {'loss': 1.934, 'learning_rate': 1.6637087529033922e-06, 'epoch': 0.97}
 97%|█████████▋| 2322/2382 [7:08:20<10:45, 10.76s/it] 98%|█████████▊| 2323/2382 [7:08:30<10:25, 10.60s/it]                                                     {'loss': 2.0011, 'learning_rate': 1.6087434459635674e-06, 'epoch': 0.97}
 98%|█████████▊| 2323/2382 [7:08:30<10:25, 10.60s/it] 98%|█████████▊| 2324/2382 [7:08:40<10:02, 10.39s/it]                                                     {'loss': 2.0422, 'learning_rate': 1.554699959038619e-06, 'epoch': 0.98}
 98%|█████████▊| 2324/2382 [7:08:40<10:02, 10.39s/it] 98%|█████████▊| 2325/2382 [7:08:50<09:45, 10.26s/it]                                                     {'loss': 2.0435, 'learning_rate': 1.5015783920867554e-06, 'epoch': 0.98}
 98%|█████████▊| 2325/2382 [7:08:50<09:45, 10.26s/it] 98%|█████████▊| 2326/2382 [7:08:59<09:13,  9.89s/it]                                                     {'loss': 2.0217, 'learning_rate': 1.4493788433612708e-06, 'epoch': 0.98}
 98%|█████████▊| 2326/2382 [7:08:59<09:13,  9.89s/it] 98%|█████████▊| 2327/2382 [7:09:10<09:16, 10.11s/it]                                                     {'loss': 2.0106, 'learning_rate': 1.3981014094099353e-06, 'epoch': 0.98}
 98%|█████████▊| 2327/2382 [7:09:10<09:16, 10.11s/it] 98%|█████████▊| 2328/2382 [7:09:23<09:56, 11.04s/it]                                                     {'loss': 2.0545, 'learning_rate': 1.347746185074994e-06, 'epoch': 0.98}
 98%|█████████▊| 2328/2382 [7:09:23<09:56, 11.04s/it] 98%|█████████▊| 2329/2382 [7:09:36<10:20, 11.72s/it]                                                     {'loss': 2.0267, 'learning_rate': 1.2983132634931117e-06, 'epoch': 0.98}
 98%|█████████▊| 2329/2382 [7:09:36<10:20, 11.72s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1181 > 1024). Running this sequence through the model will result in indexing errors
 98%|█████████▊| 2330/2382 [7:09:47<09:52, 11.40s/it]                                                     {'loss': 2.0721, 'learning_rate': 1.2498027360948739e-06, 'epoch': 0.98}
 98%|█████████▊| 2330/2382 [7:09:47<09:52, 11.40s/it] 98%|█████████▊| 2331/2382 [7:09:59<09:50, 11.57s/it]                                                     {'loss': 2.062, 'learning_rate': 1.2022146926049527e-06, 'epoch': 0.98}
 98%|█████████▊| 2331/2382 [7:09:59<09:50, 11.57s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1074 > 1024). Running this sequence through the model will result in indexing errors
 98%|█████████▊| 2332/2382 [7:10:10<09:27, 11.35s/it]                                                     {'loss': 1.9605, 'learning_rate': 1.1555492210418294e-06, 'epoch': 0.98}
 98%|█████████▊| 2332/2382 [7:10:10<09:27, 11.35s/it] 98%|█████████▊| 2333/2382 [7:10:25<10:13, 12.52s/it]                                                     {'loss': 2.1084, 'learning_rate': 1.1098064077174619e-06, 'epoch': 0.98}
 98%|█████████▊| 2333/2382 [7:10:25<10:13, 12.52s/it] 98%|█████████▊| 2334/2382 [7:10:36<09:34, 11.96s/it]                                                     {'loss': 2.0018, 'learning_rate': 1.0649863372373946e-06, 'epoch': 0.98}
 98%|█████████▊| 2334/2382 [7:10:36<09:34, 11.96s/it] 98%|█████████▊| 2335/2382 [7:10:49<09:34, 12.22s/it]                                                     {'loss': 1.9546, 'learning_rate': 1.0210890925004267e-06, 'epoch': 0.98}
 98%|█████████▊| 2335/2382 [7:10:49<09:34, 12.22s/it] 98%|█████████▊| 2336/2382 [7:10:59<08:59, 11.73s/it]                                                     {'loss': 2.0908, 'learning_rate': 9.781147546985004e-07, 'epoch': 0.98}
 98%|█████████▊| 2336/2382 [7:10:59<08:59, 11.73s/it] 98%|█████████▊| 2337/2382 [7:11:09<08:26, 11.25s/it]                                                     {'loss': 2.1309, 'learning_rate': 9.360634033165338e-07, 'epoch': 0.98}
 98%|█████████▊| 2337/2382 [7:11:09<08:26, 11.25s/it] 98%|█████████▊| 2338/2382 [7:11:20<08:03, 10.99s/it]                                                     {'loss': 2.0042, 'learning_rate': 8.949351161324226e-07, 'epoch': 0.98}
 98%|█████████▊| 2338/2382 [7:11:20<08:03, 10.99s/it] 98%|█████████▊| 2339/2382 [7:11:33<08:22, 11.67s/it]                                                     {'loss': 2.0718, 'learning_rate': 8.547299692165944e-07, 'epoch': 0.98}
 98%|█████████▊| 2339/2382 [7:11:33<08:22, 11.67s/it] 98%|█████████▊| 2340/2382 [7:11:43<07:50, 11.21s/it]                                                     {'loss': 2.191, 'learning_rate': 8.15448036932176e-07, 'epoch': 0.98}
 98%|█████████▊| 2340/2382 [7:11:43<07:50, 11.21s/it] 98%|█████████▊| 2341/2382 [7:11:54<07:37, 11.15s/it]                                                     {'loss': 1.8867, 'learning_rate': 7.770893919346045e-07, 'epoch': 0.98}
 98%|█████████▊| 2341/2382 [7:11:54<07:37, 11.15s/it] 98%|█████████▊| 2342/2382 [7:12:04<07:07, 10.70s/it]                                                     {'loss': 2.1233, 'learning_rate': 7.396541051717942e-07, 'epoch': 0.98}
 98%|█████████▊| 2342/2382 [7:12:04<07:07, 10.70s/it] 98%|█████████▊| 2343/2382 [7:12:12<06:34, 10.13s/it]                                                     {'loss': 2.0572, 'learning_rate': 7.031422458836368e-07, 'epoch': 0.98}
 98%|█████████▊| 2343/2382 [7:12:12<06:34, 10.13s/it] 98%|█████████▊| 2344/2382 [7:12:23<06:35, 10.40s/it]                                                     {'loss': 2.0397, 'learning_rate': 6.675538816022231e-07, 'epoch': 0.98}
 98%|█████████▊| 2344/2382 [7:12:23<06:35, 10.40s/it] 98%|█████████▊| 2345/2382 [7:12:34<06:26, 10.44s/it]                                                     {'loss': 2.035, 'learning_rate': 6.328890781513441e-07, 'epoch': 0.98}
 98%|█████████▊| 2345/2382 [7:12:34<06:26, 10.44s/it] 98%|█████████▊| 2346/2382 [7:12:45<06:26, 10.75s/it]                                                     {'loss': 2.0185, 'learning_rate': 5.991478996468236e-07, 'epoch': 0.98}
 98%|█████████▊| 2346/2382 [7:12:45<06:26, 10.75s/it] 99%|█████████▊| 2347/2382 [7:12:57<06:23, 10.96s/it]                                                     {'loss': 2.0109, 'learning_rate': 5.663304084960185e-07, 'epoch': 0.98}
 99%|█████████▊| 2347/2382 [7:12:57<06:23, 10.96s/it] 99%|█████████▊| 2348/2382 [7:13:09<06:20, 11.19s/it]                                                     {'loss': 2.0466, 'learning_rate': 5.344366653978194e-07, 'epoch': 0.99}
 99%|█████████▊| 2348/2382 [7:13:09<06:20, 11.19s/it] 99%|█████████▊| 2349/2382 [7:13:18<05:54, 10.75s/it]                                                     {'loss': 1.9464, 'learning_rate': 5.034667293427053e-07, 'epoch': 0.99}
 99%|█████████▊| 2349/2382 [7:13:18<05:54, 10.75s/it] 99%|█████████▊| 2350/2382 [7:13:30<05:48, 10.88s/it]                                                     {'loss': 2.0678, 'learning_rate': 4.7342065761224464e-07, 'epoch': 0.99}
 99%|█████████▊| 2350/2382 [7:13:30<05:48, 10.88s/it] 99%|█████████▊| 2351/2382 [7:13:39<05:22, 10.41s/it]                                                     {'loss': 1.9133, 'learning_rate': 4.44298505779539e-07, 'epoch': 0.99}
 99%|█████████▊| 2351/2382 [7:13:39<05:22, 10.41s/it] 99%|█████████▊| 2352/2382 [7:13:49<05:10, 10.37s/it]                                                     {'loss': 2.1329, 'learning_rate': 4.1610032770855735e-07, 'epoch': 0.99}
 99%|█████████▊| 2352/2382 [7:13:49<05:10, 10.37s/it] 99%|█████████▉| 2353/2382 [7:13:57<04:42,  9.73s/it]                                                     {'loss': 2.0819, 'learning_rate': 3.8882617555446863e-07, 'epoch': 0.99}
 99%|█████████▉| 2353/2382 [7:13:57<04:42,  9.73s/it] 99%|█████████▉| 2354/2382 [7:14:08<04:37,  9.90s/it]                                                     {'loss': 1.9288, 'learning_rate': 3.6247609976319816e-07, 'epoch': 0.99}
 99%|█████████▉| 2354/2382 [7:14:08<04:37,  9.90s/it] 99%|█████████▉| 2355/2382 [7:14:17<04:18,  9.59s/it]                                                     {'loss': 1.937, 'learning_rate': 3.3705014907176034e-07, 'epoch': 0.99}
 99%|█████████▉| 2355/2382 [7:14:17<04:18,  9.59s/it] 99%|█████████▉| 2356/2382 [7:14:27<04:19,  9.98s/it]                                                     {'loss': 2.0464, 'learning_rate': 3.1254837050764817e-07, 'epoch': 0.99}
 99%|█████████▉| 2356/2382 [7:14:27<04:19,  9.98s/it] 99%|█████████▉| 2357/2382 [7:14:38<04:16, 10.26s/it]                                                     {'loss': 1.8925, 'learning_rate': 2.889708093891663e-07, 'epoch': 0.99}
 99%|█████████▉| 2357/2382 [7:14:38<04:16, 10.26s/it] 99%|█████████▉| 2358/2382 [7:14:50<04:18, 10.77s/it]                                                     {'loss': 2.1181, 'learning_rate': 2.6631750932515354e-07, 'epoch': 0.99}
 99%|█████████▉| 2358/2382 [7:14:50<04:18, 10.77s/it] 99%|█████████▉| 2359/2382 [7:15:02<04:13, 11.03s/it]                                                     {'loss': 1.9922, 'learning_rate': 2.445885122149272e-07, 'epoch': 0.99}
 99%|█████████▉| 2359/2382 [7:15:02<04:13, 11.03s/it] 99%|█████████▉| 2360/2382 [7:15:12<03:59, 10.89s/it]                                                     {'loss': 2.0087, 'learning_rate': 2.2378385824833868e-07, 'epoch': 0.99}
 99%|█████████▉| 2360/2382 [7:15:13<03:59, 10.89s/it] 99%|█████████▉| 2361/2382 [7:15:23<03:43, 10.64s/it]                                                     {'loss': 2.0029, 'learning_rate': 2.0390358590538505e-07, 'epoch': 0.99}
 99%|█████████▉| 2361/2382 [7:15:23<03:43, 10.64s/it] 99%|█████████▉| 2362/2382 [7:15:35<03:46, 11.31s/it]                                                     {'loss': 2.058, 'learning_rate': 1.8494773195648628e-07, 'epoch': 0.99}
 99%|█████████▉| 2362/2382 [7:15:35<03:46, 11.31s/it] 99%|█████████▉| 2363/2382 [7:15:46<03:29, 11.02s/it]                                                     {'loss': 2.0467, 'learning_rate': 1.6691633146226349e-07, 'epoch': 0.99}
 99%|█████████▉| 2363/2382 [7:15:46<03:29, 11.02s/it] 99%|█████████▉| 2364/2382 [7:15:58<03:25, 11.40s/it]                                                     {'loss': 2.0425, 'learning_rate': 1.498094177733722e-07, 'epoch': 0.99}
 99%|█████████▉| 2364/2382 [7:15:58<03:25, 11.40s/it] 99%|█████████▉| 2365/2382 [7:16:09<03:10, 11.22s/it]                                                     {'loss': 1.9686, 'learning_rate': 1.3362702253061353e-07, 'epoch': 0.99}
 99%|█████████▉| 2365/2382 [7:16:09<03:10, 11.22s/it] 99%|█████████▉| 2366/2382 [7:16:21<03:01, 11.37s/it]                                                     {'loss': 2.1371, 'learning_rate': 1.1836917566482308e-07, 'epoch': 0.99}
 99%|█████████▉| 2366/2382 [7:16:21<03:01, 11.37s/it] 99%|█████████▉| 2367/2382 [7:16:30<02:42, 10.83s/it]                                                     {'loss': 1.9977, 'learning_rate': 1.0403590539675989e-07, 'epoch': 0.99}
 99%|█████████▉| 2367/2382 [7:16:30<02:42, 10.83s/it] 99%|█████████▉| 2368/2382 [7:16:41<02:29, 10.69s/it]                                                     {'loss': 2.0256, 'learning_rate': 9.06272382371065e-08, 'epoch': 0.99}
 99%|█████████▉| 2368/2382 [7:16:41<02:29, 10.69s/it] 99%|█████████▉| 2369/2382 [7:16:52<02:23, 11.02s/it]                                                     {'loss': 2.0254, 'learning_rate': 7.814319898646893e-08, 'epoch': 0.99}
 99%|█████████▉| 2369/2382 [7:16:52<02:23, 11.02s/it] 99%|█████████▉| 2370/2382 [7:17:04<02:13, 11.11s/it]                                                     {'loss': 2.0343, 'learning_rate': 6.658381073515462e-08, 'epoch': 0.99}
 99%|█████████▉| 2370/2382 [7:17:04<02:13, 11.11s/it]100%|█████████▉| 2371/2382 [7:17:18<02:11, 11.95s/it]                                                     {'loss': 1.9629, 'learning_rate': 5.5949094863283477e-08, 'epoch': 1.0}
100%|█████████▉| 2371/2382 [7:17:18<02:11, 11.95s/it]100%|█████████▉| 2372/2382 [7:17:28<01:56, 11.62s/it]                                                     {'loss': 2.0009, 'learning_rate': 4.623907104084335e-08, 'epoch': 1.0}
100%|█████████▉| 2372/2382 [7:17:28<01:56, 11.62s/it]100%|█████████▉| 2373/2382 [7:17:40<01:45, 11.71s/it]                                                     {'loss': 2.05, 'learning_rate': 3.7453757227245974e-08, 'epoch': 1.0}
100%|█████████▉| 2373/2382 [7:17:40<01:45, 11.71s/it]100%|█████████▉| 2374/2382 [7:17:54<01:37, 12.21s/it]                                                     {'loss': 2.0234, 'learning_rate': 2.959316967188208e-08, 'epoch': 1.0}
100%|█████████▉| 2374/2382 [7:17:54<01:37, 12.21s/it]100%|█████████▉| 2375/2382 [7:18:03<01:18, 11.20s/it]                                                     {'loss': 2.0053, 'learning_rate': 2.265732291356626e-08, 'epoch': 1.0}
100%|█████████▉| 2375/2382 [7:18:03<01:18, 11.20s/it]100%|█████████▉| 2376/2382 [7:18:14<01:08, 11.34s/it]                                                     {'loss': 1.9669, 'learning_rate': 1.6646229780759027e-08, 'epoch': 1.0}
100%|█████████▉| 2376/2382 [7:18:14<01:08, 11.34s/it]100%|█████████▉| 2377/2382 [7:18:24<00:54, 10.92s/it]                                                     {'loss': 2.0232, 'learning_rate': 1.1559901391511308e-08, 'epoch': 1.0}
100%|█████████▉| 2377/2382 [7:18:24<00:54, 10.92s/it]100%|█████████▉| 2378/2382 [7:18:34<00:42, 10.74s/it]                                                     {'loss': 2.1209, 'learning_rate': 7.3983471535199464e-09, 'epoch': 1.0}
100%|█████████▉| 2378/2382 [7:18:34<00:42, 10.74s/it]100%|█████████▉| 2379/2382 [7:18:44<00:31, 10.47s/it]                                                     {'loss': 2.1479, 'learning_rate': 4.1615747639056626e-09, 'epoch': 1.0}
100%|█████████▉| 2379/2382 [7:18:44<00:31, 10.47s/it]100%|█████████▉| 2380/2382 [7:18:55<00:21, 10.61s/it]                                                     {'loss': 2.0074, 'learning_rate': 1.8495902093795814e-09, 'epoch': 1.0}
100%|█████████▉| 2380/2382 [7:18:55<00:21, 10.61s/it]100%|█████████▉| 2381/2382 [7:19:08<00:11, 11.19s/it]                                                     {'loss': 1.9773, 'learning_rate': 4.623977661322165e-10, 'epoch': 1.0}
100%|█████████▉| 2381/2382 [7:19:08<00:11, 11.19s/it]100%|██████████| 2382/2382 [7:19:18<00:00, 10.84s/it]                                                     {'loss': 1.9806, 'learning_rate': 0.0, 'epoch': 1.0}
100%|██████████| 2382/2382 [7:19:18<00:00, 10.84s/it]                                                     {'train_runtime': 26360.0666, 'train_samples_per_second': 23.141, 'train_steps_per_second': 0.09, 'train_loss': 2.0708076845288375, 'epoch': 1.0}
100%|██████████| 2382/2382 [7:19:20<00:00, 10.84s/it]100%|██████████| 2382/2382 [7:19:20<00:00, 11.07s/it]
[2024-08-10 06:29:14,045] [INFO] [launch.py:347:main] Process 4151708 exits successfully.
[2024-08-10 06:29:14,046] [INFO] [launch.py:347:main] Process 4151705 exits successfully.
[2024-08-10 06:29:14,047] [INFO] [launch.py:347:main] Process 4151706 exits successfully.
[2024-08-10 06:29:14,048] [INFO] [launch.py:347:main] Process 4151701 exits successfully.
[2024-08-10 06:29:14,049] [INFO] [launch.py:347:main] Process 4151707 exits successfully.
[2024-08-10 06:29:15,050] [INFO] [launch.py:347:main] Process 4151703 exits successfully.
[2024-08-10 06:29:15,051] [INFO] [launch.py:347:main] Process 4151704 exits successfully.
[2024-08-10 06:29:15,052] [INFO] [launch.py:347:main] Process 4151702 exits successfully.
