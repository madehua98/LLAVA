nohup: 忽略输入
1,2,3,4,5,6,7,8
[2024-08-12 13:42:31,415] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-12 13:42:33,942] [WARNING] [runner.py:196:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2024-08-12 13:42:33,943] [INFO] [runner.py:555:main] cmd = /home/data_llm/anaconda3/envs/moellava/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMSwgMiwgMywgNCwgNSwgNiwgNywgOF19 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None llava/train/train_xformers.py --deepspeed ./scripts/zero2.json --model_name_or_path /media/fast_data/model/vicuna-7b-v1.5 --version plain --data_path /mnt/data_llm/json_file/llava_pretrain_data.json --image_folder /media/fast_data --vision_tower /media/fast_data/model/clip-vit-base-patch16 --mm_projector_type mlp2x_gelu --tune_mm_mlp_adapter True --mm_vision_select_layer -2 --mm_use_im_start_end False --mm_use_im_patch_token False --bf16 True --output_dir /mnt/data_llm/model/checkpoints/llava1.5-7b-clip_base-pretrain --num_train_epochs 1 --per_device_train_batch_size 4 --per_device_eval_batch_size 4 --gradient_accumulation_steps 8 --evaluation_strategy no --save_strategy epoch --save_total_limit 1 --learning_rate 1e-3 --weight_decay 0. --warmup_ratio 0.03 --lr_scheduler_type cosine --logging_steps 1 --tf32 True --model_max_length 1024 --gradient_checkpointing True --dataloader_num_workers 64 --lazy_preprocess True
[2024-08-12 13:42:35,231] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-12 13:42:37,633] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [1, 2, 3, 4, 5, 6, 7, 8]}
[2024-08-12 13:42:37,633] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=8, node_rank=0
[2024-08-12 13:42:37,633] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]})
[2024-08-12 13:42:37,633] [INFO] [launch.py:163:main] dist_world_size=8
[2024-08-12 13:42:37,633] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7,8
[2024-08-12 13:42:41,177] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-12 13:42:41,262] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-12 13:42:41,278] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-12 13:42:41,377] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-12 13:42:41,437] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-12 13:42:41,492] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-12 13:42:41,597] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-12 13:42:41,610] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-12 13:42:42,434] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-08-12 13:42:42,434] [INFO] [comm.py:594:init_distributed] cdb=None
[2024-08-12 13:42:42,530] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-08-12 13:42:42,530] [INFO] [comm.py:594:init_distributed] cdb=None
[2024-08-12 13:42:42,624] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-08-12 13:42:42,624] [INFO] [comm.py:594:init_distributed] cdb=None
[2024-08-12 13:42:42,650] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-08-12 13:42:42,650] [INFO] [comm.py:594:init_distributed] cdb=None
[2024-08-12 13:42:42,674] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-08-12 13:42:42,674] [INFO] [comm.py:594:init_distributed] cdb=None
[2024-08-12 13:42:42,840] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-08-12 13:42:42,840] [INFO] [comm.py:594:init_distributed] cdb=None
[2024-08-12 13:42:42,842] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-08-12 13:42:42,842] [INFO] [comm.py:594:init_distributed] cdb=None
[2024-08-12 13:42:42,953] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2024-08-12 13:42:42,953] [INFO] [comm.py:594:init_distributed] cdb=None
[2024-08-12 13:42:42,953] [INFO] [comm.py:625:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  7.00s/it]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.30s/it]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.91s/it]
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
Using CLIPVisionTower
Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.73s/it]
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
Using CLIPVisionTower
Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.05s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.42s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.41s/it]
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
Using CLIPVisionTower
Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.80s/it]
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
Using CLIPVisionTower
Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.71s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.94s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.17s/it]
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
Using CLIPVisionTower
Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.20s/it]
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.20s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.09s/it]
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
Using CLIPVisionTower
Using CLIPVisionTower
Using CLIPVisionTower
Formatting inputs...Skip in lazy mode
Rank: 0 partition count [8, 8] and sizes[(2490368, False), (1024, False)] 
Rank: 5 partition count [8, 8] and sizes[(2490368, False), (1024, False)] 
Rank: 2 partition count [8, 8] and sizes[(2490368, False), (1024, False)] 
Rank: 7 partition count [8, 8] and sizes[(2490368, False), (1024, False)] 
Rank: 1 partition count [8, 8] and sizes[(2490368, False), (1024, False)] 
Rank: 3 partition count [8, 8] and sizes[(2490368, False), (1024, False)] 
Rank: 4 partition count [8, 8] and sizes[(2490368, False), (1024, False)] 
Rank: 6 partition count [8, 8] and sizes[(2490368, False), (1024, False)] 
  0%|          | 0/2382 [00:00<?, ?it/s]/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/torch/autograd/__init__.py:266: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at ../torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1828: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  overflow_gpu = get_accelerator().ByteTensor([overflow])
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1828: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  overflow_gpu = get_accelerator().ByteTensor([overflow])
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1828: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  overflow_gpu = get_accelerator().ByteTensor([overflow])
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1828: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  overflow_gpu = get_accelerator().ByteTensor([overflow])
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1828: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  overflow_gpu = get_accelerator().ByteTensor([overflow])
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1828: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  overflow_gpu = get_accelerator().ByteTensor([overflow])
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1828: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  overflow_gpu = get_accelerator().ByteTensor([overflow])
/home/data_llm/anaconda3/envs/moellava/lib/python3.12/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1828: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  overflow_gpu = get_accelerator().ByteTensor([overflow])
  0%|          | 1/2382 [00:17<11:49:59, 17.89s/it]                                                   {'loss': 6.3763, 'learning_rate': 1.3888888888888888e-05, 'epoch': 0.0}
  0%|          | 1/2382 [00:17<11:49:59, 17.89s/it]  0%|          | 2/2382 [00:31<10:00:37, 15.14s/it]                                                   {'loss': 6.2458, 'learning_rate': 2.7777777777777776e-05, 'epoch': 0.0}
  0%|          | 2/2382 [00:31<10:00:37, 15.14s/it]  0%|          | 3/2382 [00:44<9:23:03, 14.20s/it]                                                   {'loss': 5.9036, 'learning_rate': 4.1666666666666665e-05, 'epoch': 0.0}
  0%|          | 3/2382 [00:44<9:23:03, 14.20s/it]  0%|          | 4/2382 [00:58<9:18:27, 14.09s/it]                                                  {'loss': 4.749, 'learning_rate': 5.555555555555555e-05, 'epoch': 0.0}
  0%|          | 4/2382 [00:58<9:18:27, 14.09s/it]  0%|          | 5/2382 [01:10<8:57:17, 13.56s/it]                                                  {'loss': 4.2313, 'learning_rate': 6.944444444444444e-05, 'epoch': 0.0}
  0%|          | 5/2382 [01:10<8:57:17, 13.56s/it]  0%|          | 6/2382 [01:23<8:44:33, 13.25s/it]                                                  {'loss': 3.9535, 'learning_rate': 8.333333333333333e-05, 'epoch': 0.0}
  0%|          | 6/2382 [01:23<8:44:33, 13.25s/it]  0%|          | 7/2382 [01:37<8:57:16, 13.57s/it]                                                  {'loss': 3.6829, 'learning_rate': 9.722222222222223e-05, 'epoch': 0.0}
  0%|          | 7/2382 [01:37<8:57:16, 13.57s/it]  0%|          | 8/2382 [01:52<9:17:04, 14.08s/it]                                                  {'loss': 3.4485, 'learning_rate': 0.0001111111111111111, 'epoch': 0.0}
  0%|          | 8/2382 [01:52<9:17:04, 14.08s/it]  0%|          | 9/2382 [02:07<9:21:43, 14.20s/it]                                                  {'loss': 3.3187, 'learning_rate': 0.000125, 'epoch': 0.0}
  0%|          | 9/2382 [02:07<9:21:43, 14.20s/it]  0%|          | 10/2382 [02:21<9:18:35, 14.13s/it]                                                   {'loss': 2.9478, 'learning_rate': 0.0001388888888888889, 'epoch': 0.0}
  0%|          | 10/2382 [02:21<9:18:35, 14.13s/it]  0%|          | 11/2382 [02:35<9:15:28, 14.06s/it]                                                   {'loss': 3.0054, 'learning_rate': 0.0001527777777777778, 'epoch': 0.0}
  0%|          | 11/2382 [02:35<9:15:28, 14.06s/it]  1%|          | 12/2382 [02:49<9:14:38, 14.04s/it]                                                   {'loss': 2.9393, 'learning_rate': 0.00016666666666666666, 'epoch': 0.01}
  1%|          | 12/2382 [02:49<9:14:38, 14.04s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1067 > 1024). Running this sequence through the model will result in indexing errors
  1%|          | 13/2382 [03:04<9:29:27, 14.42s/it]                                                   {'loss': 2.7416, 'learning_rate': 0.00018055555555555555, 'epoch': 0.01}
  1%|          | 13/2382 [03:04<9:29:27, 14.42s/it]  1%|          | 14/2382 [03:20<9:44:41, 14.81s/it]                                                   {'loss': 2.7304, 'learning_rate': 0.00019444444444444446, 'epoch': 0.01}
  1%|          | 14/2382 [03:20<9:44:41, 14.81s/it]  1%|          | 15/2382 [03:36<10:01:55, 15.26s/it]                                                    {'loss': 2.8381, 'learning_rate': 0.00020833333333333335, 'epoch': 0.01}
  1%|          | 15/2382 [03:36<10:01:55, 15.26s/it]  1%|          | 16/2382 [03:52<10:09:12, 15.45s/it]                                                    {'loss': 2.7606, 'learning_rate': 0.0002222222222222222, 'epoch': 0.01}
  1%|          | 16/2382 [03:52<10:09:12, 15.45s/it]  1%|          | 17/2382 [04:05<9:46:20, 14.88s/it]                                                    {'loss': 2.7623, 'learning_rate': 0.00023611111111111112, 'epoch': 0.01}
  1%|          | 17/2382 [04:05<9:46:20, 14.88s/it]  1%|          | 18/2382 [04:20<9:41:34, 14.76s/it]                                                   {'loss': 2.8843, 'learning_rate': 0.00025, 'epoch': 0.01}
  1%|          | 18/2382 [04:20<9:41:34, 14.76s/it]  1%|          | 19/2382 [04:35<9:46:41, 14.90s/it]                                                   {'loss': 2.6634, 'learning_rate': 0.0002638888888888889, 'epoch': 0.01}
  1%|          | 19/2382 [04:35<9:46:41, 14.90s/it]  1%|          | 20/2382 [04:49<9:31:55, 14.53s/it]                                                   {'loss': 2.6446, 'learning_rate': 0.0002777777777777778, 'epoch': 0.01}
  1%|          | 20/2382 [04:49<9:31:55, 14.53s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1333 > 1024). Running this sequence through the model will result in indexing errors
  1%|          | 21/2382 [05:04<9:44:23, 14.85s/it]                                                   {'loss': 2.5223, 'learning_rate': 0.0002916666666666667, 'epoch': 0.01}
  1%|          | 21/2382 [05:04<9:44:23, 14.85s/it]  1%|          | 22/2382 [05:18<9:35:32, 14.63s/it]                                                   {'loss': 2.6582, 'learning_rate': 0.0003055555555555556, 'epoch': 0.01}
  1%|          | 22/2382 [05:18<9:35:32, 14.63s/it]  1%|          | 23/2382 [05:37<10:24:58, 15.90s/it]                                                    {'loss': 2.5553, 'learning_rate': 0.0003194444444444444, 'epoch': 0.01}
  1%|          | 23/2382 [05:37<10:24:58, 15.90s/it]  1%|          | 24/2382 [05:51<10:00:37, 15.28s/it]                                                    {'loss': 2.6647, 'learning_rate': 0.0003333333333333333, 'epoch': 0.01}
  1%|          | 24/2382 [05:51<10:00:37, 15.28s/it]  1%|          | 25/2382 [06:03<9:24:04, 14.36s/it]                                                    {'loss': 2.4623, 'learning_rate': 0.00034722222222222224, 'epoch': 0.01}
  1%|          | 25/2382 [06:03<9:24:04, 14.36s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1657 > 1024). Running this sequence through the model will result in indexing errors
  1%|          | 26/2382 [06:17<9:14:54, 14.13s/it]                                                   {'loss': 2.5277, 'learning_rate': 0.0003611111111111111, 'epoch': 0.01}
  1%|          | 26/2382 [06:17<9:14:54, 14.13s/it]  1%|          | 27/2382 [06:32<9:23:36, 14.36s/it]                                                   {'loss': 2.5456, 'learning_rate': 0.000375, 'epoch': 0.01}
  1%|          | 27/2382 [06:32<9:23:36, 14.36s/it]  1%|          | 28/2382 [06:46<9:24:25, 14.39s/it]                                                   {'loss': 2.5652, 'learning_rate': 0.0003888888888888889, 'epoch': 0.01}
  1%|          | 28/2382 [06:46<9:24:25, 14.39s/it]  1%|          | 29/2382 [07:02<9:35:23, 14.67s/it]                                                   {'loss': 2.5081, 'learning_rate': 0.0004027777777777778, 'epoch': 0.01}
  1%|          | 29/2382 [07:02<9:35:23, 14.67s/it]  1%|▏         | 30/2382 [07:15<9:25:04, 14.42s/it]                                                   {'loss': 2.6329, 'learning_rate': 0.0004166666666666667, 'epoch': 0.01}
  1%|▏         | 30/2382 [07:15<9:25:04, 14.42s/it]  1%|▏         | 31/2382 [07:28<9:05:40, 13.93s/it]                                                   {'loss': 2.4592, 'learning_rate': 0.0004305555555555556, 'epoch': 0.01}
  1%|▏         | 31/2382 [07:28<9:05:40, 13.93s/it]  1%|▏         | 32/2382 [07:41<8:47:47, 13.48s/it]                                                   {'loss': 2.5082, 'learning_rate': 0.0004444444444444444, 'epoch': 0.01}
  1%|▏         | 32/2382 [07:41<8:47:47, 13.48s/it]  1%|▏         | 33/2382 [07:54<8:50:46, 13.56s/it]                                                   {'loss': 2.4755, 'learning_rate': 0.0004583333333333333, 'epoch': 0.01}
  1%|▏         | 33/2382 [07:54<8:50:46, 13.56s/it]  1%|▏         | 34/2382 [08:07<8:36:17, 13.19s/it]                                                   {'loss': 2.3754, 'learning_rate': 0.00047222222222222224, 'epoch': 0.01}
  1%|▏         | 34/2382 [08:07<8:36:17, 13.19s/it]  1%|▏         | 35/2382 [08:18<8:16:49, 12.70s/it]                                                   {'loss': 2.4309, 'learning_rate': 0.0004861111111111111, 'epoch': 0.01}
  1%|▏         | 35/2382 [08:18<8:16:49, 12.70s/it]  2%|▏         | 36/2382 [08:30<8:02:52, 12.35s/it]                                                   {'loss': 2.3605, 'learning_rate': 0.0005, 'epoch': 0.02}
  2%|▏         | 36/2382 [08:30<8:02:52, 12.35s/it]  2%|▏         | 37/2382 [08:44<8:24:00, 12.90s/it]                                                   {'loss': 2.5013, 'learning_rate': 0.0005138888888888888, 'epoch': 0.02}
  2%|▏         | 37/2382 [08:44<8:24:00, 12.90s/it]  2%|▏         | 38/2382 [08:58<8:31:19, 13.09s/it]                                                   {'loss': 2.3273, 'learning_rate': 0.0005277777777777778, 'epoch': 0.02}
  2%|▏         | 38/2382 [08:58<8:31:19, 13.09s/it]  2%|▏         | 39/2382 [09:12<8:52:53, 13.65s/it]                                                   {'loss': 2.3922, 'learning_rate': 0.0005416666666666666, 'epoch': 0.02}
  2%|▏         | 39/2382 [09:12<8:52:53, 13.65s/it]  2%|▏         | 40/2382 [09:26<8:48:12, 13.53s/it]                                                   {'loss': 2.2868, 'learning_rate': 0.0005555555555555556, 'epoch': 0.02}
  2%|▏         | 40/2382 [09:26<8:48:12, 13.53s/it]  2%|▏         | 41/2382 [09:39<8:44:00, 13.43s/it]                                                   {'loss': 2.0733, 'learning_rate': 0.0005694444444444445, 'epoch': 0.02}
  2%|▏         | 41/2382 [09:39<8:44:00, 13.43s/it]  2%|▏         | 42/2382 [09:52<8:42:36, 13.40s/it]                                                   {'loss': 2.2681, 'learning_rate': 0.0005833333333333334, 'epoch': 0.02}
  2%|▏         | 42/2382 [09:52<8:42:36, 13.40s/it]  2%|▏         | 43/2382 [10:05<8:39:48, 13.33s/it]                                                   {'loss': 2.4181, 'learning_rate': 0.0005972222222222222, 'epoch': 0.02}
  2%|▏         | 43/2382 [10:05<8:39:48, 13.33s/it]  2%|▏         | 44/2382 [10:19<8:37:43, 13.29s/it]                                                   {'loss': 2.3392, 'learning_rate': 0.0006111111111111112, 'epoch': 0.02}
  2%|▏         | 44/2382 [10:19<8:37:43, 13.29s/it]  2%|▏         | 45/2382 [10:33<8:51:51, 13.65s/it]                                                   {'loss': 2.2619, 'learning_rate': 0.000625, 'epoch': 0.02}
  2%|▏         | 45/2382 [10:33<8:51:51, 13.65s/it]  2%|▏         | 46/2382 [10:48<9:03:53, 13.97s/it]                                                   {'loss': 2.2262, 'learning_rate': 0.0006388888888888888, 'epoch': 0.02}
  2%|▏         | 46/2382 [10:48<9:03:53, 13.97s/it]  2%|▏         | 47/2382 [11:00<8:38:57, 13.34s/it]                                                   {'loss': 2.2484, 'learning_rate': 0.0006527777777777778, 'epoch': 0.02}
  2%|▏         | 47/2382 [11:00<8:38:57, 13.34s/it]  2%|▏         | 48/2382 [11:12<8:24:56, 12.98s/it]                                                   {'loss': 2.2677, 'learning_rate': 0.0006666666666666666, 'epoch': 0.02}
  2%|▏         | 48/2382 [11:12<8:24:56, 12.98s/it]  2%|▏         | 49/2382 [11:26<8:37:11, 13.30s/it]                                                   {'loss': 2.2276, 'learning_rate': 0.0006805555555555556, 'epoch': 0.02}
  2%|▏         | 49/2382 [11:26<8:37:11, 13.30s/it]  2%|▏         | 50/2382 [11:40<8:43:42, 13.47s/it]                                                   {'loss': 2.312, 'learning_rate': 0.0006944444444444445, 'epoch': 0.02}
  2%|▏         | 50/2382 [11:40<8:43:42, 13.47s/it]  2%|▏         | 51/2382 [11:54<8:46:37, 13.56s/it]                                                   {'loss': 2.3047, 'learning_rate': 0.0007083333333333334, 'epoch': 0.02}
  2%|▏         | 51/2382 [11:54<8:46:37, 13.56s/it]  2%|▏         | 52/2382 [12:06<8:33:28, 13.22s/it]                                                   {'loss': 2.3796, 'learning_rate': 0.0007222222222222222, 'epoch': 0.02}
  2%|▏         | 52/2382 [12:06<8:33:28, 13.22s/it]  2%|▏         | 53/2382 [12:17<8:06:29, 12.53s/it]                                                   {'loss': 2.4428, 'learning_rate': 0.0007361111111111112, 'epoch': 0.02}
  2%|▏         | 53/2382 [12:17<8:06:29, 12.53s/it]  2%|▏         | 54/2382 [12:29<8:01:56, 12.42s/it]                                                   {'loss': 2.1996, 'learning_rate': 0.00075, 'epoch': 0.02}
  2%|▏         | 54/2382 [12:29<8:01:56, 12.42s/it]  2%|▏         | 55/2382 [12:42<8:12:20, 12.69s/it]                                                   {'loss': 2.3882, 'learning_rate': 0.0007638888888888888, 'epoch': 0.02}
  2%|▏         | 55/2382 [12:42<8:12:20, 12.69s/it]  2%|▏         | 56/2382 [12:56<8:17:21, 12.83s/it]                                                   {'loss': 2.2809, 'learning_rate': 0.0007777777777777778, 'epoch': 0.02}
  2%|▏         | 56/2382 [12:56<8:17:21, 12.83s/it]  2%|▏         | 57/2382 [13:07<7:58:22, 12.35s/it]                                                   {'loss': 2.2179, 'learning_rate': 0.0007916666666666666, 'epoch': 0.02}
  2%|▏         | 57/2382 [13:07<7:58:22, 12.35s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1245 > 1024). Running this sequence through the model will result in indexing errors
  2%|▏         | 58/2382 [13:19<7:52:58, 12.21s/it]                                                   {'loss': 2.2295, 'learning_rate': 0.0008055555555555556, 'epoch': 0.02}
  2%|▏         | 58/2382 [13:19<7:52:58, 12.21s/it]  2%|▏         | 59/2382 [13:32<8:00:18, 12.41s/it]                                                   {'loss': 2.1223, 'learning_rate': 0.0008194444444444445, 'epoch': 0.02}
  2%|▏         | 59/2382 [13:32<8:00:18, 12.41s/it]  3%|▎         | 60/2382 [13:45<8:18:22, 12.88s/it]                                                   {'loss': 2.2692, 'learning_rate': 0.0008333333333333334, 'epoch': 0.03}
  3%|▎         | 60/2382 [13:45<8:18:22, 12.88s/it]  3%|▎         | 61/2382 [13:58<8:13:37, 12.76s/it]                                                   {'loss': 2.2314, 'learning_rate': 0.0008472222222222222, 'epoch': 0.03}
  3%|▎         | 61/2382 [13:58<8:13:37, 12.76s/it]  3%|▎         | 62/2382 [14:11<8:14:01, 12.78s/it]                                                   {'loss': 2.1397, 'learning_rate': 0.0008611111111111112, 'epoch': 0.03}
  3%|▎         | 62/2382 [14:11<8:14:01, 12.78s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1040 > 1024). Running this sequence through the model will result in indexing errors
  3%|▎         | 63/2382 [14:25<8:26:56, 13.12s/it]                                                   {'loss': 2.1374, 'learning_rate': 0.000875, 'epoch': 0.03}
  3%|▎         | 63/2382 [14:25<8:26:56, 13.12s/it]  3%|▎         | 64/2382 [14:37<8:16:54, 12.86s/it]                                                   {'loss': 2.1812, 'learning_rate': 0.0008888888888888888, 'epoch': 0.03}
  3%|▎         | 64/2382 [14:37<8:16:54, 12.86s/it]  3%|▎         | 65/2382 [14:51<8:32:33, 13.27s/it]                                                   {'loss': 2.1857, 'learning_rate': 0.0009027777777777778, 'epoch': 0.03}
  3%|▎         | 65/2382 [14:51<8:32:33, 13.27s/it]  3%|▎         | 66/2382 [15:04<8:29:26, 13.20s/it]                                                   {'loss': 2.2323, 'learning_rate': 0.0009166666666666666, 'epoch': 0.03}
  3%|▎         | 66/2382 [15:04<8:29:26, 13.20s/it]  3%|▎         | 67/2382 [15:17<8:29:28, 13.20s/it]                                                   {'loss': 2.275, 'learning_rate': 0.0009305555555555556, 'epoch': 0.03}
  3%|▎         | 67/2382 [15:17<8:29:28, 13.20s/it]  3%|▎         | 68/2382 [15:31<8:32:22, 13.29s/it]                                                   {'loss': 2.1115, 'learning_rate': 0.0009444444444444445, 'epoch': 0.03}
  3%|▎         | 68/2382 [15:31<8:32:22, 13.29s/it]  3%|▎         | 69/2382 [15:43<8:22:44, 13.04s/it]                                                   {'loss': 2.3258, 'learning_rate': 0.0009583333333333334, 'epoch': 0.03}
  3%|▎         | 69/2382 [15:43<8:22:44, 13.04s/it]  3%|▎         | 70/2382 [15:58<8:41:01, 13.52s/it]                                                   {'loss': 2.2783, 'learning_rate': 0.0009722222222222222, 'epoch': 0.03}
  3%|▎         | 70/2382 [15:58<8:41:01, 13.52s/it]  3%|▎         | 71/2382 [16:10<8:21:52, 13.03s/it]                                                   {'loss': 2.1538, 'learning_rate': 0.0009861111111111112, 'epoch': 0.03}
  3%|▎         | 71/2382 [16:10<8:21:52, 13.03s/it]  3%|▎         | 72/2382 [16:23<8:23:33, 13.08s/it]                                                   {'loss': 2.2265, 'learning_rate': 0.001, 'epoch': 0.03}
  3%|▎         | 72/2382 [16:23<8:23:33, 13.08s/it]  3%|▎         | 73/2382 [16:40<9:06:50, 14.21s/it]                                                   {'loss': 2.1426, 'learning_rate': 0.000999999537602234, 'epoch': 0.03}
  3%|▎         | 73/2382 [16:40<9:06:50, 14.21s/it]  3%|▎         | 74/2382 [16:52<8:39:54, 13.52s/it]                                                   {'loss': 2.2183, 'learning_rate': 0.0009999981504097905, 'epoch': 0.03}
  3%|▎         | 74/2382 [16:52<8:39:54, 13.52s/it]  3%|▎         | 75/2382 [17:05<8:32:33, 13.33s/it]                                                   {'loss': 2.2725, 'learning_rate': 0.0009999958384252362, 'epoch': 0.03}
  3%|▎         | 75/2382 [17:05<8:32:33, 13.33s/it]  3%|▎         | 76/2382 [17:19<8:37:28, 13.46s/it]                                                   {'loss': 2.2198, 'learning_rate': 0.0009999926016528464, 'epoch': 0.03}
  3%|▎         | 76/2382 [17:19<8:37:28, 13.46s/it]  3%|▎         | 77/2382 [17:31<8:21:26, 13.05s/it]                                                   {'loss': 2.282, 'learning_rate': 0.0009999884400986086, 'epoch': 0.03}
  3%|▎         | 77/2382 [17:31<8:21:26, 13.05s/it]  3%|▎         | 78/2382 [17:43<8:14:15, 12.87s/it]                                                   {'loss': 2.2566, 'learning_rate': 0.0009999833537702191, 'epoch': 0.03}
  3%|▎         | 78/2382 [17:43<8:14:15, 12.87s/it]  3%|▎         | 79/2382 [17:59<8:44:24, 13.66s/it]                                                   {'loss': 2.1555, 'learning_rate': 0.0009999773426770863, 'epoch': 0.03}
  3%|▎         | 79/2382 [17:59<8:44:24, 13.66s/it]  3%|▎         | 80/2382 [18:13<8:47:16, 13.74s/it]                                                   {'loss': 2.1427, 'learning_rate': 0.000999970406830328, 'epoch': 0.03}
  3%|▎         | 80/2382 [18:13<8:47:16, 13.74s/it]  3%|▎         | 81/2382 [18:28<9:11:25, 14.38s/it]                                                   {'loss': 2.1347, 'learning_rate': 0.0009999625462427729, 'epoch': 0.03}
  3%|▎         | 81/2382 [18:28<9:11:25, 14.38s/it]  3%|▎         | 82/2382 [18:43<9:13:37, 14.44s/it]                                                   {'loss': 2.1149, 'learning_rate': 0.0009999537609289592, 'epoch': 0.03}
  3%|▎         | 82/2382 [18:43<9:13:37, 14.44s/it]  3%|▎         | 83/2382 [18:58<9:25:05, 14.75s/it]                                                   {'loss': 2.1643, 'learning_rate': 0.0009999440509051367, 'epoch': 0.03}
  3%|▎         | 83/2382 [18:58<9:25:05, 14.75s/it]  4%|▎         | 84/2382 [19:12<9:09:58, 14.36s/it]                                                   {'loss': 2.0787, 'learning_rate': 0.0009999334161892649, 'epoch': 0.04}
  4%|▎         | 84/2382 [19:12<9:09:58, 14.36s/it]  4%|▎         | 85/2382 [19:26<9:10:41, 14.38s/it]                                                   {'loss': 2.2977, 'learning_rate': 0.0009999218568010136, 'epoch': 0.04}
  4%|▎         | 85/2382 [19:26<9:10:41, 14.38s/it]  4%|▎         | 86/2382 [19:41<9:10:47, 14.39s/it]                                                   {'loss': 2.0923, 'learning_rate': 0.000999909372761763, 'epoch': 0.04}
  4%|▎         | 86/2382 [19:41<9:10:47, 14.39s/it]  4%|▎         | 87/2382 [19:52<8:33:14, 13.42s/it]                                                   {'loss': 2.1334, 'learning_rate': 0.0009998959640946032, 'epoch': 0.04}
  4%|▎         | 87/2382 [19:52<8:33:14, 13.42s/it]  4%|▎         | 88/2382 [20:07<8:53:55, 13.96s/it]                                                   {'loss': 1.9752, 'learning_rate': 0.0009998816308243352, 'epoch': 0.04}
  4%|▎         | 88/2382 [20:07<8:53:55, 13.96s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1196 > 1024). Running this sequence through the model will result in indexing errors
  4%|▎         | 89/2382 [20:21<8:47:50, 13.81s/it]                                                   {'loss': 2.0545, 'learning_rate': 0.0009998663729774693, 'epoch': 0.04}
  4%|▎         | 89/2382 [20:21<8:47:50, 13.81s/it]  4%|▍         | 90/2382 [20:34<8:39:17, 13.59s/it]                                                   {'loss': 2.155, 'learning_rate': 0.0009998501905822267, 'epoch': 0.04}
  4%|▍         | 90/2382 [20:34<8:39:17, 13.59s/it]  4%|▍         | 91/2382 [20:46<8:26:20, 13.26s/it]                                                   {'loss': 2.1745, 'learning_rate': 0.0009998330836685377, 'epoch': 0.04}
  4%|▍         | 91/2382 [20:46<8:26:20, 13.26s/it]  4%|▍         | 92/2382 [20:58<8:13:06, 12.92s/it]                                                   {'loss': 2.1104, 'learning_rate': 0.0009998150522680437, 'epoch': 0.04}
  4%|▍         | 92/2382 [20:58<8:13:06, 12.92s/it]  4%|▍         | 93/2382 [21:11<8:06:22, 12.75s/it]                                                   {'loss': 2.1386, 'learning_rate': 0.0009997960964140947, 'epoch': 0.04}
  4%|▍         | 93/2382 [21:11<8:06:22, 12.75s/it]  4%|▍         | 94/2382 [21:22<7:55:08, 12.46s/it]                                                   {'loss': 2.1348, 'learning_rate': 0.0009997762161417516, 'epoch': 0.04}
  4%|▍         | 94/2382 [21:22<7:55:08, 12.46s/it]  4%|▍         | 95/2382 [21:35<7:57:09, 12.52s/it]                                                   {'loss': 2.137, 'learning_rate': 0.0009997554114877852, 'epoch': 0.04}
  4%|▍         | 95/2382 [21:35<7:57:09, 12.52s/it]  4%|▍         | 96/2382 [21:49<8:13:40, 12.96s/it]                                                   {'loss': 2.1378, 'learning_rate': 0.000999733682490675, 'epoch': 0.04}
  4%|▍         | 96/2382 [21:49<8:13:40, 12.96s/it]  4%|▍         | 97/2382 [22:04<8:36:32, 13.56s/it]                                                   {'loss': 2.2195, 'learning_rate': 0.0009997110291906108, 'epoch': 0.04}
  4%|▍         | 97/2382 [22:04<8:36:32, 13.56s/it]  4%|▍         | 98/2382 [22:18<8:41:02, 13.69s/it]                                                   {'loss': 2.1903, 'learning_rate': 0.0009996874516294925, 'epoch': 0.04}
  4%|▍         | 98/2382 [22:18<8:41:02, 13.69s/it]  4%|▍         | 99/2382 [22:31<8:38:32, 13.63s/it]                                                   {'loss': 2.1193, 'learning_rate': 0.0009996629498509283, 'epoch': 0.04}
  4%|▍         | 99/2382 [22:31<8:38:32, 13.63s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1547 > 1024). Running this sequence through the model will result in indexing errors
  4%|▍         | 100/2382 [22:49<9:23:06, 14.81s/it]                                                    {'loss': 2.1647, 'learning_rate': 0.0009996375239002368, 'epoch': 0.04}
  4%|▍         | 100/2382 [22:49<9:23:06, 14.81s/it]  4%|▍         | 101/2382 [23:03<9:09:13, 14.45s/it]                                                    {'loss': 2.1355, 'learning_rate': 0.0009996111738244456, 'epoch': 0.04}
  4%|▍         | 101/2382 [23:03<9:09:13, 14.45s/it]  4%|▍         | 102/2382 [23:16<8:55:58, 14.10s/it]                                                    {'loss': 2.0763, 'learning_rate': 0.0009995838996722914, 'epoch': 0.04}
  4%|▍         | 102/2382 [23:16<8:55:58, 14.10s/it]  4%|▍         | 103/2382 [23:30<8:57:17, 14.15s/it]                                                    {'loss': 2.0479, 'learning_rate': 0.0009995557014942204, 'epoch': 0.04}
  4%|▍         | 103/2382 [23:30<8:57:17, 14.15s/it]  4%|▍         | 104/2382 [23:46<9:21:25, 14.79s/it]                                                    {'loss': 2.1051, 'learning_rate': 0.0009995265793423878, 'epoch': 0.04}
  4%|▍         | 104/2382 [23:46<9:21:25, 14.79s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1059 > 1024). Running this sequence through the model will result in indexing errors
  4%|▍         | 105/2382 [24:05<10:00:26, 15.82s/it]                                                     {'loss': 2.2141, 'learning_rate': 0.0009994965332706573, 'epoch': 0.04}
  4%|▍         | 105/2382 [24:05<10:00:26, 15.82s/it]  4%|▍         | 106/2382 [24:21<10:03:16, 15.90s/it]                                                     {'loss': 2.0351, 'learning_rate': 0.0009994655633346022, 'epoch': 0.04}
  4%|▍         | 106/2382 [24:21<10:03:16, 15.90s/it]  4%|▍         | 107/2382 [24:35<9:38:31, 15.26s/it]                                                     {'loss': 2.1688, 'learning_rate': 0.000999433669591504, 'epoch': 0.04}
  4%|▍         | 107/2382 [24:35<9:38:31, 15.26s/it]  5%|▍         | 108/2382 [24:47<9:04:59, 14.38s/it]                                                    {'loss': 2.1485, 'learning_rate': 0.0009994008521003533, 'epoch': 0.05}
  5%|▍         | 108/2382 [24:47<9:04:59, 14.38s/it]  5%|▍         | 109/2382 [24:59<8:42:47, 13.80s/it]                                                    {'loss': 2.1155, 'learning_rate': 0.0009993671109218487, 'epoch': 0.05}
  5%|▍         | 109/2382 [24:59<8:42:47, 13.80s/it]  5%|▍         | 110/2382 [25:14<8:51:24, 14.03s/it]                                                    {'loss': 2.0904, 'learning_rate': 0.0009993324461183978, 'epoch': 0.05}
  5%|▍         | 110/2382 [25:14<8:51:24, 14.03s/it]  5%|▍         | 111/2382 [25:27<8:34:46, 13.60s/it]                                                    {'loss': 2.1813, 'learning_rate': 0.0009992968577541164, 'epoch': 0.05}
  5%|▍         | 111/2382 [25:27<8:34:46, 13.60s/it]  5%|▍         | 112/2382 [25:39<8:20:57, 13.24s/it]                                                    {'loss': 2.1415, 'learning_rate': 0.0009992603458948283, 'epoch': 0.05}
  5%|▍         | 112/2382 [25:39<8:20:57, 13.24s/it]  5%|▍         | 113/2382 [25:51<8:09:49, 12.95s/it]                                                    {'loss': 2.0664, 'learning_rate': 0.0009992229106080654, 'epoch': 0.05}
  5%|▍         | 113/2382 [25:51<8:09:49, 12.95s/it]  5%|▍         | 114/2382 [26:04<8:09:45, 12.96s/it]                                                    {'loss': 2.1729, 'learning_rate': 0.0009991845519630679, 'epoch': 0.05}
  5%|▍         | 114/2382 [26:04<8:09:45, 12.96s/it]  5%|▍         | 115/2382 [26:17<8:06:59, 12.89s/it]                                                    {'loss': 2.2639, 'learning_rate': 0.0009991452700307834, 'epoch': 0.05}
  5%|▍         | 115/2382 [26:17<8:06:59, 12.89s/it]  5%|▍         | 116/2382 [26:32<8:29:38, 13.49s/it]                                                    {'loss': 2.0698, 'learning_rate': 0.0009991050648838675, 'epoch': 0.05}
  5%|▍         | 116/2382 [26:32<8:29:38, 13.49s/it]  5%|▍         | 117/2382 [26:47<8:44:07, 13.88s/it]                                                    {'loss': 2.1926, 'learning_rate': 0.0009990639365966836, 'epoch': 0.05}
  5%|▍         | 117/2382 [26:47<8:44:07, 13.88s/it]  5%|▍         | 118/2382 [27:02<9:06:27, 14.48s/it]                                                    {'loss': 2.1081, 'learning_rate': 0.0009990218852453014, 'epoch': 0.05}
  5%|▍         | 118/2382 [27:02<9:06:27, 14.48s/it]  5%|▍         | 119/2382 [27:17<9:04:16, 14.43s/it]                                                    {'loss': 2.1592, 'learning_rate': 0.0009989789109074996, 'epoch': 0.05}
  5%|▍         | 119/2382 [27:17<9:04:16, 14.43s/it]  5%|▌         | 120/2382 [27:32<9:07:39, 14.53s/it]                                                    {'loss': 2.0709, 'learning_rate': 0.0009989350136627626, 'epoch': 0.05}
  5%|▌         | 120/2382 [27:32<9:07:39, 14.53s/it]  5%|▌         | 121/2382 [27:47<9:17:41, 14.80s/it]                                                    {'loss': 2.14, 'learning_rate': 0.0009988901935922825, 'epoch': 0.05}
  5%|▌         | 121/2382 [27:47<9:17:41, 14.80s/it]  5%|▌         | 122/2382 [27:58<8:40:17, 13.81s/it]                                                    {'loss': 2.0587, 'learning_rate': 0.0009988444507789582, 'epoch': 0.05}
  5%|▌         | 122/2382 [27:58<8:40:17, 13.81s/it]  5%|▌         | 123/2382 [28:15<9:08:53, 14.58s/it]                                                    {'loss': 2.1208, 'learning_rate': 0.0009987977853073951, 'epoch': 0.05}
  5%|▌         | 123/2382 [28:15<9:08:53, 14.58s/it]  5%|▌         | 124/2382 [28:31<9:26:44, 15.06s/it]                                                    {'loss': 2.0106, 'learning_rate': 0.0009987501972639052, 'epoch': 0.05}
  5%|▌         | 124/2382 [28:31<9:26:44, 15.06s/it]  5%|▌         | 125/2382 [28:44<9:00:26, 14.37s/it]                                                    {'loss': 2.0855, 'learning_rate': 0.000998701686736507, 'epoch': 0.05}
  5%|▌         | 125/2382 [28:44<9:00:26, 14.37s/it]  5%|▌         | 126/2382 [28:54<8:18:03, 13.25s/it]                                                    {'loss': 2.0615, 'learning_rate': 0.000998652253814925, 'epoch': 0.05}
  5%|▌         | 126/2382 [28:54<8:18:03, 13.25s/it]  5%|▌         | 127/2382 [29:08<8:19:43, 13.30s/it]                                                    {'loss': 2.0531, 'learning_rate': 0.00099860189859059, 'epoch': 0.05}
  5%|▌         | 127/2382 [29:08<8:19:43, 13.30s/it]  5%|▌         | 128/2382 [29:21<8:18:52, 13.28s/it]                                                    {'loss': 2.0641, 'learning_rate': 0.0009985506211566387, 'epoch': 0.05}
  5%|▌         | 128/2382 [29:21<8:18:52, 13.28s/it]  5%|▌         | 129/2382 [29:32<7:51:31, 12.56s/it]                                                    {'loss': 2.1459, 'learning_rate': 0.0009984984216079133, 'epoch': 0.05}
  5%|▌         | 129/2382 [29:32<7:51:31, 12.56s/it]  5%|▌         | 130/2382 [29:46<8:05:41, 12.94s/it]                                                    {'loss': 2.0028, 'learning_rate': 0.0009984453000409614, 'epoch': 0.05}
  5%|▌         | 130/2382 [29:46<8:05:41, 12.94s/it]  5%|▌         | 131/2382 [29:57<7:46:07, 12.42s/it]                                                    {'loss': 2.0389, 'learning_rate': 0.0009983912565540364, 'epoch': 0.05}
  5%|▌         | 131/2382 [29:57<7:46:07, 12.42s/it]  6%|▌         | 132/2382 [30:10<7:53:51, 12.64s/it]                                                    {'loss': 2.0442, 'learning_rate': 0.0009983362912470966, 'epoch': 0.06}
  6%|▌         | 132/2382 [30:10<7:53:51, 12.64s/it]  6%|▌         | 133/2382 [30:24<8:08:16, 13.03s/it]                                                    {'loss': 2.0399, 'learning_rate': 0.0009982804042218054, 'epoch': 0.06}
  6%|▌         | 133/2382 [30:24<8:08:16, 13.03s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1118 > 1024). Running this sequence through the model will result in indexing errors
  6%|▌         | 134/2382 [30:37<8:01:45, 12.86s/it]                                                    {'loss': 2.0365, 'learning_rate': 0.0009982235955815308, 'epoch': 0.06}
  6%|▌         | 134/2382 [30:37<8:01:45, 12.86s/it]  6%|▌         | 135/2382 [30:52<8:30:57, 13.64s/it]                                                    {'loss': 2.0966, 'learning_rate': 0.0009981658654313456, 'epoch': 0.06}
  6%|▌         | 135/2382 [30:52<8:30:57, 13.64s/it]  6%|▌         | 136/2382 [31:06<8:33:39, 13.72s/it]                                                    {'loss': 2.0528, 'learning_rate': 0.000998107213878027, 'epoch': 0.06}
  6%|▌         | 136/2382 [31:06<8:33:39, 13.72s/it]  6%|▌         | 137/2382 [31:17<8:09:35, 13.08s/it]                                                    {'loss': 2.1153, 'learning_rate': 0.0009980476410300567, 'epoch': 0.06}
  6%|▌         | 137/2382 [31:18<8:09:35, 13.08s/it]  6%|▌         | 138/2382 [31:29<7:53:46, 12.67s/it]                                                    {'loss': 2.1155, 'learning_rate': 0.0009979871469976197, 'epoch': 0.06}
  6%|▌         | 138/2382 [31:29<7:53:46, 12.67s/it]  6%|▌         | 139/2382 [31:47<8:46:38, 14.09s/it]                                                    {'loss': 2.0669, 'learning_rate': 0.000997925731892605, 'epoch': 0.06}
  6%|▌         | 139/2382 [31:47<8:46:38, 14.09s/it]  6%|▌         | 140/2382 [32:00<8:36:06, 13.81s/it]                                                    {'loss': 1.9705, 'learning_rate': 0.0009978633958286059, 'epoch': 0.06}
  6%|▌         | 140/2382 [32:00<8:36:06, 13.81s/it]  6%|▌         | 141/2382 [32:12<8:21:16, 13.42s/it]                                                    {'loss': 2.1574, 'learning_rate': 0.0009978001389209187, 'epoch': 0.06}
  6%|▌         | 141/2382 [32:12<8:21:16, 13.42s/it]  6%|▌         | 142/2382 [32:23<7:50:49, 12.61s/it]                                                    {'loss': 2.1399, 'learning_rate': 0.0009977359612865424, 'epoch': 0.06}
  6%|▌         | 142/2382 [32:23<7:50:49, 12.61s/it]  6%|▌         | 143/2382 [32:38<8:21:21, 13.44s/it]                                                    {'loss': 2.0868, 'learning_rate': 0.0009976708630441795, 'epoch': 0.06}
  6%|▌         | 143/2382 [32:38<8:21:21, 13.44s/it]  6%|▌         | 144/2382 [32:49<7:51:44, 12.65s/it]                                                    {'loss': 2.066, 'learning_rate': 0.0009976048443142353, 'epoch': 0.06}
  6%|▌         | 144/2382 [32:49<7:51:44, 12.65s/it]  6%|▌         | 145/2382 [33:03<8:09:51, 13.14s/it]                                                    {'loss': 2.0042, 'learning_rate': 0.0009975379052188174, 'epoch': 0.06}
  6%|▌         | 145/2382 [33:03<8:09:51, 13.14s/it]  6%|▌         | 146/2382 [33:17<8:16:13, 13.32s/it]                                                    {'loss': 2.0685, 'learning_rate': 0.0009974700458817356, 'epoch': 0.06}
  6%|▌         | 146/2382 [33:17<8:16:13, 13.32s/it]  6%|▌         | 147/2382 [33:32<8:38:18, 13.91s/it]                                                    {'loss': 1.9892, 'learning_rate': 0.000997401266428502, 'epoch': 0.06}
  6%|▌         | 147/2382 [33:32<8:38:18, 13.91s/it]  6%|▌         | 148/2382 [33:45<8:23:43, 13.53s/it]                                                    {'loss': 1.9536, 'learning_rate': 0.0009973315669863305, 'epoch': 0.06}
  6%|▌         | 148/2382 [33:45<8:23:43, 13.53s/it]  6%|▋         | 149/2382 [34:00<8:38:13, 13.92s/it]                                                    {'loss': 1.9436, 'learning_rate': 0.0009972609476841367, 'epoch': 0.06}
  6%|▋         | 149/2382 [34:00<8:38:13, 13.92s/it]  6%|▋         | 150/2382 [34:17<9:07:25, 14.72s/it]                                                    {'loss': 2.0428, 'learning_rate': 0.0009971894086525373, 'epoch': 0.06}
  6%|▋         | 150/2382 [34:17<9:07:25, 14.72s/it]  6%|▋         | 151/2382 [34:31<9:08:55, 14.76s/it]                                                    {'loss': 2.0353, 'learning_rate': 0.0009971169500238499, 'epoch': 0.06}
  6%|▋         | 151/2382 [34:31<9:08:55, 14.76s/it]  6%|▋         | 152/2382 [34:43<8:37:43, 13.93s/it]                                                    {'loss': 2.0628, 'learning_rate': 0.000997043571932094, 'epoch': 0.06}
  6%|▋         | 152/2382 [34:43<8:37:43, 13.93s/it]  6%|▋         | 153/2382 [34:56<8:21:04, 13.49s/it]                                                    {'loss': 2.1185, 'learning_rate': 0.0009969692745129886, 'epoch': 0.06}
  6%|▋         | 153/2382 [34:56<8:21:04, 13.49s/it]  6%|▋         | 154/2382 [35:12<8:53:54, 14.38s/it]                                                    {'loss': 1.9042, 'learning_rate': 0.0009968940579039539, 'epoch': 0.06}
  6%|▋         | 154/2382 [35:12<8:53:54, 14.38s/it]  7%|▋         | 155/2382 [35:26<8:44:43, 14.14s/it]                                                    {'loss': 2.0483, 'learning_rate': 0.0009968179222441093, 'epoch': 0.07}
  7%|▋         | 155/2382 [35:26<8:44:43, 14.14s/it]  7%|▋         | 156/2382 [35:40<8:40:44, 14.04s/it]                                                    {'loss': 2.0469, 'learning_rate': 0.0009967408676742752, 'epoch': 0.07}
  7%|▋         | 156/2382 [35:40<8:40:44, 14.04s/it]  7%|▋         | 157/2382 [35:54<8:42:42, 14.10s/it]                                                    {'loss': 1.8848, 'learning_rate': 0.0009966628943369707, 'epoch': 0.07}
  7%|▋         | 157/2382 [35:54<8:42:42, 14.10s/it]  7%|▋         | 158/2382 [36:06<8:23:06, 13.57s/it]                                                    {'loss': 1.9185, 'learning_rate': 0.0009965840023764148, 'epoch': 0.07}
  7%|▋         | 158/2382 [36:06<8:23:06, 13.57s/it]  7%|▋         | 159/2382 [36:18<8:07:21, 13.15s/it]                                                    {'loss': 2.0019, 'learning_rate': 0.0009965041919385252, 'epoch': 0.07}
  7%|▋         | 159/2382 [36:18<8:07:21, 13.15s/it]  7%|▋         | 160/2382 [36:32<8:06:32, 13.14s/it]                                                    {'loss': 2.0265, 'learning_rate': 0.0009964234631709187, 'epoch': 0.07}
  7%|▋         | 160/2382 [36:32<8:06:32, 13.14s/it]  7%|▋         | 161/2382 [36:46<8:16:56, 13.42s/it]                                                    {'loss': 2.0572, 'learning_rate': 0.0009963418162229104, 'epoch': 0.07}
  7%|▋         | 161/2382 [36:46<8:16:56, 13.42s/it]  7%|▋         | 162/2382 [36:59<8:13:44, 13.34s/it]                                                    {'loss': 2.024, 'learning_rate': 0.000996259251245514, 'epoch': 0.07}
  7%|▋         | 162/2382 [36:59<8:13:44, 13.34s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1084 > 1024). Running this sequence through the model will result in indexing errors
  7%|▋         | 163/2382 [37:11<7:58:22, 12.94s/it]                                                    {'loss': 1.9878, 'learning_rate': 0.0009961757683914405, 'epoch': 0.07}
  7%|▋         | 163/2382 [37:11<7:58:22, 12.94s/it]  7%|▋         | 164/2382 [37:27<8:36:46, 13.98s/it]                                                    {'loss': 1.9738, 'learning_rate': 0.0009960913678150995, 'epoch': 0.07}
  7%|▋         | 164/2382 [37:27<8:36:46, 13.98s/it]  7%|▋         | 165/2382 [37:40<8:28:39, 13.77s/it]                                                    {'loss': 1.9155, 'learning_rate': 0.0009960060496725974, 'epoch': 0.07}
  7%|▋         | 165/2382 [37:40<8:28:39, 13.77s/it]  7%|▋         | 166/2382 [37:54<8:23:08, 13.62s/it]                                                    {'loss': 2.0713, 'learning_rate': 0.0009959198141217375, 'epoch': 0.07}
  7%|▋         | 166/2382 [37:54<8:23:08, 13.62s/it]  7%|▋         | 167/2382 [38:06<8:09:58, 13.27s/it]                                                    {'loss': 1.9459, 'learning_rate': 0.000995832661322021, 'epoch': 0.07}
  7%|▋         | 167/2382 [38:06<8:09:58, 13.27s/it]  7%|▋         | 168/2382 [38:20<8:20:18, 13.56s/it]                                                    {'loss': 1.9495, 'learning_rate': 0.0009957445914346443, 'epoch': 0.07}
  7%|▋         | 168/2382 [38:20<8:20:18, 13.56s/it]  7%|▋         | 169/2382 [38:34<8:15:27, 13.43s/it]                                                    {'loss': 1.941, 'learning_rate': 0.0009956556046225012, 'epoch': 0.07}
  7%|▋         | 169/2382 [38:34<8:15:27, 13.43s/it]  7%|▋         | 170/2382 [38:47<8:14:55, 13.42s/it]                                                    {'loss': 2.0189, 'learning_rate': 0.0009955657010501807, 'epoch': 0.07}
  7%|▋         | 170/2382 [38:47<8:14:55, 13.42s/it]  7%|▋         | 171/2382 [38:59<8:00:35, 13.04s/it]                                                    {'loss': 2.0786, 'learning_rate': 0.0009954748808839674, 'epoch': 0.07}
  7%|▋         | 171/2382 [38:59<8:00:35, 13.04s/it]  7%|▋         | 172/2382 [39:15<8:26:15, 13.74s/it]                                                    {'loss': 1.9833, 'learning_rate': 0.0009953831442918418, 'epoch': 0.07}
  7%|▋         | 172/2382 [39:15<8:26:15, 13.74s/it]  7%|▋         | 173/2382 [39:27<8:10:34, 13.32s/it]                                                    {'loss': 1.9811, 'learning_rate': 0.0009952904914434788, 'epoch': 0.07}
  7%|▋         | 173/2382 [39:27<8:10:34, 13.32s/it]  7%|▋         | 174/2382 [39:42<8:31:21, 13.90s/it]                                                    {'loss': 1.9613, 'learning_rate': 0.0009951969225102486, 'epoch': 0.07}
  7%|▋         | 174/2382 [39:42<8:31:21, 13.90s/it]  7%|▋         | 175/2382 [39:56<8:30:54, 13.89s/it]                                                    {'loss': 2.0181, 'learning_rate': 0.0009951024376652154, 'epoch': 0.07}
  7%|▋         | 175/2382 [39:56<8:30:54, 13.89s/it]  7%|▋         | 176/2382 [40:09<8:23:44, 13.70s/it]                                                    {'loss': 2.0587, 'learning_rate': 0.0009950070370831371, 'epoch': 0.07}
  7%|▋         | 176/2382 [40:09<8:23:44, 13.70s/it]  7%|▋         | 177/2382 [40:22<8:08:12, 13.28s/it]                                                    {'loss': 2.0212, 'learning_rate': 0.0009949107209404665, 'epoch': 0.07}
  7%|▋         | 177/2382 [40:22<8:08:12, 13.28s/it]  7%|▋         | 178/2382 [40:33<7:46:50, 12.71s/it]                                                    {'loss': 1.9891, 'learning_rate': 0.0009948134894153483, 'epoch': 0.07}
  7%|▋         | 178/2382 [40:33<7:46:50, 12.71s/it]  8%|▊         | 179/2382 [40:48<8:09:38, 13.34s/it]                                                    {'loss': 2.0784, 'learning_rate': 0.0009947153426876217, 'epoch': 0.08}
  8%|▊         | 179/2382 [40:48<8:09:38, 13.34s/it]  8%|▊         | 180/2382 [41:05<8:51:29, 14.48s/it]                                                    {'loss': 1.8786, 'learning_rate': 0.0009946162809388176, 'epoch': 0.08}
  8%|▊         | 180/2382 [41:05<8:51:29, 14.48s/it]  8%|▊         | 181/2382 [41:17<8:25:18, 13.77s/it]                                                    {'loss': 1.9919, 'learning_rate': 0.00099451630435216, 'epoch': 0.08}
  8%|▊         | 181/2382 [41:17<8:25:18, 13.77s/it]  8%|▊         | 182/2382 [41:31<8:31:37, 13.95s/it]                                                    {'loss': 1.9746, 'learning_rate': 0.0009944154131125641, 'epoch': 0.08}
  8%|▊         | 182/2382 [41:31<8:31:37, 13.95s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1227 > 1024). Running this sequence through the model will result in indexing errors
  8%|▊         | 183/2382 [41:44<8:20:29, 13.66s/it]                                                    {'loss': 2.1058, 'learning_rate': 0.0009943136074066384, 'epoch': 0.08}
  8%|▊         | 183/2382 [41:44<8:20:29, 13.66s/it]  8%|▊         | 184/2382 [41:55<7:44:46, 12.69s/it]                                                    {'loss': 2.0232, 'learning_rate': 0.0009942108874226813, 'epoch': 0.08}
  8%|▊         | 184/2382 [41:55<7:44:46, 12.69s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1813 > 1024). Running this sequence through the model will result in indexing errors
  8%|▊         | 185/2382 [42:09<8:00:06, 13.11s/it]                                                    {'loss': 1.9896, 'learning_rate': 0.0009941072533506826, 'epoch': 0.08}
  8%|▊         | 185/2382 [42:09<8:00:06, 13.11s/it]  8%|▊         | 186/2382 [42:22<7:55:32, 12.99s/it]                                                    {'loss': 1.9806, 'learning_rate': 0.0009940027053823232, 'epoch': 0.08}
  8%|▊         | 186/2382 [42:22<7:55:32, 12.99s/it]  8%|▊         | 187/2382 [42:36<8:06:54, 13.31s/it]                                                    {'loss': 2.0122, 'learning_rate': 0.000993897243710974, 'epoch': 0.08}
  8%|▊         | 187/2382 [42:36<8:06:54, 13.31s/it]  8%|▊         | 188/2382 [42:49<8:06:27, 13.30s/it]                                                    {'loss': 1.9236, 'learning_rate': 0.000993790868531696, 'epoch': 0.08}
  8%|▊         | 188/2382 [42:49<8:06:27, 13.30s/it]  8%|▊         | 189/2382 [43:05<8:42:01, 14.28s/it]                                                    {'loss': 1.8816, 'learning_rate': 0.0009936835800412398, 'epoch': 0.08}
  8%|▊         | 189/2382 [43:05<8:42:01, 14.28s/it]  8%|▊         | 190/2382 [43:18<8:17:45, 13.62s/it]                                                    {'loss': 2.0444, 'learning_rate': 0.0009935753784380455, 'epoch': 0.08}
  8%|▊         | 190/2382 [43:18<8:17:45, 13.62s/it]  8%|▊         | 191/2382 [43:32<8:24:39, 13.82s/it]                                                    {'loss': 1.9482, 'learning_rate': 0.0009934662639222412, 'epoch': 0.08}
  8%|▊         | 191/2382 [43:32<8:24:39, 13.82s/it]  8%|▊         | 192/2382 [43:46<8:32:37, 14.04s/it]                                                    {'loss': 2.1341, 'learning_rate': 0.0009933562366956443, 'epoch': 0.08}
  8%|▊         | 192/2382 [43:46<8:32:37, 14.04s/it]  8%|▊         | 193/2382 [43:59<8:15:26, 13.58s/it]                                                    {'loss': 1.9667, 'learning_rate': 0.0009932452969617608, 'epoch': 0.08}
  8%|▊         | 193/2382 [43:59<8:15:26, 13.58s/it]  8%|▊         | 194/2382 [44:13<8:20:13, 13.72s/it]                                                    {'loss': 2.0118, 'learning_rate': 0.0009931334449257833, 'epoch': 0.08}
  8%|▊         | 194/2382 [44:13<8:20:13, 13.72s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1145 > 1024). Running this sequence through the model will result in indexing errors
  8%|▊         | 195/2382 [44:25<8:03:53, 13.28s/it]                                                    {'loss': 2.0494, 'learning_rate': 0.000993020680794592, 'epoch': 0.08}
  8%|▊         | 195/2382 [44:25<8:03:53, 13.28s/it]  8%|▊         | 196/2382 [44:40<8:19:41, 13.72s/it]                                                    {'loss': 2.0853, 'learning_rate': 0.000992907004776755, 'epoch': 0.08}
  8%|▊         | 196/2382 [44:40<8:19:41, 13.72s/it]  8%|▊         | 197/2382 [44:53<8:14:52, 13.59s/it]                                                    {'loss': 1.9611, 'learning_rate': 0.0009927924170825264, 'epoch': 0.08}
  8%|▊         | 197/2382 [44:53<8:14:52, 13.59s/it]  8%|▊         | 198/2382 [45:03<7:36:39, 12.55s/it]                                                    {'loss': 2.1114, 'learning_rate': 0.0009926769179238466, 'epoch': 0.08}
  8%|▊         | 198/2382 [45:03<7:36:39, 12.55s/it]  8%|▊         | 199/2382 [45:17<7:50:14, 12.92s/it]                                                    {'loss': 1.9325, 'learning_rate': 0.0009925605075143413, 'epoch': 0.08}
  8%|▊         | 199/2382 [45:17<7:50:14, 12.92s/it]  8%|▊         | 200/2382 [45:31<8:04:29, 13.32s/it]                                                    {'loss': 2.0159, 'learning_rate': 0.000992443186069323, 'epoch': 0.08}
  8%|▊         | 200/2382 [45:31<8:04:29, 13.32s/it]  8%|▊         | 201/2382 [45:48<8:43:17, 14.40s/it]                                                    {'loss': 1.9605, 'learning_rate': 0.0009923249538057875, 'epoch': 0.08}
  8%|▊         | 201/2382 [45:48<8:43:17, 14.40s/it]  8%|▊         | 202/2382 [46:01<8:24:13, 13.88s/it]                                                    {'loss': 1.9137, 'learning_rate': 0.0009922058109424166, 'epoch': 0.08}
  8%|▊         | 202/2382 [46:01<8:24:13, 13.88s/it]  9%|▊         | 203/2382 [46:15<8:21:20, 13.80s/it]                                                    {'loss': 1.8779, 'learning_rate': 0.000992085757699576, 'epoch': 0.09}
  9%|▊         | 203/2382 [46:15<8:21:20, 13.80s/it]  9%|▊         | 204/2382 [46:31<8:44:42, 14.45s/it]                                                    {'loss': 2.0103, 'learning_rate': 0.0009919647942993148, 'epoch': 0.09}
  9%|▊         | 204/2382 [46:31<8:44:42, 14.45s/it]  9%|▊         | 205/2382 [46:44<8:33:47, 14.16s/it]                                                    {'loss': 2.0535, 'learning_rate': 0.0009918429209653662, 'epoch': 0.09}
  9%|▊         | 205/2382 [46:44<8:33:47, 14.16s/it]  9%|▊         | 206/2382 [46:58<8:27:07, 13.98s/it]                                                    {'loss': 2.0288, 'learning_rate': 0.0009917201379231455, 'epoch': 0.09}
  9%|▊         | 206/2382 [46:58<8:27:07, 13.98s/it]  9%|▊         | 207/2382 [47:10<8:11:24, 13.56s/it]                                                    {'loss': 1.9868, 'learning_rate': 0.0009915964453997516, 'epoch': 0.09}
  9%|▊         | 207/2382 [47:10<8:11:24, 13.56s/it]  9%|▊         | 208/2382 [47:25<8:30:21, 14.09s/it]                                                    {'loss': 2.0195, 'learning_rate': 0.0009914718436239648, 'epoch': 0.09}
  9%|▊         | 208/2382 [47:25<8:30:21, 14.09s/it]  9%|▉         | 209/2382 [47:37<8:06:56, 13.45s/it]                                                    {'loss': 2.0505, 'learning_rate': 0.0009913463328262476, 'epoch': 0.09}
  9%|▉         | 209/2382 [47:37<8:06:56, 13.45s/it]  9%|▉         | 210/2382 [47:50<7:52:31, 13.05s/it]                                                    {'loss': 1.9815, 'learning_rate': 0.0009912199132387433, 'epoch': 0.09}
  9%|▉         | 210/2382 [47:50<7:52:31, 13.05s/it]  9%|▉         | 211/2382 [48:04<8:07:13, 13.47s/it]                                                    {'loss': 1.9992, 'learning_rate': 0.000991092585095277, 'epoch': 0.09}
  9%|▉         | 211/2382 [48:04<8:07:13, 13.47s/it]  9%|▉         | 212/2382 [48:18<8:10:58, 13.58s/it]                                                    {'loss': 1.9888, 'learning_rate': 0.0009909643486313534, 'epoch': 0.09}
  9%|▉         | 212/2382 [48:18<8:10:58, 13.58s/it]  9%|▉         | 213/2382 [48:30<7:58:53, 13.25s/it]                                                    {'loss': 1.9613, 'learning_rate': 0.0009908352040841576, 'epoch': 0.09}
  9%|▉         | 213/2382 [48:30<7:58:53, 13.25s/it]  9%|▉         | 214/2382 [48:43<7:56:09, 13.18s/it]                                                    {'loss': 1.9539, 'learning_rate': 0.0009907051516925538, 'epoch': 0.09}
  9%|▉         | 214/2382 [48:43<7:56:09, 13.18s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1480 > 1024). Running this sequence through the model will result in indexing errors
  9%|▉         | 215/2382 [48:58<8:09:56, 13.57s/it]                                                    {'loss': 2.0445, 'learning_rate': 0.0009905741916970863, 'epoch': 0.09}
  9%|▉         | 215/2382 [48:58<8:09:56, 13.57s/it]  9%|▉         | 216/2382 [49:11<8:02:54, 13.38s/it]                                                    {'loss': 2.0585, 'learning_rate': 0.0009904423243399774, 'epoch': 0.09}
  9%|▉         | 216/2382 [49:11<8:02:54, 13.38s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1121 > 1024). Running this sequence through the model will result in indexing errors
  9%|▉         | 217/2382 [49:24<8:00:39, 13.32s/it]                                                    {'loss': 1.9561, 'learning_rate': 0.0009903095498651276, 'epoch': 0.09}
  9%|▉         | 217/2382 [49:24<8:00:39, 13.32s/it]  9%|▉         | 218/2382 [49:36<7:45:49, 12.92s/it]                                                    {'loss': 1.9765, 'learning_rate': 0.0009901758685181153, 'epoch': 0.09}
  9%|▉         | 218/2382 [49:36<7:45:49, 12.92s/it]  9%|▉         | 219/2382 [49:50<7:54:20, 13.16s/it]                                                    {'loss': 1.9257, 'learning_rate': 0.0009900412805461966, 'epoch': 0.09}
  9%|▉         | 219/2382 [49:50<7:54:20, 13.16s/it]  9%|▉         | 220/2382 [50:01<7:36:00, 12.66s/it]                                                    {'loss': 2.0721, 'learning_rate': 0.0009899057861983043, 'epoch': 0.09}
  9%|▉         | 220/2382 [50:01<7:36:00, 12.66s/it]  9%|▉         | 221/2382 [50:13<7:31:28, 12.53s/it]                                                    {'loss': 1.9463, 'learning_rate': 0.000989769385725047, 'epoch': 0.09}
  9%|▉         | 221/2382 [50:13<7:31:28, 12.53s/it]  9%|▉         | 222/2382 [50:25<7:21:02, 12.25s/it]                                                    {'loss': 1.8634, 'learning_rate': 0.0009896320793787105, 'epoch': 0.09}
  9%|▉         | 222/2382 [50:25<7:21:02, 12.25s/it]  9%|▉         | 223/2382 [50:39<7:39:36, 12.77s/it]                                                    {'loss': 1.9113, 'learning_rate': 0.000989493867413255, 'epoch': 0.09}
  9%|▉         | 223/2382 [50:39<7:39:36, 12.77s/it]  9%|▉         | 224/2382 [50:50<7:23:57, 12.34s/it]                                                    {'loss': 2.0358, 'learning_rate': 0.000989354750084316, 'epoch': 0.09}
  9%|▉         | 224/2382 [50:50<7:23:57, 12.34s/it]  9%|▉         | 225/2382 [51:02<7:12:25, 12.03s/it]                                                    {'loss': 1.9739, 'learning_rate': 0.0009892147276492039, 'epoch': 0.09}
  9%|▉         | 225/2382 [51:02<7:12:25, 12.03s/it]  9%|▉         | 226/2382 [51:15<7:32:20, 12.59s/it]                                                    {'loss': 1.975, 'learning_rate': 0.0009890738003669028, 'epoch': 0.09}
  9%|▉         | 226/2382 [51:15<7:32:20, 12.59s/it] 10%|▉         | 227/2382 [51:29<7:37:12, 12.73s/it]                                                    {'loss': 1.931, 'learning_rate': 0.0009889319684980706, 'epoch': 0.1}
 10%|▉         | 227/2382 [51:29<7:37:12, 12.73s/it] 10%|▉         | 228/2382 [51:42<7:45:07, 12.96s/it]                                                    {'loss': 1.9878, 'learning_rate': 0.0009887892323050384, 'epoch': 0.1}
 10%|▉         | 228/2382 [51:42<7:45:07, 12.96s/it] 10%|▉         | 229/2382 [51:56<7:51:08, 13.13s/it]                                                    {'loss': 1.9022, 'learning_rate': 0.0009886455920518095, 'epoch': 0.1}
 10%|▉         | 229/2382 [51:56<7:51:08, 13.13s/it] 10%|▉         | 230/2382 [52:09<7:54:59, 13.24s/it]                                                    {'loss': 1.865, 'learning_rate': 0.0009885010480040598, 'epoch': 0.1}
 10%|▉         | 230/2382 [52:09<7:54:59, 13.24s/it] 10%|▉         | 231/2382 [52:24<8:16:34, 13.85s/it]                                                    {'loss': 2.0061, 'learning_rate': 0.0009883556004291368, 'epoch': 0.1}
 10%|▉         | 231/2382 [52:24<8:16:34, 13.85s/it] 10%|▉         | 232/2382 [52:38<8:14:17, 13.79s/it]                                                    {'loss': 1.975, 'learning_rate': 0.0009882092495960588, 'epoch': 0.1}
 10%|▉         | 232/2382 [52:38<8:14:17, 13.79s/it] 10%|▉         | 233/2382 [52:52<8:18:18, 13.91s/it]                                                    {'loss': 1.9538, 'learning_rate': 0.000988061995775515, 'epoch': 0.1}
 10%|▉         | 233/2382 [52:52<8:18:18, 13.91s/it] 10%|▉         | 234/2382 [53:05<8:11:18, 13.72s/it]                                                    {'loss': 1.9844, 'learning_rate': 0.000987913839239865, 'epoch': 0.1}
 10%|▉         | 234/2382 [53:05<8:11:18, 13.72s/it] 10%|▉         | 235/2382 [53:19<8:11:25, 13.73s/it]                                                    {'loss': 1.938, 'learning_rate': 0.0009877647802631374, 'epoch': 0.1}
 10%|▉         | 235/2382 [53:19<8:11:25, 13.73s/it] 10%|▉         | 236/2382 [53:32<8:01:25, 13.46s/it]                                                    {'loss': 1.9577, 'learning_rate': 0.000987614819121031, 'epoch': 0.1}
 10%|▉         | 236/2382 [53:32<8:01:25, 13.46s/it] 10%|▉         | 237/2382 [53:44<7:41:11, 12.90s/it]                                                    {'loss': 1.9547, 'learning_rate': 0.0009874639560909118, 'epoch': 0.1}
 10%|▉         | 237/2382 [53:44<7:41:11, 12.90s/it] 10%|▉         | 238/2382 [53:57<7:46:04, 13.04s/it]                                                    {'loss': 1.9316, 'learning_rate': 0.0009873121914518153, 'epoch': 0.1}
 10%|▉         | 238/2382 [53:57<7:46:04, 13.04s/it] 10%|█         | 239/2382 [54:11<7:53:25, 13.26s/it]                                                    {'loss': 1.9644, 'learning_rate': 0.0009871595254844438, 'epoch': 0.1}
 10%|█         | 239/2382 [54:11<7:53:25, 13.26s/it] 10%|█         | 240/2382 [54:26<8:11:40, 13.77s/it]                                                    {'loss': 1.9987, 'learning_rate': 0.0009870059584711668, 'epoch': 0.1}
 10%|█         | 240/2382 [54:26<8:11:40, 13.77s/it] 10%|█         | 241/2382 [54:40<8:14:40, 13.86s/it]                                                    {'loss': 1.9008, 'learning_rate': 0.0009868514906960207, 'epoch': 0.1}
 10%|█         | 241/2382 [54:40<8:14:40, 13.86s/it] 10%|█         | 242/2382 [54:54<8:22:25, 14.09s/it]                                                    {'loss': 1.8785, 'learning_rate': 0.0009866961224447076, 'epoch': 0.1}
 10%|█         | 242/2382 [54:54<8:22:25, 14.09s/it] 10%|█         | 243/2382 [55:09<8:24:28, 14.15s/it]                                                    {'loss': 1.9241, 'learning_rate': 0.0009865398540045952, 'epoch': 0.1}
 10%|█         | 243/2382 [55:09<8:24:28, 14.15s/it] 10%|█         | 244/2382 [55:22<8:18:39, 13.99s/it]                                                    {'loss': 2.0188, 'learning_rate': 0.0009863826856647163, 'epoch': 0.1}
 10%|█         | 244/2382 [55:22<8:18:39, 13.99s/it] 10%|█         | 245/2382 [55:34<7:57:11, 13.40s/it]                                                    {'loss': 1.963, 'learning_rate': 0.000986224617715768, 'epoch': 0.1}
 10%|█         | 245/2382 [55:34<7:57:11, 13.40s/it] 10%|█         | 246/2382 [55:47<7:53:47, 13.31s/it]                                                    {'loss': 1.896, 'learning_rate': 0.0009860656504501113, 'epoch': 0.1}
 10%|█         | 246/2382 [55:47<7:53:47, 13.31s/it] 10%|█         | 247/2382 [56:00<7:48:00, 13.15s/it]                                                    {'loss': 1.9698, 'learning_rate': 0.000985905784161771, 'epoch': 0.1}
 10%|█         | 247/2382 [56:00<7:48:00, 13.15s/it] 10%|█         | 248/2382 [56:12<7:34:40, 12.78s/it]                                                    {'loss': 1.8695, 'learning_rate': 0.0009857450191464337, 'epoch': 0.1}
 10%|█         | 248/2382 [56:12<7:34:40, 12.78s/it] 10%|█         | 249/2382 [56:29<8:17:25, 13.99s/it]                                                    {'loss': 1.937, 'learning_rate': 0.0009855833557014496, 'epoch': 0.1}
 10%|█         | 249/2382 [56:29<8:17:25, 13.99s/it] 10%|█         | 250/2382 [56:42<8:02:30, 13.58s/it]                                                    {'loss': 1.9895, 'learning_rate': 0.0009854207941258294, 'epoch': 0.1}
 10%|█         | 250/2382 [56:42<8:02:30, 13.58s/it] 11%|█         | 251/2382 [56:56<8:11:50, 13.85s/it]                                                    {'loss': 1.972, 'learning_rate': 0.0009852573347202461, 'epoch': 0.11}
 11%|█         | 251/2382 [56:56<8:11:50, 13.85s/it] 11%|█         | 252/2382 [57:09<8:04:26, 13.65s/it]                                                    {'loss': 2.0097, 'learning_rate': 0.0009850929777870322, 'epoch': 0.11}
 11%|█         | 252/2382 [57:09<8:04:26, 13.65s/it] 11%|█         | 253/2382 [57:23<8:04:20, 13.65s/it]                                                    {'loss': 1.8934, 'learning_rate': 0.0009849277236301812, 'epoch': 0.11}
 11%|█         | 253/2382 [57:23<8:04:20, 13.65s/it] 11%|█         | 254/2382 [57:34<7:36:05, 12.86s/it]                                                    {'loss': 1.9898, 'learning_rate': 0.0009847615725553456, 'epoch': 0.11}
 11%|█         | 254/2382 [57:34<7:36:05, 12.86s/it] 11%|█         | 255/2382 [57:49<7:54:34, 13.39s/it]                                                    {'loss': 1.9662, 'learning_rate': 0.000984594524869837, 'epoch': 0.11}
 11%|█         | 255/2382 [57:49<7:54:34, 13.39s/it] 11%|█         | 256/2382 [58:00<7:38:50, 12.95s/it]                                                    {'loss': 1.9664, 'learning_rate': 0.0009844265808826253, 'epoch': 0.11}
 11%|█         | 256/2382 [58:00<7:38:50, 12.95s/it] 11%|█         | 257/2382 [58:13<7:34:52, 12.84s/it]                                                    {'loss': 1.9532, 'learning_rate': 0.0009842577409043378, 'epoch': 0.11}
 11%|█         | 257/2382 [58:13<7:34:52, 12.84s/it] 11%|█         | 258/2382 [58:27<7:51:43, 13.33s/it]                                                    {'loss': 2.0393, 'learning_rate': 0.00098408800524726, 'epoch': 0.11}
 11%|█         | 258/2382 [58:27<7:51:43, 13.33s/it] 11%|█         | 259/2382 [58:41<7:53:31, 13.38s/it]                                                    {'loss': 1.9477, 'learning_rate': 0.0009839173742253334, 'epoch': 0.11}
 11%|█         | 259/2382 [58:41<7:53:31, 13.38s/it] 11%|█         | 260/2382 [58:53<7:37:47, 12.94s/it]                                                    {'loss': 1.9478, 'learning_rate': 0.000983745848154155, 'epoch': 0.11}
 11%|█         | 260/2382 [58:53<7:37:47, 12.94s/it] 11%|█         | 261/2382 [59:07<7:49:47, 13.29s/it]                                                    {'loss': 1.809, 'learning_rate': 0.0009835734273509786, 'epoch': 0.11}
 11%|█         | 261/2382 [59:07<7:49:47, 13.29s/it] 11%|█         | 262/2382 [59:20<7:50:34, 13.32s/it]                                                    {'loss': 1.9603, 'learning_rate': 0.0009834001121347118, 'epoch': 0.11}
 11%|█         | 262/2382 [59:20<7:50:34, 13.32s/it] 11%|█         | 263/2382 [59:34<7:54:52, 13.45s/it]                                                    {'loss': 2.0616, 'learning_rate': 0.000983225902825917, 'epoch': 0.11}
 11%|█         | 263/2382 [59:34<7:54:52, 13.45s/it] 11%|█         | 264/2382 [59:46<7:40:29, 13.05s/it]                                                    {'loss': 2.0969, 'learning_rate': 0.00098305079974681, 'epoch': 0.11}
 11%|█         | 264/2382 [59:46<7:40:29, 13.05s/it] 11%|█         | 265/2382 [1:00:00<7:44:26, 13.16s/it]                                                      {'loss': 2.0134, 'learning_rate': 0.0009828748032212602, 'epoch': 0.11}
 11%|█         | 265/2382 [1:00:00<7:44:26, 13.16s/it] 11%|█         | 266/2382 [1:00:11<7:28:33, 12.72s/it]                                                      {'loss': 1.9228, 'learning_rate': 0.0009826979135747892, 'epoch': 0.11}
 11%|█         | 266/2382 [1:00:11<7:28:33, 12.72s/it] 11%|█         | 267/2382 [1:00:25<7:38:17, 13.00s/it]                                                      {'loss': 1.8967, 'learning_rate': 0.00098252013113457, 'epoch': 0.11}
 11%|█         | 267/2382 [1:00:25<7:38:17, 13.00s/it] 11%|█▏        | 268/2382 [1:00:38<7:39:58, 13.06s/it]                                                      {'loss': 2.0089, 'learning_rate': 0.000982341456229428, 'epoch': 0.11}
 11%|█▏        | 268/2382 [1:00:38<7:39:58, 13.06s/it] 11%|█▏        | 269/2382 [1:00:54<8:03:23, 13.73s/it]                                                      {'loss': 2.0723, 'learning_rate': 0.0009821618891898384, 'epoch': 0.11}
 11%|█▏        | 269/2382 [1:00:54<8:03:23, 13.73s/it] 11%|█▏        | 270/2382 [1:01:06<7:53:47, 13.46s/it]                                                      {'loss': 2.0179, 'learning_rate': 0.0009819814303479266, 'epoch': 0.11}
 11%|█▏        | 270/2382 [1:01:06<7:53:47, 13.46s/it] 11%|█▏        | 271/2382 [1:01:20<7:53:45, 13.47s/it]                                                      {'loss': 1.9328, 'learning_rate': 0.0009818000800374683, 'epoch': 0.11}
 11%|█▏        | 271/2382 [1:01:20<7:53:45, 13.47s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1312 > 1024). Running this sequence through the model will result in indexing errors
 11%|█▏        | 272/2382 [1:01:33<7:49:39, 13.36s/it]                                                      {'loss': 1.9149, 'learning_rate': 0.0009816178385938868, 'epoch': 0.11}
 11%|█▏        | 272/2382 [1:01:33<7:49:39, 13.36s/it] 11%|█▏        | 273/2382 [1:01:45<7:35:56, 12.97s/it]                                                      {'loss': 2.104, 'learning_rate': 0.0009814347063542546, 'epoch': 0.11}
 11%|█▏        | 273/2382 [1:01:45<7:35:56, 12.97s/it] 12%|█▏        | 274/2382 [1:01:57<7:23:19, 12.62s/it]                                                      {'loss': 1.9769, 'learning_rate': 0.0009812506836572913, 'epoch': 0.11}
 12%|█▏        | 274/2382 [1:01:57<7:23:19, 12.62s/it] 12%|█▏        | 275/2382 [1:02:11<7:42:21, 13.17s/it]                                                      {'loss': 2.0514, 'learning_rate': 0.0009810657708433637, 'epoch': 0.12}
 12%|█▏        | 275/2382 [1:02:11<7:42:21, 13.17s/it] 12%|█▏        | 276/2382 [1:02:25<7:47:38, 13.32s/it]                                                      {'loss': 1.9156, 'learning_rate': 0.0009808799682544847, 'epoch': 0.12}
 12%|█▏        | 276/2382 [1:02:25<7:47:38, 13.32s/it] 12%|█▏        | 277/2382 [1:02:40<8:10:20, 13.98s/it]                                                      {'loss': 1.9541, 'learning_rate': 0.0009806932762343136, 'epoch': 0.12}
 12%|█▏        | 277/2382 [1:02:40<8:10:20, 13.98s/it] 12%|█▏        | 278/2382 [1:02:53<7:57:22, 13.61s/it]                                                      {'loss': 2.0127, 'learning_rate': 0.0009805056951281536, 'epoch': 0.12}
 12%|█▏        | 278/2382 [1:02:53<7:57:22, 13.61s/it] 12%|█▏        | 279/2382 [1:03:04<7:27:24, 12.77s/it]                                                      {'loss': 1.9851, 'learning_rate': 0.0009803172252829536, 'epoch': 0.12}
 12%|█▏        | 279/2382 [1:03:04<7:27:24, 12.77s/it] 12%|█▏        | 280/2382 [1:03:17<7:33:24, 12.94s/it]                                                      {'loss': 1.9021, 'learning_rate': 0.0009801278670473054, 'epoch': 0.12}
 12%|█▏        | 280/2382 [1:03:17<7:33:24, 12.94s/it] 12%|█▏        | 281/2382 [1:03:31<7:45:04, 13.28s/it]                                                      {'loss': 1.9589, 'learning_rate': 0.0009799376207714446, 'epoch': 0.12}
 12%|█▏        | 281/2382 [1:03:31<7:45:04, 13.28s/it] 12%|█▏        | 282/2382 [1:03:46<7:56:50, 13.62s/it]                                                      {'loss': 1.9454, 'learning_rate': 0.0009797464868072487, 'epoch': 0.12}
 12%|█▏        | 282/2382 [1:03:46<7:56:50, 13.62s/it] 12%|█▏        | 283/2382 [1:03:58<7:40:20, 13.16s/it]                                                      {'loss': 1.9562, 'learning_rate': 0.0009795544655082375, 'epoch': 0.12}
 12%|█▏        | 283/2382 [1:03:58<7:40:20, 13.16s/it] 12%|█▏        | 284/2382 [1:04:12<7:45:18, 13.31s/it]                                                      {'loss': 1.9631, 'learning_rate': 0.0009793615572295722, 'epoch': 0.12}
 12%|█▏        | 284/2382 [1:04:12<7:45:18, 13.31s/it] 12%|█▏        | 285/2382 [1:04:24<7:36:41, 13.07s/it]                                                      {'loss': 1.9892, 'learning_rate': 0.0009791677623280537, 'epoch': 0.12}
 12%|█▏        | 285/2382 [1:04:24<7:36:41, 13.07s/it] 12%|█▏        | 286/2382 [1:04:36<7:27:13, 12.80s/it]                                                      {'loss': 1.9666, 'learning_rate': 0.0009789730811621236, 'epoch': 0.12}
 12%|█▏        | 286/2382 [1:04:36<7:27:13, 12.80s/it] 12%|█▏        | 287/2382 [1:04:50<7:40:11, 13.18s/it]                                                      {'loss': 1.9135, 'learning_rate': 0.0009787775140918623, 'epoch': 0.12}
 12%|█▏        | 287/2382 [1:04:50<7:40:11, 13.18s/it] 12%|█▏        | 288/2382 [1:05:06<8:08:57, 14.01s/it]                                                      {'loss': 1.8602, 'learning_rate': 0.000978581061478989, 'epoch': 0.12}
 12%|█▏        | 288/2382 [1:05:06<8:08:57, 14.01s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1054 > 1024). Running this sequence through the model will result in indexing errors
 12%|█▏        | 289/2382 [1:05:18<7:39:55, 13.18s/it]                                                      {'loss': 2.0078, 'learning_rate': 0.0009783837236868609, 'epoch': 0.12}
 12%|█▏        | 289/2382 [1:05:18<7:39:55, 13.18s/it] 12%|█▏        | 290/2382 [1:05:31<7:39:25, 13.18s/it]                                                      {'loss': 1.9324, 'learning_rate': 0.000978185501080472, 'epoch': 0.12}
 12%|█▏        | 290/2382 [1:05:31<7:39:25, 13.18s/it] 12%|█▏        | 291/2382 [1:05:41<7:09:57, 12.34s/it]                                                      {'loss': 2.1108, 'learning_rate': 0.0009779863940264529, 'epoch': 0.12}
 12%|█▏        | 291/2382 [1:05:41<7:09:57, 12.34s/it] 12%|█▏        | 292/2382 [1:05:55<7:28:51, 12.89s/it]                                                      {'loss': 2.0247, 'learning_rate': 0.0009777864028930705, 'epoch': 0.12}
 12%|█▏        | 292/2382 [1:05:55<7:28:51, 12.89s/it] 12%|█▏        | 293/2382 [1:06:08<7:25:27, 12.79s/it]                                                      {'loss': 1.9481, 'learning_rate': 0.0009775855280502264, 'epoch': 0.12}
 12%|█▏        | 293/2382 [1:06:08<7:25:27, 12.79s/it] 12%|█▏        | 294/2382 [1:06:23<7:50:54, 13.53s/it]                                                      {'loss': 1.9268, 'learning_rate': 0.000977383769869457, 'epoch': 0.12}
 12%|█▏        | 294/2382 [1:06:23<7:50:54, 13.53s/it] 12%|█▏        | 295/2382 [1:06:39<8:11:50, 14.14s/it]                                                      {'loss': 1.9653, 'learning_rate': 0.0009771811287239327, 'epoch': 0.12}
 12%|█▏        | 295/2382 [1:06:39<8:11:50, 14.14s/it] 12%|█▏        | 296/2382 [1:06:51<7:57:33, 13.74s/it]                                                      {'loss': 1.9294, 'learning_rate': 0.0009769776049884564, 'epoch': 0.12}
 12%|█▏        | 296/2382 [1:06:51<7:57:33, 13.74s/it] 12%|█▏        | 297/2382 [1:07:06<8:11:01, 14.13s/it]                                                      {'loss': 1.9326, 'learning_rate': 0.0009767731990394637, 'epoch': 0.12}
 12%|█▏        | 297/2382 [1:07:06<8:11:01, 14.13s/it] 13%|█▎        | 298/2382 [1:07:20<8:03:02, 13.91s/it]                                                      {'loss': 1.8756, 'learning_rate': 0.0009765679112550226, 'epoch': 0.13}
 13%|█▎        | 298/2382 [1:07:20<8:03:02, 13.91s/it] 13%|█▎        | 299/2382 [1:07:34<8:06:02, 14.00s/it]                                                      {'loss': 1.8385, 'learning_rate': 0.000976361742014831, 'epoch': 0.13}
 13%|█▎        | 299/2382 [1:07:34<8:06:02, 14.00s/it] 13%|█▎        | 300/2382 [1:07:47<7:51:43, 13.59s/it]                                                      {'loss': 1.8955, 'learning_rate': 0.0009761546917002177, 'epoch': 0.13}
 13%|█▎        | 300/2382 [1:07:47<7:51:43, 13.59s/it] 13%|█▎        | 301/2382 [1:07:59<7:42:48, 13.34s/it]                                                      {'loss': 1.8571, 'learning_rate': 0.0009759467606941414, 'epoch': 0.13}
 13%|█▎        | 301/2382 [1:07:59<7:42:48, 13.34s/it] 13%|█▎        | 302/2382 [1:08:11<7:23:37, 12.80s/it]                                                      {'loss': 1.9951, 'learning_rate': 0.0009757379493811892, 'epoch': 0.13}
 13%|█▎        | 302/2382 [1:08:11<7:23:37, 12.80s/it] 13%|█▎        | 303/2382 [1:08:23<7:19:31, 12.68s/it]                                                      {'loss': 2.0107, 'learning_rate': 0.0009755282581475768, 'epoch': 0.13}
 13%|█▎        | 303/2382 [1:08:23<7:19:31, 12.68s/it] 13%|█▎        | 304/2382 [1:08:36<7:20:45, 12.73s/it]                                                      {'loss': 1.9029, 'learning_rate': 0.0009753176873811471, 'epoch': 0.13}
 13%|█▎        | 304/2382 [1:08:36<7:20:45, 12.73s/it] 13%|█▎        | 305/2382 [1:08:51<7:42:45, 13.37s/it]                                                      {'loss': 1.9359, 'learning_rate': 0.00097510623747137, 'epoch': 0.13}
 13%|█▎        | 305/2382 [1:08:51<7:42:45, 13.37s/it] 13%|█▎        | 306/2382 [1:09:04<7:37:14, 13.22s/it]                                                      {'loss': 1.9961, 'learning_rate': 0.0009748939088093414, 'epoch': 0.13}
 13%|█▎        | 306/2382 [1:09:04<7:37:14, 13.22s/it] 13%|█▎        | 307/2382 [1:09:18<7:44:56, 13.44s/it]                                                      {'loss': 2.0043, 'learning_rate': 0.0009746807017877823, 'epoch': 0.13}
 13%|█▎        | 307/2382 [1:09:18<7:44:56, 13.44s/it] 13%|█▎        | 308/2382 [1:09:31<7:36:35, 13.21s/it]                                                      {'loss': 1.9152, 'learning_rate': 0.0009744666168010387, 'epoch': 0.13}
 13%|█▎        | 308/2382 [1:09:31<7:36:35, 13.21s/it] 13%|█▎        | 309/2382 [1:09:42<7:17:35, 12.67s/it]                                                      {'loss': 1.9198, 'learning_rate': 0.0009742516542450803, 'epoch': 0.13}
 13%|█▎        | 309/2382 [1:09:42<7:17:35, 12.67s/it] 13%|█▎        | 310/2382 [1:09:54<7:09:27, 12.44s/it]                                                      {'loss': 1.9645, 'learning_rate': 0.0009740358145174998, 'epoch': 0.13}
 13%|█▎        | 310/2382 [1:09:54<7:09:27, 12.44s/it] 13%|█▎        | 311/2382 [1:10:07<7:20:25, 12.76s/it]                                                      {'loss': 1.9175, 'learning_rate': 0.0009738190980175123, 'epoch': 0.13}
 13%|█▎        | 311/2382 [1:10:07<7:20:25, 12.76s/it] 13%|█▎        | 312/2382 [1:10:19<7:10:49, 12.49s/it]                                                      {'loss': 1.9602, 'learning_rate': 0.0009736015051459551, 'epoch': 0.13}
 13%|█▎        | 312/2382 [1:10:19<7:10:49, 12.49s/it] 13%|█▎        | 313/2382 [1:10:34<7:29:41, 13.04s/it]                                                      {'loss': 1.9865, 'learning_rate': 0.0009733830363052856, 'epoch': 0.13}
 13%|█▎        | 313/2382 [1:10:34<7:29:41, 13.04s/it] 13%|█▎        | 314/2382 [1:10:49<7:53:27, 13.74s/it]                                                      {'loss': 1.9519, 'learning_rate': 0.0009731636918995821, 'epoch': 0.13}
 13%|█▎        | 314/2382 [1:10:49<7:53:27, 13.74s/it] 13%|█▎        | 315/2382 [1:11:02<7:50:25, 13.66s/it]                                                      {'loss': 1.9094, 'learning_rate': 0.0009729434723345419, 'epoch': 0.13}
 13%|█▎        | 315/2382 [1:11:02<7:50:25, 13.66s/it] 13%|█▎        | 316/2382 [1:11:15<7:43:59, 13.48s/it]                                                      {'loss': 1.9452, 'learning_rate': 0.0009727223780174813, 'epoch': 0.13}
 13%|█▎        | 316/2382 [1:11:15<7:43:59, 13.48s/it] 13%|█▎        | 317/2382 [1:11:29<7:48:58, 13.63s/it]                                                      {'loss': 1.8594, 'learning_rate': 0.0009725004093573342, 'epoch': 0.13}
 13%|█▎        | 317/2382 [1:11:29<7:48:58, 13.63s/it] 13%|█▎        | 318/2382 [1:11:42<7:36:05, 13.26s/it]                                                      {'loss': 1.9112, 'learning_rate': 0.0009722775667646519, 'epoch': 0.13}
 13%|█▎        | 318/2382 [1:11:42<7:36:05, 13.26s/it] 13%|█▎        | 319/2382 [1:11:56<7:47:49, 13.61s/it]                                                      {'loss': 1.933, 'learning_rate': 0.0009720538506516024, 'epoch': 0.13}
 13%|█▎        | 319/2382 [1:11:56<7:47:49, 13.61s/it] 13%|█▎        | 320/2382 [1:12:09<7:42:24, 13.46s/it]                                                      {'loss': 1.9132, 'learning_rate': 0.0009718292614319684, 'epoch': 0.13}
 13%|█▎        | 320/2382 [1:12:09<7:42:24, 13.46s/it] 13%|█▎        | 321/2382 [1:12:22<7:30:53, 13.13s/it]                                                      {'loss': 1.9539, 'learning_rate': 0.0009716037995211484, 'epoch': 0.13}
 13%|█▎        | 321/2382 [1:12:22<7:30:53, 13.13s/it] 14%|█▎        | 322/2382 [1:12:37<7:50:30, 13.70s/it]                                                      {'loss': 1.9137, 'learning_rate': 0.0009713774653361549, 'epoch': 0.14}
 14%|█▎        | 322/2382 [1:12:37<7:50:30, 13.70s/it] 14%|█▎        | 323/2382 [1:12:50<7:43:04, 13.49s/it]                                                      {'loss': 1.9343, 'learning_rate': 0.0009711502592956135, 'epoch': 0.14}
 14%|█▎        | 323/2382 [1:12:50<7:43:04, 13.49s/it] 14%|█▎        | 324/2382 [1:13:03<7:38:19, 13.36s/it]                                                      {'loss': 1.9476, 'learning_rate': 0.0009709221818197624, 'epoch': 0.14}
 14%|█▎        | 324/2382 [1:13:03<7:38:19, 13.36s/it] 14%|█▎        | 325/2382 [1:13:14<7:14:46, 12.68s/it]                                                      {'loss': 1.8915, 'learning_rate': 0.0009706932333304517, 'epoch': 0.14}
 14%|█▎        | 325/2382 [1:13:14<7:14:46, 12.68s/it] 14%|█▎        | 326/2382 [1:13:28<7:24:02, 12.96s/it]                                                      {'loss': 1.8439, 'learning_rate': 0.0009704634142511424, 'epoch': 0.14}
 14%|█▎        | 326/2382 [1:13:28<7:24:02, 12.96s/it] 14%|█▎        | 327/2382 [1:13:45<8:10:16, 14.31s/it]                                                      {'loss': 1.9149, 'learning_rate': 0.0009702327250069059, 'epoch': 0.14}
 14%|█▎        | 327/2382 [1:13:45<8:10:16, 14.31s/it] 14%|█▍        | 328/2382 [1:14:01<8:25:36, 14.77s/it]                                                      {'loss': 1.948, 'learning_rate': 0.0009700011660244228, 'epoch': 0.14}
 14%|█▍        | 328/2382 [1:14:01<8:25:36, 14.77s/it] 14%|█▍        | 329/2382 [1:14:17<8:39:17, 15.18s/it]                                                      {'loss': 1.8812, 'learning_rate': 0.0009697687377319828, 'epoch': 0.14}
 14%|█▍        | 329/2382 [1:14:17<8:39:17, 15.18s/it] 14%|█▍        | 330/2382 [1:14:30<8:15:16, 14.48s/it]                                                      {'loss': 1.8833, 'learning_rate': 0.000969535440559483, 'epoch': 0.14}
 14%|█▍        | 330/2382 [1:14:30<8:15:16, 14.48s/it] 14%|█▍        | 331/2382 [1:14:45<8:24:40, 14.76s/it]                                                      {'loss': 1.8603, 'learning_rate': 0.0009693012749384279, 'epoch': 0.14}
 14%|█▍        | 331/2382 [1:14:45<8:24:40, 14.76s/it] 14%|█▍        | 332/2382 [1:14:58<8:04:49, 14.19s/it]                                                      {'loss': 1.8967, 'learning_rate': 0.000969066241301928, 'epoch': 0.14}
 14%|█▍        | 332/2382 [1:14:58<8:04:49, 14.19s/it] 14%|█▍        | 333/2382 [1:15:12<8:02:00, 14.11s/it]                                                      {'loss': 1.9251, 'learning_rate': 0.0009688303400846995, 'epoch': 0.14}
 14%|█▍        | 333/2382 [1:15:12<8:02:00, 14.11s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 1024). Running this sequence through the model will result in indexing errors
 14%|█▍        | 334/2382 [1:15:26<7:55:57, 13.94s/it]                                                      {'loss': 1.8884, 'learning_rate': 0.0009685935717230632, 'epoch': 0.14}
 14%|█▍        | 334/2382 [1:15:26<7:55:57, 13.94s/it] 14%|█▍        | 335/2382 [1:15:41<8:05:43, 14.24s/it]                                                      {'loss': 1.9347, 'learning_rate': 0.0009683559366549437, 'epoch': 0.14}
 14%|█▍        | 335/2382 [1:15:41<8:05:43, 14.24s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1591 > 1024). Running this sequence through the model will result in indexing errors
 14%|█▍        | 336/2382 [1:15:55<8:04:05, 14.20s/it]                                                      {'loss': 1.9929, 'learning_rate': 0.0009681174353198686, 'epoch': 0.14}
 14%|█▍        | 336/2382 [1:15:55<8:04:05, 14.20s/it] 14%|█▍        | 337/2382 [1:16:07<7:48:23, 13.74s/it]                                                      {'loss': 1.9161, 'learning_rate': 0.0009678780681589681, 'epoch': 0.14}
 14%|█▍        | 337/2382 [1:16:07<7:48:23, 13.74s/it] 14%|█▍        | 338/2382 [1:16:24<8:15:33, 14.55s/it]                                                      {'loss': 1.9347, 'learning_rate': 0.0009676378356149733, 'epoch': 0.14}
 14%|█▍        | 338/2382 [1:16:24<8:15:33, 14.55s/it] 14%|█▍        | 339/2382 [1:16:37<8:05:24, 14.26s/it]                                                      {'loss': 1.8298, 'learning_rate': 0.0009673967381322163, 'epoch': 0.14}
 14%|█▍        | 339/2382 [1:16:37<8:05:24, 14.26s/it] 14%|█▍        | 340/2382 [1:16:49<7:41:23, 13.56s/it]                                                      {'loss': 2.1164, 'learning_rate': 0.0009671547761566288, 'epoch': 0.14}
 14%|█▍        | 340/2382 [1:16:49<7:41:23, 13.56s/it] 14%|█▍        | 341/2382 [1:17:01<7:21:02, 12.97s/it]                                                      {'loss': 2.0424, 'learning_rate': 0.0009669119501357416, 'epoch': 0.14}
 14%|█▍        | 341/2382 [1:17:01<7:21:02, 12.97s/it] 14%|█▍        | 342/2382 [1:17:11<6:48:23, 12.01s/it]                                                      {'loss': 1.9902, 'learning_rate': 0.0009666682605186834, 'epoch': 0.14}
 14%|█▍        | 342/2382 [1:17:11<6:48:23, 12.01s/it] 14%|█▍        | 343/2382 [1:17:24<7:04:02, 12.48s/it]                                                      {'loss': 1.8882, 'learning_rate': 0.0009664237077561804, 'epoch': 0.14}
 14%|█▍        | 343/2382 [1:17:24<7:04:02, 12.48s/it] 14%|█▍        | 344/2382 [1:17:38<7:20:51, 12.98s/it]                                                      {'loss': 1.9395, 'learning_rate': 0.0009661782923005553, 'epoch': 0.14}
 14%|█▍        | 344/2382 [1:17:38<7:20:51, 12.98s/it] 14%|█▍        | 345/2382 [1:17:51<7:18:31, 12.92s/it]                                                      {'loss': 1.9951, 'learning_rate': 0.0009659320146057262, 'epoch': 0.14}
 14%|█▍        | 345/2382 [1:17:51<7:18:31, 12.92s/it] 15%|█▍        | 346/2382 [1:18:02<6:53:22, 12.18s/it]                                                      {'loss': 2.003, 'learning_rate': 0.0009656848751272061, 'epoch': 0.15}
 15%|█▍        | 346/2382 [1:18:02<6:53:22, 12.18s/it] 15%|█▍        | 347/2382 [1:18:16<7:15:17, 12.83s/it]                                                      {'loss': 1.9501, 'learning_rate': 0.0009654368743221021, 'epoch': 0.15}
 15%|█▍        | 347/2382 [1:18:16<7:15:17, 12.83s/it] 15%|█▍        | 348/2382 [1:18:29<7:14:33, 12.82s/it]                                                      {'loss': 1.9767, 'learning_rate': 0.0009651880126491142, 'epoch': 0.15}
 15%|█▍        | 348/2382 [1:18:29<7:14:33, 12.82s/it] 15%|█▍        | 349/2382 [1:18:42<7:20:05, 12.99s/it]                                                      {'loss': 1.893, 'learning_rate': 0.0009649382905685349, 'epoch': 0.15}
 15%|█▍        | 349/2382 [1:18:42<7:20:05, 12.99s/it] 15%|█▍        | 350/2382 [1:18:57<7:37:45, 13.52s/it]                                                      {'loss': 1.9247, 'learning_rate': 0.0009646877085422476, 'epoch': 0.15}
 15%|█▍        | 350/2382 [1:18:57<7:37:45, 13.52s/it] 15%|█▍        | 351/2382 [1:19:10<7:30:47, 13.32s/it]                                                      {'loss': 1.976, 'learning_rate': 0.0009644362670337268, 'epoch': 0.15}
 15%|█▍        | 351/2382 [1:19:10<7:30:47, 13.32s/it] 15%|█▍        | 352/2382 [1:19:25<7:47:31, 13.82s/it]                                                      {'loss': 1.9996, 'learning_rate': 0.0009641839665080363, 'epoch': 0.15}
 15%|█▍        | 352/2382 [1:19:25<7:47:31, 13.82s/it] 15%|█▍        | 353/2382 [1:19:38<7:46:55, 13.81s/it]                                                      {'loss': 2.0002, 'learning_rate': 0.0009639308074318292, 'epoch': 0.15}
 15%|█▍        | 353/2382 [1:19:38<7:46:55, 13.81s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1065 > 1024). Running this sequence through the model will result in indexing errors
 15%|█▍        | 354/2382 [1:19:52<7:42:02, 13.67s/it]                                                      {'loss': 1.9252, 'learning_rate': 0.0009636767902733459, 'epoch': 0.15}
 15%|█▍        | 354/2382 [1:19:52<7:42:02, 13.67s/it] 15%|█▍        | 355/2382 [1:20:06<7:45:01, 13.76s/it]                                                      {'loss': 1.9171, 'learning_rate': 0.0009634219155024146, 'epoch': 0.15}
 15%|█▍        | 355/2382 [1:20:06<7:45:01, 13.76s/it] 15%|█▍        | 356/2382 [1:20:19<7:38:54, 13.59s/it]                                                      {'loss': 1.9356, 'learning_rate': 0.000963166183590449, 'epoch': 0.15}
 15%|█▍        | 356/2382 [1:20:19<7:38:54, 13.59s/it] 15%|█▍        | 357/2382 [1:20:34<7:53:14, 14.02s/it]                                                      {'loss': 1.823, 'learning_rate': 0.0009629095950104491, 'epoch': 0.15}
 15%|█▍        | 357/2382 [1:20:34<7:53:14, 14.02s/it] 15%|█▌        | 358/2382 [1:20:47<7:39:18, 13.62s/it]                                                      {'loss': 1.9753, 'learning_rate': 0.0009626521502369983, 'epoch': 0.15}
 15%|█▌        | 358/2382 [1:20:47<7:39:18, 13.62s/it] 15%|█▌        | 359/2382 [1:20:58<7:18:55, 13.02s/it]                                                      {'loss': 1.8832, 'learning_rate': 0.0009623938497462645, 'epoch': 0.15}
 15%|█▌        | 359/2382 [1:20:58<7:18:55, 13.02s/it] 15%|█▌        | 360/2382 [1:21:13<7:32:43, 13.43s/it]                                                      {'loss': 2.0081, 'learning_rate': 0.0009621346940159981, 'epoch': 0.15}
 15%|█▌        | 360/2382 [1:21:13<7:32:43, 13.43s/it] 15%|█▌        | 361/2382 [1:21:25<7:21:22, 13.10s/it]                                                      {'loss': 1.8511, 'learning_rate': 0.0009618746835255307, 'epoch': 0.15}
 15%|█▌        | 361/2382 [1:21:25<7:21:22, 13.10s/it] 15%|█▌        | 362/2382 [1:21:43<8:07:30, 14.48s/it]                                                      {'loss': 1.8214, 'learning_rate': 0.0009616138187557757, 'epoch': 0.15}
 15%|█▌        | 362/2382 [1:21:43<8:07:30, 14.48s/it] 15%|█▌        | 363/2382 [1:21:55<7:46:14, 13.86s/it]                                                      {'loss': 1.8892, 'learning_rate': 0.0009613521001892263, 'epoch': 0.15}
 15%|█▌        | 363/2382 [1:21:55<7:46:14, 13.86s/it] 15%|█▌        | 364/2382 [1:22:09<7:48:16, 13.92s/it]                                                      {'loss': 1.8754, 'learning_rate': 0.0009610895283099547, 'epoch': 0.15}
 15%|█▌        | 364/2382 [1:22:09<7:48:16, 13.92s/it] 15%|█▌        | 365/2382 [1:22:20<7:19:25, 13.07s/it]                                                      {'loss': 1.9482, 'learning_rate': 0.0009608261036036117, 'epoch': 0.15}
 15%|█▌        | 365/2382 [1:22:20<7:19:25, 13.07s/it] 15%|█▌        | 366/2382 [1:22:36<7:42:54, 13.78s/it]                                                      {'loss': 1.8557, 'learning_rate': 0.0009605618265574251, 'epoch': 0.15}
 15%|█▌        | 366/2382 [1:22:36<7:42:54, 13.78s/it] 15%|█▌        | 367/2382 [1:22:47<7:21:54, 13.16s/it]                                                      {'loss': 1.8548, 'learning_rate': 0.0009602966976601994, 'epoch': 0.15}
 15%|█▌        | 367/2382 [1:22:47<7:21:54, 13.16s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1050 > 1024). Running this sequence through the model will result in indexing errors
 15%|█▌        | 368/2382 [1:23:01<7:24:30, 13.24s/it]                                                      {'loss': 1.9898, 'learning_rate': 0.0009600307174023145, 'epoch': 0.15}
 15%|█▌        | 368/2382 [1:23:01<7:24:30, 13.24s/it] 15%|█▌        | 369/2382 [1:23:14<7:18:45, 13.08s/it]                                                      {'loss': 1.7587, 'learning_rate': 0.0009597638862757254, 'epoch': 0.15}
 15%|█▌        | 369/2382 [1:23:14<7:18:45, 13.08s/it] 16%|█▌        | 370/2382 [1:23:29<7:39:12, 13.69s/it]                                                      {'loss': 1.8398, 'learning_rate': 0.0009594962047739603, 'epoch': 0.16}
 16%|█▌        | 370/2382 [1:23:29<7:39:12, 13.69s/it] 16%|█▌        | 371/2382 [1:23:42<7:32:34, 13.50s/it]                                                      {'loss': 1.878, 'learning_rate': 0.0009592276733921206, 'epoch': 0.16}
 16%|█▌        | 371/2382 [1:23:42<7:32:34, 13.50s/it] 16%|█▌        | 372/2382 [1:23:55<7:24:52, 13.28s/it]                                                      {'loss': 1.8814, 'learning_rate': 0.0009589582926268797, 'epoch': 0.16}
 16%|█▌        | 372/2382 [1:23:55<7:24:52, 13.28s/it] 16%|█▌        | 373/2382 [1:24:06<7:11:00, 12.87s/it]                                                      {'loss': 1.8556, 'learning_rate': 0.0009586880629764817, 'epoch': 0.16}
 16%|█▌        | 373/2382 [1:24:06<7:11:00, 12.87s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1063 > 1024). Running this sequence through the model will result in indexing errors
 16%|█▌        | 374/2382 [1:24:20<7:15:56, 13.03s/it]                                                      {'loss': 1.9787, 'learning_rate': 0.000958416984940741, 'epoch': 0.16}
 16%|█▌        | 374/2382 [1:24:20<7:15:56, 13.03s/it] 16%|█▌        | 375/2382 [1:24:33<7:21:03, 13.19s/it]                                                      {'loss': 1.9155, 'learning_rate': 0.000958145059021041, 'epoch': 0.16}
 16%|█▌        | 375/2382 [1:24:33<7:21:03, 13.19s/it] 16%|█▌        | 376/2382 [1:24:45<7:06:37, 12.76s/it]                                                      {'loss': 2.079, 'learning_rate': 0.0009578722857203336, 'epoch': 0.16}
 16%|█▌        | 376/2382 [1:24:45<7:06:37, 12.76s/it] 16%|█▌        | 377/2382 [1:24:58<7:11:11, 12.90s/it]                                                      {'loss': 1.954, 'learning_rate': 0.0009575986655431377, 'epoch': 0.16}
 16%|█▌        | 377/2382 [1:24:58<7:11:11, 12.90s/it] 16%|█▌        | 378/2382 [1:25:11<7:09:46, 12.87s/it]                                                      {'loss': 2.0202, 'learning_rate': 0.000957324198995539, 'epoch': 0.16}
 16%|█▌        | 378/2382 [1:25:11<7:09:46, 12.87s/it] 16%|█▌        | 379/2382 [1:25:25<7:15:55, 13.06s/it]                                                      {'loss': 1.9117, 'learning_rate': 0.000957048886585188, 'epoch': 0.16}
 16%|█▌        | 379/2382 [1:25:25<7:15:55, 13.06s/it] 16%|█▌        | 380/2382 [1:25:39<7:27:44, 13.42s/it]                                                      {'loss': 1.8989, 'learning_rate': 0.0009567727288213005, 'epoch': 0.16}
 16%|█▌        | 380/2382 [1:25:39<7:27:44, 13.42s/it] 16%|█▌        | 381/2382 [1:25:52<7:19:20, 13.17s/it]                                                      {'loss': 1.8995, 'learning_rate': 0.0009564957262146551, 'epoch': 0.16}
 16%|█▌        | 381/2382 [1:25:52<7:19:20, 13.17s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1440 > 1024). Running this sequence through the model will result in indexing errors
 16%|█▌        | 382/2382 [1:26:03<6:57:36, 12.53s/it]                                                      {'loss': 1.962, 'learning_rate': 0.0009562178792775935, 'epoch': 0.16}
 16%|█▌        | 382/2382 [1:26:03<6:57:36, 12.53s/it] 16%|█▌        | 383/2382 [1:26:16<7:10:03, 12.91s/it]                                                      {'loss': 1.9578, 'learning_rate': 0.0009559391885240188, 'epoch': 0.16}
 16%|█▌        | 383/2382 [1:26:16<7:10:03, 12.91s/it] 16%|█▌        | 384/2382 [1:26:34<8:01:32, 14.46s/it]                                                      {'loss': 1.7953, 'learning_rate': 0.0009556596544693951, 'epoch': 0.16}
 16%|█▌        | 384/2382 [1:26:34<8:01:32, 14.46s/it] 16%|█▌        | 385/2382 [1:26:47<7:37:43, 13.75s/it]                                                      {'loss': 1.8936, 'learning_rate': 0.000955379277630746, 'epoch': 0.16}
 16%|█▌        | 385/2382 [1:26:47<7:37:43, 13.75s/it] 16%|█▌        | 386/2382 [1:26:59<7:24:49, 13.37s/it]                                                      {'loss': 1.953, 'learning_rate': 0.0009550980585266537, 'epoch': 0.16}
 16%|█▌        | 386/2382 [1:26:59<7:24:49, 13.37s/it] 16%|█▌        | 387/2382 [1:27:13<7:28:03, 13.48s/it]                                                      {'loss': 1.8622, 'learning_rate': 0.0009548159976772592, 'epoch': 0.16}
 16%|█▌        | 387/2382 [1:27:13<7:28:03, 13.48s/it] 16%|█▋        | 388/2382 [1:27:23<7:00:34, 12.66s/it]                                                      {'loss': 1.9151, 'learning_rate': 0.0009545330956042592, 'epoch': 0.16}
 16%|█▋        | 388/2382 [1:27:23<7:00:34, 12.66s/it] 16%|█▋        | 389/2382 [1:27:37<7:10:45, 12.97s/it]                                                      {'loss': 1.8866, 'learning_rate': 0.0009542493528309071, 'epoch': 0.16}
 16%|█▋        | 389/2382 [1:27:37<7:10:45, 12.97s/it] 16%|█▋        | 390/2382 [1:27:51<7:18:12, 13.20s/it]                                                      {'loss': 1.8554, 'learning_rate': 0.0009539647698820108, 'epoch': 0.16}
 16%|█▋        | 390/2382 [1:27:51<7:18:12, 13.20s/it] 16%|█▋        | 391/2382 [1:28:07<7:46:36, 14.06s/it]                                                      {'loss': 1.9292, 'learning_rate': 0.0009536793472839324, 'epoch': 0.16}
 16%|█▋        | 391/2382 [1:28:07<7:46:36, 14.06s/it] 16%|█▋        | 392/2382 [1:28:21<7:47:05, 14.08s/it]                                                      {'loss': 1.9933, 'learning_rate': 0.0009533930855645872, 'epoch': 0.16}
 16%|█▋        | 392/2382 [1:28:21<7:47:05, 14.08s/it] 16%|█▋        | 393/2382 [1:28:35<7:46:31, 14.07s/it]                                                      {'loss': 1.8653, 'learning_rate': 0.0009531059852534422, 'epoch': 0.16}
 16%|█▋        | 393/2382 [1:28:35<7:46:31, 14.07s/it] 17%|█▋        | 394/2382 [1:28:48<7:36:25, 13.78s/it]                                                      {'loss': 1.8237, 'learning_rate': 0.0009528180468815154, 'epoch': 0.17}
 17%|█▋        | 394/2382 [1:28:48<7:36:25, 13.78s/it] 17%|█▋        | 395/2382 [1:29:00<7:20:39, 13.31s/it]                                                      {'loss': 1.9715, 'learning_rate': 0.0009525292709813753, 'epoch': 0.17}
 17%|█▋        | 395/2382 [1:29:00<7:20:39, 13.31s/it] 17%|█▋        | 396/2382 [1:29:15<7:32:44, 13.68s/it]                                                      {'loss': 1.9335, 'learning_rate': 0.000952239658087139, 'epoch': 0.17}
 17%|█▋        | 396/2382 [1:29:15<7:32:44, 13.68s/it] 17%|█▋        | 397/2382 [1:29:29<7:38:38, 13.86s/it]                                                      {'loss': 1.8859, 'learning_rate': 0.0009519492087344723, 'epoch': 0.17}
 17%|█▋        | 397/2382 [1:29:29<7:38:38, 13.86s/it] 17%|█▋        | 398/2382 [1:29:42<7:25:48, 13.48s/it]                                                      {'loss': 2.0269, 'learning_rate': 0.0009516579234605874, 'epoch': 0.17}
 17%|█▋        | 398/2382 [1:29:42<7:25:48, 13.48s/it] 17%|█▋        | 399/2382 [1:29:54<7:10:07, 13.01s/it]                                                      {'loss': 1.9324, 'learning_rate': 0.0009513658028042429, 'epoch': 0.17}
 17%|█▋        | 399/2382 [1:29:54<7:10:07, 13.01s/it] 17%|█▋        | 400/2382 [1:30:07<7:10:34, 13.03s/it]                                                      {'loss': 1.8631, 'learning_rate': 0.0009510728473057426, 'epoch': 0.17}
 17%|█▋        | 400/2382 [1:30:07<7:10:34, 13.03s/it] 17%|█▋        | 401/2382 [1:30:20<7:10:33, 13.04s/it]                                                      {'loss': 1.9402, 'learning_rate': 0.0009507790575069346, 'epoch': 0.17}
 17%|█▋        | 401/2382 [1:30:20<7:10:33, 13.04s/it] 17%|█▋        | 402/2382 [1:30:33<7:09:24, 13.01s/it]                                                      {'loss': 1.9275, 'learning_rate': 0.0009504844339512095, 'epoch': 0.17}
 17%|█▋        | 402/2382 [1:30:33<7:09:24, 13.01s/it] 17%|█▋        | 403/2382 [1:30:46<7:09:51, 13.03s/it]                                                      {'loss': 1.9288, 'learning_rate': 0.0009501889771835008, 'epoch': 0.17}
 17%|█▋        | 403/2382 [1:30:46<7:09:51, 13.03s/it] 17%|█▋        | 404/2382 [1:31:01<7:25:41, 13.52s/it]                                                      {'loss': 1.8831, 'learning_rate': 0.0009498926877502824, 'epoch': 0.17}
 17%|█▋        | 404/2382 [1:31:01<7:25:41, 13.52s/it] 17%|█▋        | 405/2382 [1:31:14<7:26:45, 13.56s/it]                                                      {'loss': 1.9442, 'learning_rate': 0.000949595566199569, 'epoch': 0.17}
 17%|█▋        | 405/2382 [1:31:14<7:26:45, 13.56s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1196 > 1024). Running this sequence through the model will result in indexing errors
 17%|█▋        | 406/2382 [1:31:29<7:34:13, 13.79s/it]                                                      {'loss': 1.9544, 'learning_rate': 0.0009492976130809134, 'epoch': 0.17}
 17%|█▋        | 406/2382 [1:31:29<7:34:13, 13.79s/it] 17%|█▋        | 407/2382 [1:31:41<7:23:12, 13.46s/it]                                                      {'loss': 1.8475, 'learning_rate': 0.0009489988289454073, 'epoch': 0.17}
 17%|█▋        | 407/2382 [1:31:41<7:23:12, 13.46s/it] 17%|█▋        | 408/2382 [1:31:54<7:15:00, 13.22s/it]                                                      {'loss': 1.9612, 'learning_rate': 0.0009486992143456792, 'epoch': 0.17}
 17%|█▋        | 408/2382 [1:31:54<7:15:00, 13.22s/it] 17%|█▋        | 409/2382 [1:32:06<7:05:40, 12.94s/it]                                                      {'loss': 1.8852, 'learning_rate': 0.0009483987698358935, 'epoch': 0.17}
 17%|█▋        | 409/2382 [1:32:06<7:05:40, 12.94s/it] 17%|█▋        | 410/2382 [1:32:20<7:15:37, 13.25s/it]                                                      {'loss': 1.8387, 'learning_rate': 0.0009480974959717498, 'epoch': 0.17}
 17%|█▋        | 410/2382 [1:32:20<7:15:37, 13.25s/it] 17%|█▋        | 411/2382 [1:32:34<7:18:23, 13.35s/it]                                                      {'loss': 1.974, 'learning_rate': 0.0009477953933104815, 'epoch': 0.17}
 17%|█▋        | 411/2382 [1:32:34<7:18:23, 13.35s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1042 > 1024). Running this sequence through the model will result in indexing errors
 17%|█▋        | 412/2382 [1:32:48<7:22:56, 13.49s/it]                                                      {'loss': 2.0356, 'learning_rate': 0.0009474924624108549, 'epoch': 0.17}
 17%|█▋        | 412/2382 [1:32:48<7:22:56, 13.49s/it] 17%|█▋        | 413/2382 [1:33:01<7:23:10, 13.50s/it]                                                      {'loss': 1.9645, 'learning_rate': 0.0009471887038331685, 'epoch': 0.17}
 17%|█▋        | 413/2382 [1:33:01<7:23:10, 13.50s/it] 17%|█▋        | 414/2382 [1:33:17<7:49:33, 14.32s/it]                                                      {'loss': 1.9959, 'learning_rate': 0.0009468841181392511, 'epoch': 0.17}
 17%|█▋        | 414/2382 [1:33:17<7:49:33, 14.32s/it] 17%|█▋        | 415/2382 [1:33:29<7:24:10, 13.55s/it]                                                      {'loss': 1.8504, 'learning_rate': 0.000946578705892462, 'epoch': 0.17}
 17%|█▋        | 415/2382 [1:33:29<7:24:10, 13.55s/it] 17%|█▋        | 416/2382 [1:33:46<7:54:02, 14.47s/it]                                                      {'loss': 1.8815, 'learning_rate': 0.0009462724676576887, 'epoch': 0.17}
 17%|█▋        | 416/2382 [1:33:46<7:54:02, 14.47s/it] 18%|█▊        | 417/2382 [1:34:02<8:13:55, 15.08s/it]                                                      {'loss': 1.9381, 'learning_rate': 0.000945965404001347, 'epoch': 0.17}
 18%|█▊        | 417/2382 [1:34:02<8:13:55, 15.08s/it] 18%|█▊        | 418/2382 [1:34:14<7:38:09, 14.00s/it]                                                      {'loss': 2.0053, 'learning_rate': 0.0009456575154913788, 'epoch': 0.18}
 18%|█▊        | 418/2382 [1:34:14<7:38:09, 14.00s/it] 18%|█▊        | 419/2382 [1:34:25<7:12:25, 13.22s/it]                                                      {'loss': 1.9393, 'learning_rate': 0.0009453488026972521, 'epoch': 0.18}
 18%|█▊        | 419/2382 [1:34:25<7:12:25, 13.22s/it] 18%|█▊        | 420/2382 [1:34:39<7:22:45, 13.54s/it]                                                      {'loss': 1.8247, 'learning_rate': 0.0009450392661899593, 'epoch': 0.18}
 18%|█▊        | 420/2382 [1:34:39<7:22:45, 13.54s/it] 18%|█▊        | 421/2382 [1:34:53<7:19:01, 13.43s/it]                                                      {'loss': 1.9669, 'learning_rate': 0.0009447289065420164, 'epoch': 0.18}
 18%|█▊        | 421/2382 [1:34:53<7:19:01, 13.43s/it] 18%|█▊        | 422/2382 [1:35:07<7:31:20, 13.82s/it]                                                      {'loss': 1.9499, 'learning_rate': 0.0009444177243274617, 'epoch': 0.18}
 18%|█▊        | 422/2382 [1:35:07<7:31:20, 13.82s/it] 18%|█▊        | 423/2382 [1:35:20<7:21:30, 13.52s/it]                                                      {'loss': 1.9635, 'learning_rate': 0.0009441057201218553, 'epoch': 0.18}
 18%|█▊        | 423/2382 [1:35:20<7:21:30, 13.52s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1072 > 1024). Running this sequence through the model will result in indexing errors
 18%|█▊        | 424/2382 [1:35:33<7:16:21, 13.37s/it]                                                      {'loss': 1.9206, 'learning_rate': 0.0009437928945022771, 'epoch': 0.18}
 18%|█▊        | 424/2382 [1:35:33<7:16:21, 13.37s/it] 18%|█▊        | 425/2382 [1:35:47<7:19:19, 13.47s/it]                                                      {'loss': 1.9441, 'learning_rate': 0.0009434792480473267, 'epoch': 0.18}
 18%|█▊        | 425/2382 [1:35:47<7:19:19, 13.47s/it] 18%|█▊        | 426/2382 [1:36:00<7:13:58, 13.31s/it]                                                      {'loss': 1.9221, 'learning_rate': 0.0009431647813371218, 'epoch': 0.18}
 18%|█▊        | 426/2382 [1:36:00<7:13:58, 13.31s/it] 18%|█▊        | 427/2382 [1:36:13<7:08:03, 13.14s/it]                                                      {'loss': 1.9105, 'learning_rate': 0.000942849494953297, 'epoch': 0.18}
 18%|█▊        | 427/2382 [1:36:13<7:08:03, 13.14s/it] 18%|█▊        | 428/2382 [1:36:26<7:15:21, 13.37s/it]                                                      {'loss': 1.9199, 'learning_rate': 0.0009425333894790036, 'epoch': 0.18}
 18%|█▊        | 428/2382 [1:36:26<7:15:21, 13.37s/it] 18%|█▊        | 429/2382 [1:36:40<7:17:18, 13.44s/it]                                                      {'loss': 1.8627, 'learning_rate': 0.0009422164654989072, 'epoch': 0.18}
 18%|█▊        | 429/2382 [1:36:40<7:17:18, 13.44s/it] 18%|█▊        | 430/2382 [1:36:55<7:35:37, 14.01s/it]                                                      {'loss': 1.9032, 'learning_rate': 0.0009418987235991876, 'epoch': 0.18}
 18%|█▊        | 430/2382 [1:36:55<7:35:37, 14.01s/it] 18%|█▊        | 431/2382 [1:37:08<7:19:27, 13.51s/it]                                                      {'loss': 1.8968, 'learning_rate': 0.0009415801643675373, 'epoch': 0.18}
 18%|█▊        | 431/2382 [1:37:08<7:19:27, 13.51s/it] 18%|█▊        | 432/2382 [1:37:20<7:05:52, 13.10s/it]                                                      {'loss': 1.9427, 'learning_rate': 0.0009412607883931606, 'epoch': 0.18}
 18%|█▊        | 432/2382 [1:37:20<7:05:52, 13.10s/it] 18%|█▊        | 433/2382 [1:37:33<7:07:31, 13.16s/it]                                                      {'loss': 1.9012, 'learning_rate': 0.0009409405962667727, 'epoch': 0.18}
 18%|█▊        | 433/2382 [1:37:33<7:07:31, 13.16s/it] 18%|█▊        | 434/2382 [1:37:45<6:54:03, 12.75s/it]                                                      {'loss': 1.8964, 'learning_rate': 0.0009406195885805978, 'epoch': 0.18}
 18%|█▊        | 434/2382 [1:37:45<6:54:03, 12.75s/it] 18%|█▊        | 435/2382 [1:37:57<6:46:13, 12.52s/it]                                                      {'loss': 1.9679, 'learning_rate': 0.000940297765928369, 'epoch': 0.18}
 18%|█▊        | 435/2382 [1:37:57<6:46:13, 12.52s/it] 18%|█▊        | 436/2382 [1:38:11<7:01:58, 13.01s/it]                                                      {'loss': 1.9318, 'learning_rate': 0.0009399751289053266, 'epoch': 0.18}
 18%|█▊        | 436/2382 [1:38:11<7:01:58, 13.01s/it] 18%|█▊        | 437/2382 [1:38:24<6:59:22, 12.94s/it]                                                      {'loss': 1.8608, 'learning_rate': 0.0009396516781082172, 'epoch': 0.18}
 18%|█▊        | 437/2382 [1:38:24<6:59:22, 12.94s/it] 18%|█▊        | 438/2382 [1:38:35<6:43:40, 12.46s/it]                                                      {'loss': 2.0151, 'learning_rate': 0.0009393274141352924, 'epoch': 0.18}
 18%|█▊        | 438/2382 [1:38:35<6:43:40, 12.46s/it] 18%|█▊        | 439/2382 [1:38:49<6:52:51, 12.75s/it]                                                      {'loss': 1.8501, 'learning_rate': 0.0009390023375863077, 'epoch': 0.18}
 18%|█▊        | 439/2382 [1:38:49<6:52:51, 12.75s/it] 18%|█▊        | 440/2382 [1:39:03<7:06:22, 13.17s/it]                                                      {'loss': 1.9245, 'learning_rate': 0.0009386764490625224, 'epoch': 0.18}
 18%|█▊        | 440/2382 [1:39:03<7:06:22, 13.17s/it] 19%|█▊        | 441/2382 [1:39:15<6:54:44, 12.82s/it]                                                      {'loss': 1.9198, 'learning_rate': 0.0009383497491666964, 'epoch': 0.19}
 19%|█▊        | 441/2382 [1:39:15<6:54:44, 12.82s/it] 19%|█▊        | 442/2382 [1:39:28<6:58:28, 12.94s/it]                                                      {'loss': 1.9043, 'learning_rate': 0.0009380222385030915, 'epoch': 0.19}
 19%|█▊        | 442/2382 [1:39:28<6:58:28, 12.94s/it] 19%|█▊        | 443/2382 [1:39:42<7:05:23, 13.16s/it]                                                      {'loss': 2.0076, 'learning_rate': 0.0009376939176774678, 'epoch': 0.19}
 19%|█▊        | 443/2382 [1:39:42<7:05:23, 13.16s/it] 19%|█▊        | 444/2382 [1:39:53<6:51:04, 12.73s/it]                                                      {'loss': 1.9639, 'learning_rate': 0.0009373647872970852, 'epoch': 0.19}
 19%|█▊        | 444/2382 [1:39:53<6:51:04, 12.73s/it] 19%|█▊        | 445/2382 [1:40:08<7:11:09, 13.36s/it]                                                      {'loss': 1.9224, 'learning_rate': 0.0009370348479706998, 'epoch': 0.19}
 19%|█▊        | 445/2382 [1:40:08<7:11:09, 13.36s/it] 19%|█▊        | 446/2382 [1:40:22<7:19:26, 13.62s/it]                                                      {'loss': 1.8943, 'learning_rate': 0.0009367041003085648, 'epoch': 0.19}
 19%|█▊        | 446/2382 [1:40:22<7:19:26, 13.62s/it] 19%|█▉        | 447/2382 [1:40:37<7:25:21, 13.81s/it]                                                      {'loss': 1.8838, 'learning_rate': 0.000936372544922428, 'epoch': 0.19}
 19%|█▉        | 447/2382 [1:40:37<7:25:21, 13.81s/it] 19%|█▉        | 448/2382 [1:40:49<7:11:41, 13.39s/it]                                                      {'loss': 1.8495, 'learning_rate': 0.0009360401824255313, 'epoch': 0.19}
 19%|█▉        | 448/2382 [1:40:49<7:11:41, 13.39s/it] 19%|█▉        | 449/2382 [1:41:05<7:33:36, 14.08s/it]                                                      {'loss': 1.7557, 'learning_rate': 0.0009357070134326093, 'epoch': 0.19}
 19%|█▉        | 449/2382 [1:41:05<7:33:36, 14.08s/it] 19%|█▉        | 450/2382 [1:41:18<7:27:56, 13.91s/it]                                                      {'loss': 1.854, 'learning_rate': 0.0009353730385598887, 'epoch': 0.19}
 19%|█▉        | 450/2382 [1:41:18<7:27:56, 13.91s/it] 19%|█▉        | 451/2382 [1:41:31<7:18:12, 13.62s/it]                                                      {'loss': 1.8949, 'learning_rate': 0.0009350382584250859, 'epoch': 0.19}
 19%|█▉        | 451/2382 [1:41:31<7:18:12, 13.62s/it] 19%|█▉        | 452/2382 [1:41:44<7:09:09, 13.34s/it]                                                      {'loss': 1.8471, 'learning_rate': 0.0009347026736474076, 'epoch': 0.19}
 19%|█▉        | 452/2382 [1:41:44<7:09:09, 13.34s/it] 19%|█▉        | 453/2382 [1:41:58<7:16:53, 13.59s/it]                                                      {'loss': 1.892, 'learning_rate': 0.0009343662848475485, 'epoch': 0.19}
 19%|█▉        | 453/2382 [1:41:58<7:16:53, 13.59s/it] 19%|█▉        | 454/2382 [1:42:11<7:13:55, 13.50s/it]                                                      {'loss': 1.8647, 'learning_rate': 0.0009340290926476901, 'epoch': 0.19}
 19%|█▉        | 454/2382 [1:42:11<7:13:55, 13.50s/it] 19%|█▉        | 455/2382 [1:42:24<7:02:45, 13.16s/it]                                                      {'loss': 1.9227, 'learning_rate': 0.0009336910976715003, 'epoch': 0.19}
 19%|█▉        | 455/2382 [1:42:24<7:02:45, 13.16s/it] 19%|█▉        | 456/2382 [1:42:37<7:04:38, 13.23s/it]                                                      {'loss': 1.9552, 'learning_rate': 0.0009333523005441313, 'epoch': 0.19}
 19%|█▉        | 456/2382 [1:42:37<7:04:38, 13.23s/it] 19%|█▉        | 457/2382 [1:42:49<6:52:24, 12.85s/it]                                                      {'loss': 1.8903, 'learning_rate': 0.0009330127018922195, 'epoch': 0.19}
 19%|█▉        | 457/2382 [1:42:49<6:52:24, 12.85s/it] 19%|█▉        | 458/2382 [1:43:06<7:28:03, 13.97s/it]                                                      {'loss': 1.8576, 'learning_rate': 0.0009326723023438833, 'epoch': 0.19}
 19%|█▉        | 458/2382 [1:43:06<7:28:03, 13.97s/it] 19%|█▉        | 459/2382 [1:43:18<7:06:45, 13.32s/it]                                                      {'loss': 1.9485, 'learning_rate': 0.0009323311025287227, 'epoch': 0.19}
 19%|█▉        | 459/2382 [1:43:18<7:06:45, 13.32s/it] 19%|█▉        | 460/2382 [1:43:30<7:00:05, 13.11s/it]                                                      {'loss': 1.7789, 'learning_rate': 0.000931989103077818, 'epoch': 0.19}
 19%|█▉        | 460/2382 [1:43:30<7:00:05, 13.11s/it] 19%|█▉        | 461/2382 [1:43:43<7:00:41, 13.14s/it]                                                      {'loss': 1.892, 'learning_rate': 0.0009316463046237282, 'epoch': 0.19}
 19%|█▉        | 461/2382 [1:43:43<7:00:41, 13.14s/it] 19%|█▉        | 462/2382 [1:43:56<6:54:04, 12.94s/it]                                                      {'loss': 1.9545, 'learning_rate': 0.0009313027078004903, 'epoch': 0.19}
 19%|█▉        | 462/2382 [1:43:56<6:54:04, 12.94s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1219 > 1024). Running this sequence through the model will result in indexing errors
 19%|█▉        | 463/2382 [1:44:07<6:34:19, 12.33s/it]                                                      {'loss': 1.9583, 'learning_rate': 0.0009309583132436181, 'epoch': 0.19}
 19%|█▉        | 463/2382 [1:44:07<6:34:19, 12.33s/it] 19%|█▉        | 464/2382 [1:44:18<6:23:39, 12.00s/it]                                                      {'loss': 1.9314, 'learning_rate': 0.0009306131215901003, 'epoch': 0.19}
 19%|█▉        | 464/2382 [1:44:18<6:23:39, 12.00s/it] 20%|█▉        | 465/2382 [1:44:31<6:34:38, 12.35s/it]                                                      {'loss': 1.8799, 'learning_rate': 0.0009302671334784006, 'epoch': 0.2}
 20%|█▉        | 465/2382 [1:44:31<6:34:38, 12.35s/it] 20%|█▉        | 466/2382 [1:44:46<6:59:30, 13.14s/it]                                                      {'loss': 1.9148, 'learning_rate': 0.0009299203495484554, 'epoch': 0.2}
 20%|█▉        | 466/2382 [1:44:46<6:59:30, 13.14s/it] 20%|█▉        | 467/2382 [1:44:59<7:00:33, 13.18s/it]                                                      {'loss': 1.8768, 'learning_rate': 0.0009295727704416731, 'epoch': 0.2}
 20%|█▉        | 467/2382 [1:44:59<7:00:33, 13.18s/it] 20%|█▉        | 468/2382 [1:45:12<6:55:20, 13.02s/it]                                                      {'loss': 1.8967, 'learning_rate': 0.000929224396800933, 'epoch': 0.2}
 20%|█▉        | 468/2382 [1:45:12<6:55:20, 13.02s/it] 20%|█▉        | 469/2382 [1:45:28<7:18:44, 13.76s/it]                                                      {'loss': 1.8958, 'learning_rate': 0.000928875229270584, 'epoch': 0.2}
 20%|█▉        | 469/2382 [1:45:28<7:18:44, 13.76s/it] 20%|█▉        | 470/2382 [1:45:41<7:15:41, 13.67s/it]                                                      {'loss': 1.8801, 'learning_rate': 0.000928525268496443, 'epoch': 0.2}
 20%|█▉        | 470/2382 [1:45:41<7:15:41, 13.67s/it] 20%|█▉        | 471/2382 [1:45:54<7:09:21, 13.48s/it]                                                      {'loss': 1.8385, 'learning_rate': 0.0009281745151257945, 'epoch': 0.2}
 20%|█▉        | 471/2382 [1:45:54<7:09:21, 13.48s/it] 20%|█▉        | 472/2382 [1:46:09<7:22:40, 13.91s/it]                                                      {'loss': 1.7768, 'learning_rate': 0.0009278229698073888, 'epoch': 0.2}
 20%|█▉        | 472/2382 [1:46:09<7:22:40, 13.91s/it] 20%|█▉        | 473/2382 [1:46:21<7:05:40, 13.38s/it]                                                      {'loss': 1.9755, 'learning_rate': 0.0009274706331914407, 'epoch': 0.2}
 20%|█▉        | 473/2382 [1:46:21<7:05:40, 13.38s/it] 20%|█▉        | 474/2382 [1:46:35<7:06:05, 13.40s/it]                                                      {'loss': 1.8704, 'learning_rate': 0.0009271175059296292, 'epoch': 0.2}
 20%|█▉        | 474/2382 [1:46:35<7:06:05, 13.40s/it] 20%|█▉        | 475/2382 [1:46:50<7:25:47, 14.03s/it]                                                      {'loss': 1.8568, 'learning_rate': 0.0009267635886750952, 'epoch': 0.2}
 20%|█▉        | 475/2382 [1:46:50<7:25:47, 14.03s/it] 20%|█▉        | 476/2382 [1:47:03<7:11:44, 13.59s/it]                                                      {'loss': 1.8587, 'learning_rate': 0.0009264088820824408, 'epoch': 0.2}
 20%|█▉        | 476/2382 [1:47:03<7:11:44, 13.59s/it] 20%|██        | 477/2382 [1:47:18<7:28:14, 14.12s/it]                                                      {'loss': 1.8995, 'learning_rate': 0.0009260533868077283, 'epoch': 0.2}
 20%|██        | 477/2382 [1:47:18<7:28:14, 14.12s/it] 20%|██        | 478/2382 [1:47:32<7:26:21, 14.07s/it]                                                      {'loss': 1.9564, 'learning_rate': 0.0009256971035084784, 'epoch': 0.2}
 20%|██        | 478/2382 [1:47:32<7:26:21, 14.07s/it] 20%|██        | 479/2382 [1:47:47<7:38:56, 14.47s/it]                                                      {'loss': 1.856, 'learning_rate': 0.0009253400328436698, 'epoch': 0.2}
 20%|██        | 479/2382 [1:47:47<7:38:56, 14.47s/it] 20%|██        | 480/2382 [1:48:01<7:28:29, 14.15s/it]                                                      {'loss': 1.8004, 'learning_rate': 0.0009249821754737369, 'epoch': 0.2}
 20%|██        | 480/2382 [1:48:01<7:28:29, 14.15s/it] 20%|██        | 481/2382 [1:48:14<7:22:30, 13.97s/it]                                                      {'loss': 1.9579, 'learning_rate': 0.0009246235320605697, 'epoch': 0.2}
 20%|██        | 481/2382 [1:48:14<7:22:30, 13.97s/it] 20%|██        | 482/2382 [1:48:32<8:00:58, 15.19s/it]                                                      {'loss': 1.8008, 'learning_rate': 0.0009242641032675118, 'epoch': 0.2}
 20%|██        | 482/2382 [1:48:32<8:00:58, 15.19s/it] 20%|██        | 483/2382 [1:48:46<7:48:29, 14.80s/it]                                                      {'loss': 1.8584, 'learning_rate': 0.0009239038897593593, 'epoch': 0.2}
 20%|██        | 483/2382 [1:48:46<7:48:29, 14.80s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1145 > 1024). Running this sequence through the model will result in indexing errors
 20%|██        | 484/2382 [1:48:59<7:31:25, 14.27s/it]                                                      {'loss': 1.9352, 'learning_rate': 0.0009235428922023603, 'epoch': 0.2}
 20%|██        | 484/2382 [1:48:59<7:31:25, 14.27s/it] 20%|██        | 485/2382 [1:49:11<7:10:21, 13.61s/it]                                                      {'loss': 1.8065, 'learning_rate': 0.0009231811112642122, 'epoch': 0.2}
 20%|██        | 485/2382 [1:49:11<7:10:21, 13.61s/it] 20%|██        | 486/2382 [1:49:22<6:41:52, 12.72s/it]                                                      {'loss': 1.956, 'learning_rate': 0.000922818547614062, 'epoch': 0.2}
 20%|██        | 486/2382 [1:49:22<6:41:52, 12.72s/it] 20%|██        | 487/2382 [1:49:36<6:53:22, 13.09s/it]                                                      {'loss': 1.9903, 'learning_rate': 0.0009224552019225043, 'epoch': 0.2}
 20%|██        | 487/2382 [1:49:36<6:53:22, 13.09s/it] 20%|██        | 488/2382 [1:49:48<6:42:31, 12.75s/it]                                                      {'loss': 1.947, 'learning_rate': 0.0009220910748615798, 'epoch': 0.2}
 20%|██        | 488/2382 [1:49:48<6:42:31, 12.75s/it] 21%|██        | 489/2382 [1:50:01<6:48:39, 12.95s/it]                                                      {'loss': 1.871, 'learning_rate': 0.000921726167104775, 'epoch': 0.21}
 21%|██        | 489/2382 [1:50:01<6:48:39, 12.95s/it] 21%|██        | 490/2382 [1:50:18<7:25:05, 14.11s/it]                                                      {'loss': 1.7842, 'learning_rate': 0.0009213604793270196, 'epoch': 0.21}
 21%|██        | 490/2382 [1:50:18<7:25:05, 14.11s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1044 > 1024). Running this sequence through the model will result in indexing errors
 21%|██        | 491/2382 [1:50:32<7:20:02, 13.96s/it]                                                      {'loss': 1.9515, 'learning_rate': 0.0009209940122046867, 'epoch': 0.21}
 21%|██        | 491/2382 [1:50:32<7:20:02, 13.96s/it] 21%|██        | 492/2382 [1:50:47<7:35:20, 14.46s/it]                                                      {'loss': 2.0024, 'learning_rate': 0.0009206267664155906, 'epoch': 0.21}
 21%|██        | 492/2382 [1:50:47<7:35:20, 14.46s/it] 21%|██        | 493/2382 [1:51:01<7:28:21, 14.24s/it]                                                      {'loss': 1.9021, 'learning_rate': 0.0009202587426389858, 'epoch': 0.21}
 21%|██        | 493/2382 [1:51:01<7:28:21, 14.24s/it] 21%|██        | 494/2382 [1:51:14<7:19:25, 13.96s/it]                                                      {'loss': 1.8913, 'learning_rate': 0.0009198899415555658, 'epoch': 0.21}
 21%|██        | 494/2382 [1:51:14<7:19:25, 13.96s/it] 21%|██        | 495/2382 [1:51:28<7:19:29, 13.97s/it]                                                      {'loss': 1.8427, 'learning_rate': 0.0009195203638474618, 'epoch': 0.21}
 21%|██        | 495/2382 [1:51:28<7:19:29, 13.97s/it] 21%|██        | 496/2382 [1:51:43<7:29:04, 14.29s/it]                                                      {'loss': 1.918, 'learning_rate': 0.0009191500101982413, 'epoch': 0.21}
 21%|██        | 496/2382 [1:51:43<7:29:04, 14.29s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1066 > 1024). Running this sequence through the model will result in indexing errors
 21%|██        | 497/2382 [1:51:56<7:09:47, 13.68s/it]                                                      {'loss': 1.8478, 'learning_rate': 0.0009187788812929073, 'epoch': 0.21}
 21%|██        | 497/2382 [1:51:56<7:09:47, 13.68s/it] 21%|██        | 498/2382 [1:52:09<7:02:50, 13.47s/it]                                                      {'loss': 1.8937, 'learning_rate': 0.0009184069778178964, 'epoch': 0.21}
 21%|██        | 498/2382 [1:52:09<7:02:50, 13.47s/it] 21%|██        | 499/2382 [1:52:22<7:05:28, 13.56s/it]                                                      {'loss': 1.9688, 'learning_rate': 0.000918034300461078, 'epoch': 0.21}
 21%|██        | 499/2382 [1:52:22<7:05:28, 13.56s/it] 21%|██        | 500/2382 [1:52:36<7:04:53, 13.55s/it]                                                      {'loss': 1.8614, 'learning_rate': 0.0009176608499117527, 'epoch': 0.21}
 21%|██        | 500/2382 [1:52:36<7:04:53, 13.55s/it] 21%|██        | 501/2382 [1:52:47<6:45:20, 12.93s/it]                                                      {'loss': 1.9093, 'learning_rate': 0.0009172866268606513, 'epoch': 0.21}
 21%|██        | 501/2382 [1:52:47<6:45:20, 12.93s/it] 21%|██        | 502/2382 [1:53:04<7:16:01, 13.92s/it]                                                      {'loss': 1.8905, 'learning_rate': 0.0009169116319999336, 'epoch': 0.21}
 21%|██        | 502/2382 [1:53:04<7:16:01, 13.92s/it] 21%|██        | 503/2382 [1:53:19<7:25:08, 14.21s/it]                                                      {'loss': 1.7929, 'learning_rate': 0.0009165358660231867, 'epoch': 0.21}
 21%|██        | 503/2382 [1:53:19<7:25:08, 14.21s/it] 21%|██        | 504/2382 [1:53:35<7:43:27, 14.81s/it]                                                      {'loss': 1.8322, 'learning_rate': 0.0009161593296254236, 'epoch': 0.21}
 21%|██        | 504/2382 [1:53:35<7:43:27, 14.81s/it] 21%|██        | 505/2382 [1:53:48<7:24:51, 14.22s/it]                                                      {'loss': 1.8677, 'learning_rate': 0.0009157820235030832, 'epoch': 0.21}
 21%|██        | 505/2382 [1:53:48<7:24:51, 14.22s/it] 21%|██        | 506/2382 [1:54:01<7:21:37, 14.12s/it]                                                      {'loss': 1.9608, 'learning_rate': 0.0009154039483540273, 'epoch': 0.21}
 21%|██        | 506/2382 [1:54:01<7:21:37, 14.12s/it] 21%|██▏       | 507/2382 [1:54:16<7:29:23, 14.38s/it]                                                      {'loss': 2.0165, 'learning_rate': 0.0009150251048775403, 'epoch': 0.21}
 21%|██▏       | 507/2382 [1:54:16<7:29:23, 14.38s/it] 21%|██▏       | 508/2382 [1:54:28<7:04:31, 13.59s/it]                                                      {'loss': 1.9931, 'learning_rate': 0.0009146454937743278, 'epoch': 0.21}
 21%|██▏       | 508/2382 [1:54:28<7:04:31, 13.59s/it] 21%|██▏       | 509/2382 [1:54:42<7:09:00, 13.74s/it]                                                      {'loss': 1.8081, 'learning_rate': 0.000914265115746515, 'epoch': 0.21}
 21%|██▏       | 509/2382 [1:54:42<7:09:00, 13.74s/it] 21%|██▏       | 510/2382 [1:54:55<6:56:44, 13.36s/it]                                                      {'loss': 1.9665, 'learning_rate': 0.0009138839714976456, 'epoch': 0.21}
 21%|██▏       | 510/2382 [1:54:55<6:56:44, 13.36s/it] 21%|██▏       | 511/2382 [1:55:11<7:20:43, 14.13s/it]                                                      {'loss': 1.9095, 'learning_rate': 0.0009135020617326808, 'epoch': 0.21}
 21%|██▏       | 511/2382 [1:55:11<7:20:43, 14.13s/it] 21%|██▏       | 512/2382 [1:55:23<7:06:55, 13.70s/it]                                                      {'loss': 1.9926, 'learning_rate': 0.0009131193871579975, 'epoch': 0.21}
 21%|██▏       | 512/2382 [1:55:23<7:06:55, 13.70s/it] 22%|██▏       | 513/2382 [1:55:38<7:16:27, 14.01s/it]                                                      {'loss': 1.9142, 'learning_rate': 0.000912735948481387, 'epoch': 0.22}
 22%|██▏       | 513/2382 [1:55:38<7:16:27, 14.01s/it] 22%|██▏       | 514/2382 [1:55:53<7:23:00, 14.23s/it]                                                      {'loss': 1.9055, 'learning_rate': 0.0009123517464120542, 'epoch': 0.22}
 22%|██▏       | 514/2382 [1:55:53<7:23:00, 14.23s/it] 22%|██▏       | 515/2382 [1:56:07<7:18:04, 14.08s/it]                                                      {'loss': 1.9371, 'learning_rate': 0.0009119667816606157, 'epoch': 0.22}
 22%|██▏       | 515/2382 [1:56:07<7:18:04, 14.08s/it] 22%|██▏       | 516/2382 [1:56:20<7:15:32, 14.00s/it]                                                      {'loss': 1.8919, 'learning_rate': 0.000911581054939099, 'epoch': 0.22}
 22%|██▏       | 516/2382 [1:56:20<7:15:32, 14.00s/it] 22%|██▏       | 517/2382 [1:56:33<6:57:44, 13.44s/it]                                                      {'loss': 1.94, 'learning_rate': 0.0009111945669609407, 'epoch': 0.22}
 22%|██▏       | 517/2382 [1:56:33<6:57:44, 13.44s/it] 22%|██▏       | 518/2382 [1:56:48<7:15:26, 14.02s/it]                                                      {'loss': 1.8822, 'learning_rate': 0.0009108073184409855, 'epoch': 0.22}
 22%|██▏       | 518/2382 [1:56:48<7:15:26, 14.02s/it] 22%|██▏       | 519/2382 [1:57:01<7:07:31, 13.77s/it]                                                      {'loss': 1.8344, 'learning_rate': 0.000910419310095485, 'epoch': 0.22}
 22%|██▏       | 519/2382 [1:57:01<7:07:31, 13.77s/it] 22%|██▏       | 520/2382 [1:57:15<7:03:59, 13.66s/it]                                                      {'loss': 1.8802, 'learning_rate': 0.0009100305426420956, 'epoch': 0.22}
 22%|██▏       | 520/2382 [1:57:15<7:03:59, 13.66s/it] 22%|██▏       | 521/2382 [1:57:29<7:09:12, 13.84s/it]                                                      {'loss': 1.9909, 'learning_rate': 0.0009096410167998783, 'epoch': 0.22}
 22%|██▏       | 521/2382 [1:57:29<7:09:12, 13.84s/it] 22%|██▏       | 522/2382 [1:57:44<7:17:58, 14.13s/it]                                                      {'loss': 1.8345, 'learning_rate': 0.0009092507332892967, 'epoch': 0.22}
 22%|██▏       | 522/2382 [1:57:44<7:17:58, 14.13s/it] 22%|██▏       | 523/2382 [1:58:00<7:35:33, 14.70s/it]                                                      {'loss': 1.812, 'learning_rate': 0.0009088596928322157, 'epoch': 0.22}
 22%|██▏       | 523/2382 [1:58:00<7:35:33, 14.70s/it] 22%|██▏       | 524/2382 [1:58:13<7:20:27, 14.22s/it]                                                      {'loss': 1.8713, 'learning_rate': 0.0009084678961519, 'epoch': 0.22}
 22%|██▏       | 524/2382 [1:58:13<7:20:27, 14.22s/it] 22%|██▏       | 525/2382 [1:58:24<6:54:20, 13.39s/it]                                                      {'loss': 1.9301, 'learning_rate': 0.0009080753439730136, 'epoch': 0.22}
 22%|██▏       | 525/2382 [1:58:24<6:54:20, 13.39s/it] 22%|██▏       | 526/2382 [1:58:38<6:55:23, 13.43s/it]                                                      {'loss': 1.9162, 'learning_rate': 0.0009076820370216173, 'epoch': 0.22}
 22%|██▏       | 526/2382 [1:58:38<6:55:23, 13.43s/it] 22%|██▏       | 527/2382 [1:58:50<6:41:24, 12.98s/it]                                                      {'loss': 1.9793, 'learning_rate': 0.0009072879760251679, 'epoch': 0.22}
 22%|██▏       | 527/2382 [1:58:50<6:41:24, 12.98s/it] 22%|██▏       | 528/2382 [1:59:01<6:28:59, 12.59s/it]                                                      {'loss': 1.8584, 'learning_rate': 0.0009068931617125174, 'epoch': 0.22}
 22%|██▏       | 528/2382 [1:59:01<6:28:59, 12.59s/it] 22%|██▏       | 529/2382 [1:59:14<6:32:50, 12.72s/it]                                                      {'loss': 1.8694, 'learning_rate': 0.0009064975948139108, 'epoch': 0.22}
 22%|██▏       | 529/2382 [1:59:14<6:32:50, 12.72s/it] 22%|██▏       | 530/2382 [1:59:29<6:49:06, 13.25s/it]                                                      {'loss': 1.879, 'learning_rate': 0.000906101276060985, 'epoch': 0.22}
 22%|██▏       | 530/2382 [1:59:29<6:49:06, 13.25s/it] 22%|██▏       | 531/2382 [1:59:42<6:46:53, 13.19s/it]                                                      {'loss': 1.8558, 'learning_rate': 0.0009057042061867678, 'epoch': 0.22}
 22%|██▏       | 531/2382 [1:59:42<6:46:53, 13.19s/it] 22%|██▏       | 532/2382 [1:59:56<6:58:53, 13.59s/it]                                                      {'loss': 1.9004, 'learning_rate': 0.0009053063859256758, 'epoch': 0.22}
 22%|██▏       | 532/2382 [1:59:56<6:58:53, 13.59s/it] 22%|██▏       | 533/2382 [2:00:08<6:39:19, 12.96s/it]                                                      {'loss': 1.9169, 'learning_rate': 0.0009049078160135141, 'epoch': 0.22}
 22%|██▏       | 533/2382 [2:00:08<6:39:19, 12.96s/it] 22%|██▏       | 534/2382 [2:00:21<6:40:39, 13.01s/it]                                                      {'loss': 1.9249, 'learning_rate': 0.0009045084971874737, 'epoch': 0.22}
 22%|██▏       | 534/2382 [2:00:21<6:40:39, 13.01s/it] 22%|██▏       | 535/2382 [2:00:33<6:34:08, 12.80s/it]                                                      {'loss': 1.901, 'learning_rate': 0.0009041084301861315, 'epoch': 0.22}
 22%|██▏       | 535/2382 [2:00:33<6:34:08, 12.80s/it] 23%|██▎       | 536/2382 [2:00:47<6:37:26, 12.92s/it]                                                      {'loss': 1.933, 'learning_rate': 0.0009037076157494478, 'epoch': 0.22}
 23%|██▎       | 536/2382 [2:00:47<6:37:26, 12.92s/it] 23%|██▎       | 537/2382 [2:01:00<6:41:16, 13.05s/it]                                                      {'loss': 1.7979, 'learning_rate': 0.000903306054618765, 'epoch': 0.23}
 23%|██▎       | 537/2382 [2:01:00<6:41:16, 13.05s/it] 23%|██▎       | 538/2382 [2:01:12<6:33:18, 12.80s/it]                                                      {'loss': 1.9008, 'learning_rate': 0.0009029037475368075, 'epoch': 0.23}
 23%|██▎       | 538/2382 [2:01:12<6:33:18, 12.80s/it] 23%|██▎       | 539/2382 [2:01:24<6:23:40, 12.49s/it]                                                      {'loss': 1.8936, 'learning_rate': 0.0009025006952476786, 'epoch': 0.23}
 23%|██▎       | 539/2382 [2:01:24<6:23:40, 12.49s/it] 23%|██▎       | 540/2382 [2:01:36<6:23:53, 12.50s/it]                                                      {'loss': 1.9882, 'learning_rate': 0.0009020968984968603, 'epoch': 0.23}
 23%|██▎       | 540/2382 [2:01:36<6:23:53, 12.50s/it] 23%|██▎       | 541/2382 [2:01:49<6:28:29, 12.66s/it]                                                      {'loss': 1.8791, 'learning_rate': 0.0009016923580312113, 'epoch': 0.23}
 23%|██▎       | 541/2382 [2:01:49<6:28:29, 12.66s/it] 23%|██▎       | 542/2382 [2:02:03<6:38:51, 13.01s/it]                                                      {'loss': 1.7611, 'learning_rate': 0.0009012870745989663, 'epoch': 0.23}
 23%|██▎       | 542/2382 [2:02:03<6:38:51, 13.01s/it] 23%|██▎       | 543/2382 [2:02:16<6:37:40, 12.97s/it]                                                      {'loss': 1.8096, 'learning_rate': 0.0009008810489497338, 'epoch': 0.23}
 23%|██▎       | 543/2382 [2:02:16<6:37:40, 12.97s/it] 23%|██▎       | 544/2382 [2:02:29<6:41:01, 13.09s/it]                                                      {'loss': 1.8847, 'learning_rate': 0.000900474281834495, 'epoch': 0.23}
 23%|██▎       | 544/2382 [2:02:29<6:41:01, 13.09s/it] 23%|██▎       | 545/2382 [2:02:43<6:48:49, 13.35s/it]                                                      {'loss': 1.9197, 'learning_rate': 0.0009000667740056032, 'epoch': 0.23}
 23%|██▎       | 545/2382 [2:02:43<6:48:49, 13.35s/it] 23%|██▎       | 546/2382 [2:02:58<7:00:30, 13.74s/it]                                                      {'loss': 1.8676, 'learning_rate': 0.0008996585262167807, 'epoch': 0.23}
 23%|██▎       | 546/2382 [2:02:58<7:00:30, 13.74s/it] 23%|██▎       | 547/2382 [2:03:10<6:44:17, 13.22s/it]                                                      {'loss': 1.9423, 'learning_rate': 0.0008992495392231195, 'epoch': 0.23}
 23%|██▎       | 547/2382 [2:03:10<6:44:17, 13.22s/it] 23%|██▎       | 548/2382 [2:03:24<6:47:26, 13.33s/it]                                                      {'loss': 1.8956, 'learning_rate': 0.0008988398137810777, 'epoch': 0.23}
 23%|██▎       | 548/2382 [2:03:24<6:47:26, 13.33s/it] 23%|██▎       | 549/2382 [2:03:35<6:29:24, 12.75s/it]                                                      {'loss': 1.9761, 'learning_rate': 0.0008984293506484802, 'epoch': 0.23}
 23%|██▎       | 549/2382 [2:03:35<6:29:24, 12.75s/it] 23%|██▎       | 550/2382 [2:03:49<6:41:19, 13.14s/it]                                                      {'loss': 1.8918, 'learning_rate': 0.000898018150584516, 'epoch': 0.23}
 23%|██▎       | 550/2382 [2:03:49<6:41:19, 13.14s/it] 23%|██▎       | 551/2382 [2:04:06<7:11:05, 14.13s/it]                                                      {'loss': 1.937, 'learning_rate': 0.0008976062143497368, 'epoch': 0.23}
 23%|██▎       | 551/2382 [2:04:06<7:11:05, 14.13s/it] 23%|██▎       | 552/2382 [2:04:18<6:59:01, 13.74s/it]                                                      {'loss': 1.8477, 'learning_rate': 0.0008971935427060562, 'epoch': 0.23}
 23%|██▎       | 552/2382 [2:04:18<6:59:01, 13.74s/it] 23%|██▎       | 553/2382 [2:04:33<7:10:08, 14.11s/it]                                                      {'loss': 1.7608, 'learning_rate': 0.0008967801364167484, 'epoch': 0.23}
 23%|██▎       | 553/2382 [2:04:33<7:10:08, 14.11s/it] 23%|██▎       | 554/2382 [2:04:47<7:09:46, 14.11s/it]                                                      {'loss': 1.9426, 'learning_rate': 0.0008963659962464455, 'epoch': 0.23}
 23%|██▎       | 554/2382 [2:04:47<7:09:46, 14.11s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1760 > 1024). Running this sequence through the model will result in indexing errors
 23%|██▎       | 555/2382 [2:04:59<6:45:39, 13.32s/it]                                                      {'loss': 2.0314, 'learning_rate': 0.0008959511229611376, 'epoch': 0.23}
 23%|██▎       | 555/2382 [2:04:59<6:45:39, 13.32s/it] 23%|██▎       | 556/2382 [2:05:11<6:32:26, 12.90s/it]                                                      {'loss': 1.8656, 'learning_rate': 0.0008955355173281707, 'epoch': 0.23}
 23%|██▎       | 556/2382 [2:05:11<6:32:26, 12.90s/it] 23%|██▎       | 557/2382 [2:05:27<6:57:32, 13.73s/it]                                                      {'loss': 1.8568, 'learning_rate': 0.0008951191801162452, 'epoch': 0.23}
 23%|██▎       | 557/2382 [2:05:27<6:57:32, 13.73s/it] 23%|██▎       | 558/2382 [2:05:40<6:55:24, 13.66s/it]                                                      {'loss': 1.9012, 'learning_rate': 0.0008947021120954146, 'epoch': 0.23}
 23%|██▎       | 558/2382 [2:05:40<6:55:24, 13.66s/it] 23%|██▎       | 559/2382 [2:05:54<7:00:10, 13.83s/it]                                                      {'loss': 1.831, 'learning_rate': 0.0008942843140370844, 'epoch': 0.23}
 23%|██▎       | 559/2382 [2:05:54<7:00:10, 13.83s/it] 24%|██▎       | 560/2382 [2:06:08<6:59:24, 13.81s/it]                                                      {'loss': 1.9127, 'learning_rate': 0.0008938657867140101, 'epoch': 0.24}
 24%|██▎       | 560/2382 [2:06:08<6:59:24, 13.81s/it] 24%|██▎       | 561/2382 [2:06:20<6:46:16, 13.39s/it]                                                      {'loss': 1.913, 'learning_rate': 0.0008934465309002959, 'epoch': 0.24}
 24%|██▎       | 561/2382 [2:06:20<6:46:16, 13.39s/it] 24%|██▎       | 562/2382 [2:06:33<6:37:35, 13.11s/it]                                                      {'loss': 1.9326, 'learning_rate': 0.0008930265473713938, 'epoch': 0.24}
 24%|██▎       | 562/2382 [2:06:33<6:37:35, 13.11s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1143 > 1024). Running this sequence through the model will result in indexing errors
 24%|██▎       | 563/2382 [2:06:47<6:44:39, 13.35s/it]                                                      {'loss': 1.933, 'learning_rate': 0.0008926058369041014, 'epoch': 0.24}
 24%|██▎       | 563/2382 [2:06:47<6:44:39, 13.35s/it] 24%|██▎       | 564/2382 [2:07:00<6:44:36, 13.35s/it]                                                      {'loss': 1.9197, 'learning_rate': 0.0008921844002765613, 'epoch': 0.24}
 24%|██▎       | 564/2382 [2:07:00<6:44:36, 13.35s/it] 24%|██▎       | 565/2382 [2:07:16<7:06:19, 14.08s/it]                                                      {'loss': 1.843, 'learning_rate': 0.0008917622382682589, 'epoch': 0.24}
 24%|██▎       | 565/2382 [2:07:16<7:06:19, 14.08s/it] 24%|██▍       | 566/2382 [2:07:29<6:55:57, 13.74s/it]                                                      {'loss': 1.9527, 'learning_rate': 0.0008913393516600209, 'epoch': 0.24}
 24%|██▍       | 566/2382 [2:07:29<6:55:57, 13.74s/it] 24%|██▍       | 567/2382 [2:07:41<6:45:05, 13.39s/it]                                                      {'loss': 1.8143, 'learning_rate': 0.000890915741234015, 'epoch': 0.24}
 24%|██▍       | 567/2382 [2:07:41<6:45:05, 13.39s/it] 24%|██▍       | 568/2382 [2:07:56<6:57:32, 13.81s/it]                                                      {'loss': 1.8464, 'learning_rate': 0.0008904914077737469, 'epoch': 0.24}
 24%|██▍       | 568/2382 [2:07:56<6:57:32, 13.81s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1176 > 1024). Running this sequence through the model will result in indexing errors
 24%|██▍       | 569/2382 [2:08:07<6:28:31, 12.86s/it]                                                      {'loss': 1.8165, 'learning_rate': 0.0008900663520640604, 'epoch': 0.24}
 24%|██▍       | 569/2382 [2:08:07<6:28:31, 12.86s/it] 24%|██▍       | 570/2382 [2:08:20<6:28:30, 12.86s/it]                                                      {'loss': 1.8934, 'learning_rate': 0.0008896405748911345, 'epoch': 0.24}
 24%|██▍       | 570/2382 [2:08:20<6:28:30, 12.86s/it] 24%|██▍       | 571/2382 [2:08:37<7:08:20, 14.19s/it]                                                      {'loss': 1.8997, 'learning_rate': 0.0008892140770424827, 'epoch': 0.24}
 24%|██▍       | 571/2382 [2:08:37<7:08:20, 14.19s/it] 24%|██▍       | 572/2382 [2:08:51<7:08:27, 14.20s/it]                                                      {'loss': 1.9558, 'learning_rate': 0.0008887868593069519, 'epoch': 0.24}
 24%|██▍       | 572/2382 [2:08:51<7:08:27, 14.20s/it] 24%|██▍       | 573/2382 [2:09:05<7:07:32, 14.18s/it]                                                      {'loss': 1.8956, 'learning_rate': 0.0008883589224747201, 'epoch': 0.24}
 24%|██▍       | 573/2382 [2:09:05<7:07:32, 14.18s/it] 24%|██▍       | 574/2382 [2:09:19<6:59:31, 13.92s/it]                                                      {'loss': 1.9073, 'learning_rate': 0.0008879302673372953, 'epoch': 0.24}
 24%|██▍       | 574/2382 [2:09:19<6:59:31, 13.92s/it] 24%|██▍       | 575/2382 [2:09:31<6:40:06, 13.29s/it]                                                      {'loss': 1.9289, 'learning_rate': 0.0008875008946875144, 'epoch': 0.24}
 24%|██▍       | 575/2382 [2:09:31<6:40:06, 13.29s/it] 24%|██▍       | 576/2382 [2:09:42<6:23:52, 12.75s/it]                                                      {'loss': 1.9431, 'learning_rate': 0.0008870708053195413, 'epoch': 0.24}
 24%|██▍       | 576/2382 [2:09:42<6:23:52, 12.75s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1216 > 1024). Running this sequence through the model will result in indexing errors
 24%|██▍       | 577/2382 [2:09:57<6:44:12, 13.44s/it]                                                      {'loss': 1.8764, 'learning_rate': 0.0008866400000288651, 'epoch': 0.24}
 24%|██▍       | 577/2382 [2:09:57<6:44:12, 13.44s/it] 24%|██▍       | 578/2382 [2:10:11<6:44:07, 13.44s/it]                                                      {'loss': 1.8738, 'learning_rate': 0.0008862084796122997, 'epoch': 0.24}
 24%|██▍       | 578/2382 [2:10:11<6:44:07, 13.44s/it] 24%|██▍       | 579/2382 [2:10:26<6:59:21, 13.96s/it]                                                      {'loss': 1.8937, 'learning_rate': 0.0008857762448679815, 'epoch': 0.24}
 24%|██▍       | 579/2382 [2:10:26<6:59:21, 13.96s/it] 24%|██▍       | 580/2382 [2:10:39<6:55:53, 13.85s/it]                                                      {'loss': 1.8362, 'learning_rate': 0.0008853432965953676, 'epoch': 0.24}
 24%|██▍       | 580/2382 [2:10:39<6:55:53, 13.85s/it] 24%|██▍       | 581/2382 [2:10:53<6:52:25, 13.74s/it]                                                      {'loss': 1.812, 'learning_rate': 0.0008849096355952358, 'epoch': 0.24}
 24%|██▍       | 581/2382 [2:10:53<6:52:25, 13.74s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1267 > 1024). Running this sequence through the model will result in indexing errors
 24%|██▍       | 582/2382 [2:11:04<6:29:16, 12.98s/it]                                                      {'loss': 1.9313, 'learning_rate': 0.0008844752626696811, 'epoch': 0.24}
 24%|██▍       | 582/2382 [2:11:04<6:29:16, 12.98s/it] 24%|██▍       | 583/2382 [2:11:15<6:15:06, 12.51s/it]                                                      {'loss': 1.9086, 'learning_rate': 0.0008840401786221159, 'epoch': 0.24}
 24%|██▍       | 583/2382 [2:11:15<6:15:06, 12.51s/it] 25%|██▍       | 584/2382 [2:11:28<6:15:29, 12.53s/it]                                                      {'loss': 1.9695, 'learning_rate': 0.0008836043842572681, 'epoch': 0.25}
 25%|██▍       | 584/2382 [2:11:28<6:15:29, 12.53s/it] 25%|██▍       | 585/2382 [2:11:42<6:29:18, 13.00s/it]                                                      {'loss': 1.9076, 'learning_rate': 0.0008831678803811788, 'epoch': 0.25}
 25%|██▍       | 585/2382 [2:11:42<6:29:18, 13.00s/it] 25%|██▍       | 586/2382 [2:11:57<6:44:38, 13.52s/it]                                                      {'loss': 2.0013, 'learning_rate': 0.0008827306678012016, 'epoch': 0.25}
 25%|██▍       | 586/2382 [2:11:57<6:44:38, 13.52s/it] 25%|██▍       | 587/2382 [2:12:10<6:38:14, 13.31s/it]                                                      {'loss': 2.0312, 'learning_rate': 0.0008822927473260012, 'epoch': 0.25}
 25%|██▍       | 587/2382 [2:12:10<6:38:14, 13.31s/it] 25%|██▍       | 588/2382 [2:12:24<6:44:08, 13.52s/it]                                                      {'loss': 1.8855, 'learning_rate': 0.0008818541197655512, 'epoch': 0.25}
 25%|██▍       | 588/2382 [2:12:24<6:44:08, 13.52s/it] 25%|██▍       | 589/2382 [2:12:38<6:47:41, 13.64s/it]                                                      {'loss': 1.9249, 'learning_rate': 0.0008814147859311332, 'epoch': 0.25}
 25%|██▍       | 589/2382 [2:12:38<6:47:41, 13.64s/it] 25%|██▍       | 590/2382 [2:12:52<6:52:08, 13.80s/it]                                                      {'loss': 1.9577, 'learning_rate': 0.0008809747466353355, 'epoch': 0.25}
 25%|██▍       | 590/2382 [2:12:52<6:52:08, 13.80s/it] 25%|██▍       | 591/2382 [2:13:03<6:33:40, 13.19s/it]                                                      {'loss': 1.8534, 'learning_rate': 0.0008805340026920503, 'epoch': 0.25}
 25%|██▍       | 591/2382 [2:13:03<6:33:40, 13.19s/it] 25%|██▍       | 592/2382 [2:13:16<6:28:13, 13.01s/it]                                                      {'loss': 1.9331, 'learning_rate': 0.0008800925549164741, 'epoch': 0.25}
 25%|██▍       | 592/2382 [2:13:16<6:28:13, 13.01s/it] 25%|██▍       | 593/2382 [2:13:31<6:42:21, 13.49s/it]                                                      {'loss': 1.9302, 'learning_rate': 0.0008796504041251045, 'epoch': 0.25}
 25%|██▍       | 593/2382 [2:13:31<6:42:21, 13.49s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1127 > 1024). Running this sequence through the model will result in indexing errors
 25%|██▍       | 594/2382 [2:13:42<6:24:54, 12.92s/it]                                                      {'loss': 1.8812, 'learning_rate': 0.00087920755113574, 'epoch': 0.25}
 25%|██▍       | 594/2382 [2:13:42<6:24:54, 12.92s/it] 25%|██▍       | 595/2382 [2:13:55<6:23:24, 12.87s/it]                                                      {'loss': 1.9293, 'learning_rate': 0.000878763996767477, 'epoch': 0.25}
 25%|██▍       | 595/2382 [2:13:55<6:23:24, 12.87s/it] 25%|██▌       | 596/2382 [2:14:09<6:29:01, 13.07s/it]                                                      {'loss': 1.8069, 'learning_rate': 0.0008783197418407101, 'epoch': 0.25}
 25%|██▌       | 596/2382 [2:14:09<6:29:01, 13.07s/it] 25%|██▌       | 597/2382 [2:14:21<6:19:46, 12.77s/it]                                                      {'loss': 1.8635, 'learning_rate': 0.0008778747871771292, 'epoch': 0.25}
 25%|██▌       | 597/2382 [2:14:21<6:19:46, 12.77s/it] 25%|██▌       | 598/2382 [2:14:38<7:00:22, 14.14s/it]                                                      {'loss': 1.9235, 'learning_rate': 0.0008774291335997182, 'epoch': 0.25}
 25%|██▌       | 598/2382 [2:14:38<7:00:22, 14.14s/it] 25%|██▌       | 599/2382 [2:14:49<6:34:24, 13.27s/it]                                                      {'loss': 1.8856, 'learning_rate': 0.0008769827819327543, 'epoch': 0.25}
 25%|██▌       | 599/2382 [2:14:49<6:34:24, 13.27s/it] 25%|██▌       | 600/2382 [2:15:03<6:40:49, 13.50s/it]                                                      {'loss': 1.9393, 'learning_rate': 0.0008765357330018055, 'epoch': 0.25}
 25%|██▌       | 600/2382 [2:15:03<6:40:49, 13.50s/it] 25%|██▌       | 601/2382 [2:15:17<6:41:32, 13.53s/it]                                                      {'loss': 1.8649, 'learning_rate': 0.0008760879876337294, 'epoch': 0.25}
 25%|██▌       | 601/2382 [2:15:17<6:41:32, 13.53s/it] 25%|██▌       | 602/2382 [2:15:31<6:46:02, 13.69s/it]                                                      {'loss': 1.7751, 'learning_rate': 0.0008756395466566717, 'epoch': 0.25}
 25%|██▌       | 602/2382 [2:15:31<6:46:02, 13.69s/it] 25%|██▌       | 603/2382 [2:15:49<7:23:08, 14.95s/it]                                                      {'loss': 1.8606, 'learning_rate': 0.0008751904109000652, 'epoch': 0.25}
 25%|██▌       | 603/2382 [2:15:49<7:23:08, 14.95s/it] 25%|██▌       | 604/2382 [2:16:04<7:28:41, 15.14s/it]                                                      {'loss': 1.8468, 'learning_rate': 0.0008747405811946271, 'epoch': 0.25}
 25%|██▌       | 604/2382 [2:16:04<7:28:41, 15.14s/it] 25%|██▌       | 605/2382 [2:16:17<7:02:17, 14.26s/it]                                                      {'loss': 1.8687, 'learning_rate': 0.0008742900583723583, 'epoch': 0.25}
 25%|██▌       | 605/2382 [2:16:17<7:02:17, 14.26s/it] 25%|██▌       | 606/2382 [2:16:31<7:05:12, 14.37s/it]                                                      {'loss': 1.8106, 'learning_rate': 0.0008738388432665423, 'epoch': 0.25}
 25%|██▌       | 606/2382 [2:16:31<7:05:12, 14.37s/it] 25%|██▌       | 607/2382 [2:16:45<6:57:24, 14.11s/it]                                                      {'loss': 1.8825, 'learning_rate': 0.000873386936711742, 'epoch': 0.25}
 25%|██▌       | 607/2382 [2:16:45<6:57:24, 14.11s/it] 26%|██▌       | 608/2382 [2:16:56<6:31:25, 13.24s/it]                                                      {'loss': 1.9268, 'learning_rate': 0.0008729343395437999, 'epoch': 0.26}
 26%|██▌       | 608/2382 [2:16:56<6:31:25, 13.24s/it] 26%|██▌       | 609/2382 [2:17:06<6:07:45, 12.45s/it]                                                      {'loss': 1.9002, 'learning_rate': 0.0008724810525998357, 'epoch': 0.26}
 26%|██▌       | 609/2382 [2:17:06<6:07:45, 12.45s/it] 26%|██▌       | 610/2382 [2:17:22<6:33:33, 13.33s/it]                                                      {'loss': 1.9474, 'learning_rate': 0.0008720270767182448, 'epoch': 0.26}
 26%|██▌       | 610/2382 [2:17:22<6:33:33, 13.33s/it] 26%|██▌       | 611/2382 [2:17:35<6:33:38, 13.34s/it]                                                      {'loss': 1.9369, 'learning_rate': 0.0008715724127386971, 'epoch': 0.26}
 26%|██▌       | 611/2382 [2:17:35<6:33:38, 13.34s/it] 26%|██▌       | 612/2382 [2:17:48<6:27:34, 13.14s/it]                                                      {'loss': 2.0161, 'learning_rate': 0.000871117061502135, 'epoch': 0.26}
 26%|██▌       | 612/2382 [2:17:48<6:27:34, 13.14s/it] 26%|██▌       | 613/2382 [2:18:01<6:26:59, 13.13s/it]                                                      {'loss': 1.9368, 'learning_rate': 0.000870661023850772, 'epoch': 0.26}
 26%|██▌       | 613/2382 [2:18:01<6:26:59, 13.13s/it] 26%|██▌       | 614/2382 [2:18:14<6:24:46, 13.06s/it]                                                      {'loss': 1.8714, 'learning_rate': 0.0008702043006280912, 'epoch': 0.26}
 26%|██▌       | 614/2382 [2:18:14<6:24:46, 13.06s/it] 26%|██▌       | 615/2382 [2:18:26<6:11:42, 12.62s/it]                                                      {'loss': 1.8712, 'learning_rate': 0.0008697468926788438, 'epoch': 0.26}
 26%|██▌       | 615/2382 [2:18:26<6:11:42, 12.62s/it] 26%|██▌       | 616/2382 [2:18:38<6:11:58, 12.64s/it]                                                      {'loss': 1.8901, 'learning_rate': 0.0008692888008490478, 'epoch': 0.26}
 26%|██▌       | 616/2382 [2:18:38<6:11:58, 12.64s/it] 26%|██▌       | 617/2382 [2:18:53<6:33:49, 13.39s/it]                                                      {'loss': 1.8676, 'learning_rate': 0.0008688300259859854, 'epoch': 0.26}
 26%|██▌       | 617/2382 [2:18:53<6:33:49, 13.39s/it] 26%|██▌       | 618/2382 [2:19:08<6:45:56, 13.81s/it]                                                      {'loss': 1.8247, 'learning_rate': 0.0008683705689382025, 'epoch': 0.26}
 26%|██▌       | 618/2382 [2:19:08<6:45:56, 13.81s/it] 26%|██▌       | 619/2382 [2:19:19<6:19:54, 12.93s/it]                                                      {'loss': 1.9276, 'learning_rate': 0.0008679104305555068, 'epoch': 0.26}
 26%|██▌       | 619/2382 [2:19:19<6:19:54, 12.93s/it] 26%|██▌       | 620/2382 [2:19:31<6:07:48, 12.52s/it]                                                      {'loss': 1.8445, 'learning_rate': 0.0008674496116889663, 'epoch': 0.26}
 26%|██▌       | 620/2382 [2:19:31<6:07:48, 12.52s/it] 26%|██▌       | 621/2382 [2:19:44<6:15:45, 12.80s/it]                                                      {'loss': 1.8633, 'learning_rate': 0.0008669881131909072, 'epoch': 0.26}
 26%|██▌       | 621/2382 [2:19:44<6:15:45, 12.80s/it] 26%|██▌       | 622/2382 [2:19:57<6:18:08, 12.89s/it]                                                      {'loss': 1.8526, 'learning_rate': 0.0008665259359149131, 'epoch': 0.26}
 26%|██▌       | 622/2382 [2:19:57<6:18:08, 12.89s/it] 26%|██▌       | 623/2382 [2:20:10<6:13:46, 12.75s/it]                                                      {'loss': 1.8705, 'learning_rate': 0.0008660630807158232, 'epoch': 0.26}
 26%|██▌       | 623/2382 [2:20:10<6:13:46, 12.75s/it] 26%|██▌       | 624/2382 [2:20:25<6:34:47, 13.47s/it]                                                      {'loss': 1.8518, 'learning_rate': 0.0008655995484497298, 'epoch': 0.26}
 26%|██▌       | 624/2382 [2:20:25<6:34:47, 13.47s/it] 26%|██▌       | 625/2382 [2:20:39<6:44:35, 13.82s/it]                                                      {'loss': 1.768, 'learning_rate': 0.0008651353399739787, 'epoch': 0.26}
 26%|██▌       | 625/2382 [2:20:39<6:44:35, 13.82s/it] 26%|██▋       | 626/2382 [2:20:52<6:34:55, 13.49s/it]                                                      {'loss': 1.9641, 'learning_rate': 0.0008646704561471652, 'epoch': 0.26}
 26%|██▋       | 626/2382 [2:20:52<6:34:55, 13.49s/it] 26%|██▋       | 627/2382 [2:21:05<6:28:19, 13.28s/it]                                                      {'loss': 1.8488, 'learning_rate': 0.0008642048978291345, 'epoch': 0.26}
 26%|██▋       | 627/2382 [2:21:05<6:28:19, 13.28s/it] 26%|██▋       | 628/2382 [2:21:17<6:14:12, 12.80s/it]                                                      {'loss': 1.9304, 'learning_rate': 0.0008637386658809791, 'epoch': 0.26}
 26%|██▋       | 628/2382 [2:21:17<6:14:12, 12.80s/it] 26%|██▋       | 629/2382 [2:21:29<6:08:34, 12.62s/it]                                                      {'loss': 1.9323, 'learning_rate': 0.0008632717611650376, 'epoch': 0.26}
 26%|██▋       | 629/2382 [2:21:29<6:08:34, 12.62s/it] 26%|██▋       | 630/2382 [2:21:43<6:19:02, 12.98s/it]                                                      {'loss': 1.9241, 'learning_rate': 0.0008628041845448924, 'epoch': 0.26}
 26%|██▋       | 630/2382 [2:21:43<6:19:02, 12.98s/it] 26%|██▋       | 631/2382 [2:21:56<6:22:20, 13.10s/it]                                                      {'loss': 1.8012, 'learning_rate': 0.0008623359368853694, 'epoch': 0.26}
 26%|██▋       | 631/2382 [2:21:56<6:22:20, 13.10s/it] 27%|██▋       | 632/2382 [2:22:09<6:22:30, 13.11s/it]                                                      {'loss': 2.0545, 'learning_rate': 0.000861867019052535, 'epoch': 0.27}
 27%|██▋       | 632/2382 [2:22:09<6:22:30, 13.11s/it] 27%|██▋       | 633/2382 [2:22:22<6:25:01, 13.21s/it]                                                      {'loss': 1.8317, 'learning_rate': 0.0008613974319136957, 'epoch': 0.27}
 27%|██▋       | 633/2382 [2:22:22<6:25:01, 13.21s/it] 27%|██▋       | 634/2382 [2:22:35<6:21:34, 13.10s/it]                                                      {'loss': 1.9308, 'learning_rate': 0.0008609271763373956, 'epoch': 0.27}
 27%|██▋       | 634/2382 [2:22:35<6:21:34, 13.10s/it] 27%|██▋       | 635/2382 [2:22:49<6:26:33, 13.28s/it]                                                      {'loss': 1.9784, 'learning_rate': 0.0008604562531934151, 'epoch': 0.27}
 27%|██▋       | 635/2382 [2:22:49<6:26:33, 13.28s/it] 27%|██▋       | 636/2382 [2:23:03<6:31:54, 13.47s/it]                                                      {'loss': 1.9094, 'learning_rate': 0.0008599846633527696, 'epoch': 0.27}
 27%|██▋       | 636/2382 [2:23:03<6:31:54, 13.47s/it] 27%|██▋       | 637/2382 [2:23:14<6:08:45, 12.68s/it]                                                      {'loss': 1.876, 'learning_rate': 0.0008595124076877073, 'epoch': 0.27}
 27%|██▋       | 637/2382 [2:23:14<6:08:45, 12.68s/it] 27%|██▋       | 638/2382 [2:23:28<6:19:27, 13.05s/it]                                                      {'loss': 1.8955, 'learning_rate': 0.0008590394870717081, 'epoch': 0.27}
 27%|██▋       | 638/2382 [2:23:28<6:19:27, 13.05s/it] 27%|██▋       | 639/2382 [2:23:41<6:17:19, 12.99s/it]                                                      {'loss': 1.7989, 'learning_rate': 0.0008585659023794818, 'epoch': 0.27}
 27%|██▋       | 639/2382 [2:23:41<6:17:19, 12.99s/it] 27%|██▋       | 640/2382 [2:23:53<6:15:21, 12.93s/it]                                                      {'loss': 1.8602, 'learning_rate': 0.0008580916544869663, 'epoch': 0.27}
 27%|██▋       | 640/2382 [2:23:53<6:15:21, 12.93s/it] 27%|██▋       | 641/2382 [2:24:08<6:31:56, 13.51s/it]                                                      {'loss': 1.7951, 'learning_rate': 0.0008576167442713265, 'epoch': 0.27}
 27%|██▋       | 641/2382 [2:24:08<6:31:56, 13.51s/it] 27%|██▋       | 642/2382 [2:24:21<6:23:29, 13.22s/it]                                                      {'loss': 1.8584, 'learning_rate': 0.0008571411726109519, 'epoch': 0.27}
 27%|██▋       | 642/2382 [2:24:21<6:23:29, 13.22s/it] 27%|██▋       | 643/2382 [2:24:34<6:27:13, 13.36s/it]                                                      {'loss': 1.8806, 'learning_rate': 0.0008566649403854555, 'epoch': 0.27}
 27%|██▋       | 643/2382 [2:24:34<6:27:13, 13.36s/it] 27%|██▋       | 644/2382 [2:24:50<6:42:51, 13.91s/it]                                                      {'loss': 1.9281, 'learning_rate': 0.0008561880484756724, 'epoch': 0.27}
 27%|██▋       | 644/2382 [2:24:50<6:42:51, 13.91s/it] 27%|██▋       | 645/2382 [2:25:02<6:31:23, 13.52s/it]                                                      {'loss': 1.9279, 'learning_rate': 0.0008557104977636576, 'epoch': 0.27}
 27%|██▋       | 645/2382 [2:25:02<6:31:23, 13.52s/it] 27%|██▋       | 646/2382 [2:25:15<6:27:27, 13.39s/it]                                                      {'loss': 1.8897, 'learning_rate': 0.0008552322891326845, 'epoch': 0.27}
 27%|██▋       | 646/2382 [2:25:15<6:27:27, 13.39s/it] 27%|██▋       | 647/2382 [2:25:30<6:42:29, 13.92s/it]                                                      {'loss': 1.899, 'learning_rate': 0.0008547534234672433, 'epoch': 0.27}
 27%|██▋       | 647/2382 [2:25:30<6:42:29, 13.92s/it] 27%|██▋       | 648/2382 [2:25:42<6:25:44, 13.35s/it]                                                      {'loss': 1.8944, 'learning_rate': 0.0008542739016530403, 'epoch': 0.27}
 27%|██▋       | 648/2382 [2:25:42<6:25:44, 13.35s/it] 27%|██▋       | 649/2382 [2:25:56<6:29:59, 13.50s/it]                                                      {'loss': 1.9454, 'learning_rate': 0.0008537937245769943, 'epoch': 0.27}
 27%|██▋       | 649/2382 [2:25:56<6:29:59, 13.50s/it] 27%|██▋       | 650/2382 [2:26:13<6:58:46, 14.51s/it]                                                      {'loss': 1.9318, 'learning_rate': 0.0008533128931272365, 'epoch': 0.27}
 27%|██▋       | 650/2382 [2:26:13<6:58:46, 14.51s/it] 27%|██▋       | 651/2382 [2:26:27<6:50:30, 14.23s/it]                                                      {'loss': 1.8384, 'learning_rate': 0.0008528314081931085, 'epoch': 0.27}
 27%|██▋       | 651/2382 [2:26:27<6:50:30, 14.23s/it] 27%|██▋       | 652/2382 [2:26:38<6:27:45, 13.45s/it]                                                      {'loss': 1.9918, 'learning_rate': 0.0008523492706651607, 'epoch': 0.27}
 27%|██▋       | 652/2382 [2:26:38<6:27:45, 13.45s/it] 27%|██▋       | 653/2382 [2:26:52<6:24:50, 13.36s/it]                                                      {'loss': 2.0402, 'learning_rate': 0.0008518664814351503, 'epoch': 0.27}
 27%|██▋       | 653/2382 [2:26:52<6:24:50, 13.36s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1160 > 1024). Running this sequence through the model will result in indexing errors
 27%|██▋       | 654/2382 [2:27:07<6:41:16, 13.93s/it]                                                      {'loss': 1.8958, 'learning_rate': 0.0008513830413960399, 'epoch': 0.27}
 27%|██▋       | 654/2382 [2:27:07<6:41:16, 13.93s/it] 27%|██▋       | 655/2382 [2:27:20<6:33:57, 13.69s/it]                                                      {'loss': 1.9094, 'learning_rate': 0.0008508989514419958, 'epoch': 0.27}
 27%|██▋       | 655/2382 [2:27:20<6:33:57, 13.69s/it] 28%|██▊       | 656/2382 [2:27:33<6:27:05, 13.46s/it]                                                      {'loss': 1.932, 'learning_rate': 0.0008504142124683865, 'epoch': 0.28}
 28%|██▊       | 656/2382 [2:27:33<6:27:05, 13.46s/it] 28%|██▊       | 657/2382 [2:27:47<6:35:25, 13.75s/it]                                                      {'loss': 1.8806, 'learning_rate': 0.0008499288253717809, 'epoch': 0.28}
 28%|██▊       | 657/2382 [2:27:47<6:35:25, 13.75s/it] 28%|██▊       | 658/2382 [2:28:00<6:25:46, 13.43s/it]                                                      {'loss': 1.8245, 'learning_rate': 0.0008494427910499467, 'epoch': 0.28}
 28%|██▊       | 658/2382 [2:28:00<6:25:46, 13.43s/it] 28%|██▊       | 659/2382 [2:28:17<6:53:25, 14.40s/it]                                                      {'loss': 1.9331, 'learning_rate': 0.0008489561104018486, 'epoch': 0.28}
 28%|██▊       | 659/2382 [2:28:17<6:53:25, 14.40s/it] 28%|██▊       | 660/2382 [2:28:32<7:01:37, 14.69s/it]                                                      {'loss': 1.9302, 'learning_rate': 0.0008484687843276469, 'epoch': 0.28}
 28%|██▊       | 660/2382 [2:28:32<7:01:37, 14.69s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1512 > 1024). Running this sequence through the model will result in indexing errors
 28%|██▊       | 661/2382 [2:28:44<6:39:44, 13.94s/it]                                                      {'loss': 1.8813, 'learning_rate': 0.000847980813728695, 'epoch': 0.28}
 28%|██▊       | 661/2382 [2:28:44<6:39:44, 13.94s/it] 28%|██▊       | 662/2382 [2:28:56<6:23:14, 13.37s/it]                                                      {'loss': 1.8157, 'learning_rate': 0.0008474921995075398, 'epoch': 0.28}
 28%|██▊       | 662/2382 [2:28:56<6:23:14, 13.37s/it] 28%|██▊       | 663/2382 [2:29:11<6:35:04, 13.79s/it]                                                      {'loss': 1.9066, 'learning_rate': 0.0008470029425679171, 'epoch': 0.28}
 28%|██▊       | 663/2382 [2:29:11<6:35:04, 13.79s/it] 28%|██▊       | 664/2382 [2:29:25<6:34:55, 13.79s/it]                                                      {'loss': 1.7915, 'learning_rate': 0.0008465130438147526, 'epoch': 0.28}
 28%|██▊       | 664/2382 [2:29:25<6:34:55, 13.79s/it] 28%|██▊       | 665/2382 [2:29:39<6:39:43, 13.97s/it]                                                      {'loss': 1.9406, 'learning_rate': 0.0008460225041541584, 'epoch': 0.28}
 28%|██▊       | 665/2382 [2:29:39<6:39:43, 13.97s/it] 28%|██▊       | 666/2382 [2:29:53<6:34:56, 13.81s/it]                                                      {'loss': 1.9699, 'learning_rate': 0.0008455313244934324, 'epoch': 0.28}
 28%|██▊       | 666/2382 [2:29:53<6:34:56, 13.81s/it] 28%|██▊       | 667/2382 [2:30:05<6:21:49, 13.36s/it]                                                      {'loss': 1.9078, 'learning_rate': 0.000845039505741056, 'epoch': 0.28}
 28%|██▊       | 667/2382 [2:30:05<6:21:49, 13.36s/it] 28%|██▊       | 668/2382 [2:30:20<6:37:42, 13.92s/it]                                                      {'loss': 1.8531, 'learning_rate': 0.0008445470488066929, 'epoch': 0.28}
 28%|██▊       | 668/2382 [2:30:20<6:37:42, 13.92s/it] 28%|██▊       | 669/2382 [2:30:32<6:21:30, 13.36s/it]                                                      {'loss': 1.8992, 'learning_rate': 0.000844053954601187, 'epoch': 0.28}
 28%|██▊       | 669/2382 [2:30:32<6:21:30, 13.36s/it] 28%|██▊       | 670/2382 [2:30:45<6:13:26, 13.09s/it]                                                      {'loss': 2.0216, 'learning_rate': 0.0008435602240365609, 'epoch': 0.28}
 28%|██▊       | 670/2382 [2:30:45<6:13:26, 13.09s/it] 28%|██▊       | 671/2382 [2:31:00<6:34:26, 13.83s/it]                                                      {'loss': 1.8816, 'learning_rate': 0.0008430658580260143, 'epoch': 0.28}
 28%|██▊       | 671/2382 [2:31:00<6:34:26, 13.83s/it] 28%|██▊       | 672/2382 [2:31:13<6:23:02, 13.44s/it]                                                      {'loss': 1.8053, 'learning_rate': 0.0008425708574839221, 'epoch': 0.28}
 28%|██▊       | 672/2382 [2:31:13<6:23:02, 13.44s/it] 28%|██▊       | 673/2382 [2:31:25<6:12:58, 13.09s/it]                                                      {'loss': 1.7878, 'learning_rate': 0.0008420752233258329, 'epoch': 0.28}
 28%|██▊       | 673/2382 [2:31:25<6:12:58, 13.09s/it] 28%|██▊       | 674/2382 [2:31:36<5:58:17, 12.59s/it]                                                      {'loss': 1.8591, 'learning_rate': 0.0008415789564684673, 'epoch': 0.28}
 28%|██▊       | 674/2382 [2:31:36<5:58:17, 12.59s/it] 28%|██▊       | 675/2382 [2:31:50<6:03:12, 12.77s/it]                                                      {'loss': 1.8595, 'learning_rate': 0.0008410820578297158, 'epoch': 0.28}
 28%|██▊       | 675/2382 [2:31:50<6:03:12, 12.77s/it] 28%|██▊       | 676/2382 [2:32:02<6:02:00, 12.73s/it]                                                      {'loss': 1.865, 'learning_rate': 0.000840584528328638, 'epoch': 0.28}
 28%|██▊       | 676/2382 [2:32:02<6:02:00, 12.73s/it] 28%|██▊       | 677/2382 [2:32:18<6:23:40, 13.50s/it]                                                      {'loss': 1.8949, 'learning_rate': 0.0008400863688854596, 'epoch': 0.28}
 28%|██▊       | 677/2382 [2:32:18<6:23:40, 13.50s/it] 28%|██▊       | 678/2382 [2:32:31<6:20:16, 13.39s/it]                                                      {'loss': 1.8593, 'learning_rate': 0.0008395875804215725, 'epoch': 0.28}
 28%|██▊       | 678/2382 [2:32:31<6:20:16, 13.39s/it] 29%|██▊       | 679/2382 [2:32:47<6:41:53, 14.16s/it]                                                      {'loss': 1.8817, 'learning_rate': 0.0008390881638595306, 'epoch': 0.28}
 29%|██▊       | 679/2382 [2:32:47<6:41:53, 14.16s/it] 29%|██▊       | 680/2382 [2:32:58<6:19:23, 13.37s/it]                                                      {'loss': 1.9188, 'learning_rate': 0.000838588120123051, 'epoch': 0.29}
 29%|██▊       | 680/2382 [2:32:58<6:19:23, 13.37s/it] 29%|██▊       | 681/2382 [2:33:11<6:17:40, 13.32s/it]                                                      {'loss': 1.9278, 'learning_rate': 0.0008380874501370098, 'epoch': 0.29}
 29%|██▊       | 681/2382 [2:33:11<6:17:40, 13.32s/it] 29%|██▊       | 682/2382 [2:33:24<6:13:19, 13.18s/it]                                                      {'loss': 1.9895, 'learning_rate': 0.0008375861548274417, 'epoch': 0.29}
 29%|██▊       | 682/2382 [2:33:24<6:13:19, 13.18s/it] 29%|██▊       | 683/2382 [2:33:38<6:14:44, 13.23s/it]                                                      {'loss': 1.8781, 'learning_rate': 0.000837084235121538, 'epoch': 0.29}
 29%|██▊       | 683/2382 [2:33:38<6:14:44, 13.23s/it] 29%|██▊       | 684/2382 [2:33:51<6:13:12, 13.19s/it]                                                      {'loss': 2.0074, 'learning_rate': 0.0008365816919476452, 'epoch': 0.29}
 29%|██▊       | 684/2382 [2:33:51<6:13:12, 13.19s/it] 29%|██▉       | 685/2382 [2:34:05<6:23:43, 13.57s/it]                                                      {'loss': 1.8093, 'learning_rate': 0.0008360785262352624, 'epoch': 0.29}
 29%|██▉       | 685/2382 [2:34:05<6:23:43, 13.57s/it] 29%|██▉       | 686/2382 [2:34:16<6:04:07, 12.88s/it]                                                      {'loss': 1.8709, 'learning_rate': 0.0008355747389150403, 'epoch': 0.29}
 29%|██▉       | 686/2382 [2:34:16<6:04:07, 12.88s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1049 > 1024). Running this sequence through the model will result in indexing errors
 29%|██▉       | 687/2382 [2:34:30<6:12:42, 13.19s/it]                                                      {'loss': 1.8203, 'learning_rate': 0.0008350703309187798, 'epoch': 0.29}
 29%|██▉       | 687/2382 [2:34:30<6:12:42, 13.19s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 1024). Running this sequence through the model will result in indexing errors
 29%|██▉       | 688/2382 [2:34:46<6:31:25, 13.86s/it]                                                      {'loss': 1.888, 'learning_rate': 0.0008345653031794292, 'epoch': 0.29}
 29%|██▉       | 688/2382 [2:34:46<6:31:25, 13.86s/it] 29%|██▉       | 689/2382 [2:34:58<6:18:00, 13.40s/it]                                                      {'loss': 1.9139, 'learning_rate': 0.0008340596566310832, 'epoch': 0.29}
 29%|██▉       | 689/2382 [2:34:58<6:18:00, 13.40s/it] 29%|██▉       | 690/2382 [2:35:13<6:27:29, 13.74s/it]                                                      {'loss': 1.8614, 'learning_rate': 0.0008335533922089813, 'epoch': 0.29}
 29%|██▉       | 690/2382 [2:35:13<6:27:29, 13.74s/it] 29%|██▉       | 691/2382 [2:35:26<6:24:26, 13.64s/it]                                                      {'loss': 1.8485, 'learning_rate': 0.0008330465108495055, 'epoch': 0.29}
 29%|██▉       | 691/2382 [2:35:26<6:24:26, 13.64s/it] 29%|██▉       | 692/2382 [2:35:41<6:32:22, 13.93s/it]                                                      {'loss': 1.9365, 'learning_rate': 0.0008325390134901793, 'epoch': 0.29}
 29%|██▉       | 692/2382 [2:35:41<6:32:22, 13.93s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1045 > 1024). Running this sequence through the model will result in indexing errors
 29%|██▉       | 693/2382 [2:35:53<6:19:04, 13.47s/it]                                                      {'loss': 1.9069, 'learning_rate': 0.0008320309010696652, 'epoch': 0.29}
 29%|██▉       | 693/2382 [2:35:53<6:19:04, 13.47s/it] 29%|██▉       | 694/2382 [2:36:07<6:19:49, 13.50s/it]                                                      {'loss': 1.9017, 'learning_rate': 0.000831522174527763, 'epoch': 0.29}
 29%|██▉       | 694/2382 [2:36:07<6:19:49, 13.50s/it] 29%|██▉       | 695/2382 [2:36:18<6:03:04, 12.91s/it]                                                      {'loss': 1.9296, 'learning_rate': 0.0008310128348054094, 'epoch': 0.29}
 29%|██▉       | 695/2382 [2:36:18<6:03:04, 12.91s/it] 29%|██▉       | 696/2382 [2:36:30<5:55:34, 12.65s/it]                                                      {'loss': 1.9854, 'learning_rate': 0.000830502882844674, 'epoch': 0.29}
 29%|██▉       | 696/2382 [2:36:30<5:55:34, 12.65s/it] 29%|██▉       | 697/2382 [2:36:47<6:31:18, 13.93s/it]                                                      {'loss': 1.8746, 'learning_rate': 0.0008299923195887597, 'epoch': 0.29}
 29%|██▉       | 697/2382 [2:36:47<6:31:18, 13.93s/it] 29%|██▉       | 698/2382 [2:37:00<6:22:35, 13.63s/it]                                                      {'loss': 1.8777, 'learning_rate': 0.0008294811459819998, 'epoch': 0.29}
 29%|██▉       | 698/2382 [2:37:00<6:22:35, 13.63s/it] 29%|██▉       | 699/2382 [2:37:13<6:14:15, 13.34s/it]                                                      {'loss': 1.8886, 'learning_rate': 0.0008289693629698564, 'epoch': 0.29}
 29%|██▉       | 699/2382 [2:37:13<6:14:15, 13.34s/it] 29%|██▉       | 700/2382 [2:37:26<6:15:03, 13.38s/it]                                                      {'loss': 1.8559, 'learning_rate': 0.0008284569714989185, 'epoch': 0.29}
 29%|██▉       | 700/2382 [2:37:26<6:15:03, 13.38s/it] 29%|██▉       | 701/2382 [2:37:41<6:26:22, 13.79s/it]                                                      {'loss': 1.9263, 'learning_rate': 0.0008279439725169011, 'epoch': 0.29}
 29%|██▉       | 701/2382 [2:37:41<6:26:22, 13.79s/it] 29%|██▉       | 702/2382 [2:37:56<6:38:59, 14.25s/it]                                                      {'loss': 1.8479, 'learning_rate': 0.0008274303669726426, 'epoch': 0.29}
 29%|██▉       | 702/2382 [2:37:56<6:38:59, 14.25s/it] 30%|██▉       | 703/2382 [2:38:12<6:53:12, 14.77s/it]                                                      {'loss': 1.8426, 'learning_rate': 0.0008269161558161029, 'epoch': 0.3}
 30%|██▉       | 703/2382 [2:38:12<6:53:12, 14.77s/it] 30%|██▉       | 704/2382 [2:38:27<6:52:58, 14.77s/it]                                                      {'loss': 1.8494, 'learning_rate': 0.0008264013399983625, 'epoch': 0.3}
 30%|██▉       | 704/2382 [2:38:27<6:52:58, 14.77s/it] 30%|██▉       | 705/2382 [2:38:41<6:46:30, 14.54s/it]                                                      {'loss': 1.9517, 'learning_rate': 0.0008258859204716203, 'epoch': 0.3}
 30%|██▉       | 705/2382 [2:38:41<6:46:30, 14.54s/it] 30%|██▉       | 706/2382 [2:38:56<6:50:40, 14.70s/it]                                                      {'loss': 1.878, 'learning_rate': 0.0008253698981891915, 'epoch': 0.3}
 30%|██▉       | 706/2382 [2:38:56<6:50:40, 14.70s/it] 30%|██▉       | 707/2382 [2:39:12<7:01:59, 15.12s/it]                                                      {'loss': 1.8981, 'learning_rate': 0.0008248532741055062, 'epoch': 0.3}
 30%|██▉       | 707/2382 [2:39:12<7:01:59, 15.12s/it] 30%|██▉       | 708/2382 [2:39:24<6:33:36, 14.11s/it]                                                      {'loss': 1.8338, 'learning_rate': 0.0008243360491761078, 'epoch': 0.3}
 30%|██▉       | 708/2382 [2:39:24<6:33:36, 14.11s/it] 30%|██▉       | 709/2382 [2:39:39<6:39:55, 14.34s/it]                                                      {'loss': 1.9668, 'learning_rate': 0.0008238182243576511, 'epoch': 0.3}
 30%|██▉       | 709/2382 [2:39:39<6:39:55, 14.34s/it] 30%|██▉       | 710/2382 [2:39:56<6:59:29, 15.05s/it]                                                      {'loss': 1.9021, 'learning_rate': 0.0008232998006078997, 'epoch': 0.3}
 30%|██▉       | 710/2382 [2:39:56<6:59:29, 15.05s/it] 30%|██▉       | 711/2382 [2:40:09<6:46:59, 14.61s/it]                                                      {'loss': 1.8546, 'learning_rate': 0.0008227807788857264, 'epoch': 0.3}
 30%|██▉       | 711/2382 [2:40:09<6:46:59, 14.61s/it] 30%|██▉       | 712/2382 [2:40:25<6:55:11, 14.92s/it]                                                      {'loss': 1.8395, 'learning_rate': 0.0008222611601511083, 'epoch': 0.3}
 30%|██▉       | 712/2382 [2:40:25<6:55:11, 14.92s/it] 30%|██▉       | 713/2382 [2:40:38<6:41:33, 14.44s/it]                                                      {'loss': 1.8066, 'learning_rate': 0.000821740945365128, 'epoch': 0.3}
 30%|██▉       | 713/2382 [2:40:38<6:41:33, 14.44s/it] 30%|██▉       | 714/2382 [2:40:51<6:27:24, 13.94s/it]                                                      {'loss': 1.8805, 'learning_rate': 0.00082122013548997, 'epoch': 0.3}
 30%|██▉       | 714/2382 [2:40:51<6:27:24, 13.94s/it] 30%|███       | 715/2382 [2:41:03<6:10:18, 13.33s/it]                                                      {'loss': 1.8847, 'learning_rate': 0.0008206987314889197, 'epoch': 0.3}
 30%|███       | 715/2382 [2:41:03<6:10:18, 13.33s/it] 30%|███       | 716/2382 [2:41:15<6:04:28, 13.13s/it]                                                      {'loss': 1.8482, 'learning_rate': 0.0008201767343263612, 'epoch': 0.3}
 30%|███       | 716/2382 [2:41:15<6:04:28, 13.13s/it] 30%|███       | 717/2382 [2:41:29<6:05:35, 13.17s/it]                                                      {'loss': 1.8849, 'learning_rate': 0.0008196541449677758, 'epoch': 0.3}
 30%|███       | 717/2382 [2:41:29<6:05:35, 13.17s/it] 30%|███       | 718/2382 [2:41:42<6:06:05, 13.20s/it]                                                      {'loss': 1.8985, 'learning_rate': 0.00081913096437974, 'epoch': 0.3}
 30%|███       | 718/2382 [2:41:42<6:06:05, 13.20s/it] 30%|███       | 719/2382 [2:41:56<6:15:48, 13.56s/it]                                                      {'loss': 1.8919, 'learning_rate': 0.0008186071935299242, 'epoch': 0.3}
 30%|███       | 719/2382 [2:41:56<6:15:48, 13.56s/it] 30%|███       | 720/2382 [2:42:10<6:12:29, 13.45s/it]                                                      {'loss': 1.9241, 'learning_rate': 0.00081808283338709, 'epoch': 0.3}
 30%|███       | 720/2382 [2:42:10<6:12:29, 13.45s/it] 30%|███       | 721/2382 [2:42:23<6:08:37, 13.32s/it]                                                      {'loss': 2.0022, 'learning_rate': 0.0008175578849210894, 'epoch': 0.3}
 30%|███       | 721/2382 [2:42:23<6:08:37, 13.32s/it] 30%|███       | 722/2382 [2:42:35<6:03:04, 13.12s/it]                                                      {'loss': 1.9332, 'learning_rate': 0.0008170323491028624, 'epoch': 0.3}
 30%|███       | 722/2382 [2:42:35<6:03:04, 13.12s/it] 30%|███       | 723/2382 [2:42:50<6:14:57, 13.56s/it]                                                      {'loss': 1.8689, 'learning_rate': 0.0008165062269044352, 'epoch': 0.3}
 30%|███       | 723/2382 [2:42:50<6:14:57, 13.56s/it] 30%|███       | 724/2382 [2:43:03<6:13:57, 13.53s/it]                                                      {'loss': 1.8662, 'learning_rate': 0.0008159795192989189, 'epoch': 0.3}
 30%|███       | 724/2382 [2:43:03<6:13:57, 13.53s/it] 30%|███       | 725/2382 [2:43:17<6:12:14, 13.48s/it]                                                      {'loss': 1.8271, 'learning_rate': 0.0008154522272605071, 'epoch': 0.3}
 30%|███       | 725/2382 [2:43:17<6:12:14, 13.48s/it] 30%|███       | 726/2382 [2:43:31<6:22:47, 13.87s/it]                                                      {'loss': 1.9226, 'learning_rate': 0.0008149243517644744, 'epoch': 0.3}
 30%|███       | 726/2382 [2:43:31<6:22:47, 13.87s/it] 31%|███       | 727/2382 [2:43:46<6:31:40, 14.20s/it]                                                      {'loss': 1.7822, 'learning_rate': 0.0008143958937871747, 'epoch': 0.31}
 31%|███       | 727/2382 [2:43:46<6:31:40, 14.20s/it] 31%|███       | 728/2382 [2:44:02<6:44:40, 14.68s/it]                                                      {'loss': 1.8499, 'learning_rate': 0.0008138668543060391, 'epoch': 0.31}
 31%|███       | 728/2382 [2:44:02<6:44:40, 14.68s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1511 > 1024). Running this sequence through the model will result in indexing errors
 31%|███       | 729/2382 [2:44:15<6:32:46, 14.26s/it]                                                      {'loss': 1.912, 'learning_rate': 0.0008133372342995744, 'epoch': 0.31}
 31%|███       | 729/2382 [2:44:15<6:32:46, 14.26s/it] 31%|███       | 730/2382 [2:44:30<6:31:48, 14.23s/it]                                                      {'loss': 1.9282, 'learning_rate': 0.0008128070347473608, 'epoch': 0.31}
 31%|███       | 730/2382 [2:44:30<6:31:48, 14.23s/it] 31%|███       | 731/2382 [2:44:44<6:34:32, 14.34s/it]                                                      {'loss': 1.9275, 'learning_rate': 0.0008122762566300508, 'epoch': 0.31}
 31%|███       | 731/2382 [2:44:44<6:34:32, 14.34s/it] 31%|███       | 732/2382 [2:44:58<6:27:17, 14.08s/it]                                                      {'loss': 1.8602, 'learning_rate': 0.0008117449009293668, 'epoch': 0.31}
 31%|███       | 732/2382 [2:44:58<6:27:17, 14.08s/it] 31%|███       | 733/2382 [2:45:13<6:33:26, 14.32s/it]                                                      {'loss': 1.9586, 'learning_rate': 0.0008112129686280996, 'epoch': 0.31}
 31%|███       | 733/2382 [2:45:13<6:33:26, 14.32s/it] 31%|███       | 734/2382 [2:45:28<6:39:08, 14.53s/it]                                                      {'loss': 1.9013, 'learning_rate': 0.0008106804607101066, 'epoch': 0.31}
 31%|███       | 734/2382 [2:45:28<6:39:08, 14.53s/it] 31%|███       | 735/2382 [2:45:39<6:13:06, 13.59s/it]                                                      {'loss': 1.9442, 'learning_rate': 0.0008101473781603094, 'epoch': 0.31}
 31%|███       | 735/2382 [2:45:39<6:13:06, 13.59s/it] 31%|███       | 736/2382 [2:45:51<5:57:14, 13.02s/it]                                                      {'loss': 1.9146, 'learning_rate': 0.0008096137219646928, 'epoch': 0.31}
 31%|███       | 736/2382 [2:45:51<5:57:14, 13.02s/it] 31%|███       | 737/2382 [2:46:05<6:05:45, 13.34s/it]                                                      {'loss': 1.8322, 'learning_rate': 0.0008090794931103026, 'epoch': 0.31}
 31%|███       | 737/2382 [2:46:05<6:05:45, 13.34s/it] 31%|███       | 738/2382 [2:46:18<6:05:10, 13.33s/it]                                                      {'loss': 1.8242, 'learning_rate': 0.0008085446925852437, 'epoch': 0.31}
 31%|███       | 738/2382 [2:46:18<6:05:10, 13.33s/it] 31%|███       | 739/2382 [2:46:29<5:49:07, 12.75s/it]                                                      {'loss': 2.011, 'learning_rate': 0.0008080093213786783, 'epoch': 0.31}
 31%|███       | 739/2382 [2:46:29<5:49:07, 12.75s/it] 31%|███       | 740/2382 [2:46:44<6:04:26, 13.32s/it]                                                      {'loss': 1.8149, 'learning_rate': 0.0008074733804808245, 'epoch': 0.31}
 31%|███       | 740/2382 [2:46:44<6:04:26, 13.32s/it] 31%|███       | 741/2382 [2:46:59<6:16:28, 13.76s/it]                                                      {'loss': 1.826, 'learning_rate': 0.0008069368708829534, 'epoch': 0.31}
 31%|███       | 741/2382 [2:46:59<6:16:28, 13.76s/it] 31%|███       | 742/2382 [2:47:10<5:58:05, 13.10s/it]                                                      {'loss': 1.8192, 'learning_rate': 0.0008063997935773884, 'epoch': 0.31}
 31%|███       | 742/2382 [2:47:10<5:58:05, 13.10s/it] 31%|███       | 743/2382 [2:47:23<5:57:11, 13.08s/it]                                                      {'loss': 1.8893, 'learning_rate': 0.0008058621495575032, 'epoch': 0.31}
 31%|███       | 743/2382 [2:47:23<5:57:11, 13.08s/it] 31%|███       | 744/2382 [2:47:37<6:01:40, 13.25s/it]                                                      {'loss': 1.8808, 'learning_rate': 0.0008053239398177191, 'epoch': 0.31}
 31%|███       | 744/2382 [2:47:37<6:01:40, 13.25s/it] 31%|███▏      | 745/2382 [2:47:50<5:56:14, 13.06s/it]                                                      {'loss': 1.9304, 'learning_rate': 0.0008047851653535041, 'epoch': 0.31}
 31%|███▏      | 745/2382 [2:47:50<5:56:14, 13.06s/it] 31%|███▏      | 746/2382 [2:48:03<5:54:51, 13.01s/it]                                                      {'loss': 1.9087, 'learning_rate': 0.0008042458271613706, 'epoch': 0.31}
 31%|███▏      | 746/2382 [2:48:03<5:54:51, 13.01s/it] 31%|███▏      | 747/2382 [2:48:15<5:50:55, 12.88s/it]                                                      {'loss': 1.8692, 'learning_rate': 0.0008037059262388738, 'epoch': 0.31}
 31%|███▏      | 747/2382 [2:48:15<5:50:55, 12.88s/it] 31%|███▏      | 748/2382 [2:48:29<5:58:49, 13.18s/it]                                                      {'loss': 1.9799, 'learning_rate': 0.0008031654635846095, 'epoch': 0.31}
 31%|███▏      | 748/2382 [2:48:29<5:58:49, 13.18s/it] 31%|███▏      | 749/2382 [2:48:43<6:06:43, 13.47s/it]                                                      {'loss': 1.8721, 'learning_rate': 0.0008026244401982127, 'epoch': 0.31}
 31%|███▏      | 749/2382 [2:48:43<6:06:43, 13.47s/it] 31%|███▏      | 750/2382 [2:48:56<6:01:18, 13.28s/it]                                                      {'loss': 1.8698, 'learning_rate': 0.0008020828570803553, 'epoch': 0.31}
 31%|███▏      | 750/2382 [2:48:56<6:01:18, 13.28s/it] 32%|███▏      | 751/2382 [2:49:10<6:05:58, 13.46s/it]                                                      {'loss': 1.8841, 'learning_rate': 0.0008015407152327448, 'epoch': 0.32}
 32%|███▏      | 751/2382 [2:49:10<6:05:58, 13.46s/it] 32%|███▏      | 752/2382 [2:49:24<6:14:15, 13.78s/it]                                                      {'loss': 1.9197, 'learning_rate': 0.0008009980156581216, 'epoch': 0.32}
 32%|███▏      | 752/2382 [2:49:24<6:14:15, 13.78s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1097 > 1024). Running this sequence through the model will result in indexing errors
 32%|███▏      | 753/2382 [2:49:38<6:14:58, 13.81s/it]                                                      {'loss': 1.9522, 'learning_rate': 0.0008004547593602585, 'epoch': 0.32}
 32%|███▏      | 753/2382 [2:49:38<6:14:58, 13.81s/it] 32%|███▏      | 754/2382 [2:49:50<5:55:29, 13.10s/it]                                                      {'loss': 1.9069, 'learning_rate': 0.0007999109473439569, 'epoch': 0.32}
 32%|███▏      | 754/2382 [2:49:50<5:55:29, 13.10s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1274 > 1024). Running this sequence through the model will result in indexing errors
 32%|███▏      | 755/2382 [2:50:03<5:52:54, 13.01s/it]                                                      {'loss': 1.8189, 'learning_rate': 0.000799366580615047, 'epoch': 0.32}
 32%|███▏      | 755/2382 [2:50:03<5:52:54, 13.01s/it] 32%|███▏      | 756/2382 [2:50:17<6:02:04, 13.36s/it]                                                      {'loss': 1.9461, 'learning_rate': 0.0007988216601803844, 'epoch': 0.32}
 32%|███▏      | 756/2382 [2:50:17<6:02:04, 13.36s/it] 32%|███▏      | 757/2382 [2:50:30<5:59:28, 13.27s/it]                                                      {'loss': 1.8661, 'learning_rate': 0.0007982761870478494, 'epoch': 0.32}
 32%|███▏      | 757/2382 [2:50:30<5:59:28, 13.27s/it] 32%|███▏      | 758/2382 [2:50:44<6:07:00, 13.56s/it]                                                      {'loss': 1.8515, 'learning_rate': 0.000797730162226344, 'epoch': 0.32}
 32%|███▏      | 758/2382 [2:50:44<6:07:00, 13.56s/it] 32%|███▏      | 759/2382 [2:50:59<6:19:10, 14.02s/it]                                                      {'loss': 1.8807, 'learning_rate': 0.0007971835867257909, 'epoch': 0.32}
 32%|███▏      | 759/2382 [2:50:59<6:19:10, 14.02s/it] 32%|███▏      | 760/2382 [2:51:14<6:22:45, 14.16s/it]                                                      {'loss': 1.8354, 'learning_rate': 0.0007966364615571314, 'epoch': 0.32}
 32%|███▏      | 760/2382 [2:51:14<6:22:45, 14.16s/it] 32%|███▏      | 761/2382 [2:51:31<6:45:40, 15.02s/it]                                                      {'loss': 1.8391, 'learning_rate': 0.0007960887877323229, 'epoch': 0.32}
 32%|███▏      | 761/2382 [2:51:31<6:45:40, 15.02s/it] 32%|███▏      | 762/2382 [2:51:43<6:23:03, 14.19s/it]                                                      {'loss': 1.8824, 'learning_rate': 0.0007955405662643383, 'epoch': 0.32}
 32%|███▏      | 762/2382 [2:51:43<6:23:03, 14.19s/it] 32%|███▏      | 763/2382 [2:51:54<5:59:11, 13.31s/it]                                                      {'loss': 1.9661, 'learning_rate': 0.0007949917981671632, 'epoch': 0.32}
 32%|███▏      | 763/2382 [2:51:54<5:59:11, 13.31s/it] 32%|███▏      | 764/2382 [2:52:06<5:49:16, 12.95s/it]                                                      {'loss': 1.9606, 'learning_rate': 0.0007944424844557941, 'epoch': 0.32}
 32%|███▏      | 764/2382 [2:52:06<5:49:16, 12.95s/it] 32%|███▏      | 765/2382 [2:52:19<5:49:50, 12.98s/it]                                                      {'loss': 1.9333, 'learning_rate': 0.0007938926261462366, 'epoch': 0.32}
 32%|███▏      | 765/2382 [2:52:19<5:49:50, 12.98s/it] 32%|███▏      | 766/2382 [2:52:32<5:49:53, 12.99s/it]                                                      {'loss': 1.9336, 'learning_rate': 0.000793342224255504, 'epoch': 0.32}
 32%|███▏      | 766/2382 [2:52:32<5:49:53, 12.99s/it] 32%|███▏      | 767/2382 [2:52:44<5:41:47, 12.70s/it]                                                      {'loss': 1.9616, 'learning_rate': 0.0007927912798016143, 'epoch': 0.32}
 32%|███▏      | 767/2382 [2:52:44<5:41:47, 12.70s/it] 32%|███▏      | 768/2382 [2:52:56<5:29:58, 12.27s/it]                                                      {'loss': 1.9701, 'learning_rate': 0.00079223979380359, 'epoch': 0.32}
 32%|███▏      | 768/2382 [2:52:56<5:29:58, 12.27s/it] 32%|███▏      | 769/2382 [2:53:10<5:47:38, 12.93s/it]                                                      {'loss': 1.8498, 'learning_rate': 0.000791687767281454, 'epoch': 0.32}
 32%|███▏      | 769/2382 [2:53:10<5:47:38, 12.93s/it] 32%|███▏      | 770/2382 [2:53:26<6:15:04, 13.96s/it]                                                      {'loss': 1.8553, 'learning_rate': 0.0007911352012562301, 'epoch': 0.32}
 32%|███▏      | 770/2382 [2:53:26<6:15:04, 13.96s/it] 32%|███▏      | 771/2382 [2:53:41<6:20:32, 14.17s/it]                                                      {'loss': 1.8476, 'learning_rate': 0.0007905820967499395, 'epoch': 0.32}
 32%|███▏      | 771/2382 [2:53:41<6:20:32, 14.17s/it] 32%|███▏      | 772/2382 [2:53:53<6:01:34, 13.47s/it]                                                      {'loss': 1.885, 'learning_rate': 0.0007900284547855992, 'epoch': 0.32}
 32%|███▏      | 772/2382 [2:53:53<6:01:34, 13.47s/it] 32%|███▏      | 773/2382 [2:54:09<6:17:58, 14.09s/it]                                                      {'loss': 1.9154, 'learning_rate': 0.0007894742763872203, 'epoch': 0.32}
 32%|███▏      | 773/2382 [2:54:09<6:17:58, 14.09s/it] 32%|███▏      | 774/2382 [2:54:20<5:53:43, 13.20s/it]                                                      {'loss': 1.8761, 'learning_rate': 0.0007889195625798064, 'epoch': 0.32}
 32%|███▏      | 774/2382 [2:54:20<5:53:43, 13.20s/it] 33%|███▎      | 775/2382 [2:54:36<6:15:40, 14.03s/it]                                                      {'loss': 1.8748, 'learning_rate': 0.0007883643143893513, 'epoch': 0.33}
 33%|███▎      | 775/2382 [2:54:36<6:15:40, 14.03s/it] 33%|███▎      | 776/2382 [2:54:52<6:30:55, 14.61s/it]                                                      {'loss': 1.955, 'learning_rate': 0.0007878085328428368, 'epoch': 0.33}
 33%|███▎      | 776/2382 [2:54:52<6:30:55, 14.61s/it] 33%|███▎      | 777/2382 [2:55:07<6:34:50, 14.76s/it]                                                      {'loss': 1.7847, 'learning_rate': 0.0007872522189682318, 'epoch': 0.33}
 33%|███▎      | 777/2382 [2:55:07<6:34:50, 14.76s/it] 33%|███▎      | 778/2382 [2:55:18<6:10:27, 13.86s/it]                                                      {'loss': 2.0574, 'learning_rate': 0.0007866953737944891, 'epoch': 0.33}
 33%|███▎      | 778/2382 [2:55:18<6:10:27, 13.86s/it] 33%|███▎      | 779/2382 [2:55:31<5:58:58, 13.44s/it]                                                      {'loss': 1.8926, 'learning_rate': 0.0007861379983515449, 'epoch': 0.33}
 33%|███▎      | 779/2382 [2:55:31<5:58:58, 13.44s/it] 33%|███▎      | 780/2382 [2:55:45<6:03:50, 13.63s/it]                                                      {'loss': 1.7562, 'learning_rate': 0.0007855800936703157, 'epoch': 0.33}
 33%|███▎      | 780/2382 [2:55:45<6:03:50, 13.63s/it] 33%|███▎      | 781/2382 [2:55:59<6:07:23, 13.77s/it]                                                      {'loss': 1.9605, 'learning_rate': 0.0007850216607826969, 'epoch': 0.33}
 33%|███▎      | 781/2382 [2:55:59<6:07:23, 13.77s/it] 33%|███▎      | 782/2382 [2:56:12<6:00:11, 13.51s/it]                                                      {'loss': 1.8079, 'learning_rate': 0.0007844627007215613, 'epoch': 0.33}
 33%|███▎      | 782/2382 [2:56:12<6:00:11, 13.51s/it] 33%|███▎      | 783/2382 [2:56:26<6:05:35, 13.72s/it]                                                      {'loss': 1.8687, 'learning_rate': 0.000783903214520756, 'epoch': 0.33}
 33%|███▎      | 783/2382 [2:56:26<6:05:35, 13.72s/it] 33%|███▎      | 784/2382 [2:56:40<6:03:23, 13.64s/it]                                                      {'loss': 1.988, 'learning_rate': 0.000783343203215102, 'epoch': 0.33}
 33%|███▎      | 784/2382 [2:56:40<6:03:23, 13.64s/it] 33%|███▎      | 785/2382 [2:56:54<6:09:11, 13.87s/it]                                                      {'loss': 1.8429, 'learning_rate': 0.0007827826678403912, 'epoch': 0.33}
 33%|███▎      | 785/2382 [2:56:54<6:09:11, 13.87s/it] 33%|███▎      | 786/2382 [2:57:06<5:50:22, 13.17s/it]                                                      {'loss': 1.9583, 'learning_rate': 0.0007822216094333848, 'epoch': 0.33}
 33%|███▎      | 786/2382 [2:57:06<5:50:22, 13.17s/it] 33%|███▎      | 787/2382 [2:57:19<5:51:29, 13.22s/it]                                                      {'loss': 1.8472, 'learning_rate': 0.000781660029031811, 'epoch': 0.33}
 33%|███▎      | 787/2382 [2:57:19<5:51:29, 13.22s/it] 33%|███▎      | 788/2382 [2:57:29<5:27:11, 12.32s/it]                                                      {'loss': 1.8822, 'learning_rate': 0.0007810979276743646, 'epoch': 0.33}
 33%|███▎      | 788/2382 [2:57:29<5:27:11, 12.32s/it] 33%|███▎      | 789/2382 [2:57:45<5:56:30, 13.43s/it]                                                      {'loss': 1.8155, 'learning_rate': 0.0007805353064007027, 'epoch': 0.33}
 33%|███▎      | 789/2382 [2:57:45<5:56:30, 13.43s/it] 33%|███▎      | 790/2382 [2:58:00<6:07:03, 13.83s/it]                                                      {'loss': 1.7427, 'learning_rate': 0.0007799721662514448, 'epoch': 0.33}
 33%|███▎      | 790/2382 [2:58:00<6:07:03, 13.83s/it] 33%|███▎      | 791/2382 [2:58:15<6:14:41, 14.13s/it]                                                      {'loss': 1.8374, 'learning_rate': 0.0007794085082681699, 'epoch': 0.33}
 33%|███▎      | 791/2382 [2:58:15<6:14:41, 14.13s/it] 33%|███▎      | 792/2382 [2:58:28<6:09:01, 13.93s/it]                                                      {'loss': 1.8268, 'learning_rate': 0.0007788443334934147, 'epoch': 0.33}
 33%|███▎      | 792/2382 [2:58:28<6:09:01, 13.93s/it] 33%|███▎      | 793/2382 [2:58:40<5:53:02, 13.33s/it]                                                      {'loss': 1.8746, 'learning_rate': 0.000778279642970672, 'epoch': 0.33}
 33%|███▎      | 793/2382 [2:58:40<5:53:02, 13.33s/it] 33%|███▎      | 794/2382 [2:58:54<5:56:02, 13.45s/it]                                                      {'loss': 1.8104, 'learning_rate': 0.0007777144377443881, 'epoch': 0.33}
 33%|███▎      | 794/2382 [2:58:54<5:56:02, 13.45s/it] 33%|███▎      | 795/2382 [2:59:07<5:50:31, 13.25s/it]                                                      {'loss': 1.9532, 'learning_rate': 0.0007771487188599615, 'epoch': 0.33}
 33%|███▎      | 795/2382 [2:59:07<5:50:31, 13.25s/it] 33%|███▎      | 796/2382 [2:59:22<6:03:03, 13.74s/it]                                                      {'loss': 1.8878, 'learning_rate': 0.000776582487363741, 'epoch': 0.33}
 33%|███▎      | 796/2382 [2:59:22<6:03:03, 13.74s/it] 33%|███▎      | 797/2382 [2:59:34<5:52:32, 13.35s/it]                                                      {'loss': 2.0214, 'learning_rate': 0.0007760157443030233, 'epoch': 0.33}
 33%|███▎      | 797/2382 [2:59:34<5:52:32, 13.35s/it] 34%|███▎      | 798/2382 [2:59:50<6:10:35, 14.04s/it]                                                      {'loss': 1.8567, 'learning_rate': 0.0007754484907260512, 'epoch': 0.33}
 34%|███▎      | 798/2382 [2:59:50<6:10:35, 14.04s/it] 34%|███▎      | 799/2382 [3:00:04<6:11:57, 14.10s/it]                                                      {'loss': 1.8483, 'learning_rate': 0.000774880727682012, 'epoch': 0.34}
 34%|███▎      | 799/2382 [3:00:04<6:11:57, 14.10s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1223 > 1024). Running this sequence through the model will result in indexing errors
 34%|███▎      | 800/2382 [3:00:16<5:53:07, 13.39s/it]                                                      {'loss': 1.8626, 'learning_rate': 0.0007743124562210351, 'epoch': 0.34}
 34%|███▎      | 800/2382 [3:00:16<5:53:07, 13.39s/it] 34%|███▎      | 801/2382 [3:00:27<5:36:38, 12.78s/it]                                                      {'loss': 1.768, 'learning_rate': 0.00077374367739419, 'epoch': 0.34}
 34%|███▎      | 801/2382 [3:00:27<5:36:38, 12.78s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1462 > 1024). Running this sequence through the model will result in indexing errors
 34%|███▎      | 802/2382 [3:00:43<6:03:58, 13.82s/it]                                                      {'loss': 1.9176, 'learning_rate': 0.0007731743922534853, 'epoch': 0.34}
 34%|███▎      | 802/2382 [3:00:43<6:03:58, 13.82s/it] 34%|███▎      | 803/2382 [3:00:56<5:54:24, 13.47s/it]                                                      {'loss': 1.816, 'learning_rate': 0.0007726046018518657, 'epoch': 0.34}
 34%|███▎      | 803/2382 [3:00:56<5:54:24, 13.47s/it] 34%|███▍      | 804/2382 [3:01:11<6:05:50, 13.91s/it]                                                      {'loss': 1.8896, 'learning_rate': 0.0007720343072432104, 'epoch': 0.34}
 34%|███▍      | 804/2382 [3:01:11<6:05:50, 13.91s/it] 34%|███▍      | 805/2382 [3:01:27<6:25:56, 14.68s/it]                                                      {'loss': 1.7983, 'learning_rate': 0.0007714635094823309, 'epoch': 0.34}
 34%|███▍      | 805/2382 [3:01:27<6:25:56, 14.68s/it] 34%|███▍      | 806/2382 [3:01:40<6:11:38, 14.15s/it]                                                      {'loss': 1.9089, 'learning_rate': 0.0007708922096249701, 'epoch': 0.34}
 34%|███▍      | 806/2382 [3:01:40<6:11:38, 14.15s/it] 34%|███▍      | 807/2382 [3:01:50<5:40:02, 12.95s/it]                                                      {'loss': 1.8923, 'learning_rate': 0.0007703204087277988, 'epoch': 0.34}
 34%|███▍      | 807/2382 [3:01:50<5:40:02, 12.95s/it] 34%|███▍      | 808/2382 [3:02:03<5:35:28, 12.79s/it]                                                      {'loss': 1.9204, 'learning_rate': 0.000769748107848415, 'epoch': 0.34}
 34%|███▍      | 808/2382 [3:02:03<5:35:28, 12.79s/it] 34%|███▍      | 809/2382 [3:02:20<6:12:20, 14.20s/it]                                                      {'loss': 1.769, 'learning_rate': 0.0007691753080453412, 'epoch': 0.34}
 34%|███▍      | 809/2382 [3:02:20<6:12:20, 14.20s/it] 34%|███▍      | 810/2382 [3:02:34<6:06:50, 14.00s/it]                                                      {'loss': 1.9265, 'learning_rate': 0.0007686020103780228, 'epoch': 0.34}
 34%|███▍      | 810/2382 [3:02:34<6:06:50, 14.00s/it] 34%|███▍      | 811/2382 [3:02:46<5:51:41, 13.43s/it]                                                      {'loss': 1.8584, 'learning_rate': 0.0007680282159068262, 'epoch': 0.34}
 34%|███▍      | 811/2382 [3:02:46<5:51:41, 13.43s/it] 34%|███▍      | 812/2382 [3:02:57<5:34:50, 12.80s/it]                                                      {'loss': 1.7733, 'learning_rate': 0.0007674539256930363, 'epoch': 0.34}
 34%|███▍      | 812/2382 [3:02:57<5:34:50, 12.80s/it] 34%|███▍      | 813/2382 [3:03:12<5:47:38, 13.29s/it]                                                      {'loss': 1.7818, 'learning_rate': 0.0007668791407988551, 'epoch': 0.34}
 34%|███▍      | 813/2382 [3:03:12<5:47:38, 13.29s/it] 34%|███▍      | 814/2382 [3:03:27<6:05:02, 13.97s/it]                                                      {'loss': 1.8344, 'learning_rate': 0.0007663038622873999, 'epoch': 0.34}
 34%|███▍      | 814/2382 [3:03:27<6:05:02, 13.97s/it] 34%|███▍      | 815/2382 [3:03:40<5:59:36, 13.77s/it]                                                      {'loss': 1.9238, 'learning_rate': 0.0007657280912227008, 'epoch': 0.34}
 34%|███▍      | 815/2382 [3:03:40<5:59:36, 13.77s/it] 34%|███▍      | 816/2382 [3:03:57<6:22:14, 14.65s/it]                                                      {'loss': 1.8887, 'learning_rate': 0.0007651518286696981, 'epoch': 0.34}
 34%|███▍      | 816/2382 [3:03:57<6:22:14, 14.65s/it] 34%|███▍      | 817/2382 [3:04:09<6:00:07, 13.81s/it]                                                      {'loss': 1.8894, 'learning_rate': 0.0007645750756942424, 'epoch': 0.34}
 34%|███▍      | 817/2382 [3:04:09<6:00:07, 13.81s/it] 34%|███▍      | 818/2382 [3:04:23<6:01:10, 13.86s/it]                                                      {'loss': 2.0168, 'learning_rate': 0.0007639978333630911, 'epoch': 0.34}
 34%|███▍      | 818/2382 [3:04:23<6:01:10, 13.86s/it] 34%|███▍      | 819/2382 [3:04:38<6:13:27, 14.34s/it]                                                      {'loss': 1.8231, 'learning_rate': 0.0007634201027439058, 'epoch': 0.34}
 34%|███▍      | 819/2382 [3:04:38<6:13:27, 14.34s/it] 34%|███▍      | 820/2382 [3:04:50<5:53:05, 13.56s/it]                                                      {'loss': 2.004, 'learning_rate': 0.0007628418849052523, 'epoch': 0.34}
 34%|███▍      | 820/2382 [3:04:50<5:53:05, 13.56s/it] 34%|███▍      | 821/2382 [3:05:02<5:36:18, 12.93s/it]                                                      {'loss': 1.9214, 'learning_rate': 0.0007622631809165971, 'epoch': 0.34}
 34%|███▍      | 821/2382 [3:05:02<5:36:18, 12.93s/it] 35%|███▍      | 822/2382 [3:05:14<5:30:19, 12.70s/it]                                                      {'loss': 1.9708, 'learning_rate': 0.000761683991848306, 'epoch': 0.34}
 35%|███▍      | 822/2382 [3:05:14<5:30:19, 12.70s/it] 35%|███▍      | 823/2382 [3:05:26<5:29:04, 12.66s/it]                                                      {'loss': 1.9145, 'learning_rate': 0.0007611043187716418, 'epoch': 0.35}
 35%|███▍      | 823/2382 [3:05:26<5:29:04, 12.66s/it] 35%|███▍      | 824/2382 [3:05:40<5:35:10, 12.91s/it]                                                      {'loss': 1.8832, 'learning_rate': 0.0007605241627587627, 'epoch': 0.35}
 35%|███▍      | 824/2382 [3:05:40<5:35:10, 12.91s/it] 35%|███▍      | 825/2382 [3:05:54<5:46:30, 13.35s/it]                                                      {'loss': 1.8852, 'learning_rate': 0.0007599435248827198, 'epoch': 0.35}
 35%|███▍      | 825/2382 [3:05:54<5:46:30, 13.35s/it] 35%|███▍      | 826/2382 [3:06:10<6:01:52, 13.95s/it]                                                      {'loss': 1.951, 'learning_rate': 0.0007593624062174562, 'epoch': 0.35}
 35%|███▍      | 826/2382 [3:06:10<6:01:52, 13.95s/it] 35%|███▍      | 827/2382 [3:06:21<5:44:56, 13.31s/it]                                                      {'loss': 1.8064, 'learning_rate': 0.0007587808078378036, 'epoch': 0.35}
 35%|███▍      | 827/2382 [3:06:21<5:44:56, 13.31s/it] 35%|███▍      | 828/2382 [3:06:34<5:41:27, 13.18s/it]                                                      {'loss': 1.7543, 'learning_rate': 0.000758198730819481, 'epoch': 0.35}
 35%|███▍      | 828/2382 [3:06:34<5:41:27, 13.18s/it] 35%|███▍      | 829/2382 [3:06:48<5:45:09, 13.34s/it]                                                      {'loss': 1.8471, 'learning_rate': 0.000757616176239093, 'epoch': 0.35}
 35%|███▍      | 829/2382 [3:06:48<5:45:09, 13.34s/it] 35%|███▍      | 830/2382 [3:07:02<5:46:42, 13.40s/it]                                                      {'loss': 1.8185, 'learning_rate': 0.0007570331451741274, 'epoch': 0.35}
 35%|███▍      | 830/2382 [3:07:02<5:46:42, 13.40s/it] 35%|███▍      | 831/2382 [3:07:14<5:41:10, 13.20s/it]                                                      {'loss': 1.9108, 'learning_rate': 0.0007564496387029531, 'epoch': 0.35}
 35%|███▍      | 831/2382 [3:07:14<5:41:10, 13.20s/it] 35%|███▍      | 832/2382 [3:07:27<5:38:23, 13.10s/it]                                                      {'loss': 1.9103, 'learning_rate': 0.0007558656579048185, 'epoch': 0.35}
 35%|███▍      | 832/2382 [3:07:27<5:38:23, 13.10s/it] 35%|███▍      | 833/2382 [3:07:42<5:50:04, 13.56s/it]                                                      {'loss': 1.8429, 'learning_rate': 0.0007552812038598494, 'epoch': 0.35}
 35%|███▍      | 833/2382 [3:07:42<5:50:04, 13.56s/it] 35%|███▌      | 834/2382 [3:07:55<5:43:55, 13.33s/it]                                                      {'loss': 1.8808, 'learning_rate': 0.0007546962776490467, 'epoch': 0.35}
 35%|███▌      | 834/2382 [3:07:55<5:43:55, 13.33s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1719 > 1024). Running this sequence through the model will result in indexing errors
 35%|███▌      | 835/2382 [3:08:08<5:44:42, 13.37s/it]                                                      {'loss': 1.8391, 'learning_rate': 0.0007541108803542846, 'epoch': 0.35}
 35%|███▌      | 835/2382 [3:08:08<5:44:42, 13.37s/it] 35%|███▌      | 836/2382 [3:08:23<5:58:15, 13.90s/it]                                                      {'loss': 1.8486, 'learning_rate': 0.0007535250130583088, 'epoch': 0.35}
 35%|███▌      | 836/2382 [3:08:23<5:58:15, 13.90s/it] 35%|███▌      | 837/2382 [3:08:37<5:59:22, 13.96s/it]                                                      {'loss': 1.8322, 'learning_rate': 0.0007529386768447342, 'epoch': 0.35}
 35%|███▌      | 837/2382 [3:08:37<5:59:22, 13.96s/it] 35%|███▌      | 838/2382 [3:08:50<5:52:13, 13.69s/it]                                                      {'loss': 1.9548, 'learning_rate': 0.000752351872798043, 'epoch': 0.35}
 35%|███▌      | 838/2382 [3:08:50<5:52:13, 13.69s/it] 35%|███▌      | 839/2382 [3:09:02<5:33:59, 12.99s/it]                                                      {'loss': 1.915, 'learning_rate': 0.0007517646020035827, 'epoch': 0.35}
 35%|███▌      | 839/2382 [3:09:02<5:33:59, 12.99s/it] 35%|███▌      | 840/2382 [3:09:16<5:46:02, 13.46s/it]                                                      {'loss': 1.9025, 'learning_rate': 0.0007511768655475642, 'epoch': 0.35}
 35%|███▌      | 840/2382 [3:09:16<5:46:02, 13.46s/it] 35%|███▌      | 841/2382 [3:09:27<5:28:09, 12.78s/it]                                                      {'loss': 1.8558, 'learning_rate': 0.0007505886645170594, 'epoch': 0.35}
 35%|███▌      | 841/2382 [3:09:27<5:28:09, 12.78s/it] 35%|███▌      | 842/2382 [3:09:40<5:29:30, 12.84s/it]                                                      {'loss': 1.9231, 'learning_rate': 0.00075, 'epoch': 0.35}
 35%|███▌      | 842/2382 [3:09:40<5:29:30, 12.84s/it] 35%|███▌      | 843/2382 [3:09:53<5:24:25, 12.65s/it]                                                      {'loss': 1.9458, 'learning_rate': 0.0007494108730851744, 'epoch': 0.35}
 35%|███▌      | 843/2382 [3:09:53<5:24:25, 12.65s/it] 35%|███▌      | 844/2382 [3:10:05<5:20:06, 12.49s/it]                                                      {'loss': 1.8649, 'learning_rate': 0.0007488212848622266, 'epoch': 0.35}
 35%|███▌      | 844/2382 [3:10:05<5:20:06, 12.49s/it] 35%|███▌      | 845/2382 [3:10:19<5:29:52, 12.88s/it]                                                      {'loss': 1.8743, 'learning_rate': 0.0007482312364216535, 'epoch': 0.35}
 35%|███▌      | 845/2382 [3:10:19<5:29:52, 12.88s/it] 36%|███▌      | 846/2382 [3:10:35<5:56:10, 13.91s/it]                                                      {'loss': 1.8482, 'learning_rate': 0.0007476407288548036, 'epoch': 0.36}
 36%|███▌      | 846/2382 [3:10:35<5:56:10, 13.91s/it] 36%|███▌      | 847/2382 [3:10:48<5:50:33, 13.70s/it]                                                      {'loss': 1.8091, 'learning_rate': 0.0007470497632538743, 'epoch': 0.36}
 36%|███▌      | 847/2382 [3:10:48<5:50:33, 13.70s/it] 36%|███▌      | 848/2382 [3:10:59<5:32:01, 12.99s/it]                                                      {'loss': 1.9172, 'learning_rate': 0.0007464583407119106, 'epoch': 0.36}
 36%|███▌      | 848/2382 [3:10:59<5:32:01, 12.99s/it] 36%|███▌      | 849/2382 [3:11:15<5:50:47, 13.73s/it]                                                      {'loss': 1.8716, 'learning_rate': 0.000745866462322802, 'epoch': 0.36}
 36%|███▌      | 849/2382 [3:11:15<5:50:47, 13.73s/it] 36%|███▌      | 850/2382 [3:11:27<5:37:09, 13.20s/it]                                                      {'loss': 1.8848, 'learning_rate': 0.0007452741291812814, 'epoch': 0.36}
 36%|███▌      | 850/2382 [3:11:27<5:37:09, 13.20s/it] 36%|███▌      | 851/2382 [3:11:42<5:48:48, 13.67s/it]                                                      {'loss': 1.8582, 'learning_rate': 0.0007446813423829233, 'epoch': 0.36}
 36%|███▌      | 851/2382 [3:11:42<5:48:48, 13.67s/it] 36%|███▌      | 852/2382 [3:11:54<5:39:15, 13.30s/it]                                                      {'loss': 1.8389, 'learning_rate': 0.0007440881030241406, 'epoch': 0.36}
 36%|███▌      | 852/2382 [3:11:54<5:39:15, 13.30s/it] 36%|███▌      | 853/2382 [3:12:07<5:34:17, 13.12s/it]                                                      {'loss': 1.7773, 'learning_rate': 0.0007434944122021837, 'epoch': 0.36}
 36%|███▌      | 853/2382 [3:12:07<5:34:17, 13.12s/it] 36%|███▌      | 854/2382 [3:12:22<5:50:12, 13.75s/it]                                                      {'loss': 1.9019, 'learning_rate': 0.0007429002710151375, 'epoch': 0.36}
 36%|███▌      | 854/2382 [3:12:22<5:50:12, 13.75s/it] 36%|███▌      | 855/2382 [3:12:34<5:36:35, 13.23s/it]                                                      {'loss': 1.8772, 'learning_rate': 0.0007423056805619206, 'epoch': 0.36}
 36%|███▌      | 855/2382 [3:12:34<5:36:35, 13.23s/it] 36%|███▌      | 856/2382 [3:12:48<5:41:29, 13.43s/it]                                                      {'loss': 1.9402, 'learning_rate': 0.0007417106419422819, 'epoch': 0.36}
 36%|███▌      | 856/2382 [3:12:48<5:41:29, 13.43s/it] 36%|███▌      | 857/2382 [3:13:03<5:55:50, 14.00s/it]                                                      {'loss': 1.8417, 'learning_rate': 0.0007411151562567998, 'epoch': 0.36}
 36%|███▌      | 857/2382 [3:13:03<5:55:50, 14.00s/it] 36%|███▌      | 858/2382 [3:13:14<5:35:00, 13.19s/it]                                                      {'loss': 1.9204, 'learning_rate': 0.000740519224606879, 'epoch': 0.36}
 36%|███▌      | 858/2382 [3:13:14<5:35:00, 13.19s/it] 36%|███▌      | 859/2382 [3:13:26<5:20:27, 12.62s/it]                                                      {'loss': 1.905, 'learning_rate': 0.0007399228480947495, 'epoch': 0.36}
 36%|███▌      | 859/2382 [3:13:26<5:20:27, 12.62s/it] 36%|███▌      | 860/2382 [3:13:38<5:17:37, 12.52s/it]                                                      {'loss': 1.8875, 'learning_rate': 0.0007393260278234641, 'epoch': 0.36}
 36%|███▌      | 860/2382 [3:13:38<5:17:37, 12.52s/it] 36%|███▌      | 861/2382 [3:13:52<5:24:58, 12.82s/it]                                                      {'loss': 1.833, 'learning_rate': 0.000738728764896896, 'epoch': 0.36}
 36%|███▌      | 861/2382 [3:13:52<5:24:58, 12.82s/it] 36%|███▌      | 862/2382 [3:14:05<5:31:12, 13.07s/it]                                                      {'loss': 1.8934, 'learning_rate': 0.0007381310604197374, 'epoch': 0.36}
 36%|███▌      | 862/2382 [3:14:05<5:31:12, 13.07s/it] 36%|███▌      | 863/2382 [3:14:20<5:45:24, 13.64s/it]                                                      {'loss': 1.9394, 'learning_rate': 0.0007375329154974975, 'epoch': 0.36}
 36%|███▌      | 863/2382 [3:14:20<5:45:24, 13.64s/it] 36%|███▋      | 864/2382 [3:14:36<5:57:51, 14.14s/it]                                                      {'loss': 1.8246, 'learning_rate': 0.0007369343312364993, 'epoch': 0.36}
 36%|███▋      | 864/2382 [3:14:36<5:57:51, 14.14s/it] 36%|███▋      | 865/2382 [3:14:48<5:45:06, 13.65s/it]                                                      {'loss': 1.7678, 'learning_rate': 0.0007363353087438792, 'epoch': 0.36}
 36%|███▋      | 865/2382 [3:14:48<5:45:06, 13.65s/it] 36%|███▋      | 866/2382 [3:15:02<5:45:43, 13.68s/it]                                                      {'loss': 1.8544, 'learning_rate': 0.000735735849127584, 'epoch': 0.36}
 36%|███▋      | 866/2382 [3:15:02<5:45:43, 13.68s/it] 36%|███▋      | 867/2382 [3:15:16<5:49:17, 13.83s/it]                                                      {'loss': 1.8808, 'learning_rate': 0.0007351359534963684, 'epoch': 0.36}
 36%|███▋      | 867/2382 [3:15:16<5:49:17, 13.83s/it] 36%|███▋      | 868/2382 [3:15:29<5:41:55, 13.55s/it]                                                      {'loss': 1.8893, 'learning_rate': 0.0007345356229597943, 'epoch': 0.36}
 36%|███▋      | 868/2382 [3:15:29<5:41:55, 13.55s/it] 36%|███▋      | 869/2382 [3:15:44<5:52:14, 13.97s/it]                                                      {'loss': 1.9443, 'learning_rate': 0.0007339348586282278, 'epoch': 0.36}
 36%|███▋      | 869/2382 [3:15:44<5:52:14, 13.97s/it] 37%|███▋      | 870/2382 [3:15:56<5:40:43, 13.52s/it]                                                      {'loss': 1.8194, 'learning_rate': 0.0007333336616128369, 'epoch': 0.37}
 37%|███▋      | 870/2382 [3:15:56<5:40:43, 13.52s/it] 37%|███▋      | 871/2382 [3:16:08<5:29:55, 13.10s/it]                                                      {'loss': 1.9693, 'learning_rate': 0.0007327320330255904, 'epoch': 0.37}
 37%|███▋      | 871/2382 [3:16:08<5:29:55, 13.10s/it] 37%|███▋      | 872/2382 [3:16:22<5:32:47, 13.22s/it]                                                      {'loss': 1.9055, 'learning_rate': 0.0007321299739792553, 'epoch': 0.37}
 37%|███▋      | 872/2382 [3:16:22<5:32:47, 13.22s/it] 37%|███▋      | 873/2382 [3:16:32<5:10:25, 12.34s/it]                                                      {'loss': 1.8562, 'learning_rate': 0.0007315274855873943, 'epoch': 0.37}
 37%|███▋      | 873/2382 [3:16:32<5:10:25, 12.34s/it] 37%|███▋      | 874/2382 [3:16:47<5:29:04, 13.09s/it]                                                      {'loss': 1.7741, 'learning_rate': 0.000730924568964365, 'epoch': 0.37}
 37%|███▋      | 874/2382 [3:16:47<5:29:04, 13.09s/it] 37%|███▋      | 875/2382 [3:17:02<5:42:41, 13.64s/it]                                                      {'loss': 1.7416, 'learning_rate': 0.0007303212252253162, 'epoch': 0.37}
 37%|███▋      | 875/2382 [3:17:02<5:42:41, 13.64s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1362 > 1024). Running this sequence through the model will result in indexing errors
 37%|███▋      | 876/2382 [3:17:17<5:49:12, 13.91s/it]                                                      {'loss': 1.9278, 'learning_rate': 0.0007297174554861871, 'epoch': 0.37}
 37%|███▋      | 876/2382 [3:17:17<5:49:12, 13.91s/it] 37%|███▋      | 877/2382 [3:17:29<5:41:03, 13.60s/it]                                                      {'loss': 1.8818, 'learning_rate': 0.0007291132608637052, 'epoch': 0.37}
 37%|███▋      | 877/2382 [3:17:29<5:41:03, 13.60s/it] 37%|███▋      | 878/2382 [3:17:44<5:48:14, 13.89s/it]                                                      {'loss': 1.8123, 'learning_rate': 0.0007285086424753832, 'epoch': 0.37}
 37%|███▋      | 878/2382 [3:17:44<5:48:14, 13.89s/it] 37%|███▋      | 879/2382 [3:17:55<5:29:49, 13.17s/it]                                                      {'loss': 1.9776, 'learning_rate': 0.0007279036014395178, 'epoch': 0.37}
 37%|███▋      | 879/2382 [3:17:55<5:29:49, 13.17s/it] 37%|███▋      | 880/2382 [3:18:08<5:24:03, 12.95s/it]                                                      {'loss': 1.7663, 'learning_rate': 0.0007272981388751875, 'epoch': 0.37}
 37%|███▋      | 880/2382 [3:18:08<5:24:03, 12.95s/it] 37%|███▋      | 881/2382 [3:18:23<5:38:42, 13.54s/it]                                                      {'loss': 1.8333, 'learning_rate': 0.0007266922559022506, 'epoch': 0.37}
 37%|███▋      | 881/2382 [3:18:23<5:38:42, 13.54s/it] 37%|███▋      | 882/2382 [3:18:37<5:40:08, 13.61s/it]                                                      {'loss': 1.9183, 'learning_rate': 0.0007260859536413429, 'epoch': 0.37}
 37%|███▋      | 882/2382 [3:18:37<5:40:08, 13.61s/it] 37%|███▋      | 883/2382 [3:18:49<5:27:56, 13.13s/it]                                                      {'loss': 1.8945, 'learning_rate': 0.0007254792332138753, 'epoch': 0.37}
 37%|███▋      | 883/2382 [3:18:49<5:27:56, 13.13s/it] 37%|███▋      | 884/2382 [3:19:02<5:31:36, 13.28s/it]                                                      {'loss': 1.8016, 'learning_rate': 0.0007248720957420329, 'epoch': 0.37}
 37%|███▋      | 884/2382 [3:19:02<5:31:36, 13.28s/it] 37%|███▋      | 885/2382 [3:19:17<5:40:48, 13.66s/it]                                                      {'loss': 1.7937, 'learning_rate': 0.0007242645423487714, 'epoch': 0.37}
 37%|███▋      | 885/2382 [3:19:17<5:40:48, 13.66s/it] 37%|███▋      | 886/2382 [3:19:30<5:36:02, 13.48s/it]                                                      {'loss': 1.8526, 'learning_rate': 0.0007236565741578163, 'epoch': 0.37}
 37%|███▋      | 886/2382 [3:19:30<5:36:02, 13.48s/it] 37%|███▋      | 887/2382 [3:19:44<5:41:16, 13.70s/it]                                                      {'loss': 1.8508, 'learning_rate': 0.0007230481922936602, 'epoch': 0.37}
 37%|███▋      | 887/2382 [3:19:44<5:41:16, 13.70s/it] 37%|███▋      | 888/2382 [3:19:57<5:39:27, 13.63s/it]                                                      {'loss': 1.8402, 'learning_rate': 0.0007224393978815604, 'epoch': 0.37}
 37%|███▋      | 888/2382 [3:19:58<5:39:27, 13.63s/it] 37%|███▋      | 889/2382 [3:20:11<5:34:51, 13.46s/it]                                                      {'loss': 1.8627, 'learning_rate': 0.000721830192047538, 'epoch': 0.37}
 37%|███▋      | 889/2382 [3:20:11<5:34:51, 13.46s/it] 37%|███▋      | 890/2382 [3:20:24<5:34:43, 13.46s/it]                                                      {'loss': 1.8568, 'learning_rate': 0.0007212205759183748, 'epoch': 0.37}
 37%|███▋      | 890/2382 [3:20:24<5:34:43, 13.46s/it] 37%|███▋      | 891/2382 [3:20:37<5:28:28, 13.22s/it]                                                      {'loss': 1.8946, 'learning_rate': 0.0007206105506216106, 'epoch': 0.37}
 37%|███▋      | 891/2382 [3:20:37<5:28:28, 13.22s/it] 37%|███▋      | 892/2382 [3:20:49<5:25:11, 13.09s/it]                                                      {'loss': 1.9736, 'learning_rate': 0.0007200001172855435, 'epoch': 0.37}
 37%|███▋      | 892/2382 [3:20:49<5:25:11, 13.09s/it] 37%|███▋      | 893/2382 [3:21:04<5:37:27, 13.60s/it]                                                      {'loss': 1.798, 'learning_rate': 0.0007193892770392252, 'epoch': 0.37}
 37%|███▋      | 893/2382 [3:21:04<5:37:27, 13.60s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1157 > 1024). Running this sequence through the model will result in indexing errors
 38%|███▊      | 894/2382 [3:21:16<5:23:10, 13.03s/it]                                                      {'loss': 1.9242, 'learning_rate': 0.0007187780310124604, 'epoch': 0.38}
 38%|███▊      | 894/2382 [3:21:16<5:23:10, 13.03s/it] 38%|███▊      | 895/2382 [3:21:28<5:15:08, 12.72s/it]                                                      {'loss': 1.8966, 'learning_rate': 0.0007181663803358043, 'epoch': 0.38}
 38%|███▊      | 895/2382 [3:21:28<5:15:08, 12.72s/it] 38%|███▊      | 896/2382 [3:21:42<5:24:35, 13.11s/it]                                                      {'loss': 1.8148, 'learning_rate': 0.0007175543261405607, 'epoch': 0.38}
 38%|███▊      | 896/2382 [3:21:42<5:24:35, 13.11s/it] 38%|███▊      | 897/2382 [3:21:57<5:36:50, 13.61s/it]                                                      {'loss': 1.8697, 'learning_rate': 0.0007169418695587791, 'epoch': 0.38}
 38%|███▊      | 897/2382 [3:21:57<5:36:50, 13.61s/it] 38%|███▊      | 898/2382 [3:22:11<5:37:56, 13.66s/it]                                                      {'loss': 1.8889, 'learning_rate': 0.0007163290117232541, 'epoch': 0.38}
 38%|███▊      | 898/2382 [3:22:11<5:37:56, 13.66s/it] 38%|███▊      | 899/2382 [3:22:24<5:36:08, 13.60s/it]                                                      {'loss': 1.7838, 'learning_rate': 0.000715715753767522, 'epoch': 0.38}
 38%|███▊      | 899/2382 [3:22:24<5:36:08, 13.60s/it] 38%|███▊      | 900/2382 [3:22:38<5:38:15, 13.69s/it]                                                      {'loss': 1.8453, 'learning_rate': 0.0007151020968258595, 'epoch': 0.38}
 38%|███▊      | 900/2382 [3:22:38<5:38:15, 13.69s/it] 38%|███▊      | 901/2382 [3:22:51<5:35:15, 13.58s/it]                                                      {'loss': 1.8653, 'learning_rate': 0.0007144880420332804, 'epoch': 0.38}
 38%|███▊      | 901/2382 [3:22:51<5:35:15, 13.58s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1044 > 1024). Running this sequence through the model will result in indexing errors
 38%|███▊      | 902/2382 [3:23:04<5:27:09, 13.26s/it]                                                      {'loss': 1.9218, 'learning_rate': 0.0007138735905255354, 'epoch': 0.38}
 38%|███▊      | 902/2382 [3:23:04<5:27:09, 13.26s/it] 38%|███▊      | 903/2382 [3:23:16<5:17:41, 12.89s/it]                                                      {'loss': 1.8743, 'learning_rate': 0.0007132587434391086, 'epoch': 0.38}
 38%|███▊      | 903/2382 [3:23:16<5:17:41, 12.89s/it] 38%|███▊      | 904/2382 [3:23:29<5:19:06, 12.95s/it]                                                      {'loss': 1.8422, 'learning_rate': 0.0007126435019112152, 'epoch': 0.38}
 38%|███▊      | 904/2382 [3:23:29<5:19:06, 12.95s/it] 38%|███▊      | 905/2382 [3:23:43<5:25:00, 13.20s/it]                                                      {'loss': 1.8839, 'learning_rate': 0.0007120278670798009, 'epoch': 0.38}
 38%|███▊      | 905/2382 [3:23:43<5:25:00, 13.20s/it] 38%|███▊      | 906/2382 [3:23:56<5:28:36, 13.36s/it]                                                      {'loss': 1.9748, 'learning_rate': 0.0007114118400835381, 'epoch': 0.38}
 38%|███▊      | 906/2382 [3:23:56<5:28:36, 13.36s/it] 38%|███▊      | 907/2382 [3:24:09<5:20:36, 13.04s/it]                                                      {'loss': 1.8771, 'learning_rate': 0.000710795422061825, 'epoch': 0.38}
 38%|███▊      | 907/2382 [3:24:09<5:20:36, 13.04s/it] 38%|███▊      | 908/2382 [3:24:23<5:28:46, 13.38s/it]                                                      {'loss': 1.8631, 'learning_rate': 0.0007101786141547828, 'epoch': 0.38}
 38%|███▊      | 908/2382 [3:24:23<5:28:46, 13.38s/it] 38%|███▊      | 909/2382 [3:24:40<5:52:49, 14.37s/it]                                                      {'loss': 1.9226, 'learning_rate': 0.0007095614175032539, 'epoch': 0.38}
 38%|███▊      | 909/2382 [3:24:40<5:52:49, 14.37s/it] 38%|███▊      | 910/2382 [3:24:55<6:04:02, 14.84s/it]                                                      {'loss': 1.851, 'learning_rate': 0.0007089438332487997, 'epoch': 0.38}
 38%|███▊      | 910/2382 [3:24:55<6:04:02, 14.84s/it] 38%|███▊      | 911/2382 [3:25:10<5:58:34, 14.63s/it]                                                      {'loss': 1.8178, 'learning_rate': 0.0007083258625336983, 'epoch': 0.38}
 38%|███▊      | 911/2382 [3:25:10<5:58:34, 14.63s/it] 38%|███▊      | 912/2382 [3:25:24<5:55:48, 14.52s/it]                                                      {'loss': 2.0617, 'learning_rate': 0.0007077075065009433, 'epoch': 0.38}
 38%|███▊      | 912/2382 [3:25:24<5:55:48, 14.52s/it] 38%|███▊      | 913/2382 [3:25:37<5:46:41, 14.16s/it]                                                      {'loss': 1.83, 'learning_rate': 0.0007070887662942401, 'epoch': 0.38}
 38%|███▊      | 913/2382 [3:25:37<5:46:41, 14.16s/it] 38%|███▊      | 914/2382 [3:25:51<5:44:30, 14.08s/it]                                                      {'loss': 1.8622, 'learning_rate': 0.0007064696430580051, 'epoch': 0.38}
 38%|███▊      | 914/2382 [3:25:51<5:44:30, 14.08s/it] 38%|███▊      | 915/2382 [3:26:02<5:22:35, 13.19s/it]                                                      {'loss': 1.9101, 'learning_rate': 0.0007058501379373634, 'epoch': 0.38}
 38%|███▊      | 915/2382 [3:26:02<5:22:35, 13.19s/it] 38%|███▊      | 916/2382 [3:26:17<5:31:14, 13.56s/it]                                                      {'loss': 1.8544, 'learning_rate': 0.0007052302520781458, 'epoch': 0.38}
 38%|███▊      | 916/2382 [3:26:17<5:31:14, 13.56s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1414 > 1024). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (1168 > 1024). Running this sequence through the model will result in indexing errors
 38%|███▊      | 917/2382 [3:26:29<5:21:11, 13.15s/it]                                                      {'loss': 1.9257, 'learning_rate': 0.0007046099866268877, 'epoch': 0.38}
 38%|███▊      | 917/2382 [3:26:29<5:21:11, 13.15s/it] 39%|███▊      | 918/2382 [3:26:45<5:43:12, 14.07s/it]                                                      {'loss': 1.9204, 'learning_rate': 0.0007039893427308268, 'epoch': 0.39}
 39%|███▊      | 918/2382 [3:26:45<5:43:12, 14.07s/it] 39%|███▊      | 919/2382 [3:27:00<5:50:14, 14.36s/it]                                                      {'loss': 1.861, 'learning_rate': 0.0007033683215379002, 'epoch': 0.39}
 39%|███▊      | 919/2382 [3:27:00<5:50:14, 14.36s/it] 39%|███▊      | 920/2382 [3:27:14<5:43:23, 14.09s/it]                                                      {'loss': 1.8362, 'learning_rate': 0.0007027469241967432, 'epoch': 0.39}
 39%|███▊      | 920/2382 [3:27:14<5:43:23, 14.09s/it] 39%|███▊      | 921/2382 [3:27:24<5:18:09, 13.07s/it]                                                      {'loss': 2.0204, 'learning_rate': 0.0007021251518566868, 'epoch': 0.39}
 39%|███▊      | 921/2382 [3:27:24<5:18:09, 13.07s/it] 39%|███▊      | 922/2382 [3:27:36<5:11:37, 12.81s/it]                                                      {'loss': 1.9033, 'learning_rate': 0.0007015030056677558, 'epoch': 0.39}
 39%|███▊      | 922/2382 [3:27:36<5:11:37, 12.81s/it] 39%|███▊      | 923/2382 [3:27:50<5:20:02, 13.16s/it]                                                      {'loss': 2.0343, 'learning_rate': 0.0007008804867806659, 'epoch': 0.39}
 39%|███▊      | 923/2382 [3:27:50<5:20:02, 13.16s/it] 39%|███▉      | 924/2382 [3:28:05<5:29:49, 13.57s/it]                                                      {'loss': 1.9419, 'learning_rate': 0.0007002575963468225, 'epoch': 0.39}
 39%|███▉      | 924/2382 [3:28:05<5:29:49, 13.57s/it] 39%|███▉      | 925/2382 [3:28:19<5:33:35, 13.74s/it]                                                      {'loss': 1.929, 'learning_rate': 0.0006996343355183185, 'epoch': 0.39}
 39%|███▉      | 925/2382 [3:28:19<5:33:35, 13.74s/it] 39%|███▉      | 926/2382 [3:28:30<5:15:57, 13.02s/it]                                                      {'loss': 1.8357, 'learning_rate': 0.0006990107054479312, 'epoch': 0.39}
 39%|███▉      | 926/2382 [3:28:30<5:15:57, 13.02s/it] 39%|███▉      | 927/2382 [3:28:44<5:22:26, 13.30s/it]                                                      {'loss': 1.8926, 'learning_rate': 0.0006983867072891212, 'epoch': 0.39}
 39%|███▉      | 927/2382 [3:28:44<5:22:26, 13.30s/it] 39%|███▉      | 928/2382 [3:28:57<5:14:24, 12.97s/it]                                                      {'loss': 1.8983, 'learning_rate': 0.0006977623421960303, 'epoch': 0.39}
 39%|███▉      | 928/2382 [3:28:57<5:14:24, 12.97s/it] 39%|███▉      | 929/2382 [3:29:12<5:30:58, 13.67s/it]                                                      {'loss': 1.8383, 'learning_rate': 0.0006971376113234782, 'epoch': 0.39}
 39%|███▉      | 929/2382 [3:29:12<5:30:58, 13.67s/it] 39%|███▉      | 930/2382 [3:29:26<5:35:28, 13.86s/it]                                                      {'loss': 2.008, 'learning_rate': 0.0006965125158269618, 'epoch': 0.39}
 39%|███▉      | 930/2382 [3:29:26<5:35:28, 13.86s/it] 39%|███▉      | 931/2382 [3:29:37<5:16:58, 13.11s/it]                                                      {'loss': 1.9684, 'learning_rate': 0.0006958870568626521, 'epoch': 0.39}
 39%|███▉      | 931/2382 [3:29:37<5:16:58, 13.11s/it] 39%|███▉      | 932/2382 [3:29:51<5:22:12, 13.33s/it]                                                      {'loss': 1.9939, 'learning_rate': 0.0006952612355873922, 'epoch': 0.39}
 39%|███▉      | 932/2382 [3:29:51<5:22:12, 13.33s/it] 39%|███▉      | 933/2382 [3:30:09<5:56:29, 14.76s/it]                                                      {'loss': 1.8572, 'learning_rate': 0.0006946350531586958, 'epoch': 0.39}
 39%|███▉      | 933/2382 [3:30:09<5:56:29, 14.76s/it] 39%|███▉      | 934/2382 [3:30:23<5:48:34, 14.44s/it]                                                      {'loss': 1.8528, 'learning_rate': 0.0006940085107347443, 'epoch': 0.39}
 39%|███▉      | 934/2382 [3:30:23<5:48:34, 14.44s/it] 39%|███▉      | 935/2382 [3:30:36<5:36:39, 13.96s/it]                                                      {'loss': 1.8037, 'learning_rate': 0.0006933816094743846, 'epoch': 0.39}
 39%|███▉      | 935/2382 [3:30:36<5:36:39, 13.96s/it] 39%|███▉      | 936/2382 [3:30:51<5:45:50, 14.35s/it]                                                      {'loss': 1.848, 'learning_rate': 0.0006927543505371281, 'epoch': 0.39}
 39%|███▉      | 936/2382 [3:30:51<5:45:50, 14.35s/it] 39%|███▉      | 937/2382 [3:31:04<5:37:33, 14.02s/it]                                                      {'loss': 1.8262, 'learning_rate': 0.0006921267350831473, 'epoch': 0.39}
 39%|███▉      | 937/2382 [3:31:04<5:37:33, 14.02s/it] 39%|███▉      | 938/2382 [3:31:16<5:21:32, 13.36s/it]                                                      {'loss': 1.8854, 'learning_rate': 0.0006914987642732738, 'epoch': 0.39}
 39%|███▉      | 938/2382 [3:31:16<5:21:32, 13.36s/it] 39%|███▉      | 939/2382 [3:31:28<5:12:28, 12.99s/it]                                                      {'loss': 1.881, 'learning_rate': 0.0006908704392689972, 'epoch': 0.39}
 39%|███▉      | 939/2382 [3:31:28<5:12:28, 12.99s/it] 39%|███▉      | 940/2382 [3:31:39<4:58:04, 12.40s/it]                                                      {'loss': 1.929, 'learning_rate': 0.0006902417612324615, 'epoch': 0.39}
 39%|███▉      | 940/2382 [3:31:39<4:58:04, 12.40s/it] 40%|███▉      | 941/2382 [3:31:53<5:06:15, 12.75s/it]                                                      {'loss': 1.9119, 'learning_rate': 0.0006896127313264643, 'epoch': 0.39}
 40%|███▉      | 941/2382 [3:31:53<5:06:15, 12.75s/it] 40%|███▉      | 942/2382 [3:32:05<5:03:53, 12.66s/it]                                                      {'loss': 1.9307, 'learning_rate': 0.0006889833507144532, 'epoch': 0.4}
 40%|███▉      | 942/2382 [3:32:05<5:03:53, 12.66s/it] 40%|███▉      | 943/2382 [3:32:17<4:57:52, 12.42s/it]                                                      {'loss': 1.8929, 'learning_rate': 0.0006883536205605255, 'epoch': 0.4}
 40%|███▉      | 943/2382 [3:32:17<4:57:52, 12.42s/it] 40%|███▉      | 944/2382 [3:32:33<5:22:10, 13.44s/it]                                                      {'loss': 1.83, 'learning_rate': 0.0006877235420294244, 'epoch': 0.4}
 40%|███▉      | 944/2382 [3:32:33<5:22:10, 13.44s/it] 40%|███▉      | 945/2382 [3:32:48<5:28:50, 13.73s/it]                                                      {'loss': 1.822, 'learning_rate': 0.0006870931162865369, 'epoch': 0.4}
 40%|███▉      | 945/2382 [3:32:48<5:28:50, 13.73s/it] 40%|███▉      | 946/2382 [3:33:01<5:29:24, 13.76s/it]                                                      {'loss': 1.8793, 'learning_rate': 0.0006864623444978934, 'epoch': 0.4}
 40%|███▉      | 946/2382 [3:33:01<5:29:24, 13.76s/it] 40%|███▉      | 947/2382 [3:33:14<5:23:17, 13.52s/it]                                                      {'loss': 1.8603, 'learning_rate': 0.0006858312278301637, 'epoch': 0.4}
 40%|███▉      | 947/2382 [3:33:14<5:23:17, 13.52s/it] 40%|███▉      | 948/2382 [3:33:27<5:16:18, 13.23s/it]                                                      {'loss': 1.9038, 'learning_rate': 0.0006851997674506556, 'epoch': 0.4}
 40%|███▉      | 948/2382 [3:33:27<5:16:18, 13.23s/it] 40%|███▉      | 949/2382 [3:33:39<5:10:06, 12.98s/it]                                                      {'loss': 1.7787, 'learning_rate': 0.0006845679645273124, 'epoch': 0.4}
 40%|███▉      | 949/2382 [3:33:39<5:10:06, 12.98s/it] 40%|███▉      | 950/2382 [3:33:53<5:11:59, 13.07s/it]                                                      {'loss': 1.8484, 'learning_rate': 0.000683935820228711, 'epoch': 0.4}
 40%|███▉      | 950/2382 [3:33:53<5:11:59, 13.07s/it] 40%|███▉      | 951/2382 [3:34:05<5:04:45, 12.78s/it]                                                      {'loss': 1.8772, 'learning_rate': 0.0006833033357240602, 'epoch': 0.4}
 40%|███▉      | 951/2382 [3:34:05<5:04:45, 12.78s/it] 40%|███▉      | 952/2382 [3:34:18<5:06:14, 12.85s/it]                                                      {'loss': 1.9148, 'learning_rate': 0.0006826705121831977, 'epoch': 0.4}
 40%|███▉      | 952/2382 [3:34:18<5:06:14, 12.85s/it] 40%|████      | 953/2382 [3:34:30<4:58:55, 12.55s/it]                                                      {'loss': 1.9175, 'learning_rate': 0.0006820373507765878, 'epoch': 0.4}
 40%|████      | 953/2382 [3:34:30<4:58:55, 12.55s/it] 40%|████      | 954/2382 [3:34:47<5:32:43, 13.98s/it]                                                      {'loss': 1.8705, 'learning_rate': 0.0006814038526753205, 'epoch': 0.4}
 40%|████      | 954/2382 [3:34:47<5:32:43, 13.98s/it] 40%|████      | 955/2382 [3:35:02<5:39:37, 14.28s/it]                                                      {'loss': 1.8482, 'learning_rate': 0.0006807700190511084, 'epoch': 0.4}
 40%|████      | 955/2382 [3:35:02<5:39:37, 14.28s/it] 40%|████      | 956/2382 [3:35:17<5:46:52, 14.60s/it]                                                      {'loss': 1.8606, 'learning_rate': 0.0006801358510762842, 'epoch': 0.4}
 40%|████      | 956/2382 [3:35:17<5:46:52, 14.60s/it] 40%|████      | 957/2382 [3:35:31<5:37:58, 14.23s/it]                                                      {'loss': 1.9213, 'learning_rate': 0.0006795013499237994, 'epoch': 0.4}
 40%|████      | 957/2382 [3:35:31<5:37:58, 14.23s/it] 40%|████      | 958/2382 [3:35:46<5:45:44, 14.57s/it]                                                      {'loss': 1.8787, 'learning_rate': 0.0006788665167672217, 'epoch': 0.4}
 40%|████      | 958/2382 [3:35:46<5:45:44, 14.57s/it] 40%|████      | 959/2382 [3:36:00<5:45:22, 14.56s/it]                                                      {'loss': 1.8249, 'learning_rate': 0.0006782313527807329, 'epoch': 0.4}
 40%|████      | 959/2382 [3:36:00<5:45:22, 14.56s/it] 40%|████      | 960/2382 [3:36:14<5:40:02, 14.35s/it]                                                      {'loss': 1.9137, 'learning_rate': 0.0006775958591391265, 'epoch': 0.4}
 40%|████      | 960/2382 [3:36:14<5:40:02, 14.35s/it] 40%|████      | 961/2382 [3:36:28<5:36:03, 14.19s/it]                                                      {'loss': 1.8375, 'learning_rate': 0.0006769600370178059, 'epoch': 0.4}
 40%|████      | 961/2382 [3:36:28<5:36:03, 14.19s/it] 40%|████      | 962/2382 [3:36:41<5:28:05, 13.86s/it]                                                      {'loss': 1.8712, 'learning_rate': 0.0006763238875927822, 'epoch': 0.4}
 40%|████      | 962/2382 [3:36:41<5:28:05, 13.86s/it] 40%|████      | 963/2382 [3:36:53<5:13:42, 13.26s/it]                                                      {'loss': 1.8806, 'learning_rate': 0.0006756874120406714, 'epoch': 0.4}
 40%|████      | 963/2382 [3:36:53<5:13:42, 13.26s/it] 40%|████      | 964/2382 [3:37:06<5:07:55, 13.03s/it]                                                      {'loss': 1.7855, 'learning_rate': 0.0006750506115386932, 'epoch': 0.4}
 40%|████      | 964/2382 [3:37:06<5:07:55, 13.03s/it] 41%|████      | 965/2382 [3:37:18<5:05:13, 12.92s/it]                                                      {'loss': 1.9175, 'learning_rate': 0.0006744134872646679, 'epoch': 0.4}
 41%|████      | 965/2382 [3:37:18<5:05:13, 12.92s/it] 41%|████      | 966/2382 [3:37:30<4:55:03, 12.50s/it]                                                      {'loss': 1.8777, 'learning_rate': 0.0006737760403970151, 'epoch': 0.41}
 41%|████      | 966/2382 [3:37:30<4:55:03, 12.50s/it] 41%|████      | 967/2382 [3:37:43<4:58:38, 12.66s/it]                                                      {'loss': 1.9814, 'learning_rate': 0.0006731382721147509, 'epoch': 0.41}
 41%|████      | 967/2382 [3:37:43<4:58:38, 12.66s/it] 41%|████      | 968/2382 [3:37:56<5:04:43, 12.93s/it]                                                      {'loss': 1.869, 'learning_rate': 0.0006725001835974853, 'epoch': 0.41}
 41%|████      | 968/2382 [3:37:56<5:04:43, 12.93s/it] 41%|████      | 969/2382 [3:38:11<5:15:30, 13.40s/it]                                                      {'loss': 1.8597, 'learning_rate': 0.0006718617760254216, 'epoch': 0.41}
 41%|████      | 969/2382 [3:38:11<5:15:30, 13.40s/it] 41%|████      | 970/2382 [3:38:24<5:15:00, 13.39s/it]                                                      {'loss': 1.8678, 'learning_rate': 0.0006712230505793529, 'epoch': 0.41}
 41%|████      | 970/2382 [3:38:24<5:15:00, 13.39s/it] 41%|████      | 971/2382 [3:38:37<5:10:03, 13.18s/it]                                                      {'loss': 1.8186, 'learning_rate': 0.0006705840084406595, 'epoch': 0.41}
 41%|████      | 971/2382 [3:38:37<5:10:03, 13.18s/it] 41%|████      | 972/2382 [3:38:52<5:24:18, 13.80s/it]                                                      {'loss': 1.954, 'learning_rate': 0.0006699446507913083, 'epoch': 0.41}
 41%|████      | 972/2382 [3:38:52<5:24:18, 13.80s/it] 41%|████      | 973/2382 [3:39:06<5:21:19, 13.68s/it]                                                      {'loss': 1.8819, 'learning_rate': 0.0006693049788138496, 'epoch': 0.41}
 41%|████      | 973/2382 [3:39:06<5:21:19, 13.68s/it] 41%|████      | 974/2382 [3:39:20<5:27:12, 13.94s/it]                                                      {'loss': 1.8413, 'learning_rate': 0.0006686649936914151, 'epoch': 0.41}
 41%|████      | 974/2382 [3:39:20<5:27:12, 13.94s/it] 41%|████      | 975/2382 [3:39:33<5:16:08, 13.48s/it]                                                      {'loss': 1.8256, 'learning_rate': 0.000668024696607715, 'epoch': 0.41}
 41%|████      | 975/2382 [3:39:33<5:16:08, 13.48s/it] 41%|████      | 976/2382 [3:39:45<5:11:33, 13.30s/it]                                                      {'loss': 1.9015, 'learning_rate': 0.0006673840887470377, 'epoch': 0.41}
 41%|████      | 976/2382 [3:39:45<5:11:33, 13.30s/it] 41%|████      | 977/2382 [3:39:59<5:12:46, 13.36s/it]                                                      {'loss': 1.9046, 'learning_rate': 0.0006667431712942453, 'epoch': 0.41}
 41%|████      | 977/2382 [3:39:59<5:12:46, 13.36s/it] 41%|████      | 978/2382 [3:40:13<5:17:42, 13.58s/it]                                                      {'loss': 1.9514, 'learning_rate': 0.0006661019454347733, 'epoch': 0.41}
 41%|████      | 978/2382 [3:40:13<5:17:42, 13.58s/it] 41%|████      | 979/2382 [3:40:28<5:26:28, 13.96s/it]                                                      {'loss': 1.8405, 'learning_rate': 0.0006654604123546273, 'epoch': 0.41}
 41%|████      | 979/2382 [3:40:28<5:26:28, 13.96s/it] 41%|████      | 980/2382 [3:40:42<5:26:30, 13.97s/it]                                                      {'loss': 1.8059, 'learning_rate': 0.0006648185732403809, 'epoch': 0.41}
 41%|████      | 980/2382 [3:40:42<5:26:30, 13.97s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1058 > 1024). Running this sequence through the model will result in indexing errors
 41%|████      | 981/2382 [3:40:54<5:14:09, 13.45s/it]                                                      {'loss': 1.9012, 'learning_rate': 0.0006641764292791742, 'epoch': 0.41}
 41%|████      | 981/2382 [3:40:54<5:14:09, 13.45s/it] 41%|████      | 982/2382 [3:41:08<5:13:52, 13.45s/it]                                                      {'loss': 1.9129, 'learning_rate': 0.0006635339816587109, 'epoch': 0.41}
 41%|████      | 982/2382 [3:41:08<5:13:52, 13.45s/it] 41%|████▏     | 983/2382 [3:41:22<5:19:26, 13.70s/it]                                                      {'loss': 1.8794, 'learning_rate': 0.0006628912315672562, 'epoch': 0.41}
 41%|████▏     | 983/2382 [3:41:22<5:19:26, 13.70s/it] 41%|████▏     | 984/2382 [3:41:35<5:14:57, 13.52s/it]                                                      {'loss': 1.9179, 'learning_rate': 0.0006622481801936353, 'epoch': 0.41}
 41%|████▏     | 984/2382 [3:41:35<5:14:57, 13.52s/it] 41%|████▏     | 985/2382 [3:41:49<5:15:55, 13.57s/it]                                                      {'loss': 1.9917, 'learning_rate': 0.0006616048287272301, 'epoch': 0.41}
 41%|████▏     | 985/2382 [3:41:49<5:15:55, 13.57s/it] 41%|████▏     | 986/2382 [3:42:01<5:08:39, 13.27s/it]                                                      {'loss': 1.8975, 'learning_rate': 0.0006609611783579775, 'epoch': 0.41}
 41%|████▏     | 986/2382 [3:42:01<5:08:39, 13.27s/it] 41%|████▏     | 987/2382 [3:42:16<5:19:28, 13.74s/it]                                                      {'loss': 1.8616, 'learning_rate': 0.0006603172302763677, 'epoch': 0.41}
 41%|████▏     | 987/2382 [3:42:16<5:19:28, 13.74s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1118 > 1024). Running this sequence through the model will result in indexing errors
 41%|████▏     | 988/2382 [3:42:30<5:21:51, 13.85s/it]                                                      {'loss': 1.8745, 'learning_rate': 0.0006596729856734413, 'epoch': 0.41}
 41%|████▏     | 988/2382 [3:42:30<5:21:51, 13.85s/it] 42%|████▏     | 989/2382 [3:42:44<5:24:46, 13.99s/it]                                                      {'loss': 1.8779, 'learning_rate': 0.0006590284457407876, 'epoch': 0.42}
 42%|████▏     | 989/2382 [3:42:44<5:24:46, 13.99s/it] 42%|████▏     | 990/2382 [3:42:59<5:29:27, 14.20s/it]                                                      {'loss': 1.8176, 'learning_rate': 0.0006583836116705413, 'epoch': 0.42}
 42%|████▏     | 990/2382 [3:42:59<5:29:27, 14.20s/it] 42%|████▏     | 991/2382 [3:43:11<5:12:25, 13.48s/it]                                                      {'loss': 1.9544, 'learning_rate': 0.0006577384846553822, 'epoch': 0.42}
 42%|████▏     | 991/2382 [3:43:11<5:12:25, 13.48s/it] 42%|████▏     | 992/2382 [3:43:24<5:06:27, 13.23s/it]                                                      {'loss': 1.8972, 'learning_rate': 0.0006570930658885314, 'epoch': 0.42}
 42%|████▏     | 992/2382 [3:43:24<5:06:27, 13.23s/it] 42%|████▏     | 993/2382 [3:43:36<4:58:05, 12.88s/it]                                                      {'loss': 1.9051, 'learning_rate': 0.0006564473565637494, 'epoch': 0.42}
 42%|████▏     | 993/2382 [3:43:36<4:58:05, 12.88s/it] 42%|████▏     | 994/2382 [3:43:49<5:00:59, 13.01s/it]                                                      {'loss': 1.9069, 'learning_rate': 0.0006558013578753347, 'epoch': 0.42}
 42%|████▏     | 994/2382 [3:43:49<5:00:59, 13.01s/it] 42%|████▏     | 995/2382 [3:44:04<5:17:22, 13.73s/it]                                                      {'loss': 1.8465, 'learning_rate': 0.0006551550710181207, 'epoch': 0.42}
 42%|████▏     | 995/2382 [3:44:04<5:17:22, 13.73s/it] 42%|████▏     | 996/2382 [3:44:16<5:03:51, 13.15s/it]                                                      {'loss': 1.8076, 'learning_rate': 0.0006545084971874737, 'epoch': 0.42}
 42%|████▏     | 996/2382 [3:44:16<5:03:51, 13.15s/it] 42%|████▏     | 997/2382 [3:44:30<5:08:55, 13.38s/it]                                                      {'loss': 1.932, 'learning_rate': 0.000653861637579291, 'epoch': 0.42}
 42%|████▏     | 997/2382 [3:44:30<5:08:55, 13.38s/it] 42%|████▏     | 998/2382 [3:44:44<5:13:05, 13.57s/it]                                                      {'loss': 1.7956, 'learning_rate': 0.0006532144933899981, 'epoch': 0.42}
 42%|████▏     | 998/2382 [3:44:44<5:13:05, 13.57s/it] 42%|████▏     | 999/2382 [3:44:58<5:17:44, 13.78s/it]                                                      {'loss': 1.806, 'learning_rate': 0.0006525670658165473, 'epoch': 0.42}
 42%|████▏     | 999/2382 [3:44:58<5:17:44, 13.78s/it] 42%|████▏     | 1000/2382 [3:45:11<5:11:09, 13.51s/it]                                                       {'loss': 1.8753, 'learning_rate': 0.0006519193560564149, 'epoch': 0.42}
 42%|████▏     | 1000/2382 [3:45:11<5:11:09, 13.51s/it] 42%|████▏     | 1001/2382 [3:45:23<4:59:48, 13.03s/it]                                                       {'loss': 1.8249, 'learning_rate': 0.0006512713653075988, 'epoch': 0.42}
 42%|████▏     | 1001/2382 [3:45:23<4:59:48, 13.03s/it] 42%|████▏     | 1002/2382 [3:45:36<4:59:28, 13.02s/it]                                                       {'loss': 1.7582, 'learning_rate': 0.0006506230947686171, 'epoch': 0.42}
 42%|████▏     | 1002/2382 [3:45:36<4:59:28, 13.02s/it] 42%|████▏     | 1003/2382 [3:45:51<5:08:35, 13.43s/it]                                                       {'loss': 1.8374, 'learning_rate': 0.0006499745456385053, 'epoch': 0.42}
 42%|████▏     | 1003/2382 [3:45:51<5:08:35, 13.43s/it] 42%|████▏     | 1004/2382 [3:46:06<5:19:58, 13.93s/it]                                                       {'loss': 1.8995, 'learning_rate': 0.000649325719116814, 'epoch': 0.42}
 42%|████▏     | 1004/2382 [3:46:06<5:19:58, 13.93s/it] 42%|████▏     | 1005/2382 [3:46:19<5:13:47, 13.67s/it]                                                       {'loss': 1.8424, 'learning_rate': 0.0006486766164036069, 'epoch': 0.42}
 42%|████▏     | 1005/2382 [3:46:19<5:13:47, 13.67s/it] 42%|████▏     | 1006/2382 [3:46:32<5:07:51, 13.42s/it]                                                       {'loss': 1.7913, 'learning_rate': 0.0006480272386994585, 'epoch': 0.42}
 42%|████▏     | 1006/2382 [3:46:32<5:07:51, 13.42s/it] 42%|████▏     | 1007/2382 [3:46:43<4:55:23, 12.89s/it]                                                       {'loss': 1.9012, 'learning_rate': 0.0006473775872054521, 'epoch': 0.42}
 42%|████▏     | 1007/2382 [3:46:43<4:55:23, 12.89s/it] 42%|████▏     | 1008/2382 [3:46:54<4:39:17, 12.20s/it]                                                       {'loss': 1.9128, 'learning_rate': 0.0006467276631231773, 'epoch': 0.42}
 42%|████▏     | 1008/2382 [3:46:54<4:39:17, 12.20s/it] 42%|████▏     | 1009/2382 [3:47:08<4:50:57, 12.71s/it]                                                       {'loss': 1.9192, 'learning_rate': 0.000646077467654728, 'epoch': 0.42}
 42%|████▏     | 1009/2382 [3:47:08<4:50:57, 12.71s/it] 42%|████▏     | 1010/2382 [3:47:21<4:55:14, 12.91s/it]                                                       {'loss': 1.912, 'learning_rate': 0.0006454270020026995, 'epoch': 0.42}
 42%|████▏     | 1010/2382 [3:47:21<4:55:14, 12.91s/it] 42%|████▏     | 1011/2382 [3:47:37<5:18:58, 13.96s/it]                                                       {'loss': 1.8406, 'learning_rate': 0.0006447762673701878, 'epoch': 0.42}
 42%|████▏     | 1011/2382 [3:47:37<5:18:58, 13.96s/it] 42%|████▏     | 1012/2382 [3:47:49<5:03:44, 13.30s/it]                                                       {'loss': 1.9104, 'learning_rate': 0.0006441252649607855, 'epoch': 0.42}
 42%|████▏     | 1012/2382 [3:47:49<5:03:44, 13.30s/it] 43%|████▎     | 1013/2382 [3:48:02<5:01:41, 13.22s/it]                                                       {'loss': 1.8984, 'learning_rate': 0.000643473995978581, 'epoch': 0.43}
 43%|████▎     | 1013/2382 [3:48:02<5:01:41, 13.22s/it] 43%|████▎     | 1014/2382 [3:48:16<5:07:42, 13.50s/it]                                                       {'loss': 1.913, 'learning_rate': 0.0006428224616281554, 'epoch': 0.43}
 43%|████▎     | 1014/2382 [3:48:16<5:07:42, 13.50s/it] 43%|████▎     | 1015/2382 [3:48:30<5:10:41, 13.64s/it]                                                       {'loss': 1.9304, 'learning_rate': 0.0006421706631145811, 'epoch': 0.43}
 43%|████▎     | 1015/2382 [3:48:30<5:10:41, 13.64s/it] 43%|████▎     | 1016/2382 [3:48:43<5:04:46, 13.39s/it]                                                       {'loss': 1.8751, 'learning_rate': 0.0006415186016434185, 'epoch': 0.43}
 43%|████▎     | 1016/2382 [3:48:43<5:04:46, 13.39s/it] 43%|████▎     | 1017/2382 [3:48:55<4:52:58, 12.88s/it]                                                       {'loss': 2.0343, 'learning_rate': 0.0006408662784207149, 'epoch': 0.43}
 43%|████▎     | 1017/2382 [3:48:55<4:52:58, 12.88s/it] 43%|████▎     | 1018/2382 [3:49:10<5:08:58, 13.59s/it]                                                       {'loss': 1.8942, 'learning_rate': 0.0006402136946530014, 'epoch': 0.43}
 43%|████▎     | 1018/2382 [3:49:10<5:08:58, 13.59s/it] 43%|████▎     | 1019/2382 [3:49:24<5:07:15, 13.53s/it]                                                       {'loss': 1.9397, 'learning_rate': 0.0006395608515472912, 'epoch': 0.43}
 43%|████▎     | 1019/2382 [3:49:24<5:07:15, 13.53s/it] 43%|████▎     | 1020/2382 [3:49:38<5:12:49, 13.78s/it]                                                       {'loss': 1.87, 'learning_rate': 0.0006389077503110769, 'epoch': 0.43}
 43%|████▎     | 1020/2382 [3:49:38<5:12:49, 13.78s/it] 43%|████▎     | 1021/2382 [3:49:50<5:01:33, 13.29s/it]                                                       {'loss': 1.9629, 'learning_rate': 0.0006382543921523289, 'epoch': 0.43}
 43%|████▎     | 1021/2382 [3:49:50<5:01:33, 13.29s/it] 43%|████▎     | 1022/2382 [3:50:04<5:02:44, 13.36s/it]                                                       {'loss': 1.7955, 'learning_rate': 0.0006376007782794926, 'epoch': 0.43}
 43%|████▎     | 1022/2382 [3:50:04<5:02:44, 13.36s/it] 43%|████▎     | 1023/2382 [3:50:17<4:59:59, 13.24s/it]                                                       {'loss': 1.8917, 'learning_rate': 0.0006369469099014862, 'epoch': 0.43}
 43%|████▎     | 1023/2382 [3:50:17<4:59:59, 13.24s/it] 43%|████▎     | 1024/2382 [3:50:29<4:55:11, 13.04s/it]                                                       {'loss': 1.9143, 'learning_rate': 0.0006362927882276989, 'epoch': 0.43}
 43%|████▎     | 1024/2382 [3:50:29<4:55:11, 13.04s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1051 > 1024). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (1359 > 1024). Running this sequence through the model will result in indexing errors
 43%|████▎     | 1025/2382 [3:50:40<4:41:30, 12.45s/it]                                                       {'loss': 1.7996, 'learning_rate': 0.0006356384144679884, 'epoch': 0.43}
 43%|████▎     | 1025/2382 [3:50:40<4:41:30, 12.45s/it] 43%|████▎     | 1026/2382 [3:50:55<4:54:40, 13.04s/it]                                                       {'loss': 1.8784, 'learning_rate': 0.0006349837898326784, 'epoch': 0.43}
 43%|████▎     | 1026/2382 [3:50:55<4:54:40, 13.04s/it] 43%|████▎     | 1027/2382 [3:51:09<5:03:38, 13.45s/it]                                                       {'loss': 1.9051, 'learning_rate': 0.000634328915532557, 'epoch': 0.43}
 43%|████▎     | 1027/2382 [3:51:09<5:03:38, 13.45s/it] 43%|████▎     | 1028/2382 [3:51:21<4:56:08, 13.12s/it]                                                       {'loss': 1.8879, 'learning_rate': 0.0006336737927788737, 'epoch': 0.43}
 43%|████▎     | 1028/2382 [3:51:21<4:56:08, 13.12s/it] 43%|████▎     | 1029/2382 [3:51:34<4:51:42, 12.94s/it]                                                       {'loss': 1.9368, 'learning_rate': 0.0006330184227833376, 'epoch': 0.43}
 43%|████▎     | 1029/2382 [3:51:34<4:51:42, 12.94s/it] 43%|████▎     | 1030/2382 [3:51:48<5:03:03, 13.45s/it]                                                       {'loss': 1.8447, 'learning_rate': 0.0006323628067581153, 'epoch': 0.43}
 43%|████▎     | 1030/2382 [3:51:48<5:03:03, 13.45s/it] 43%|████▎     | 1031/2382 [3:52:03<5:09:57, 13.77s/it]                                                       {'loss': 1.8786, 'learning_rate': 0.0006317069459158283, 'epoch': 0.43}
 43%|████▎     | 1031/2382 [3:52:03<5:09:57, 13.77s/it] 43%|████▎     | 1032/2382 [3:52:15<5:00:57, 13.38s/it]                                                       {'loss': 1.9481, 'learning_rate': 0.000631050841469551, 'epoch': 0.43}
 43%|████▎     | 1032/2382 [3:52:15<5:00:57, 13.38s/it] 43%|████▎     | 1033/2382 [3:52:30<5:10:00, 13.79s/it]                                                       {'loss': 1.8083, 'learning_rate': 0.0006303944946328085, 'epoch': 0.43}
 43%|████▎     | 1033/2382 [3:52:30<5:10:00, 13.79s/it] 43%|████▎     | 1034/2382 [3:52:44<5:11:01, 13.84s/it]                                                       {'loss': 1.9984, 'learning_rate': 0.0006297379066195737, 'epoch': 0.43}
 43%|████▎     | 1034/2382 [3:52:44<5:11:01, 13.84s/it] 43%|████▎     | 1035/2382 [3:52:58<5:10:18, 13.82s/it]                                                       {'loss': 1.7816, 'learning_rate': 0.0006290810786442661, 'epoch': 0.43}
 43%|████▎     | 1035/2382 [3:52:58<5:10:18, 13.82s/it] 43%|████▎     | 1036/2382 [3:53:12<5:10:34, 13.84s/it]                                                       {'loss': 1.8913, 'learning_rate': 0.0006284240119217488, 'epoch': 0.43}
 43%|████▎     | 1036/2382 [3:53:12<5:10:34, 13.84s/it] 44%|████▎     | 1037/2382 [3:53:26<5:11:18, 13.89s/it]                                                       {'loss': 1.8566, 'learning_rate': 0.0006277667076673266, 'epoch': 0.44}
 44%|████▎     | 1037/2382 [3:53:26<5:11:18, 13.89s/it] 44%|████▎     | 1038/2382 [3:53:40<5:10:29, 13.86s/it]                                                       {'loss': 1.7204, 'learning_rate': 0.0006271091670967436, 'epoch': 0.44}
 44%|████▎     | 1038/2382 [3:53:40<5:10:29, 13.86s/it] 44%|████▎     | 1039/2382 [3:53:53<5:08:42, 13.79s/it]                                                       {'loss': 1.7762, 'learning_rate': 0.0006264513914261807, 'epoch': 0.44}
 44%|████▎     | 1039/2382 [3:53:53<5:08:42, 13.79s/it] 44%|████▎     | 1040/2382 [3:54:05<4:56:18, 13.25s/it]                                                       {'loss': 1.8586, 'learning_rate': 0.0006257933818722543, 'epoch': 0.44}
 44%|████▎     | 1040/2382 [3:54:05<4:56:18, 13.25s/it] 44%|████▎     | 1041/2382 [3:54:20<5:03:55, 13.60s/it]                                                       {'loss': 1.8595, 'learning_rate': 0.0006251351396520129, 'epoch': 0.44}
 44%|████▎     | 1041/2382 [3:54:20<5:03:55, 13.60s/it] 44%|████▎     | 1042/2382 [3:54:37<5:28:26, 14.71s/it]                                                       {'loss': 1.8923, 'learning_rate': 0.000624476665982935, 'epoch': 0.44}
 44%|████▎     | 1042/2382 [3:54:37<5:28:26, 14.71s/it] 44%|████▍     | 1043/2382 [3:54:49<5:08:01, 13.80s/it]                                                       {'loss': 1.8714, 'learning_rate': 0.0006238179620829281, 'epoch': 0.44}
 44%|████▍     | 1043/2382 [3:54:49<5:08:01, 13.80s/it] 44%|████▍     | 1044/2382 [3:55:02<5:04:05, 13.64s/it]                                                       {'loss': 1.7706, 'learning_rate': 0.000623159029170325, 'epoch': 0.44}
 44%|████▍     | 1044/2382 [3:55:02<5:04:05, 13.64s/it] 44%|████▍     | 1045/2382 [3:55:16<5:08:54, 13.86s/it]                                                       {'loss': 1.917, 'learning_rate': 0.000622499868463882, 'epoch': 0.44}
 44%|████▍     | 1045/2382 [3:55:16<5:08:54, 13.86s/it] 44%|████▍     | 1046/2382 [3:55:29<5:03:16, 13.62s/it]                                                       {'loss': 1.9596, 'learning_rate': 0.0006218404811827767, 'epoch': 0.44}
 44%|████▍     | 1046/2382 [3:55:29<5:03:16, 13.62s/it] 44%|████▍     | 1047/2382 [3:55:43<5:01:27, 13.55s/it]                                                       {'loss': 1.9451, 'learning_rate': 0.0006211808685466063, 'epoch': 0.44}
 44%|████▍     | 1047/2382 [3:55:43<5:01:27, 13.55s/it] 44%|████▍     | 1048/2382 [3:55:56<4:59:32, 13.47s/it]                                                       {'loss': 1.8228, 'learning_rate': 0.0006205210317753842, 'epoch': 0.44}
 44%|████▍     | 1048/2382 [3:55:56<4:59:32, 13.47s/it] 44%|████▍     | 1049/2382 [3:56:08<4:49:57, 13.05s/it]                                                       {'loss': 1.7908, 'learning_rate': 0.0006198609720895384, 'epoch': 0.44}
 44%|████▍     | 1049/2382 [3:56:08<4:49:57, 13.05s/it] 44%|████▍     | 1050/2382 [3:56:22<4:58:21, 13.44s/it]                                                       {'loss': 1.8838, 'learning_rate': 0.0006192006907099098, 'epoch': 0.44}
 44%|████▍     | 1050/2382 [3:56:22<4:58:21, 13.44s/it] 44%|████▍     | 1051/2382 [3:56:34<4:48:28, 13.00s/it]                                                       {'loss': 1.9731, 'learning_rate': 0.0006185401888577488, 'epoch': 0.44}
 44%|████▍     | 1051/2382 [3:56:34<4:48:28, 13.00s/it] 44%|████▍     | 1052/2382 [3:56:48<4:50:41, 13.11s/it]                                                       {'loss': 1.8524, 'learning_rate': 0.0006178794677547138, 'epoch': 0.44}
 44%|████▍     | 1052/2382 [3:56:48<4:50:41, 13.11s/it] 44%|████▍     | 1053/2382 [3:57:02<5:00:21, 13.56s/it]                                                       {'loss': 1.7845, 'learning_rate': 0.0006172185286228684, 'epoch': 0.44}
 44%|████▍     | 1053/2382 [3:57:02<5:00:21, 13.56s/it] 44%|████▍     | 1054/2382 [3:57:17<5:08:28, 13.94s/it]                                                       {'loss': 1.8093, 'learning_rate': 0.0006165573726846797, 'epoch': 0.44}
 44%|████▍     | 1054/2382 [3:57:17<5:08:28, 13.94s/it] 44%|████▍     | 1055/2382 [3:57:30<4:59:52, 13.56s/it]                                                       {'loss': 1.8898, 'learning_rate': 0.0006158960011630162, 'epoch': 0.44}
 44%|████▍     | 1055/2382 [3:57:30<4:59:52, 13.56s/it] 44%|████▍     | 1056/2382 [3:57:45<5:06:52, 13.89s/it]                                                       {'loss': 1.8296, 'learning_rate': 0.0006152344152811444, 'epoch': 0.44}
 44%|████▍     | 1056/2382 [3:57:45<5:06:52, 13.89s/it] 44%|████▍     | 1057/2382 [3:57:59<5:12:09, 14.14s/it]                                                       {'loss': 1.9306, 'learning_rate': 0.0006145726162627278, 'epoch': 0.44}
 44%|████▍     | 1057/2382 [3:57:59<5:12:09, 14.14s/it] 44%|████▍     | 1058/2382 [3:58:13<5:10:31, 14.07s/it]                                                       {'loss': 1.8762, 'learning_rate': 0.0006139106053318239, 'epoch': 0.44}
 44%|████▍     | 1058/2382 [3:58:13<5:10:31, 14.07s/it] 44%|████▍     | 1059/2382 [3:58:26<4:58:48, 13.55s/it]                                                       {'loss': 1.86, 'learning_rate': 0.0006132483837128823, 'epoch': 0.44}
 44%|████▍     | 1059/2382 [3:58:26<4:58:48, 13.55s/it] 45%|████▍     | 1060/2382 [3:58:39<4:58:16, 13.54s/it]                                                       {'loss': 1.9166, 'learning_rate': 0.000612585952630742, 'epoch': 0.44}
 45%|████▍     | 1060/2382 [3:58:39<4:58:16, 13.54s/it] 45%|████▍     | 1061/2382 [3:58:52<4:52:31, 13.29s/it]                                                       {'loss': 1.9901, 'learning_rate': 0.0006119233133106297, 'epoch': 0.45}
 45%|████▍     | 1061/2382 [3:58:52<4:52:31, 13.29s/it] 45%|████▍     | 1062/2382 [3:59:04<4:47:46, 13.08s/it]                                                       {'loss': 1.791, 'learning_rate': 0.0006112604669781572, 'epoch': 0.45}
 45%|████▍     | 1062/2382 [3:59:04<4:47:46, 13.08s/it] 45%|████▍     | 1063/2382 [3:59:15<4:33:11, 12.43s/it]                                                       {'loss': 1.9702, 'learning_rate': 0.0006105974148593191, 'epoch': 0.45}
 45%|████▍     | 1063/2382 [3:59:15<4:33:11, 12.43s/it] 45%|████▍     | 1064/2382 [3:59:27<4:30:04, 12.29s/it]                                                       {'loss': 1.9225, 'learning_rate': 0.0006099341581804909, 'epoch': 0.45}
 45%|████▍     | 1064/2382 [3:59:27<4:30:04, 12.29s/it] 45%|████▍     | 1065/2382 [3:59:40<4:33:59, 12.48s/it]                                                       {'loss': 1.8548, 'learning_rate': 0.0006092706981684259, 'epoch': 0.45}
 45%|████▍     | 1065/2382 [3:59:40<4:33:59, 12.48s/it] 45%|████▍     | 1066/2382 [3:59:55<4:48:14, 13.14s/it]                                                       {'loss': 1.8334, 'learning_rate': 0.0006086070360502539, 'epoch': 0.45}
 45%|████▍     | 1066/2382 [3:59:55<4:48:14, 13.14s/it] 45%|████▍     | 1067/2382 [4:00:07<4:40:09, 12.78s/it]                                                       {'loss': 1.8906, 'learning_rate': 0.0006079431730534786, 'epoch': 0.45}
 45%|████▍     | 1067/2382 [4:00:07<4:40:09, 12.78s/it] 45%|████▍     | 1068/2382 [4:00:21<4:48:08, 13.16s/it]                                                       {'loss': 1.906, 'learning_rate': 0.0006072791104059748, 'epoch': 0.45}
 45%|████▍     | 1068/2382 [4:00:21<4:48:08, 13.16s/it] 45%|████▍     | 1069/2382 [4:00:34<4:50:01, 13.25s/it]                                                       {'loss': 1.8009, 'learning_rate': 0.000606614849335987, 'epoch': 0.45}
 45%|████▍     | 1069/2382 [4:00:34<4:50:01, 13.25s/it] 45%|████▍     | 1070/2382 [4:00:47<4:47:23, 13.14s/it]                                                       {'loss': 1.797, 'learning_rate': 0.0006059503910721266, 'epoch': 0.45}
 45%|████▍     | 1070/2382 [4:00:47<4:47:23, 13.14s/it] 45%|████▍     | 1071/2382 [4:01:02<4:58:23, 13.66s/it]                                                       {'loss': 1.8435, 'learning_rate': 0.0006052857368433695, 'epoch': 0.45}
 45%|████▍     | 1071/2382 [4:01:02<4:58:23, 13.66s/it] 45%|████▌     | 1072/2382 [4:01:14<4:46:19, 13.11s/it]                                                       {'loss': 1.9189, 'learning_rate': 0.0006046208878790542, 'epoch': 0.45}
 45%|████▌     | 1072/2382 [4:01:14<4:46:19, 13.11s/it] 45%|████▌     | 1073/2382 [4:01:29<5:01:04, 13.80s/it]                                                       {'loss': 1.9028, 'learning_rate': 0.0006039558454088796, 'epoch': 0.45}
 45%|████▌     | 1073/2382 [4:01:29<5:01:04, 13.80s/it] 45%|████▌     | 1074/2382 [4:01:43<4:59:44, 13.75s/it]                                                       {'loss': 1.8278, 'learning_rate': 0.0006032906106629024, 'epoch': 0.45}
 45%|████▌     | 1074/2382 [4:01:43<4:59:44, 13.75s/it] 45%|████▌     | 1075/2382 [4:01:55<4:49:19, 13.28s/it]                                                       {'loss': 1.875, 'learning_rate': 0.0006026251848715345, 'epoch': 0.45}
 45%|████▌     | 1075/2382 [4:01:55<4:49:19, 13.28s/it] 45%|████▌     | 1076/2382 [4:02:10<4:57:16, 13.66s/it]                                                       {'loss': 1.81, 'learning_rate': 0.0006019595692655415, 'epoch': 0.45}
 45%|████▌     | 1076/2382 [4:02:10<4:57:16, 13.66s/it] 45%|████▌     | 1077/2382 [4:02:23<4:53:13, 13.48s/it]                                                       {'loss': 1.7968, 'learning_rate': 0.0006012937650760405, 'epoch': 0.45}
 45%|████▌     | 1077/2382 [4:02:23<4:53:13, 13.48s/it] 45%|████▌     | 1078/2382 [4:02:35<4:45:50, 13.15s/it]                                                       {'loss': 1.8212, 'learning_rate': 0.0006006277735344967, 'epoch': 0.45}
 45%|████▌     | 1078/2382 [4:02:35<4:45:50, 13.15s/it] 45%|████▌     | 1079/2382 [4:02:50<4:58:29, 13.74s/it]                                                       {'loss': 1.8562, 'learning_rate': 0.0005999615958727219, 'epoch': 0.45}
 45%|████▌     | 1079/2382 [4:02:50<4:58:29, 13.74s/it] 45%|████▌     | 1080/2382 [4:03:04<4:59:35, 13.81s/it]                                                       {'loss': 1.8223, 'learning_rate': 0.0005992952333228728, 'epoch': 0.45}
 45%|████▌     | 1080/2382 [4:03:04<4:59:35, 13.81s/it] 45%|████▌     | 1081/2382 [4:03:18<5:01:43, 13.91s/it]                                                       {'loss': 1.8679, 'learning_rate': 0.0005986286871174474, 'epoch': 0.45}
 45%|████▌     | 1081/2382 [4:03:18<5:01:43, 13.91s/it] 45%|████▌     | 1082/2382 [4:03:31<4:52:12, 13.49s/it]                                                       {'loss': 1.8737, 'learning_rate': 0.0005979619584892833, 'epoch': 0.45}
 45%|████▌     | 1082/2382 [4:03:31<4:52:12, 13.49s/it] 45%|████▌     | 1083/2382 [4:03:42<4:35:29, 12.72s/it]                                                       {'loss': 1.8781, 'learning_rate': 0.0005972950486715563, 'epoch': 0.45}
 45%|████▌     | 1083/2382 [4:03:42<4:35:29, 12.72s/it] 46%|████▌     | 1084/2382 [4:03:54<4:34:00, 12.67s/it]                                                       {'loss': 1.8221, 'learning_rate': 0.0005966279588977767, 'epoch': 0.45}
 46%|████▌     | 1084/2382 [4:03:54<4:34:00, 12.67s/it] 46%|████▌     | 1085/2382 [4:04:08<4:41:36, 13.03s/it]                                                       {'loss': 1.8619, 'learning_rate': 0.0005959606904017877, 'epoch': 0.46}
 46%|████▌     | 1085/2382 [4:04:08<4:41:36, 13.03s/it] 46%|████▌     | 1086/2382 [4:04:22<4:49:04, 13.38s/it]                                                       {'loss': 1.9824, 'learning_rate': 0.0005952932444177631, 'epoch': 0.46}
 46%|████▌     | 1086/2382 [4:04:22<4:49:04, 13.38s/it] 46%|████▌     | 1087/2382 [4:04:37<4:55:02, 13.67s/it]                                                       {'loss': 1.8363, 'learning_rate': 0.0005946256221802051, 'epoch': 0.46}
 46%|████▌     | 1087/2382 [4:04:37<4:55:02, 13.67s/it] 46%|████▌     | 1088/2382 [4:04:51<4:56:23, 13.74s/it]                                                       {'loss': 1.9058, 'learning_rate': 0.0005939578249239419, 'epoch': 0.46}
 46%|████▌     | 1088/2382 [4:04:51<4:56:23, 13.74s/it] 46%|████▌     | 1089/2382 [4:05:05<5:00:59, 13.97s/it]                                                       {'loss': 1.8376, 'learning_rate': 0.0005932898538841254, 'epoch': 0.46}
 46%|████▌     | 1089/2382 [4:05:05<5:00:59, 13.97s/it] 46%|████▌     | 1090/2382 [4:05:20<5:08:20, 14.32s/it]                                                       {'loss': 1.8934, 'learning_rate': 0.0005926217102962285, 'epoch': 0.46}
 46%|████▌     | 1090/2382 [4:05:20<5:08:20, 14.32s/it] 46%|████▌     | 1091/2382 [4:05:32<4:50:06, 13.48s/it]                                                       {'loss': 1.8918, 'learning_rate': 0.0005919533953960439, 'epoch': 0.46}
 46%|████▌     | 1091/2382 [4:05:32<4:50:06, 13.48s/it] 46%|████▌     | 1092/2382 [4:05:45<4:49:13, 13.45s/it]                                                       {'loss': 1.8384, 'learning_rate': 0.0005912849104196809, 'epoch': 0.46}
 46%|████▌     | 1092/2382 [4:05:45<4:49:13, 13.45s/it] 46%|████▌     | 1093/2382 [4:05:56<4:32:26, 12.68s/it]                                                       {'loss': 1.8718, 'learning_rate': 0.0005906162566035632, 'epoch': 0.46}
 46%|████▌     | 1093/2382 [4:05:56<4:32:26, 12.68s/it] 46%|████▌     | 1094/2382 [4:06:11<4:46:17, 13.34s/it]                                                       {'loss': 1.8386, 'learning_rate': 0.000589947435184427, 'epoch': 0.46}
 46%|████▌     | 1094/2382 [4:06:11<4:46:17, 13.34s/it] 46%|████▌     | 1095/2382 [4:06:25<4:49:38, 13.50s/it]                                                       {'loss': 1.7939, 'learning_rate': 0.0005892784473993184, 'epoch': 0.46}
 46%|████▌     | 1095/2382 [4:06:25<4:49:38, 13.50s/it] 46%|████▌     | 1096/2382 [4:06:39<4:53:40, 13.70s/it]                                                       {'loss': 1.8784, 'learning_rate': 0.0005886092944855912, 'epoch': 0.46}
 46%|████▌     | 1096/2382 [4:06:39<4:53:40, 13.70s/it] 46%|████▌     | 1097/2382 [4:06:53<4:52:44, 13.67s/it]                                                       {'loss': 1.837, 'learning_rate': 0.0005879399776809047, 'epoch': 0.46}
 46%|████▌     | 1097/2382 [4:06:53<4:52:44, 13.67s/it] 46%|████▌     | 1098/2382 [4:07:06<4:51:35, 13.63s/it]                                                       {'loss': 1.8782, 'learning_rate': 0.0005872704982232212, 'epoch': 0.46}
 46%|████▌     | 1098/2382 [4:07:06<4:51:35, 13.63s/it] 46%|████▌     | 1099/2382 [4:07:19<4:45:34, 13.36s/it]                                                       {'loss': 1.811, 'learning_rate': 0.000586600857350804, 'epoch': 0.46}
 46%|████▌     | 1099/2382 [4:07:19<4:45:34, 13.36s/it] 46%|████▌     | 1100/2382 [4:07:32<4:45:18, 13.35s/it]                                                       {'loss': 1.833, 'learning_rate': 0.000585931056302215, 'epoch': 0.46}
 46%|████▌     | 1100/2382 [4:07:32<4:45:18, 13.35s/it] 46%|████▌     | 1101/2382 [4:07:45<4:44:34, 13.33s/it]                                                       {'loss': 1.8339, 'learning_rate': 0.0005852610963163119, 'epoch': 0.46}
 46%|████▌     | 1101/2382 [4:07:45<4:44:34, 13.33s/it] 46%|████▋     | 1102/2382 [4:07:58<4:38:18, 13.05s/it]                                                       {'loss': 1.8682, 'learning_rate': 0.0005845909786322469, 'epoch': 0.46}
 46%|████▋     | 1102/2382 [4:07:58<4:38:18, 13.05s/it] 46%|████▋     | 1103/2382 [4:08:13<4:52:34, 13.73s/it]                                                       {'loss': 1.8603, 'learning_rate': 0.0005839207044894639, 'epoch': 0.46}
 46%|████▋     | 1103/2382 [4:08:13<4:52:34, 13.73s/it] 46%|████▋     | 1104/2382 [4:08:26<4:45:37, 13.41s/it]                                                       {'loss': 1.8347, 'learning_rate': 0.0005832502751276956, 'epoch': 0.46}
 46%|████▋     | 1104/2382 [4:08:26<4:45:37, 13.41s/it] 46%|████▋     | 1105/2382 [4:08:39<4:46:44, 13.47s/it]                                                       {'loss': 1.8229, 'learning_rate': 0.0005825796917869622, 'epoch': 0.46}
 46%|████▋     | 1105/2382 [4:08:39<4:46:44, 13.47s/it] 46%|████▋     | 1106/2382 [4:08:52<4:39:05, 13.12s/it]                                                       {'loss': 1.8395, 'learning_rate': 0.0005819089557075689, 'epoch': 0.46}
 46%|████▋     | 1106/2382 [4:08:52<4:39:05, 13.12s/it] 46%|████▋     | 1107/2382 [4:09:04<4:34:31, 12.92s/it]                                                       {'loss': 1.9602, 'learning_rate': 0.0005812380681301031, 'epoch': 0.46}
 46%|████▋     | 1107/2382 [4:09:04<4:34:31, 12.92s/it] 47%|████▋     | 1108/2382 [4:09:19<4:43:27, 13.35s/it]                                                       {'loss': 1.883, 'learning_rate': 0.0005805670302954321, 'epoch': 0.46}
 47%|████▋     | 1108/2382 [4:09:19<4:43:27, 13.35s/it] 47%|████▋     | 1109/2382 [4:09:31<4:35:48, 13.00s/it]                                                       {'loss': 1.8354, 'learning_rate': 0.0005798958434447019, 'epoch': 0.47}
 47%|████▋     | 1109/2382 [4:09:31<4:35:48, 13.00s/it] 47%|████▋     | 1110/2382 [4:09:45<4:43:27, 13.37s/it]                                                       {'loss': 1.8388, 'learning_rate': 0.0005792245088193335, 'epoch': 0.47}
 47%|████▋     | 1110/2382 [4:09:45<4:43:27, 13.37s/it] 47%|████▋     | 1111/2382 [4:09:58<4:39:33, 13.20s/it]                                                       {'loss': 1.876, 'learning_rate': 0.0005785530276610216, 'epoch': 0.47}
 47%|████▋     | 1111/2382 [4:09:58<4:39:33, 13.20s/it] 47%|████▋     | 1112/2382 [4:10:09<4:30:04, 12.76s/it]                                                       {'loss': 1.9334, 'learning_rate': 0.0005778814012117315, 'epoch': 0.47}
 47%|████▋     | 1112/2382 [4:10:09<4:30:04, 12.76s/it] 47%|████▋     | 1113/2382 [4:10:21<4:23:31, 12.46s/it]                                                       {'loss': 1.9223, 'learning_rate': 0.0005772096307136978, 'epoch': 0.47}
 47%|████▋     | 1113/2382 [4:10:21<4:23:31, 12.46s/it] 47%|████▋     | 1114/2382 [4:10:35<4:30:19, 12.79s/it]                                                       {'loss': 1.8363, 'learning_rate': 0.0005765377174094208, 'epoch': 0.47}
 47%|████▋     | 1114/2382 [4:10:35<4:30:19, 12.79s/it] 47%|████▋     | 1115/2382 [4:10:46<4:19:57, 12.31s/it]                                                       {'loss': 1.8272, 'learning_rate': 0.0005758656625416658, 'epoch': 0.47}
 47%|████▋     | 1115/2382 [4:10:46<4:19:57, 12.31s/it] 47%|████▋     | 1116/2382 [4:10:59<4:21:40, 12.40s/it]                                                       {'loss': 1.9089, 'learning_rate': 0.0005751934673534592, 'epoch': 0.47}
 47%|████▋     | 1116/2382 [4:10:59<4:21:40, 12.40s/it] 47%|████▋     | 1117/2382 [4:11:12<4:27:06, 12.67s/it]                                                       {'loss': 1.9294, 'learning_rate': 0.0005745211330880871, 'epoch': 0.47}
 47%|████▋     | 1117/2382 [4:11:12<4:27:06, 12.67s/it] 47%|████▋     | 1118/2382 [4:11:28<4:46:10, 13.58s/it]                                                       {'loss': 1.9132, 'learning_rate': 0.0005738486609890934, 'epoch': 0.47}
 47%|████▋     | 1118/2382 [4:11:28<4:46:10, 13.58s/it] 47%|████▋     | 1119/2382 [4:11:43<5:00:10, 14.26s/it]                                                       {'loss': 1.7927, 'learning_rate': 0.0005731760523002761, 'epoch': 0.47}
 47%|████▋     | 1119/2382 [4:11:43<5:00:10, 14.26s/it] 47%|████▋     | 1120/2382 [4:11:55<4:43:48, 13.49s/it]                                                       {'loss': 1.7771, 'learning_rate': 0.0005725033082656862, 'epoch': 0.47}
 47%|████▋     | 1120/2382 [4:11:55<4:43:48, 13.49s/it] 47%|████▋     | 1121/2382 [4:12:08<4:39:55, 13.32s/it]                                                       {'loss': 1.9229, 'learning_rate': 0.0005718304301296252, 'epoch': 0.47}
 47%|████▋     | 1121/2382 [4:12:08<4:39:55, 13.32s/it] 47%|████▋     | 1122/2382 [4:12:22<4:42:38, 13.46s/it]                                                       {'loss': 1.8427, 'learning_rate': 0.0005711574191366427, 'epoch': 0.47}
 47%|████▋     | 1122/2382 [4:12:22<4:42:38, 13.46s/it] 47%|████▋     | 1123/2382 [4:12:35<4:42:43, 13.47s/it]                                                       {'loss': 1.833, 'learning_rate': 0.0005704842765315334, 'epoch': 0.47}
 47%|████▋     | 1123/2382 [4:12:35<4:42:43, 13.47s/it] 47%|████▋     | 1124/2382 [4:12:49<4:44:08, 13.55s/it]                                                       {'loss': 1.8117, 'learning_rate': 0.0005698110035593359, 'epoch': 0.47}
 47%|████▋     | 1124/2382 [4:12:49<4:44:08, 13.55s/it] 47%|████▋     | 1125/2382 [4:13:02<4:39:07, 13.32s/it]                                                       {'loss': 1.7569, 'learning_rate': 0.0005691376014653302, 'epoch': 0.47}
 47%|████▋     | 1125/2382 [4:13:02<4:39:07, 13.32s/it] 47%|████▋     | 1126/2382 [4:13:16<4:42:56, 13.52s/it]                                                       {'loss': 1.8876, 'learning_rate': 0.0005684640714950346, 'epoch': 0.47}
 47%|████▋     | 1126/2382 [4:13:16<4:42:56, 13.52s/it] 47%|████▋     | 1127/2382 [4:13:28<4:36:18, 13.21s/it]                                                       {'loss': 1.9053, 'learning_rate': 0.0005677904148942039, 'epoch': 0.47}
 47%|████▋     | 1127/2382 [4:13:28<4:36:18, 13.21s/it] 47%|████▋     | 1128/2382 [4:13:41<4:29:33, 12.90s/it]                                                       {'loss': 1.922, 'learning_rate': 0.0005671166329088278, 'epoch': 0.47}
 47%|████▋     | 1128/2382 [4:13:41<4:29:33, 12.90s/it] 47%|████▋     | 1129/2382 [4:13:53<4:24:41, 12.67s/it]                                                       {'loss': 1.819, 'learning_rate': 0.0005664427267851271, 'epoch': 0.47}
 47%|████▋     | 1129/2382 [4:13:53<4:24:41, 12.67s/it] 47%|████▋     | 1130/2382 [4:14:04<4:16:23, 12.29s/it]                                                       {'loss': 1.8709, 'learning_rate': 0.0005657686977695526, 'epoch': 0.47}
 47%|████▋     | 1130/2382 [4:14:04<4:16:23, 12.29s/it] 47%|████▋     | 1131/2382 [4:14:15<4:06:35, 11.83s/it]                                                       {'loss': 1.8954, 'learning_rate': 0.0005650945471087824, 'epoch': 0.47}
 47%|████▋     | 1131/2382 [4:14:15<4:06:35, 11.83s/it] 48%|████▊     | 1132/2382 [4:14:31<4:34:17, 13.17s/it]                                                       {'loss': 1.852, 'learning_rate': 0.0005644202760497195, 'epoch': 0.48}
 48%|████▊     | 1132/2382 [4:14:31<4:34:17, 13.17s/it] 48%|████▊     | 1133/2382 [4:14:45<4:38:57, 13.40s/it]                                                       {'loss': 1.8621, 'learning_rate': 0.0005637458858394896, 'epoch': 0.48}
 48%|████▊     | 1133/2382 [4:14:45<4:38:57, 13.40s/it] 48%|████▊     | 1134/2382 [4:14:59<4:41:00, 13.51s/it]                                                       {'loss': 1.8761, 'learning_rate': 0.0005630713777254389, 'epoch': 0.48}
 48%|████▊     | 1134/2382 [4:14:59<4:41:00, 13.51s/it] 48%|████▊     | 1135/2382 [4:15:11<4:34:45, 13.22s/it]                                                       {'loss': 1.794, 'learning_rate': 0.0005623967529551315, 'epoch': 0.48}
 48%|████▊     | 1135/2382 [4:15:11<4:34:45, 13.22s/it] 48%|████▊     | 1136/2382 [4:15:25<4:35:04, 13.25s/it]                                                       {'loss': 1.8836, 'learning_rate': 0.0005617220127763474, 'epoch': 0.48}
 48%|████▊     | 1136/2382 [4:15:25<4:35:04, 13.25s/it] 48%|████▊     | 1137/2382 [4:15:37<4:29:20, 12.98s/it]                                                       {'loss': 1.8416, 'learning_rate': 0.00056104715843708, 'epoch': 0.48}
 48%|████▊     | 1137/2382 [4:15:37<4:29:20, 12.98s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1149 > 1024). Running this sequence through the model will result in indexing errors
 48%|████▊     | 1138/2382 [4:15:49<4:25:29, 12.81s/it]                                                       {'loss': 1.9831, 'learning_rate': 0.0005603721911855337, 'epoch': 0.48}
 48%|████▊     | 1138/2382 [4:15:49<4:25:29, 12.81s/it] 48%|████▊     | 1139/2382 [4:16:06<4:46:53, 13.85s/it]                                                       {'loss': 1.8402, 'learning_rate': 0.0005596971122701221, 'epoch': 0.48}
 48%|████▊     | 1139/2382 [4:16:06<4:46:53, 13.85s/it] 48%|████▊     | 1140/2382 [4:16:18<4:36:05, 13.34s/it]                                                       {'loss': 1.9288, 'learning_rate': 0.0005590219229394652, 'epoch': 0.48}
 48%|████▊     | 1140/2382 [4:16:18<4:36:05, 13.34s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 1024). Running this sequence through the model will result in indexing errors
 48%|████▊     | 1141/2382 [4:16:30<4:31:00, 13.10s/it]                                                       {'loss': 1.7773, 'learning_rate': 0.0005583466244423869, 'epoch': 0.48}
 48%|████▊     | 1141/2382 [4:16:30<4:31:00, 13.10s/it] 48%|████▊     | 1142/2382 [4:16:41<4:16:45, 12.42s/it]                                                       {'loss': 1.9905, 'learning_rate': 0.0005576712180279134, 'epoch': 0.48}
 48%|████▊     | 1142/2382 [4:16:41<4:16:45, 12.42s/it] 48%|████▊     | 1143/2382 [4:16:57<4:35:33, 13.34s/it]                                                       {'loss': 1.8475, 'learning_rate': 0.0005569957049452703, 'epoch': 0.48}
 48%|████▊     | 1143/2382 [4:16:57<4:35:33, 13.34s/it] 48%|████▊     | 1144/2382 [4:17:09<4:30:57, 13.13s/it]                                                       {'loss': 1.8819, 'learning_rate': 0.0005563200864438808, 'epoch': 0.48}
 48%|████▊     | 1144/2382 [4:17:09<4:30:57, 13.13s/it] 48%|████▊     | 1145/2382 [4:17:21<4:24:02, 12.81s/it]                                                       {'loss': 1.8657, 'learning_rate': 0.0005556443637733623, 'epoch': 0.48}
 48%|████▊     | 1145/2382 [4:17:21<4:24:02, 12.81s/it] 48%|████▊     | 1146/2382 [4:17:36<4:34:25, 13.32s/it]                                                       {'loss': 1.8548, 'learning_rate': 0.0005549685381835261, 'epoch': 0.48}
 48%|████▊     | 1146/2382 [4:17:36<4:34:25, 13.32s/it] 48%|████▊     | 1147/2382 [4:17:51<4:43:00, 13.75s/it]                                                       {'loss': 1.8337, 'learning_rate': 0.0005542926109243727, 'epoch': 0.48}
 48%|████▊     | 1147/2382 [4:17:51<4:43:00, 13.75s/it] 48%|████▊     | 1148/2382 [4:18:05<4:44:24, 13.83s/it]                                                       {'loss': 1.9699, 'learning_rate': 0.0005536165832460913, 'epoch': 0.48}
 48%|████▊     | 1148/2382 [4:18:05<4:44:24, 13.83s/it] 48%|████▊     | 1149/2382 [4:18:19<4:44:46, 13.86s/it]                                                       {'loss': 1.8379, 'learning_rate': 0.0005529404563990567, 'epoch': 0.48}
 48%|████▊     | 1149/2382 [4:18:19<4:44:46, 13.86s/it] 48%|████▊     | 1150/2382 [4:18:32<4:43:16, 13.80s/it]                                                       {'loss': 1.9394, 'learning_rate': 0.0005522642316338268, 'epoch': 0.48}
 48%|████▊     | 1150/2382 [4:18:32<4:43:16, 13.80s/it] 48%|████▊     | 1151/2382 [4:18:47<4:50:32, 14.16s/it]                                                       {'loss': 1.8523, 'learning_rate': 0.0005515879102011412, 'epoch': 0.48}
 48%|████▊     | 1151/2382 [4:18:47<4:50:32, 14.16s/it] 48%|████▊     | 1152/2382 [4:19:01<4:49:19, 14.11s/it]                                                       {'loss': 1.888, 'learning_rate': 0.0005509114933519178, 'epoch': 0.48}
 48%|████▊     | 1152/2382 [4:19:01<4:49:19, 14.11s/it] 48%|████▊     | 1153/2382 [4:19:12<4:25:44, 12.97s/it]                                                       {'loss': 1.8353, 'learning_rate': 0.0005502349823372511, 'epoch': 0.48}
 48%|████▊     | 1153/2382 [4:19:12<4:25:44, 12.97s/it] 48%|████▊     | 1154/2382 [4:19:27<4:43:19, 13.84s/it]                                                       {'loss': 1.8762, 'learning_rate': 0.0005495583784084101, 'epoch': 0.48}
 48%|████▊     | 1154/2382 [4:19:27<4:43:19, 13.84s/it] 48%|████▊     | 1155/2382 [4:19:38<4:25:21, 12.98s/it]                                                       {'loss': 1.9146, 'learning_rate': 0.0005488816828168353, 'epoch': 0.48}
 48%|████▊     | 1155/2382 [4:19:38<4:25:21, 12.98s/it] 49%|████▊     | 1156/2382 [4:19:53<4:34:16, 13.42s/it]                                                       {'loss': 1.8547, 'learning_rate': 0.0005482048968141365, 'epoch': 0.49}
 49%|████▊     | 1156/2382 [4:19:53<4:34:16, 13.42s/it] 49%|████▊     | 1157/2382 [4:20:07<4:41:00, 13.76s/it]                                                       {'loss': 1.8347, 'learning_rate': 0.0005475280216520913, 'epoch': 0.49}
 49%|████▊     | 1157/2382 [4:20:07<4:41:00, 13.76s/it] 49%|████▊     | 1158/2382 [4:20:20<4:34:04, 13.44s/it]                                                       {'loss': 1.8008, 'learning_rate': 0.0005468510585826421, 'epoch': 0.49}
 49%|████▊     | 1158/2382 [4:20:20<4:34:04, 13.44s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1976 > 1024). Running this sequence through the model will result in indexing errors
 49%|████▊     | 1159/2382 [4:20:32<4:24:52, 12.99s/it]                                                       {'loss': 1.864, 'learning_rate': 0.0005461740088578934, 'epoch': 0.49}
 49%|████▊     | 1159/2382 [4:20:32<4:24:52, 12.99s/it] 49%|████▊     | 1160/2382 [4:20:43<4:14:59, 12.52s/it]                                                       {'loss': 1.9166, 'learning_rate': 0.0005454968737301107, 'epoch': 0.49}
 49%|████▊     | 1160/2382 [4:20:43<4:14:59, 12.52s/it] 49%|████▊     | 1161/2382 [4:20:57<4:18:53, 12.72s/it]                                                       {'loss': 1.854, 'learning_rate': 0.0005448196544517168, 'epoch': 0.49}
 49%|████▊     | 1161/2382 [4:20:57<4:18:53, 12.72s/it] 49%|████▉     | 1162/2382 [4:21:11<4:27:50, 13.17s/it]                                                       {'loss': 1.825, 'learning_rate': 0.0005441423522752904, 'epoch': 0.49}
 49%|████▉     | 1162/2382 [4:21:11<4:27:50, 13.17s/it] 49%|████▉     | 1163/2382 [4:21:22<4:16:32, 12.63s/it]                                                       {'loss': 2.001, 'learning_rate': 0.000543464968453564, 'epoch': 0.49}
 49%|████▉     | 1163/2382 [4:21:22<4:16:32, 12.63s/it] 49%|████▉     | 1164/2382 [4:21:37<4:29:00, 13.25s/it]                                                       {'loss': 1.9107, 'learning_rate': 0.0005427875042394199, 'epoch': 0.49}
 49%|████▉     | 1164/2382 [4:21:37<4:29:00, 13.25s/it] 49%|████▉     | 1165/2382 [4:21:48<4:17:55, 12.72s/it]                                                       {'loss': 1.9155, 'learning_rate': 0.0005421099608858904, 'epoch': 0.49}
 49%|████▉     | 1165/2382 [4:21:48<4:17:55, 12.72s/it] 49%|████▉     | 1166/2382 [4:22:00<4:09:05, 12.29s/it]                                                       {'loss': 1.8347, 'learning_rate': 0.0005414323396461537, 'epoch': 0.49}
 49%|████▉     | 1166/2382 [4:22:00<4:09:05, 12.29s/it] 49%|████▉     | 1167/2382 [4:22:12<4:06:13, 12.16s/it]                                                       {'loss': 1.8674, 'learning_rate': 0.0005407546417735316, 'epoch': 0.49}
 49%|████▉     | 1167/2382 [4:22:12<4:06:13, 12.16s/it] 49%|████▉     | 1168/2382 [4:22:23<4:02:38, 11.99s/it]                                                       {'loss': 1.9339, 'learning_rate': 0.0005400768685214882, 'epoch': 0.49}
 49%|████▉     | 1168/2382 [4:22:23<4:02:38, 11.99s/it] 49%|████▉     | 1169/2382 [4:22:39<4:26:05, 13.16s/it]                                                       {'loss': 2.0013, 'learning_rate': 0.0005393990211436272, 'epoch': 0.49}
 49%|████▉     | 1169/2382 [4:22:39<4:26:05, 13.16s/it] 49%|████▉     | 1170/2382 [4:22:54<4:37:03, 13.72s/it]                                                       {'loss': 1.8412, 'learning_rate': 0.0005387211008936885, 'epoch': 0.49}
 49%|████▉     | 1170/2382 [4:22:54<4:37:03, 13.72s/it] 49%|████▉     | 1171/2382 [4:23:05<4:20:53, 12.93s/it]                                                       {'loss': 1.8189, 'learning_rate': 0.0005380431090255476, 'epoch': 0.49}
 49%|████▉     | 1171/2382 [4:23:05<4:20:53, 12.93s/it] 49%|████▉     | 1172/2382 [4:23:18<4:18:16, 12.81s/it]                                                       {'loss': 1.9855, 'learning_rate': 0.0005373650467932121, 'epoch': 0.49}
 49%|████▉     | 1172/2382 [4:23:18<4:18:16, 12.81s/it] 49%|████▉     | 1173/2382 [4:23:29<4:09:41, 12.39s/it]                                                       {'loss': 1.914, 'learning_rate': 0.00053668691545082, 'epoch': 0.49}
 49%|████▉     | 1173/2382 [4:23:29<4:09:41, 12.39s/it] 49%|████▉     | 1174/2382 [4:23:43<4:17:52, 12.81s/it]                                                       {'loss': 1.8646, 'learning_rate': 0.000536008716252637, 'epoch': 0.49}
 49%|████▉     | 1174/2382 [4:23:43<4:17:52, 12.81s/it] 49%|████▉     | 1175/2382 [4:23:58<4:31:05, 13.48s/it]                                                       {'loss': 1.872, 'learning_rate': 0.0005353304504530541, 'epoch': 0.49}
 49%|████▉     | 1175/2382 [4:23:58<4:31:05, 13.48s/it] 49%|████▉     | 1176/2382 [4:24:14<4:45:05, 14.18s/it]                                                       {'loss': 1.8866, 'learning_rate': 0.0005346521193065856, 'epoch': 0.49}
 49%|████▉     | 1176/2382 [4:24:14<4:45:05, 14.18s/it] 49%|████▉     | 1177/2382 [4:24:25<4:29:00, 13.39s/it]                                                       {'loss': 1.8945, 'learning_rate': 0.0005339737240678671, 'epoch': 0.49}
 49%|████▉     | 1177/2382 [4:24:25<4:29:00, 13.39s/it] 49%|████▉     | 1178/2382 [4:24:40<4:38:00, 13.85s/it]                                                       {'loss': 1.8014, 'learning_rate': 0.000533295265991652, 'epoch': 0.49}
 49%|████▉     | 1178/2382 [4:24:40<4:38:00, 13.85s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1196 > 1024). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (1247 > 1024). Running this sequence through the model will result in indexing errors
 49%|████▉     | 1179/2382 [4:24:54<4:37:59, 13.86s/it]                                                       {'loss': 1.8771, 'learning_rate': 0.0005326167463328104, 'epoch': 0.49}
 49%|████▉     | 1179/2382 [4:24:54<4:37:59, 13.86s/it] 50%|████▉     | 1180/2382 [4:25:08<4:38:55, 13.92s/it]                                                       {'loss': 1.8555, 'learning_rate': 0.0005319381663463262, 'epoch': 0.5}
 50%|████▉     | 1180/2382 [4:25:08<4:38:55, 13.92s/it] 50%|████▉     | 1181/2382 [4:25:24<4:49:07, 14.44s/it]                                                       {'loss': 1.7927, 'learning_rate': 0.000531259527287295, 'epoch': 0.5}
 50%|████▉     | 1181/2382 [4:25:24<4:49:07, 14.44s/it] 50%|████▉     | 1182/2382 [4:25:37<4:41:47, 14.09s/it]                                                       {'loss': 1.7735, 'learning_rate': 0.0005305808304109215, 'epoch': 0.5}
 50%|████▉     | 1182/2382 [4:25:37<4:41:47, 14.09s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1427 > 1024). Running this sequence through the model will result in indexing errors
 50%|████▉     | 1183/2382 [4:25:52<4:44:03, 14.21s/it]                                                       {'loss': 1.9128, 'learning_rate': 0.0005299020769725172, 'epoch': 0.5}
 50%|████▉     | 1183/2382 [4:25:52<4:44:03, 14.21s/it] 50%|████▉     | 1184/2382 [4:26:02<4:22:25, 13.14s/it]                                                       {'loss': 1.8653, 'learning_rate': 0.0005292232682274985, 'epoch': 0.5}
 50%|████▉     | 1184/2382 [4:26:02<4:22:25, 13.14s/it] 50%|████▉     | 1185/2382 [4:26:17<4:31:35, 13.61s/it]                                                       {'loss': 1.8375, 'learning_rate': 0.000528544405431384, 'epoch': 0.5}
 50%|████▉     | 1185/2382 [4:26:17<4:31:35, 13.61s/it] 50%|████▉     | 1186/2382 [4:26:34<4:54:36, 14.78s/it]                                                       {'loss': 1.7968, 'learning_rate': 0.0005278654898397923, 'epoch': 0.5}
 50%|████▉     | 1186/2382 [4:26:34<4:54:36, 14.78s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1147 > 1024). Running this sequence through the model will result in indexing errors
 50%|████▉     | 1187/2382 [4:26:46<4:36:57, 13.91s/it]                                                       {'loss': 1.8109, 'learning_rate': 0.0005271865227084397, 'epoch': 0.5}
 50%|████▉     | 1187/2382 [4:26:46<4:36:57, 13.91s/it] 50%|████▉     | 1188/2382 [4:27:01<4:42:13, 14.18s/it]                                                       {'loss': 1.8096, 'learning_rate': 0.0005265075052931374, 'epoch': 0.5}
 50%|████▉     | 1188/2382 [4:27:01<4:42:13, 14.18s/it] 50%|████▉     | 1189/2382 [4:27:18<4:56:13, 14.90s/it]                                                       {'loss': 1.8756, 'learning_rate': 0.0005258284388497904, 'epoch': 0.5}
 50%|████▉     | 1189/2382 [4:27:18<4:56:13, 14.90s/it] 50%|████▉     | 1190/2382 [4:27:29<4:36:53, 13.94s/it]                                                       {'loss': 1.8228, 'learning_rate': 0.0005251493246343936, 'epoch': 0.5}
 50%|████▉     | 1190/2382 [4:27:29<4:36:53, 13.94s/it] 50%|█████     | 1191/2382 [4:27:45<4:47:32, 14.49s/it]                                                       {'loss': 1.8603, 'learning_rate': 0.0005244701639030306, 'epoch': 0.5}
 50%|█████     | 1191/2382 [4:27:45<4:47:32, 14.49s/it] 50%|█████     | 1192/2382 [4:27:56<4:27:36, 13.49s/it]                                                       {'loss': 1.913, 'learning_rate': 0.0005237909579118712, 'epoch': 0.5}
 50%|█████     | 1192/2382 [4:27:56<4:27:36, 13.49s/it] 50%|█████     | 1193/2382 [4:28:09<4:23:56, 13.32s/it]                                                       {'loss': 1.9113, 'learning_rate': 0.0005231117079171687, 'epoch': 0.5}
 50%|█████     | 1193/2382 [4:28:09<4:23:56, 13.32s/it] 50%|█████     | 1194/2382 [4:28:24<4:31:00, 13.69s/it]                                                       {'loss': 1.7906, 'learning_rate': 0.0005224324151752575, 'epoch': 0.5}
 50%|█████     | 1194/2382 [4:28:24<4:31:00, 13.69s/it] 50%|█████     | 1195/2382 [4:28:40<4:43:43, 14.34s/it]                                                       {'loss': 1.818, 'learning_rate': 0.0005217530809425517, 'epoch': 0.5}
 50%|█████     | 1195/2382 [4:28:40<4:43:43, 14.34s/it] 50%|█████     | 1196/2382 [4:28:58<5:07:42, 15.57s/it]                                                       {'loss': 1.8, 'learning_rate': 0.000521073706475542, 'epoch': 0.5}
 50%|█████     | 1196/2382 [4:28:58<5:07:42, 15.57s/it] 50%|█████     | 1197/2382 [4:29:13<5:05:26, 15.47s/it]                                                       {'loss': 1.851, 'learning_rate': 0.0005203942930307929, 'epoch': 0.5}
 50%|█████     | 1197/2382 [4:29:13<5:05:26, 15.47s/it] 50%|█████     | 1198/2382 [4:29:28<5:00:15, 15.22s/it]                                                       {'loss': 1.8952, 'learning_rate': 0.0005197148418649416, 'epoch': 0.5}
 50%|█████     | 1198/2382 [4:29:28<5:00:15, 15.22s/it] 50%|█████     | 1199/2382 [4:29:41<4:48:01, 14.61s/it]                                                       {'loss': 1.8216, 'learning_rate': 0.000519035354234695, 'epoch': 0.5}
 50%|█████     | 1199/2382 [4:29:41<4:48:01, 14.61s/it] 50%|█████     | 1200/2382 [4:29:56<4:47:17, 14.58s/it]                                                       {'loss': 1.8445, 'learning_rate': 0.0005183558313968274, 'epoch': 0.5}
 50%|█████     | 1200/2382 [4:29:56<4:47:17, 14.58s/it] 50%|█████     | 1201/2382 [4:30:08<4:32:17, 13.83s/it]                                                       {'loss': 1.7976, 'learning_rate': 0.0005176762746081779, 'epoch': 0.5}
 50%|█████     | 1201/2382 [4:30:08<4:32:17, 13.83s/it] 50%|█████     | 1202/2382 [4:30:21<4:27:35, 13.61s/it]                                                       {'loss': 1.9001, 'learning_rate': 0.0005169966851256488, 'epoch': 0.5}
 50%|█████     | 1202/2382 [4:30:21<4:27:35, 13.61s/it] 51%|█████     | 1203/2382 [4:30:35<4:32:43, 13.88s/it]                                                       {'loss': 1.9205, 'learning_rate': 0.000516317064206203, 'epoch': 0.5}
 51%|█████     | 1203/2382 [4:30:35<4:32:43, 13.88s/it] 51%|█████     | 1204/2382 [4:30:49<4:33:08, 13.91s/it]                                                       {'loss': 1.9415, 'learning_rate': 0.0005156374131068609, 'epoch': 0.51}
 51%|█████     | 1204/2382 [4:30:49<4:33:08, 13.91s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1112 > 1024). Running this sequence through the model will result in indexing errors
 51%|█████     | 1205/2382 [4:31:02<4:25:34, 13.54s/it]                                                       {'loss': 1.8792, 'learning_rate': 0.0005149577330846993, 'epoch': 0.51}
 51%|█████     | 1205/2382 [4:31:02<4:25:34, 13.54s/it] 51%|█████     | 1206/2382 [4:31:16<4:30:25, 13.80s/it]                                                       {'loss': 1.8636, 'learning_rate': 0.0005142780253968481, 'epoch': 0.51}
 51%|█████     | 1206/2382 [4:31:16<4:30:25, 13.80s/it] 51%|█████     | 1207/2382 [4:31:31<4:32:25, 13.91s/it]                                                       {'loss': 1.8614, 'learning_rate': 0.0005135982913004888, 'epoch': 0.51}
 51%|█████     | 1207/2382 [4:31:31<4:32:25, 13.91s/it] 51%|█████     | 1208/2382 [4:31:42<4:18:36, 13.22s/it]                                                       {'loss': 1.8795, 'learning_rate': 0.0005129185320528515, 'epoch': 0.51}
 51%|█████     | 1208/2382 [4:31:42<4:18:36, 13.22s/it] 51%|█████     | 1209/2382 [4:31:55<4:13:21, 12.96s/it]                                                       {'loss': 1.8378, 'learning_rate': 0.0005122387489112127, 'epoch': 0.51}
 51%|█████     | 1209/2382 [4:31:55<4:13:21, 12.96s/it] 51%|█████     | 1210/2382 [4:32:07<4:09:27, 12.77s/it]                                                       {'loss': 1.9281, 'learning_rate': 0.0005115589431328931, 'epoch': 0.51}
 51%|█████     | 1210/2382 [4:32:07<4:09:27, 12.77s/it] 51%|█████     | 1211/2382 [4:32:20<4:08:26, 12.73s/it]                                                       {'loss': 1.7764, 'learning_rate': 0.000510879115975256, 'epoch': 0.51}
 51%|█████     | 1211/2382 [4:32:20<4:08:26, 12.73s/it] 51%|█████     | 1212/2382 [4:32:32<4:03:46, 12.50s/it]                                                       {'loss': 1.879, 'learning_rate': 0.0005101992686957028, 'epoch': 0.51}
 51%|█████     | 1212/2382 [4:32:32<4:03:46, 12.50s/it] 51%|█████     | 1213/2382 [4:32:42<3:52:47, 11.95s/it]                                                       {'loss': 1.8315, 'learning_rate': 0.0005095194025516733, 'epoch': 0.51}
 51%|█████     | 1213/2382 [4:32:42<3:52:47, 11.95s/it] 51%|█████     | 1214/2382 [4:32:56<4:01:52, 12.42s/it]                                                       {'loss': 1.8383, 'learning_rate': 0.0005088395188006422, 'epoch': 0.51}
 51%|█████     | 1214/2382 [4:32:56<4:01:52, 12.42s/it] 51%|█████     | 1215/2382 [4:33:07<3:53:38, 12.01s/it]                                                       {'loss': 1.8597, 'learning_rate': 0.000508159618700116, 'epoch': 0.51}
 51%|█████     | 1215/2382 [4:33:07<3:53:38, 12.01s/it] 51%|█████     | 1216/2382 [4:33:21<4:08:57, 12.81s/it]                                                       {'loss': 1.9056, 'learning_rate': 0.0005074797035076318, 'epoch': 0.51}
 51%|█████     | 1216/2382 [4:33:21<4:08:57, 12.81s/it] 51%|█████     | 1217/2382 [4:33:34<4:07:12, 12.73s/it]                                                       {'loss': 1.738, 'learning_rate': 0.000506799774480755, 'epoch': 0.51}
 51%|█████     | 1217/2382 [4:33:34<4:07:12, 12.73s/it] 51%|█████     | 1218/2382 [4:33:46<4:01:23, 12.44s/it]                                                       {'loss': 1.8242, 'learning_rate': 0.0005061198328770761, 'epoch': 0.51}
 51%|█████     | 1218/2382 [4:33:46<4:01:23, 12.44s/it] 51%|█████     | 1219/2382 [4:33:58<4:01:25, 12.46s/it]                                                       {'loss': 1.8516, 'learning_rate': 0.0005054398799542088, 'epoch': 0.51}
 51%|█████     | 1219/2382 [4:33:58<4:01:25, 12.46s/it] 51%|█████     | 1220/2382 [4:34:12<4:08:54, 12.85s/it]                                                       {'loss': 1.8595, 'learning_rate': 0.0005047599169697884, 'epoch': 0.51}
 51%|█████     | 1220/2382 [4:34:12<4:08:54, 12.85s/it] 51%|█████▏    | 1221/2382 [4:34:30<4:38:33, 14.40s/it]                                                       {'loss': 1.9076, 'learning_rate': 0.000504079945181468, 'epoch': 0.51}
 51%|█████▏    | 1221/2382 [4:34:30<4:38:33, 14.40s/it] 51%|█████▏    | 1222/2382 [4:34:42<4:26:59, 13.81s/it]                                                       {'loss': 1.9541, 'learning_rate': 0.0005033999658469174, 'epoch': 0.51}
 51%|█████▏    | 1222/2382 [4:34:42<4:26:59, 13.81s/it] 51%|█████▏    | 1223/2382 [4:34:59<4:41:58, 14.60s/it]                                                       {'loss': 1.9206, 'learning_rate': 0.0005027199802238204, 'epoch': 0.51}
 51%|█████▏    | 1223/2382 [4:34:59<4:41:58, 14.60s/it] 51%|█████▏    | 1224/2382 [4:35:11<4:25:19, 13.75s/it]                                                       {'loss': 1.8769, 'learning_rate': 0.0005020399895698721, 'epoch': 0.51}
 51%|█████▏    | 1224/2382 [4:35:11<4:25:19, 13.75s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1086 > 1024). Running this sequence through the model will result in indexing errors
 51%|█████▏    | 1225/2382 [4:35:23<4:15:15, 13.24s/it]                                                       {'loss': 1.8476, 'learning_rate': 0.0005013599951427776, 'epoch': 0.51}
 51%|█████▏    | 1225/2382 [4:35:23<4:15:15, 13.24s/it] 51%|█████▏    | 1226/2382 [4:35:35<4:10:15, 12.99s/it]                                                       {'loss': 1.979, 'learning_rate': 0.0005006799982002482, 'epoch': 0.51}
 51%|█████▏    | 1226/2382 [4:35:35<4:10:15, 12.99s/it] 52%|█████▏    | 1227/2382 [4:35:47<4:02:13, 12.58s/it]                                                       {'loss': 1.8011, 'learning_rate': 0.0005, 'epoch': 0.51}
 52%|█████▏    | 1227/2382 [4:35:47<4:02:13, 12.58s/it] 52%|█████▏    | 1228/2382 [4:36:01<4:11:52, 13.10s/it]                                                       {'loss': 1.8843, 'learning_rate': 0.0004993200017997519, 'epoch': 0.52}
 52%|█████▏    | 1228/2382 [4:36:01<4:11:52, 13.10s/it] 52%|█████▏    | 1229/2382 [4:36:14<4:08:07, 12.91s/it]                                                       {'loss': 1.7134, 'learning_rate': 0.0004986400048572224, 'epoch': 0.52}
 52%|█████▏    | 1229/2382 [4:36:14<4:08:07, 12.91s/it] 52%|█████▏    | 1230/2382 [4:36:29<4:20:46, 13.58s/it]                                                       {'loss': 1.8673, 'learning_rate': 0.000497960010430128, 'epoch': 0.52}
 52%|█████▏    | 1230/2382 [4:36:29<4:20:46, 13.58s/it] 52%|█████▏    | 1231/2382 [4:36:44<4:32:36, 14.21s/it]                                                       {'loss': 1.8832, 'learning_rate': 0.0004972800197761798, 'epoch': 0.52}
 52%|█████▏    | 1231/2382 [4:36:44<4:32:36, 14.21s/it] 52%|█████▏    | 1232/2382 [4:36:59<4:34:14, 14.31s/it]                                                       {'loss': 1.8152, 'learning_rate': 0.0004966000341530827, 'epoch': 0.52}
 52%|█████▏    | 1232/2382 [4:36:59<4:34:14, 14.31s/it] 52%|█████▏    | 1233/2382 [4:37:12<4:29:38, 14.08s/it]                                                       {'loss': 1.8637, 'learning_rate': 0.0004959200548185322, 'epoch': 0.52}
 52%|█████▏    | 1233/2382 [4:37:12<4:29:38, 14.08s/it] 52%|█████▏    | 1234/2382 [4:37:24<4:16:11, 13.39s/it]                                                       {'loss': 1.9115, 'learning_rate': 0.0004952400830302117, 'epoch': 0.52}
 52%|█████▏    | 1234/2382 [4:37:24<4:16:11, 13.39s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1043 > 1024). Running this sequence through the model will result in indexing errors
 52%|█████▏    | 1235/2382 [4:37:38<4:16:12, 13.40s/it]                                                       {'loss': 1.8278, 'learning_rate': 0.0004945601200457911, 'epoch': 0.52}
 52%|█████▏    | 1235/2382 [4:37:38<4:16:12, 13.40s/it] 52%|█████▏    | 1236/2382 [4:37:50<4:09:55, 13.09s/it]                                                       {'loss': 1.896, 'learning_rate': 0.0004938801671229242, 'epoch': 0.52}
 52%|█████▏    | 1236/2382 [4:37:50<4:09:55, 13.09s/it] 52%|█████▏    | 1237/2382 [4:38:02<4:06:07, 12.90s/it]                                                       {'loss': 1.8535, 'learning_rate': 0.0004932002255192452, 'epoch': 0.52}
 52%|█████▏    | 1237/2382 [4:38:02<4:06:07, 12.90s/it] 52%|█████▏    | 1238/2382 [4:38:15<4:02:29, 12.72s/it]                                                       {'loss': 1.853, 'learning_rate': 0.0004925202964923683, 'epoch': 0.52}
 52%|█████▏    | 1238/2382 [4:38:15<4:02:29, 12.72s/it] 52%|█████▏    | 1239/2382 [4:38:29<4:09:35, 13.10s/it]                                                       {'loss': 1.9007, 'learning_rate': 0.0004918403812998841, 'epoch': 0.52}
 52%|█████▏    | 1239/2382 [4:38:29<4:09:35, 13.10s/it] 52%|█████▏    | 1240/2382 [4:38:41<4:01:58, 12.71s/it]                                                       {'loss': 1.9162, 'learning_rate': 0.000491160481199358, 'epoch': 0.52}
 52%|█████▏    | 1240/2382 [4:38:41<4:01:58, 12.71s/it] 52%|█████▏    | 1241/2382 [4:38:55<4:10:46, 13.19s/it]                                                       {'loss': 1.95, 'learning_rate': 0.0004904805974483267, 'epoch': 0.52}
 52%|█████▏    | 1241/2382 [4:38:55<4:10:46, 13.19s/it] 52%|█████▏    | 1242/2382 [4:39:07<4:05:09, 12.90s/it]                                                       {'loss': 1.9447, 'learning_rate': 0.0004898007313042975, 'epoch': 0.52}
 52%|█████▏    | 1242/2382 [4:39:07<4:05:09, 12.90s/it] 52%|█████▏    | 1243/2382 [4:39:20<4:04:31, 12.88s/it]                                                       {'loss': 1.8107, 'learning_rate': 0.0004891208840247443, 'epoch': 0.52}
 52%|█████▏    | 1243/2382 [4:39:20<4:04:31, 12.88s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1518 > 1024). Running this sequence through the model will result in indexing errors
 52%|█████▏    | 1244/2382 [4:39:33<4:06:19, 12.99s/it]                                                       {'loss': 1.8324, 'learning_rate': 0.0004884410568671069, 'epoch': 0.52}
 52%|█████▏    | 1244/2382 [4:39:33<4:06:19, 12.99s/it] 52%|█████▏    | 1245/2382 [4:39:48<4:14:09, 13.41s/it]                                                       {'loss': 1.8984, 'learning_rate': 0.0004877612510887874, 'epoch': 0.52}
 52%|█████▏    | 1245/2382 [4:39:48<4:14:09, 13.41s/it] 52%|█████▏    | 1246/2382 [4:40:00<4:08:03, 13.10s/it]                                                       {'loss': 1.843, 'learning_rate': 0.0004870814679471485, 'epoch': 0.52}
 52%|█████▏    | 1246/2382 [4:40:00<4:08:03, 13.10s/it] 52%|█████▏    | 1247/2382 [4:40:14<4:15:03, 13.48s/it]                                                       {'loss': 1.938, 'learning_rate': 0.00048640170869951115, 'epoch': 0.52}
 52%|█████▏    | 1247/2382 [4:40:14<4:15:03, 13.48s/it] 52%|█████▏    | 1248/2382 [4:40:30<4:26:12, 14.09s/it]                                                       {'loss': 1.8803, 'learning_rate': 0.0004857219746031519, 'epoch': 0.52}
 52%|█████▏    | 1248/2382 [4:40:30<4:26:12, 14.09s/it] 52%|█████▏    | 1249/2382 [4:40:43<4:19:24, 13.74s/it]                                                       {'loss': 1.848, 'learning_rate': 0.0004850422669153009, 'epoch': 0.52}
 52%|█████▏    | 1249/2382 [4:40:43<4:19:24, 13.74s/it] 52%|█████▏    | 1250/2382 [4:40:56<4:16:21, 13.59s/it]                                                       {'loss': 1.8206, 'learning_rate': 0.0004843625868931392, 'epoch': 0.52}
 52%|█████▏    | 1250/2382 [4:40:56<4:16:21, 13.59s/it] 53%|█████▎    | 1251/2382 [4:41:10<4:17:16, 13.65s/it]                                                       {'loss': 1.9076, 'learning_rate': 0.00048368293579379703, 'epoch': 0.52}
 53%|█████▎    | 1251/2382 [4:41:10<4:17:16, 13.65s/it] 53%|█████▎    | 1252/2382 [4:41:24<4:20:23, 13.83s/it]                                                       {'loss': 1.9132, 'learning_rate': 0.0004830033148743511, 'epoch': 0.53}
 53%|█████▎    | 1252/2382 [4:41:24<4:20:23, 13.83s/it] 53%|█████▎    | 1253/2382 [4:41:36<4:10:33, 13.32s/it]                                                       {'loss': 1.8162, 'learning_rate': 0.00048232372539182207, 'epoch': 0.53}
 53%|█████▎    | 1253/2382 [4:41:36<4:10:33, 13.32s/it] 53%|█████▎    | 1254/2382 [4:41:49<4:05:33, 13.06s/it]                                                       {'loss': 1.9139, 'learning_rate': 0.00048164416860317286, 'epoch': 0.53}
 53%|█████▎    | 1254/2382 [4:41:49<4:05:33, 13.06s/it] 53%|█████▎    | 1255/2382 [4:42:03<4:12:41, 13.45s/it]                                                       {'loss': 1.7919, 'learning_rate': 0.00048096464576530507, 'epoch': 0.53}
 53%|█████▎    | 1255/2382 [4:42:03<4:12:41, 13.45s/it] 53%|█████▎    | 1256/2382 [4:42:15<4:05:20, 13.07s/it]                                                       {'loss': 1.8528, 'learning_rate': 0.00048028515813505854, 'epoch': 0.53}
 53%|█████▎    | 1256/2382 [4:42:15<4:05:20, 13.07s/it] 53%|█████▎    | 1257/2382 [4:42:31<4:18:54, 13.81s/it]                                                       {'loss': 1.799, 'learning_rate': 0.00047960570696920727, 'epoch': 0.53}
 53%|█████▎    | 1257/2382 [4:42:31<4:18:54, 13.81s/it] 53%|█████▎    | 1258/2382 [4:42:46<4:30:03, 14.42s/it]                                                       {'loss': 1.8768, 'learning_rate': 0.0004789262935244581, 'epoch': 0.53}
 53%|█████▎    | 1258/2382 [4:42:46<4:30:03, 14.42s/it] 53%|█████▎    | 1259/2382 [4:43:00<4:22:31, 14.03s/it]                                                       {'loss': 1.866, 'learning_rate': 0.0004782469190574483, 'epoch': 0.53}
 53%|█████▎    | 1259/2382 [4:43:00<4:22:31, 14.03s/it] 53%|█████▎    | 1260/2382 [4:43:14<4:25:08, 14.18s/it]                                                       {'loss': 1.8354, 'learning_rate': 0.0004775675848247427, 'epoch': 0.53}
 53%|█████▎    | 1260/2382 [4:43:14<4:25:08, 14.18s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1267 > 1024). Running this sequence through the model will result in indexing errors
 53%|█████▎    | 1261/2382 [4:43:28<4:22:59, 14.08s/it]                                                       {'loss': 1.9057, 'learning_rate': 0.00047688829208283157, 'epoch': 0.53}
 53%|█████▎    | 1261/2382 [4:43:28<4:22:59, 14.08s/it] 53%|█████▎    | 1262/2382 [4:43:40<4:10:48, 13.44s/it]                                                       {'loss': 1.8678, 'learning_rate': 0.0004762090420881289, 'epoch': 0.53}
 53%|█████▎    | 1262/2382 [4:43:40<4:10:48, 13.44s/it] 53%|█████▎    | 1263/2382 [4:43:56<4:24:52, 14.20s/it]                                                       {'loss': 1.8676, 'learning_rate': 0.00047552983609696947, 'epoch': 0.53}
 53%|█████▎    | 1263/2382 [4:43:56<4:24:52, 14.20s/it] 53%|█████▎    | 1264/2382 [4:44:07<4:06:17, 13.22s/it]                                                       {'loss': 1.8758, 'learning_rate': 0.00047485067536560645, 'epoch': 0.53}
 53%|█████▎    | 1264/2382 [4:44:07<4:06:17, 13.22s/it] 53%|█████▎    | 1265/2382 [4:44:19<3:59:32, 12.87s/it]                                                       {'loss': 1.8021, 'learning_rate': 0.0004741715611502096, 'epoch': 0.53}
 53%|█████▎    | 1265/2382 [4:44:19<3:59:32, 12.87s/it] 53%|█████▎    | 1266/2382 [4:44:34<4:09:53, 13.43s/it]                                                       {'loss': 1.7665, 'learning_rate': 0.0004734924947068626, 'epoch': 0.53}
 53%|█████▎    | 1266/2382 [4:44:34<4:09:53, 13.43s/it] 53%|█████▎    | 1267/2382 [4:44:47<4:07:30, 13.32s/it]                                                       {'loss': 1.8908, 'learning_rate': 0.0004728134772915605, 'epoch': 0.53}
 53%|█████▎    | 1267/2382 [4:44:47<4:07:30, 13.32s/it] 53%|█████▎    | 1268/2382 [4:45:01<4:12:12, 13.58s/it]                                                       {'loss': 1.8085, 'learning_rate': 0.00047213451016020773, 'epoch': 0.53}
 53%|█████▎    | 1268/2382 [4:45:01<4:12:12, 13.58s/it] 53%|█████▎    | 1269/2382 [4:45:16<4:20:56, 14.07s/it]                                                       {'loss': 1.8436, 'learning_rate': 0.000471455594568616, 'epoch': 0.53}
 53%|█████▎    | 1269/2382 [4:45:16<4:20:56, 14.07s/it] 53%|█████▎    | 1270/2382 [4:45:27<4:03:05, 13.12s/it]                                                       {'loss': 1.8139, 'learning_rate': 0.0004707767317725016, 'epoch': 0.53}
 53%|█████▎    | 1270/2382 [4:45:27<4:03:05, 13.12s/it] 53%|█████▎    | 1271/2382 [4:45:39<3:54:50, 12.68s/it]                                                       {'loss': 1.8987, 'learning_rate': 0.0004700979230274829, 'epoch': 0.53}
 53%|█████▎    | 1271/2382 [4:45:39<3:54:50, 12.68s/it] 53%|█████▎    | 1272/2382 [4:45:51<3:51:13, 12.50s/it]                                                       {'loss': 1.7282, 'learning_rate': 0.0004694191695890788, 'epoch': 0.53}
 53%|█████▎    | 1272/2382 [4:45:51<3:51:13, 12.50s/it] 53%|█████▎    | 1273/2382 [4:46:03<3:52:16, 12.57s/it]                                                       {'loss': 1.8351, 'learning_rate': 0.00046874047271270507, 'epoch': 0.53}
 53%|█████▎    | 1273/2382 [4:46:03<3:52:16, 12.57s/it] 53%|█████▎    | 1274/2382 [4:46:17<3:59:38, 12.98s/it]                                                       {'loss': 1.9164, 'learning_rate': 0.00046806183365367396, 'epoch': 0.53}
 53%|█████▎    | 1274/2382 [4:46:17<3:59:38, 12.98s/it] 54%|█████▎    | 1275/2382 [4:46:30<3:56:14, 12.80s/it]                                                       {'loss': 1.8774, 'learning_rate': 0.0004673832536671897, 'epoch': 0.54}
 54%|█████▎    | 1275/2382 [4:46:30<3:56:14, 12.80s/it] 54%|█████▎    | 1276/2382 [4:46:43<3:59:14, 12.98s/it]                                                       {'loss': 1.7742, 'learning_rate': 0.00046670473400834805, 'epoch': 0.54}
 54%|█████▎    | 1276/2382 [4:46:43<3:59:14, 12.98s/it] 54%|█████▎    | 1277/2382 [4:46:59<4:16:54, 13.95s/it]                                                       {'loss': 1.7812, 'learning_rate': 0.000466026275932133, 'epoch': 0.54}
 54%|█████▎    | 1277/2382 [4:46:59<4:16:54, 13.95s/it] 54%|█████▎    | 1278/2382 [4:47:17<4:34:22, 14.91s/it]                                                       {'loss': 1.8041, 'learning_rate': 0.00046534788069341453, 'epoch': 0.54}
 54%|█████▎    | 1278/2382 [4:47:17<4:34:22, 14.91s/it] 54%|█████▎    | 1279/2382 [4:47:28<4:16:38, 13.96s/it]                                                       {'loss': 1.9365, 'learning_rate': 0.00046466954954694605, 'epoch': 0.54}
 54%|█████▎    | 1279/2382 [4:47:28<4:16:38, 13.96s/it] 54%|█████▎    | 1280/2382 [4:47:40<4:05:31, 13.37s/it]                                                       {'loss': 1.9595, 'learning_rate': 0.0004639912837473631, 'epoch': 0.54}
 54%|█████▎    | 1280/2382 [4:47:40<4:05:31, 13.37s/it] 54%|█████▍    | 1281/2382 [4:47:54<4:08:37, 13.55s/it]                                                       {'loss': 1.8858, 'learning_rate': 0.00046331308454918, 'epoch': 0.54}
 54%|█████▍    | 1281/2382 [4:47:54<4:08:37, 13.55s/it] 54%|█████▍    | 1282/2382 [4:48:09<4:13:40, 13.84s/it]                                                       {'loss': 1.8289, 'learning_rate': 0.0004626349532067879, 'epoch': 0.54}
 54%|█████▍    | 1282/2382 [4:48:09<4:13:40, 13.84s/it] 54%|█████▍    | 1283/2382 [4:48:22<4:09:36, 13.63s/it]                                                       {'loss': 1.8421, 'learning_rate': 0.0004619568909744524, 'epoch': 0.54}
 54%|█████▍    | 1283/2382 [4:48:22<4:09:36, 13.63s/it] 54%|█████▍    | 1284/2382 [4:48:35<4:05:57, 13.44s/it]                                                       {'loss': 1.8547, 'learning_rate': 0.00046127889910631167, 'epoch': 0.54}
 54%|█████▍    | 1284/2382 [4:48:35<4:05:57, 13.44s/it] 54%|█████▍    | 1285/2382 [4:48:48<4:06:22, 13.48s/it]                                                       {'loss': 1.9035, 'learning_rate': 0.00046060097885637305, 'epoch': 0.54}
 54%|█████▍    | 1285/2382 [4:48:48<4:06:22, 13.48s/it] 54%|█████▍    | 1286/2382 [4:49:04<4:15:55, 14.01s/it]                                                       {'loss': 1.7413, 'learning_rate': 0.0004599231314785118, 'epoch': 0.54}
 54%|█████▍    | 1286/2382 [4:49:04<4:15:55, 14.01s/it] 54%|█████▍    | 1287/2382 [4:49:19<4:24:11, 14.48s/it]                                                       {'loss': 1.826, 'learning_rate': 0.0004592453582264684, 'epoch': 0.54}
 54%|█████▍    | 1287/2382 [4:49:19<4:24:11, 14.48s/it] 54%|█████▍    | 1288/2382 [4:49:34<4:23:34, 14.46s/it]                                                       {'loss': 1.8785, 'learning_rate': 0.0004585676603538465, 'epoch': 0.54}
 54%|█████▍    | 1288/2382 [4:49:34<4:23:34, 14.46s/it] 54%|█████▍    | 1289/2382 [4:49:48<4:22:58, 14.44s/it]                                                       {'loss': 1.8504, 'learning_rate': 0.00045789003911410954, 'epoch': 0.54}
 54%|█████▍    | 1289/2382 [4:49:48<4:22:58, 14.44s/it] 54%|█████▍    | 1290/2382 [4:50:00<4:11:08, 13.80s/it]                                                       {'loss': 1.8787, 'learning_rate': 0.0004572124957605803, 'epoch': 0.54}
 54%|█████▍    | 1290/2382 [4:50:00<4:11:08, 13.80s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1815 > 1024). Running this sequence through the model will result in indexing errors
 54%|█████▍    | 1291/2382 [4:50:11<3:54:06, 12.88s/it]                                                       {'loss': 1.8855, 'learning_rate': 0.0004565350315464363, 'epoch': 0.54}
 54%|█████▍    | 1291/2382 [4:50:11<3:54:06, 12.88s/it] 54%|█████▍    | 1292/2382 [4:50:24<3:52:56, 12.82s/it]                                                       {'loss': 1.8986, 'learning_rate': 0.0004558576477247097, 'epoch': 0.54}
 54%|█████▍    | 1292/2382 [4:50:24<3:52:56, 12.82s/it] 54%|█████▍    | 1293/2382 [4:50:36<3:51:20, 12.75s/it]                                                       {'loss': 1.8453, 'learning_rate': 0.0004551803455482833, 'epoch': 0.54}
 54%|█████▍    | 1293/2382 [4:50:36<3:51:20, 12.75s/it] 54%|█████▍    | 1294/2382 [4:50:50<3:57:37, 13.10s/it]                                                       {'loss': 1.7783, 'learning_rate': 0.00045450312626988933, 'epoch': 0.54}
 54%|█████▍    | 1294/2382 [4:50:50<3:57:37, 13.10s/it] 54%|█████▍    | 1295/2382 [4:51:05<4:04:09, 13.48s/it]                                                       {'loss': 1.7719, 'learning_rate': 0.0004538259911421065, 'epoch': 0.54}
 54%|█████▍    | 1295/2382 [4:51:05<4:04:09, 13.48s/it] 54%|█████▍    | 1296/2382 [4:51:16<3:51:36, 12.80s/it]                                                       {'loss': 1.8071, 'learning_rate': 0.00045314894141735803, 'epoch': 0.54}
 54%|█████▍    | 1296/2382 [4:51:16<3:51:36, 12.80s/it] 54%|█████▍    | 1297/2382 [4:51:29<3:52:00, 12.83s/it]                                                       {'loss': 1.8726, 'learning_rate': 0.0004524719783479088, 'epoch': 0.54}
 54%|█████▍    | 1297/2382 [4:51:29<3:52:00, 12.83s/it] 54%|█████▍    | 1298/2382 [4:51:43<3:56:42, 13.10s/it]                                                       {'loss': 1.7989, 'learning_rate': 0.00045179510318586356, 'epoch': 0.54}
 54%|█████▍    | 1298/2382 [4:51:43<3:56:42, 13.10s/it] 55%|█████▍    | 1299/2382 [4:51:57<4:05:42, 13.61s/it]                                                       {'loss': 1.7584, 'learning_rate': 0.00045111831718316485, 'epoch': 0.55}
 55%|█████▍    | 1299/2382 [4:51:57<4:05:42, 13.61s/it] 55%|█████▍    | 1300/2382 [4:52:09<3:55:26, 13.06s/it]                                                       {'loss': 1.8729, 'learning_rate': 0.00045044162159159, 'epoch': 0.55}
 55%|█████▍    | 1300/2382 [4:52:09<3:55:26, 13.06s/it] 55%|█████▍    | 1301/2382 [4:52:23<3:57:29, 13.18s/it]                                                       {'loss': 1.8082, 'learning_rate': 0.00044976501766274884, 'epoch': 0.55}
 55%|█████▍    | 1301/2382 [4:52:23<3:57:29, 13.18s/it] 55%|█████▍    | 1302/2382 [4:52:37<4:04:23, 13.58s/it]                                                       {'loss': 1.9955, 'learning_rate': 0.0004490885066480824, 'epoch': 0.55}
 55%|█████▍    | 1302/2382 [4:52:37<4:04:23, 13.58s/it] 55%|█████▍    | 1303/2382 [4:52:51<4:08:17, 13.81s/it]                                                       {'loss': 1.915, 'learning_rate': 0.00044841208979885897, 'epoch': 0.55}
 55%|█████▍    | 1303/2382 [4:52:51<4:08:17, 13.81s/it] 55%|█████▍    | 1304/2382 [4:53:06<4:11:40, 14.01s/it]                                                       {'loss': 1.8856, 'learning_rate': 0.00044773576836617336, 'epoch': 0.55}
 55%|█████▍    | 1304/2382 [4:53:06<4:11:40, 14.01s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1371 > 1024). Running this sequence through the model will result in indexing errors
 55%|█████▍    | 1305/2382 [4:53:19<4:05:35, 13.68s/it]                                                       {'loss': 1.7629, 'learning_rate': 0.0004470595436009435, 'epoch': 0.55}
 55%|█████▍    | 1305/2382 [4:53:19<4:05:35, 13.68s/it] 55%|█████▍    | 1306/2382 [4:53:32<4:02:21, 13.51s/it]                                                       {'loss': 1.9044, 'learning_rate': 0.0004463834167539087, 'epoch': 0.55}
 55%|█████▍    | 1306/2382 [4:53:32<4:02:21, 13.51s/it] 55%|█████▍    | 1307/2382 [4:53:45<3:58:41, 13.32s/it]                                                       {'loss': 1.8576, 'learning_rate': 0.0004457073890756273, 'epoch': 0.55}
 55%|█████▍    | 1307/2382 [4:53:45<3:58:41, 13.32s/it] 55%|█████▍    | 1308/2382 [4:53:57<3:54:07, 13.08s/it]                                                       {'loss': 1.844, 'learning_rate': 0.0004450314618164741, 'epoch': 0.55}
 55%|█████▍    | 1308/2382 [4:53:57<3:54:07, 13.08s/it] 55%|█████▍    | 1309/2382 [4:54:12<4:04:41, 13.68s/it]                                                       {'loss': 1.7879, 'learning_rate': 0.00044435563622663774, 'epoch': 0.55}
 55%|█████▍    | 1309/2382 [4:54:12<4:04:41, 13.68s/it] 55%|█████▍    | 1310/2382 [4:54:24<3:52:57, 13.04s/it]                                                       {'loss': 1.8919, 'learning_rate': 0.00044367991355611936, 'epoch': 0.55}
 55%|█████▍    | 1310/2382 [4:54:24<3:52:57, 13.04s/it] 55%|█████▌    | 1311/2382 [4:54:39<4:01:11, 13.51s/it]                                                       {'loss': 1.8954, 'learning_rate': 0.0004430042950547297, 'epoch': 0.55}
 55%|█████▌    | 1311/2382 [4:54:39<4:01:11, 13.51s/it] 55%|█████▌    | 1312/2382 [4:54:50<3:49:23, 12.86s/it]                                                       {'loss': 1.8507, 'learning_rate': 0.0004423287819720866, 'epoch': 0.55}
 55%|█████▌    | 1312/2382 [4:54:50<3:49:23, 12.86s/it] 55%|█████▌    | 1313/2382 [4:55:04<3:55:10, 13.20s/it]                                                       {'loss': 1.8656, 'learning_rate': 0.000441653375557613, 'epoch': 0.55}
 55%|█████▌    | 1313/2382 [4:55:04<3:55:10, 13.20s/it] 55%|█████▌    | 1314/2382 [4:55:19<4:03:09, 13.66s/it]                                                       {'loss': 1.8259, 'learning_rate': 0.0004409780770605349, 'epoch': 0.55}
 55%|█████▌    | 1314/2382 [4:55:19<4:03:09, 13.66s/it] 55%|█████▌    | 1315/2382 [4:55:33<4:04:30, 13.75s/it]                                                       {'loss': 1.9064, 'learning_rate': 0.00044030288772987794, 'epoch': 0.55}
 55%|█████▌    | 1315/2382 [4:55:33<4:04:30, 13.75s/it] 55%|█████▌    | 1316/2382 [4:55:45<3:59:44, 13.49s/it]                                                       {'loss': 2.0178, 'learning_rate': 0.0004396278088144663, 'epoch': 0.55}
 55%|█████▌    | 1316/2382 [4:55:45<3:59:44, 13.49s/it] 55%|█████▌    | 1317/2382 [4:56:01<4:09:25, 14.05s/it]                                                       {'loss': 1.8193, 'learning_rate': 0.00043895284156292004, 'epoch': 0.55}
 55%|█████▌    | 1317/2382 [4:56:01<4:09:25, 14.05s/it] 55%|█████▌    | 1318/2382 [4:56:15<4:09:02, 14.04s/it]                                                       {'loss': 1.8041, 'learning_rate': 0.00043827798722365264, 'epoch': 0.55}
 55%|█████▌    | 1318/2382 [4:56:15<4:09:02, 14.04s/it] 55%|█████▌    | 1319/2382 [4:56:27<3:58:40, 13.47s/it]                                                       {'loss': 1.894, 'learning_rate': 0.00043760324704486845, 'epoch': 0.55}
 55%|█████▌    | 1319/2382 [4:56:27<3:58:40, 13.47s/it] 55%|█████▌    | 1320/2382 [4:56:42<4:05:31, 13.87s/it]                                                       {'loss': 1.7902, 'learning_rate': 0.00043692862227456125, 'epoch': 0.55}
 55%|█████▌    | 1320/2382 [4:56:42<4:05:31, 13.87s/it] 55%|█████▌    | 1321/2382 [4:56:54<3:57:25, 13.43s/it]                                                       {'loss': 1.8181, 'learning_rate': 0.0004362541141605105, 'epoch': 0.55}
 55%|█████▌    | 1321/2382 [4:56:54<3:57:25, 13.43s/it] 55%|█████▌    | 1322/2382 [4:57:10<4:07:58, 14.04s/it]                                                       {'loss': 1.8958, 'learning_rate': 0.00043557972395028065, 'epoch': 0.55}
 55%|█████▌    | 1322/2382 [4:57:10<4:07:58, 14.04s/it] 56%|█████▌    | 1323/2382 [4:57:21<3:55:42, 13.35s/it]                                                       {'loss': 1.8183, 'learning_rate': 0.0004349054528912177, 'epoch': 0.56}
 56%|█████▌    | 1323/2382 [4:57:21<3:55:42, 13.35s/it] 56%|█████▌    | 1324/2382 [4:57:31<3:36:07, 12.26s/it]                                                       {'loss': 1.9626, 'learning_rate': 0.0004342313022304474, 'epoch': 0.56}
 56%|█████▌    | 1324/2382 [4:57:31<3:36:07, 12.26s/it] 56%|█████▌    | 1325/2382 [4:57:45<3:44:32, 12.75s/it]                                                       {'loss': 1.8268, 'learning_rate': 0.000433557273214873, 'epoch': 0.56}
 56%|█████▌    | 1325/2382 [4:57:45<3:44:32, 12.75s/it] 56%|█████▌    | 1326/2382 [4:57:57<3:38:55, 12.44s/it]                                                       {'loss': 1.9394, 'learning_rate': 0.0004328833670911724, 'epoch': 0.56}
 56%|█████▌    | 1326/2382 [4:57:57<3:38:55, 12.44s/it] 56%|█████▌    | 1327/2382 [4:58:09<3:37:03, 12.34s/it]                                                       {'loss': 1.8202, 'learning_rate': 0.0004322095851057962, 'epoch': 0.56}
 56%|█████▌    | 1327/2382 [4:58:09<3:37:03, 12.34s/it] 56%|█████▌    | 1328/2382 [4:58:21<3:34:14, 12.20s/it]                                                       {'loss': 1.8523, 'learning_rate': 0.00043153592850496555, 'epoch': 0.56}
 56%|█████▌    | 1328/2382 [4:58:21<3:34:14, 12.20s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1043 > 1024). Running this sequence through the model will result in indexing errors
 56%|█████▌    | 1329/2382 [4:58:37<3:55:52, 13.44s/it]                                                       {'loss': 1.934, 'learning_rate': 0.0004308623985346699, 'epoch': 0.56}
 56%|█████▌    | 1329/2382 [4:58:37<3:55:52, 13.44s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1306 > 1024). Running this sequence through the model will result in indexing errors
 56%|█████▌    | 1330/2382 [4:58:51<4:01:06, 13.75s/it]                                                       {'loss': 1.8762, 'learning_rate': 0.0004301889964406641, 'epoch': 0.56}
 56%|█████▌    | 1330/2382 [4:58:51<4:01:06, 13.75s/it] 56%|█████▌    | 1331/2382 [4:59:04<3:52:53, 13.30s/it]                                                       {'loss': 2.055, 'learning_rate': 0.00042951572346846666, 'epoch': 0.56}
 56%|█████▌    | 1331/2382 [4:59:04<3:52:53, 13.30s/it] 56%|█████▌    | 1332/2382 [4:59:20<4:08:29, 14.20s/it]                                                       {'loss': 1.8883, 'learning_rate': 0.0004288425808633575, 'epoch': 0.56}
 56%|█████▌    | 1332/2382 [4:59:20<4:08:29, 14.20s/it] 56%|█████▌    | 1333/2382 [4:59:32<3:57:08, 13.56s/it]                                                       {'loss': 1.8528, 'learning_rate': 0.00042816956987037485, 'epoch': 0.56}
 56%|█████▌    | 1333/2382 [4:59:32<3:57:08, 13.56s/it] 56%|█████▌    | 1334/2382 [4:59:45<3:52:32, 13.31s/it]                                                       {'loss': 1.8391, 'learning_rate': 0.00042749669173431385, 'epoch': 0.56}
 56%|█████▌    | 1334/2382 [4:59:45<3:52:32, 13.31s/it] 56%|█████▌    | 1335/2382 [4:59:58<3:52:50, 13.34s/it]                                                       {'loss': 1.828, 'learning_rate': 0.000426823947699724, 'epoch': 0.56}
 56%|█████▌    | 1335/2382 [4:59:58<3:52:50, 13.34s/it] 56%|█████▌    | 1336/2382 [5:00:12<3:53:20, 13.38s/it]                                                       {'loss': 1.7813, 'learning_rate': 0.00042615133901090663, 'epoch': 0.56}
 56%|█████▌    | 1336/2382 [5:00:12<3:53:20, 13.38s/it] 56%|█████▌    | 1337/2382 [5:00:25<3:52:46, 13.37s/it]                                                       {'loss': 1.9061, 'learning_rate': 0.0004254788669119127, 'epoch': 0.56}
 56%|█████▌    | 1337/2382 [5:00:25<3:52:46, 13.37s/it] 56%|█████▌    | 1338/2382 [5:00:36<3:41:12, 12.71s/it]                                                       {'loss': 1.8591, 'learning_rate': 0.0004248065326465409, 'epoch': 0.56}
 56%|█████▌    | 1338/2382 [5:00:36<3:41:12, 12.71s/it] 56%|█████▌    | 1339/2382 [5:00:48<3:36:56, 12.48s/it]                                                       {'loss': 1.9191, 'learning_rate': 0.00042413433745833423, 'epoch': 0.56}
 56%|█████▌    | 1339/2382 [5:00:48<3:36:56, 12.48s/it] 56%|█████▋    | 1340/2382 [5:01:01<3:40:33, 12.70s/it]                                                       {'loss': 1.7777, 'learning_rate': 0.0004234622825905792, 'epoch': 0.56}
 56%|█████▋    | 1340/2382 [5:01:01<3:40:33, 12.70s/it] 56%|█████▋    | 1341/2382 [5:01:15<3:46:10, 13.04s/it]                                                       {'loss': 1.9478, 'learning_rate': 0.00042279036928630226, 'epoch': 0.56}
 56%|█████▋    | 1341/2382 [5:01:15<3:46:10, 13.04s/it] 56%|█████▋    | 1342/2382 [5:01:30<3:53:28, 13.47s/it]                                                       {'loss': 1.8696, 'learning_rate': 0.0004221185987882684, 'epoch': 0.56}
 56%|█████▋    | 1342/2382 [5:01:30<3:53:28, 13.47s/it] 56%|█████▋    | 1343/2382 [5:01:47<4:11:52, 14.55s/it]                                                       {'loss': 1.9205, 'learning_rate': 0.00042144697233897845, 'epoch': 0.56}
 56%|█████▋    | 1343/2382 [5:01:47<4:11:52, 14.55s/it] 56%|█████▋    | 1344/2382 [5:02:03<4:18:57, 14.97s/it]                                                       {'loss': 1.7766, 'learning_rate': 0.00042077549118066653, 'epoch': 0.56}
 56%|█████▋    | 1344/2382 [5:02:03<4:18:57, 14.97s/it] 56%|█████▋    | 1345/2382 [5:02:19<4:23:43, 15.26s/it]                                                       {'loss': 1.9269, 'learning_rate': 0.00042010415655529827, 'epoch': 0.56}
 56%|█████▋    | 1345/2382 [5:02:19<4:23:43, 15.26s/it] 57%|█████▋    | 1346/2382 [5:02:34<4:24:40, 15.33s/it]                                                       {'loss': 1.839, 'learning_rate': 0.000419432969704568, 'epoch': 0.56}
 57%|█████▋    | 1346/2382 [5:02:34<4:24:40, 15.33s/it] 57%|█████▋    | 1347/2382 [5:02:47<4:09:06, 14.44s/it]                                                       {'loss': 1.8246, 'learning_rate': 0.0004187619318698971, 'epoch': 0.57}
 57%|█████▋    | 1347/2382 [5:02:47<4:09:06, 14.44s/it] 57%|█████▋    | 1348/2382 [5:03:00<4:01:25, 14.01s/it]                                                       {'loss': 1.8368, 'learning_rate': 0.00041809104429243115, 'epoch': 0.57}
 57%|█████▋    | 1348/2382 [5:03:00<4:01:25, 14.01s/it] 57%|█████▋    | 1349/2382 [5:03:13<4:00:04, 13.94s/it]                                                       {'loss': 1.8302, 'learning_rate': 0.0004174203082130377, 'epoch': 0.57}
 57%|█████▋    | 1349/2382 [5:03:13<4:00:04, 13.94s/it] 57%|█████▋    | 1350/2382 [5:03:26<3:52:31, 13.52s/it]                                                       {'loss': 1.8936, 'learning_rate': 0.00041674972487230455, 'epoch': 0.57}
 57%|█████▋    | 1350/2382 [5:03:26<3:52:31, 13.52s/it] 57%|█████▋    | 1351/2382 [5:03:39<3:52:49, 13.55s/it]                                                       {'loss': 1.7955, 'learning_rate': 0.0004160792955105362, 'epoch': 0.57}
 57%|█████▋    | 1351/2382 [5:03:39<3:52:49, 13.55s/it] 57%|█████▋    | 1352/2382 [5:03:54<3:58:59, 13.92s/it]                                                       {'loss': 1.8937, 'learning_rate': 0.0004154090213677531, 'epoch': 0.57}
 57%|█████▋    | 1352/2382 [5:03:54<3:58:59, 13.92s/it] 57%|█████▋    | 1353/2382 [5:04:09<4:02:06, 14.12s/it]                                                       {'loss': 1.8877, 'learning_rate': 0.0004147389036836881, 'epoch': 0.57}
 57%|█████▋    | 1353/2382 [5:04:09<4:02:06, 14.12s/it] 57%|█████▋    | 1354/2382 [5:04:21<3:53:02, 13.60s/it]                                                       {'loss': 1.9299, 'learning_rate': 0.00041406894369778503, 'epoch': 0.57}
 57%|█████▋    | 1354/2382 [5:04:21<3:53:02, 13.60s/it] 57%|█████▋    | 1355/2382 [5:04:32<3:40:06, 12.86s/it]                                                       {'loss': 1.8553, 'learning_rate': 0.000413399142649196, 'epoch': 0.57}
 57%|█████▋    | 1355/2382 [5:04:32<3:40:06, 12.86s/it] 57%|█████▋    | 1356/2382 [5:04:45<3:41:06, 12.93s/it]                                                       {'loss': 1.7394, 'learning_rate': 0.00041272950177677895, 'epoch': 0.57}
 57%|█████▋    | 1356/2382 [5:04:45<3:41:06, 12.93s/it] 57%|█████▋    | 1357/2382 [5:05:01<3:55:56, 13.81s/it]                                                       {'loss': 1.8138, 'learning_rate': 0.0004120600223190955, 'epoch': 0.57}
 57%|█████▋    | 1357/2382 [5:05:01<3:55:56, 13.81s/it] 57%|█████▋    | 1358/2382 [5:05:16<3:58:04, 13.95s/it]                                                       {'loss': 1.8331, 'learning_rate': 0.00041139070551440886, 'epoch': 0.57}
 57%|█████▋    | 1358/2382 [5:05:16<3:58:04, 13.95s/it] 57%|█████▋    | 1359/2382 [5:05:28<3:48:31, 13.40s/it]                                                       {'loss': 1.8764, 'learning_rate': 0.0004107215526006817, 'epoch': 0.57}
 57%|█████▋    | 1359/2382 [5:05:28<3:48:31, 13.40s/it] 57%|█████▋    | 1360/2382 [5:05:39<3:38:22, 12.82s/it]                                                       {'loss': 1.8899, 'learning_rate': 0.00041005256481557305, 'epoch': 0.57}
 57%|█████▋    | 1360/2382 [5:05:39<3:38:22, 12.82s/it] 57%|█████▋    | 1361/2382 [5:05:54<3:46:59, 13.34s/it]                                                       {'loss': 1.9405, 'learning_rate': 0.00040938374339643694, 'epoch': 0.57}
 57%|█████▋    | 1361/2382 [5:05:54<3:46:59, 13.34s/it] 57%|█████▋    | 1362/2382 [5:06:09<3:54:36, 13.80s/it]                                                       {'loss': 1.8319, 'learning_rate': 0.0004087150895803192, 'epoch': 0.57}
 57%|█████▋    | 1362/2382 [5:06:09<3:54:36, 13.80s/it] 57%|█████▋    | 1363/2382 [5:06:20<3:41:39, 13.05s/it]                                                       {'loss': 1.8319, 'learning_rate': 0.0004080466046039562, 'epoch': 0.57}
 57%|█████▋    | 1363/2382 [5:06:20<3:41:39, 13.05s/it] 57%|█████▋    | 1364/2382 [5:06:34<3:49:22, 13.52s/it]                                                       {'loss': 1.9291, 'learning_rate': 0.0004073782897037716, 'epoch': 0.57}
 57%|█████▋    | 1364/2382 [5:06:35<3:49:22, 13.52s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1069 > 1024). Running this sequence through the model will result in indexing errors
 57%|█████▋    | 1365/2382 [5:06:48<3:46:40, 13.37s/it]                                                       {'loss': 1.976, 'learning_rate': 0.00040671014611587473, 'epoch': 0.57}
 57%|█████▋    | 1365/2382 [5:06:48<3:46:40, 13.37s/it] 57%|█████▋    | 1366/2382 [5:07:00<3:40:06, 13.00s/it]                                                       {'loss': 1.8434, 'learning_rate': 0.0004060421750760581, 'epoch': 0.57}
 57%|█████▋    | 1366/2382 [5:07:00<3:40:06, 13.00s/it] 57%|█████▋    | 1367/2382 [5:07:13<3:40:50, 13.05s/it]                                                       {'loss': 1.8852, 'learning_rate': 0.0004053743778197951, 'epoch': 0.57}
 57%|█████▋    | 1367/2382 [5:07:13<3:40:50, 13.05s/it] 57%|█████▋    | 1368/2382 [5:07:27<3:45:26, 13.34s/it]                                                       {'loss': 1.7489, 'learning_rate': 0.0004047067555822371, 'epoch': 0.57}
 57%|█████▋    | 1368/2382 [5:07:27<3:45:26, 13.34s/it] 57%|█████▋    | 1369/2382 [5:07:39<3:41:28, 13.12s/it]                                                       {'loss': 1.8669, 'learning_rate': 0.00040403930959821244, 'epoch': 0.57}
 57%|█████▋    | 1369/2382 [5:07:39<3:41:28, 13.12s/it] 58%|█████▊    | 1370/2382 [5:07:52<3:40:23, 13.07s/it]                                                       {'loss': 1.7386, 'learning_rate': 0.0004033720411022235, 'epoch': 0.57}
 58%|█████▊    | 1370/2382 [5:07:52<3:40:23, 13.07s/it] 58%|█████▊    | 1371/2382 [5:08:06<3:45:17, 13.37s/it]                                                       {'loss': 1.8679, 'learning_rate': 0.0004027049513284437, 'epoch': 0.58}
 58%|█████▊    | 1371/2382 [5:08:06<3:45:17, 13.37s/it] 58%|█████▊    | 1372/2382 [5:08:18<3:37:33, 12.92s/it]                                                       {'loss': 1.847, 'learning_rate': 0.00040203804151071665, 'epoch': 0.58}
 58%|█████▊    | 1372/2382 [5:08:18<3:37:33, 12.92s/it] 58%|█████▊    | 1373/2382 [5:08:30<3:31:24, 12.57s/it]                                                       {'loss': 1.8989, 'learning_rate': 0.0004013713128825529, 'epoch': 0.58}
 58%|█████▊    | 1373/2382 [5:08:30<3:31:24, 12.57s/it] 58%|█████▊    | 1374/2382 [5:08:42<3:28:20, 12.40s/it]                                                       {'loss': 1.7754, 'learning_rate': 0.00040070476667712743, 'epoch': 0.58}
 58%|█████▊    | 1374/2382 [5:08:42<3:28:20, 12.40s/it] 58%|█████▊    | 1375/2382 [5:08:56<3:34:46, 12.80s/it]                                                       {'loss': 1.8181, 'learning_rate': 0.00040003840412727816, 'epoch': 0.58}
 58%|█████▊    | 1375/2382 [5:08:56<3:34:46, 12.80s/it] 58%|█████▊    | 1376/2382 [5:09:08<3:33:04, 12.71s/it]                                                       {'loss': 1.8335, 'learning_rate': 0.0003993722264655034, 'epoch': 0.58}
 58%|█████▊    | 1376/2382 [5:09:08<3:33:04, 12.71s/it] 58%|█████▊    | 1377/2382 [5:09:25<3:54:36, 14.01s/it]                                                       {'loss': 1.7657, 'learning_rate': 0.0003987062349239596, 'epoch': 0.58}
 58%|█████▊    | 1377/2382 [5:09:25<3:54:36, 14.01s/it] 58%|█████▊    | 1378/2382 [5:09:37<3:42:39, 13.31s/it]                                                       {'loss': 1.9177, 'learning_rate': 0.0003980404307344584, 'epoch': 0.58}
 58%|█████▊    | 1378/2382 [5:09:37<3:42:39, 13.31s/it] 58%|█████▊    | 1379/2382 [5:09:49<3:36:38, 12.96s/it]                                                       {'loss': 1.7735, 'learning_rate': 0.00039737481512846574, 'epoch': 0.58}
 58%|█████▊    | 1379/2382 [5:09:49<3:36:38, 12.96s/it] 58%|█████▊    | 1380/2382 [5:10:02<3:36:02, 12.94s/it]                                                       {'loss': 1.9242, 'learning_rate': 0.00039670938933709774, 'epoch': 0.58}
 58%|█████▊    | 1380/2382 [5:10:02<3:36:02, 12.94s/it] 58%|█████▊    | 1381/2382 [5:10:18<3:50:40, 13.83s/it]                                                       {'loss': 1.7926, 'learning_rate': 0.0003960441545911204, 'epoch': 0.58}
 58%|█████▊    | 1381/2382 [5:10:18<3:50:40, 13.83s/it] 58%|█████▊    | 1382/2382 [5:10:31<3:47:28, 13.65s/it]                                                       {'loss': 1.8378, 'learning_rate': 0.0003953791121209458, 'epoch': 0.58}
 58%|█████▊    | 1382/2382 [5:10:31<3:47:28, 13.65s/it] 58%|█████▊    | 1383/2382 [5:10:44<3:41:53, 13.33s/it]                                                       {'loss': 1.77, 'learning_rate': 0.00039471426315663055, 'epoch': 0.58}
 58%|█████▊    | 1383/2382 [5:10:44<3:41:53, 13.33s/it] 58%|█████▊    | 1384/2382 [5:10:57<3:39:09, 13.18s/it]                                                       {'loss': 1.8354, 'learning_rate': 0.0003940496089278735, 'epoch': 0.58}
 58%|█████▊    | 1384/2382 [5:10:57<3:39:09, 13.18s/it] 58%|█████▊    | 1385/2382 [5:11:08<3:30:15, 12.65s/it]                                                       {'loss': 1.814, 'learning_rate': 0.0003933851506640131, 'epoch': 0.58}
 58%|█████▊    | 1385/2382 [5:11:08<3:30:15, 12.65s/it] 58%|█████▊    | 1386/2382 [5:11:21<3:31:36, 12.75s/it]                                                       {'loss': 1.7429, 'learning_rate': 0.00039272088959402534, 'epoch': 0.58}
 58%|█████▊    | 1386/2382 [5:11:21<3:31:36, 12.75s/it] 58%|█████▊    | 1387/2382 [5:11:34<3:30:59, 12.72s/it]                                                       {'loss': 1.8253, 'learning_rate': 0.00039205682694652157, 'epoch': 0.58}
 58%|█████▊    | 1387/2382 [5:11:34<3:30:59, 12.72s/it] 58%|█████▊    | 1388/2382 [5:11:51<3:52:44, 14.05s/it]                                                       {'loss': 1.8127, 'learning_rate': 0.0003913929639497462, 'epoch': 0.58}
 58%|█████▊    | 1388/2382 [5:11:51<3:52:44, 14.05s/it] 58%|█████▊    | 1389/2382 [5:12:05<3:54:59, 14.20s/it]                                                       {'loss': 1.7934, 'learning_rate': 0.0003907293018315742, 'epoch': 0.58}
 58%|█████▊    | 1389/2382 [5:12:05<3:54:59, 14.20s/it] 58%|█████▊    | 1390/2382 [5:12:19<3:54:05, 14.16s/it]                                                       {'loss': 1.86, 'learning_rate': 0.0003900658418195091, 'epoch': 0.58}
 58%|█████▊    | 1390/2382 [5:12:19<3:54:05, 14.16s/it] 58%|█████▊    | 1391/2382 [5:12:32<3:44:54, 13.62s/it]                                                       {'loss': 1.8684, 'learning_rate': 0.00038940258514068093, 'epoch': 0.58}
 58%|█████▊    | 1391/2382 [5:12:32<3:44:54, 13.62s/it] 58%|█████▊    | 1392/2382 [5:12:45<3:44:28, 13.60s/it]                                                       {'loss': 1.9527, 'learning_rate': 0.00038873953302184284, 'epoch': 0.58}
 58%|█████▊    | 1392/2382 [5:12:45<3:44:28, 13.60s/it] 58%|█████▊    | 1393/2382 [5:13:02<4:00:14, 14.57s/it]                                                       {'loss': 1.8535, 'learning_rate': 0.0003880766866893704, 'epoch': 0.58}
 58%|█████▊    | 1393/2382 [5:13:02<4:00:14, 14.57s/it] 59%|█████▊    | 1394/2382 [5:13:15<3:52:50, 14.14s/it]                                                       {'loss': 1.7516, 'learning_rate': 0.00038741404736925813, 'epoch': 0.59}
 59%|█████▊    | 1394/2382 [5:13:15<3:52:50, 14.14s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1211 > 1024). Running this sequence through the model will result in indexing errors
 59%|█████▊    | 1395/2382 [5:13:31<3:59:49, 14.58s/it]                                                       {'loss': 1.8371, 'learning_rate': 0.00038675161628711776, 'epoch': 0.59}
 59%|█████▊    | 1395/2382 [5:13:31<3:59:49, 14.58s/it] 59%|█████▊    | 1396/2382 [5:13:41<3:38:11, 13.28s/it]                                                       {'loss': 2.0067, 'learning_rate': 0.0003860893946681762, 'epoch': 0.59}
 59%|█████▊    | 1396/2382 [5:13:41<3:38:11, 13.28s/it] 59%|█████▊    | 1397/2382 [5:13:55<3:41:54, 13.52s/it]                                                       {'loss': 1.8809, 'learning_rate': 0.00038542738373727235, 'epoch': 0.59}
 59%|█████▊    | 1397/2382 [5:13:55<3:41:54, 13.52s/it] 59%|█████▊    | 1398/2382 [5:14:08<3:39:41, 13.40s/it]                                                       {'loss': 1.8096, 'learning_rate': 0.00038476558471885577, 'epoch': 0.59}
 59%|█████▊    | 1398/2382 [5:14:08<3:39:41, 13.40s/it] 59%|█████▊    | 1399/2382 [5:14:20<3:31:17, 12.90s/it]                                                       {'loss': 1.7781, 'learning_rate': 0.00038410399883698394, 'epoch': 0.59}
 59%|█████▊    | 1399/2382 [5:14:20<3:31:17, 12.90s/it] 59%|█████▉    | 1400/2382 [5:14:34<3:38:10, 13.33s/it]                                                       {'loss': 1.868, 'learning_rate': 0.0003834426273153204, 'epoch': 0.59}
 59%|█████▉    | 1400/2382 [5:14:34<3:38:10, 13.33s/it] 59%|█████▉    | 1401/2382 [5:14:48<3:39:58, 13.45s/it]                                                       {'loss': 1.8359, 'learning_rate': 0.0003827814713771318, 'epoch': 0.59}
 59%|█████▉    | 1401/2382 [5:14:48<3:39:58, 13.45s/it] 59%|█████▉    | 1402/2382 [5:15:02<3:41:23, 13.55s/it]                                                       {'loss': 1.7727, 'learning_rate': 0.0003821205322452863, 'epoch': 0.59}
 59%|█████▉    | 1402/2382 [5:15:02<3:41:23, 13.55s/it] 59%|█████▉    | 1403/2382 [5:15:14<3:32:04, 13.00s/it]                                                       {'loss': 1.8706, 'learning_rate': 0.0003814598111422513, 'epoch': 0.59}
 59%|█████▉    | 1403/2382 [5:15:14<3:32:04, 13.00s/it] 59%|█████▉    | 1404/2382 [5:15:25<3:21:22, 12.35s/it]                                                       {'loss': 1.9325, 'learning_rate': 0.0003807993092900903, 'epoch': 0.59}
 59%|█████▉    | 1404/2382 [5:15:25<3:21:22, 12.35s/it] 59%|█████▉    | 1405/2382 [5:15:39<3:33:55, 13.14s/it]                                                       {'loss': 1.9969, 'learning_rate': 0.0003801390279104617, 'epoch': 0.59}
 59%|█████▉    | 1405/2382 [5:15:39<3:33:55, 13.14s/it] 59%|█████▉    | 1406/2382 [5:15:53<3:35:15, 13.23s/it]                                                       {'loss': 1.8039, 'learning_rate': 0.000379478968224616, 'epoch': 0.59}
 59%|█████▉    | 1406/2382 [5:15:53<3:35:15, 13.23s/it] 59%|█████▉    | 1407/2382 [5:16:06<3:36:39, 13.33s/it]                                                       {'loss': 1.8633, 'learning_rate': 0.00037881913145339387, 'epoch': 0.59}
 59%|█████▉    | 1407/2382 [5:16:07<3:36:39, 13.33s/it] 59%|█████▉    | 1408/2382 [5:16:18<3:26:25, 12.72s/it]                                                       {'loss': 1.9257, 'learning_rate': 0.0003781595188172233, 'epoch': 0.59}
 59%|█████▉    | 1408/2382 [5:16:18<3:26:25, 12.72s/it] 59%|█████▉    | 1409/2382 [5:16:30<3:24:35, 12.62s/it]                                                       {'loss': 1.8787, 'learning_rate': 0.0003775001315361183, 'epoch': 0.59}
 59%|█████▉    | 1409/2382 [5:16:30<3:24:35, 12.62s/it] 59%|█████▉    | 1410/2382 [5:16:42<3:19:34, 12.32s/it]                                                       {'loss': 1.7853, 'learning_rate': 0.00037684097082967515, 'epoch': 0.59}
 59%|█████▉    | 1410/2382 [5:16:42<3:19:34, 12.32s/it] 59%|█████▉    | 1411/2382 [5:16:56<3:29:49, 12.97s/it]                                                       {'loss': 2.005, 'learning_rate': 0.000376182037917072, 'epoch': 0.59}
 59%|█████▉    | 1411/2382 [5:16:56<3:29:49, 12.97s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1060 > 1024). Running this sequence through the model will result in indexing errors
 59%|█████▉    | 1412/2382 [5:17:10<3:31:31, 13.08s/it]                                                       {'loss': 1.8917, 'learning_rate': 0.00037552333401706504, 'epoch': 0.59}
 59%|█████▉    | 1412/2382 [5:17:10<3:31:31, 13.08s/it] 59%|█████▉    | 1413/2382 [5:17:22<3:29:09, 12.95s/it]                                                       {'loss': 1.8522, 'learning_rate': 0.0003748648603479873, 'epoch': 0.59}
 59%|█████▉    | 1413/2382 [5:17:22<3:29:09, 12.95s/it] 59%|█████▉    | 1414/2382 [5:17:33<3:19:07, 12.34s/it]                                                       {'loss': 1.8174, 'learning_rate': 0.00037420661812774574, 'epoch': 0.59}
 59%|█████▉    | 1414/2382 [5:17:33<3:19:07, 12.34s/it] 59%|█████▉    | 1415/2382 [5:17:48<3:30:10, 13.04s/it]                                                       {'loss': 1.8807, 'learning_rate': 0.00037354860857381945, 'epoch': 0.59}
 59%|█████▉    | 1415/2382 [5:17:48<3:30:10, 13.04s/it] 59%|█████▉    | 1416/2382 [5:18:00<3:26:24, 12.82s/it]                                                       {'loss': 1.7531, 'learning_rate': 0.00037289083290325663, 'epoch': 0.59}
 59%|█████▉    | 1416/2382 [5:18:00<3:26:24, 12.82s/it] 59%|█████▉    | 1417/2382 [5:18:13<3:28:09, 12.94s/it]                                                       {'loss': 1.8882, 'learning_rate': 0.0003722332923326735, 'epoch': 0.59}
 59%|█████▉    | 1417/2382 [5:18:13<3:28:09, 12.94s/it] 60%|█████▉    | 1418/2382 [5:18:27<3:29:21, 13.03s/it]                                                       {'loss': 1.733, 'learning_rate': 0.00037157598807825134, 'epoch': 0.6}
 60%|█████▉    | 1418/2382 [5:18:27<3:29:21, 13.03s/it] 60%|█████▉    | 1419/2382 [5:18:41<3:33:48, 13.32s/it]                                                       {'loss': 1.8021, 'learning_rate': 0.000370918921355734, 'epoch': 0.6}
 60%|█████▉    | 1419/2382 [5:18:41<3:33:48, 13.32s/it] 60%|█████▉    | 1420/2382 [5:18:56<3:41:18, 13.80s/it]                                                       {'loss': 1.7767, 'learning_rate': 0.0003702620933804263, 'epoch': 0.6}
 60%|█████▉    | 1420/2382 [5:18:56<3:41:18, 13.80s/it] 60%|█████▉    | 1421/2382 [5:19:10<3:43:47, 13.97s/it]                                                       {'loss': 1.7929, 'learning_rate': 0.0003696055053671916, 'epoch': 0.6}
 60%|█████▉    | 1421/2382 [5:19:10<3:43:47, 13.97s/it] 60%|█████▉    | 1422/2382 [5:19:25<3:48:53, 14.31s/it]                                                       {'loss': 1.781, 'learning_rate': 0.00036894915853044906, 'epoch': 0.6}
 60%|█████▉    | 1422/2382 [5:19:25<3:48:53, 14.31s/it] 60%|█████▉    | 1423/2382 [5:19:38<3:41:31, 13.86s/it]                                                       {'loss': 1.8158, 'learning_rate': 0.00036829305408417166, 'epoch': 0.6}
 60%|█████▉    | 1423/2382 [5:19:38<3:41:31, 13.86s/it] 60%|█████▉    | 1424/2382 [5:19:53<3:48:13, 14.29s/it]                                                       {'loss': 1.8043, 'learning_rate': 0.0003676371932418847, 'epoch': 0.6}
 60%|█████▉    | 1424/2382 [5:19:53<3:48:13, 14.29s/it] 60%|█████▉    | 1425/2382 [5:20:06<3:40:36, 13.83s/it]                                                       {'loss': 1.8174, 'learning_rate': 0.0003669815772166625, 'epoch': 0.6}
 60%|█████▉    | 1425/2382 [5:20:06<3:40:36, 13.83s/it] 60%|█████▉    | 1426/2382 [5:20:20<3:43:52, 14.05s/it]                                                       {'loss': 1.7802, 'learning_rate': 0.00036632620722112637, 'epoch': 0.6}
 60%|█████▉    | 1426/2382 [5:20:20<3:43:52, 14.05s/it] 60%|█████▉    | 1427/2382 [5:20:36<3:51:33, 14.55s/it]                                                       {'loss': 1.778, 'learning_rate': 0.0003656710844674431, 'epoch': 0.6}
 60%|█████▉    | 1427/2382 [5:20:36<3:51:33, 14.55s/it] 60%|█████▉    | 1428/2382 [5:20:51<3:53:06, 14.66s/it]                                                       {'loss': 1.8981, 'learning_rate': 0.00036501621016732155, 'epoch': 0.6}
 60%|█████▉    | 1428/2382 [5:20:51<3:53:06, 14.66s/it] 60%|█████▉    | 1429/2382 [5:21:04<3:46:01, 14.23s/it]                                                       {'loss': 1.8733, 'learning_rate': 0.0003643615855320117, 'epoch': 0.6}
 60%|█████▉    | 1429/2382 [5:21:04<3:46:01, 14.23s/it] 60%|██████    | 1430/2382 [5:21:19<3:46:26, 14.27s/it]                                                       {'loss': 1.8938, 'learning_rate': 0.00036370721177230114, 'epoch': 0.6}
 60%|██████    | 1430/2382 [5:21:19<3:46:26, 14.27s/it] 60%|██████    | 1431/2382 [5:21:33<3:45:16, 14.21s/it]                                                       {'loss': 1.9148, 'learning_rate': 0.00036305309009851384, 'epoch': 0.6}
 60%|██████    | 1431/2382 [5:21:33<3:45:16, 14.21s/it] 60%|██████    | 1432/2382 [5:21:46<3:41:11, 13.97s/it]                                                       {'loss': 1.9046, 'learning_rate': 0.00036239922172050747, 'epoch': 0.6}
 60%|██████    | 1432/2382 [5:21:46<3:41:11, 13.97s/it] 60%|██████    | 1433/2382 [5:21:59<3:34:27, 13.56s/it]                                                       {'loss': 1.7998, 'learning_rate': 0.0003617456078476712, 'epoch': 0.6}
 60%|██████    | 1433/2382 [5:21:59<3:34:27, 13.56s/it] 60%|██████    | 1434/2382 [5:22:12<3:30:30, 13.32s/it]                                                       {'loss': 1.8825, 'learning_rate': 0.00036109224968892316, 'epoch': 0.6}
 60%|██████    | 1434/2382 [5:22:12<3:30:30, 13.32s/it] 60%|██████    | 1435/2382 [5:22:23<3:22:19, 12.82s/it]                                                       {'loss': 1.8066, 'learning_rate': 0.0003604391484527089, 'epoch': 0.6}
 60%|██████    | 1435/2382 [5:22:23<3:22:19, 12.82s/it] 60%|██████    | 1436/2382 [5:22:39<3:34:52, 13.63s/it]                                                       {'loss': 1.8243, 'learning_rate': 0.0003597863053469987, 'epoch': 0.6}
 60%|██████    | 1436/2382 [5:22:39<3:34:52, 13.63s/it] 60%|██████    | 1437/2382 [5:22:53<3:40:05, 13.97s/it]                                                       {'loss': 1.8909, 'learning_rate': 0.0003591337215792851, 'epoch': 0.6}
 60%|██████    | 1437/2382 [5:22:53<3:40:05, 13.97s/it] 60%|██████    | 1438/2382 [5:23:08<3:41:56, 14.11s/it]                                                       {'loss': 1.9097, 'learning_rate': 0.0003584813983565815, 'epoch': 0.6}
 60%|██████    | 1438/2382 [5:23:08<3:41:56, 14.11s/it] 60%|██████    | 1439/2382 [5:23:22<3:41:42, 14.11s/it]                                                       {'loss': 1.7722, 'learning_rate': 0.00035782933688541913, 'epoch': 0.6}
 60%|██████    | 1439/2382 [5:23:22<3:41:42, 14.11s/it] 60%|██████    | 1440/2382 [5:23:34<3:33:42, 13.61s/it]                                                       {'loss': 1.8273, 'learning_rate': 0.0003571775383718447, 'epoch': 0.6}
 60%|██████    | 1440/2382 [5:23:34<3:33:42, 13.61s/it] 60%|██████    | 1441/2382 [5:23:50<3:40:28, 14.06s/it]                                                       {'loss': 1.8297, 'learning_rate': 0.00035652600402141923, 'epoch': 0.6}
 60%|██████    | 1441/2382 [5:23:50<3:40:28, 14.06s/it] 61%|██████    | 1442/2382 [5:24:02<3:33:22, 13.62s/it]                                                       {'loss': 1.8095, 'learning_rate': 0.00035587473503921455, 'epoch': 0.61}
 61%|██████    | 1442/2382 [5:24:02<3:33:22, 13.62s/it] 61%|██████    | 1443/2382 [5:24:16<3:34:49, 13.73s/it]                                                       {'loss': 1.9441, 'learning_rate': 0.00035522373262981223, 'epoch': 0.61}
 61%|██████    | 1443/2382 [5:24:16<3:34:49, 13.73s/it] 61%|██████    | 1444/2382 [5:24:29<3:29:45, 13.42s/it]                                                       {'loss': 1.8068, 'learning_rate': 0.00035457299799730046, 'epoch': 0.61}
 61%|██████    | 1444/2382 [5:24:29<3:29:45, 13.42s/it] 61%|██████    | 1445/2382 [5:24:42<3:26:24, 13.22s/it]                                                       {'loss': 1.8648, 'learning_rate': 0.00035392253234527225, 'epoch': 0.61}
 61%|██████    | 1445/2382 [5:24:42<3:26:24, 13.22s/it] 61%|██████    | 1446/2382 [5:24:55<3:27:47, 13.32s/it]                                                       {'loss': 1.854, 'learning_rate': 0.00035327233687682273, 'epoch': 0.61}
 61%|██████    | 1446/2382 [5:24:55<3:27:47, 13.32s/it] 61%|██████    | 1447/2382 [5:25:08<3:25:33, 13.19s/it]                                                       {'loss': 1.8577, 'learning_rate': 0.00035262241279454787, 'epoch': 0.61}
 61%|██████    | 1447/2382 [5:25:08<3:25:33, 13.19s/it] 61%|██████    | 1448/2382 [5:25:22<3:29:02, 13.43s/it]                                                       {'loss': 1.8515, 'learning_rate': 0.0003519727613005416, 'epoch': 0.61}
 61%|██████    | 1448/2382 [5:25:22<3:29:02, 13.43s/it] 61%|██████    | 1449/2382 [5:25:35<3:27:07, 13.32s/it]                                                       {'loss': 1.8275, 'learning_rate': 0.00035132338359639316, 'epoch': 0.61}
 61%|██████    | 1449/2382 [5:25:35<3:27:07, 13.32s/it] 61%|██████    | 1450/2382 [5:25:49<3:29:46, 13.51s/it]                                                       {'loss': 1.8175, 'learning_rate': 0.000350674280883186, 'epoch': 0.61}
 61%|██████    | 1450/2382 [5:25:49<3:29:46, 13.51s/it] 61%|██████    | 1451/2382 [5:26:03<3:31:49, 13.65s/it]                                                       {'loss': 1.8617, 'learning_rate': 0.00035002545436149473, 'epoch': 0.61}
 61%|██████    | 1451/2382 [5:26:03<3:31:49, 13.65s/it] 61%|██████    | 1452/2382 [5:26:16<3:29:00, 13.48s/it]                                                       {'loss': 1.867, 'learning_rate': 0.000349376905231383, 'epoch': 0.61}
 61%|██████    | 1452/2382 [5:26:16<3:29:00, 13.48s/it] 61%|██████    | 1453/2382 [5:26:29<3:27:59, 13.43s/it]                                                       {'loss': 1.856, 'learning_rate': 0.00034872863469240136, 'epoch': 0.61}
 61%|██████    | 1453/2382 [5:26:29<3:27:59, 13.43s/it] 61%|██████    | 1454/2382 [5:26:41<3:17:37, 12.78s/it]                                                       {'loss': 1.8381, 'learning_rate': 0.00034808064394358526, 'epoch': 0.61}
 61%|██████    | 1454/2382 [5:26:41<3:17:37, 12.78s/it] 61%|██████    | 1455/2382 [5:26:53<3:17:31, 12.78s/it]                                                       {'loss': 1.8476, 'learning_rate': 0.00034743293418345277, 'epoch': 0.61}
 61%|██████    | 1455/2382 [5:26:53<3:17:31, 12.78s/it] 61%|██████    | 1456/2382 [5:27:08<3:25:17, 13.30s/it]                                                       {'loss': 1.8247, 'learning_rate': 0.00034678550661000195, 'epoch': 0.61}
 61%|██████    | 1456/2382 [5:27:08<3:25:17, 13.30s/it] 61%|██████    | 1457/2382 [5:27:20<3:17:04, 12.78s/it]                                                       {'loss': 1.8716, 'learning_rate': 0.0003461383624207092, 'epoch': 0.61}
 61%|██████    | 1457/2382 [5:27:20<3:17:04, 12.78s/it] 61%|██████    | 1458/2382 [5:27:34<3:24:44, 13.29s/it]                                                       {'loss': 1.9115, 'learning_rate': 0.00034549150281252633, 'epoch': 0.61}
 61%|██████    | 1458/2382 [5:27:34<3:24:44, 13.29s/it] 61%|██████▏   | 1459/2382 [5:27:49<3:30:17, 13.67s/it]                                                       {'loss': 1.9503, 'learning_rate': 0.00034484492898187934, 'epoch': 0.61}
 61%|██████▏   | 1459/2382 [5:27:49<3:30:17, 13.67s/it] 61%|██████▏   | 1460/2382 [5:28:05<3:43:24, 14.54s/it]                                                       {'loss': 1.8264, 'learning_rate': 0.0003441986421246653, 'epoch': 0.61}
 61%|██████▏   | 1460/2382 [5:28:05<3:43:24, 14.54s/it] 61%|██████▏   | 1461/2382 [5:28:19<3:38:29, 14.23s/it]                                                       {'loss': 1.7571, 'learning_rate': 0.0003435526434362506, 'epoch': 0.61}
 61%|██████▏   | 1461/2382 [5:28:19<3:38:29, 14.23s/it] 61%|██████▏   | 1462/2382 [5:28:30<3:26:03, 13.44s/it]                                                       {'loss': 1.9344, 'learning_rate': 0.00034290693411146876, 'epoch': 0.61}
 61%|██████▏   | 1462/2382 [5:28:30<3:26:03, 13.44s/it] 61%|██████▏   | 1463/2382 [5:28:44<3:27:06, 13.52s/it]                                                       {'loss': 1.897, 'learning_rate': 0.000342261515344618, 'epoch': 0.61}
 61%|██████▏   | 1463/2382 [5:28:44<3:27:06, 13.52s/it] 61%|██████▏   | 1464/2382 [5:29:00<3:38:38, 14.29s/it]                                                       {'loss': 1.8101, 'learning_rate': 0.00034161638832945886, 'epoch': 0.61}
 61%|██████▏   | 1464/2382 [5:29:00<3:38:38, 14.29s/it] 62%|██████▏   | 1465/2382 [5:29:14<3:36:25, 14.16s/it]                                                       {'loss': 1.762, 'learning_rate': 0.00034097155425921255, 'epoch': 0.61}
 62%|██████▏   | 1465/2382 [5:29:14<3:36:25, 14.16s/it] 62%|██████▏   | 1466/2382 [5:29:25<3:23:50, 13.35s/it]                                                       {'loss': 1.8849, 'learning_rate': 0.0003403270143265587, 'epoch': 0.62}
 62%|██████▏   | 1466/2382 [5:29:25<3:23:50, 13.35s/it] 62%|██████▏   | 1467/2382 [5:29:38<3:20:04, 13.12s/it]                                                       {'loss': 1.9, 'learning_rate': 0.0003396827697236322, 'epoch': 0.62}
 62%|██████▏   | 1467/2382 [5:29:38<3:20:04, 13.12s/it] 62%|██████▏   | 1468/2382 [5:29:51<3:18:03, 13.00s/it]                                                       {'loss': 1.8673, 'learning_rate': 0.00033903882164202243, 'epoch': 0.62}
 62%|██████▏   | 1468/2382 [5:29:51<3:18:03, 13.00s/it] 62%|██████▏   | 1469/2382 [5:30:07<3:32:26, 13.96s/it]                                                       {'loss': 1.8743, 'learning_rate': 0.00033839517127277007, 'epoch': 0.62}
 62%|██████▏   | 1469/2382 [5:30:07<3:32:26, 13.96s/it] 62%|██████▏   | 1470/2382 [5:30:21<3:34:48, 14.13s/it]                                                       {'loss': 1.8942, 'learning_rate': 0.00033775181980636484, 'epoch': 0.62}
 62%|██████▏   | 1470/2382 [5:30:21<3:34:48, 14.13s/it] 62%|██████▏   | 1471/2382 [5:30:33<3:24:27, 13.47s/it]                                                       {'loss': 1.8353, 'learning_rate': 0.0003371087684327438, 'epoch': 0.62}
 62%|██████▏   | 1471/2382 [5:30:33<3:24:27, 13.47s/it] 62%|██████▏   | 1472/2382 [5:30:50<3:39:07, 14.45s/it]                                                       {'loss': 1.7515, 'learning_rate': 0.0003364660183412892, 'epoch': 0.62}
 62%|██████▏   | 1472/2382 [5:30:50<3:39:07, 14.45s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1774 > 1024). Running this sequence through the model will result in indexing errors
 62%|██████▏   | 1473/2382 [5:31:01<3:24:17, 13.48s/it]                                                       {'loss': 1.7874, 'learning_rate': 0.0003358235707208259, 'epoch': 0.62}
 62%|██████▏   | 1473/2382 [5:31:01<3:24:17, 13.48s/it] 62%|██████▏   | 1474/2382 [5:31:16<3:27:50, 13.73s/it]                                                       {'loss': 1.7489, 'learning_rate': 0.00033518142675961917, 'epoch': 0.62}
 62%|██████▏   | 1474/2382 [5:31:16<3:27:50, 13.73s/it] 62%|██████▏   | 1475/2382 [5:31:27<3:17:44, 13.08s/it]                                                       {'loss': 1.9677, 'learning_rate': 0.00033453958764537297, 'epoch': 0.62}
 62%|██████▏   | 1475/2382 [5:31:27<3:17:44, 13.08s/it] 62%|██████▏   | 1476/2382 [5:31:39<3:10:59, 12.65s/it]                                                       {'loss': 1.861, 'learning_rate': 0.0003338980545652267, 'epoch': 0.62}
 62%|██████▏   | 1476/2382 [5:31:39<3:10:59, 12.65s/it] 62%|██████▏   | 1477/2382 [5:31:51<3:07:02, 12.40s/it]                                                       {'loss': 1.8155, 'learning_rate': 0.00033325682870575477, 'epoch': 0.62}
 62%|██████▏   | 1477/2382 [5:31:51<3:07:02, 12.40s/it] 62%|██████▏   | 1478/2382 [5:32:03<3:06:45, 12.40s/it]                                                       {'loss': 1.8954, 'learning_rate': 0.0003326159112529624, 'epoch': 0.62}
 62%|██████▏   | 1478/2382 [5:32:03<3:06:45, 12.40s/it] 62%|██████▏   | 1479/2382 [5:32:17<3:14:01, 12.89s/it]                                                       {'loss': 1.8681, 'learning_rate': 0.00033197530339228485, 'epoch': 0.62}
 62%|██████▏   | 1479/2382 [5:32:17<3:14:01, 12.89s/it] 62%|██████▏   | 1480/2382 [5:32:29<3:11:01, 12.71s/it]                                                       {'loss': 1.8746, 'learning_rate': 0.00033133500630858504, 'epoch': 0.62}
 62%|██████▏   | 1480/2382 [5:32:29<3:11:01, 12.71s/it] 62%|██████▏   | 1481/2382 [5:32:45<3:23:59, 13.58s/it]                                                       {'loss': 1.8171, 'learning_rate': 0.00033069502118615037, 'epoch': 0.62}
 62%|██████▏   | 1481/2382 [5:32:45<3:23:59, 13.58s/it] 62%|██████▏   | 1482/2382 [5:32:56<3:13:29, 12.90s/it]                                                       {'loss': 1.8857, 'learning_rate': 0.00033005534920869175, 'epoch': 0.62}
 62%|██████▏   | 1482/2382 [5:32:56<3:13:29, 12.90s/it] 62%|██████▏   | 1483/2382 [5:33:09<3:14:42, 12.99s/it]                                                       {'loss': 1.8591, 'learning_rate': 0.00032941599155934055, 'epoch': 0.62}
 62%|██████▏   | 1483/2382 [5:33:09<3:14:42, 12.99s/it] 62%|██████▏   | 1484/2382 [5:33:21<3:09:40, 12.67s/it]                                                       {'loss': 1.8803, 'learning_rate': 0.00032877694942064716, 'epoch': 0.62}
 62%|██████▏   | 1484/2382 [5:33:21<3:09:40, 12.67s/it] 62%|██████▏   | 1485/2382 [5:33:36<3:17:27, 13.21s/it]                                                       {'loss': 1.8661, 'learning_rate': 0.00032813822397457826, 'epoch': 0.62}
 62%|██████▏   | 1485/2382 [5:33:36<3:17:27, 13.21s/it] 62%|██████▏   | 1486/2382 [5:33:50<3:22:22, 13.55s/it]                                                       {'loss': 1.831, 'learning_rate': 0.0003274998164025148, 'epoch': 0.62}
 62%|██████▏   | 1486/2382 [5:33:50<3:22:22, 13.55s/it] 62%|██████▏   | 1487/2382 [5:34:04<3:22:42, 13.59s/it]                                                       {'loss': 1.8884, 'learning_rate': 0.0003268617278852494, 'epoch': 0.62}
 62%|██████▏   | 1487/2382 [5:34:04<3:22:42, 13.59s/it] 62%|██████▏   | 1488/2382 [5:34:18<3:25:55, 13.82s/it]                                                       {'loss': 1.8546, 'learning_rate': 0.0003262239596029849, 'epoch': 0.62}
 62%|██████▏   | 1488/2382 [5:34:18<3:25:55, 13.82s/it] 63%|██████▎   | 1489/2382 [5:34:31<3:20:17, 13.46s/it]                                                       {'loss': 1.8129, 'learning_rate': 0.0003255865127353321, 'epoch': 0.62}
 63%|██████▎   | 1489/2382 [5:34:31<3:20:17, 13.46s/it] 63%|██████▎   | 1490/2382 [5:34:45<3:25:20, 13.81s/it]                                                       {'loss': 1.9564, 'learning_rate': 0.0003249493884613069, 'epoch': 0.63}
 63%|██████▎   | 1490/2382 [5:34:45<3:25:20, 13.81s/it] 63%|██████▎   | 1491/2382 [5:34:59<3:22:19, 13.62s/it]                                                       {'loss': 1.9606, 'learning_rate': 0.0003243125879593286, 'epoch': 0.63}
 63%|██████▎   | 1491/2382 [5:34:59<3:22:19, 13.62s/it] 63%|██████▎   | 1492/2382 [5:35:13<3:24:52, 13.81s/it]                                                       {'loss': 1.9108, 'learning_rate': 0.00032367611240721793, 'epoch': 0.63}
 63%|██████▎   | 1492/2382 [5:35:13<3:24:52, 13.81s/it] 63%|██████▎   | 1493/2382 [5:35:25<3:17:01, 13.30s/it]                                                       {'loss': 1.8743, 'learning_rate': 0.00032303996298219416, 'epoch': 0.63}
 63%|██████▎   | 1493/2382 [5:35:25<3:17:01, 13.30s/it] 63%|██████▎   | 1494/2382 [5:35:38<3:17:32, 13.35s/it]                                                       {'loss': 1.8337, 'learning_rate': 0.00032240414086087357, 'epoch': 0.63}
 63%|██████▎   | 1494/2382 [5:35:38<3:17:32, 13.35s/it] 63%|██████▎   | 1495/2382 [5:35:55<3:30:54, 14.27s/it]                                                       {'loss': 1.7864, 'learning_rate': 0.0003217686472192671, 'epoch': 0.63}
 63%|██████▎   | 1495/2382 [5:35:55<3:30:54, 14.27s/it] 63%|██████▎   | 1496/2382 [5:36:08<3:27:33, 14.06s/it]                                                       {'loss': 1.8156, 'learning_rate': 0.00032113348323277837, 'epoch': 0.63}
 63%|██████▎   | 1496/2382 [5:36:08<3:27:33, 14.06s/it] 63%|██████▎   | 1497/2382 [5:36:22<3:24:33, 13.87s/it]                                                       {'loss': 1.8867, 'learning_rate': 0.0003204986500762006, 'epoch': 0.63}
 63%|██████▎   | 1497/2382 [5:36:22<3:24:33, 13.87s/it] 63%|██████▎   | 1498/2382 [5:36:34<3:18:09, 13.45s/it]                                                       {'loss': 1.7425, 'learning_rate': 0.000319864148923716, 'epoch': 0.63}
 63%|██████▎   | 1498/2382 [5:36:34<3:18:09, 13.45s/it] 63%|██████▎   | 1499/2382 [5:36:46<3:11:39, 13.02s/it]                                                       {'loss': 1.8583, 'learning_rate': 0.00031922998094889175, 'epoch': 0.63}
 63%|██████▎   | 1499/2382 [5:36:46<3:11:39, 13.02s/it] 63%|██████▎   | 1500/2382 [5:36:59<3:09:03, 12.86s/it]                                                       {'loss': 1.7932, 'learning_rate': 0.00031859614732467957, 'epoch': 0.63}
 63%|██████▎   | 1500/2382 [5:36:59<3:09:03, 12.86s/it] 63%|██████▎   | 1501/2382 [5:37:12<3:10:55, 13.00s/it]                                                       {'loss': 1.7627, 'learning_rate': 0.0003179626492234123, 'epoch': 0.63}
 63%|██████▎   | 1501/2382 [5:37:12<3:10:55, 13.00s/it] 63%|██████▎   | 1502/2382 [5:37:25<3:10:42, 13.00s/it]                                                       {'loss': 1.8865, 'learning_rate': 0.0003173294878168025, 'epoch': 0.63}
 63%|██████▎   | 1502/2382 [5:37:25<3:10:42, 13.00s/it] 63%|██████▎   | 1503/2382 [5:37:40<3:20:23, 13.68s/it]                                                       {'loss': 1.7878, 'learning_rate': 0.0003166966642759398, 'epoch': 0.63}
 63%|██████▎   | 1503/2382 [5:37:40<3:20:23, 13.68s/it] 63%|██████▎   | 1504/2382 [5:37:55<3:22:03, 13.81s/it]                                                       {'loss': 1.8812, 'learning_rate': 0.0003160641797712891, 'epoch': 0.63}
 63%|██████▎   | 1504/2382 [5:37:55<3:22:03, 13.81s/it] 63%|██████▎   | 1505/2382 [5:38:08<3:20:49, 13.74s/it]                                                       {'loss': 1.8595, 'learning_rate': 0.0003154320354726878, 'epoch': 0.63}
 63%|██████▎   | 1505/2382 [5:38:08<3:20:49, 13.74s/it] 63%|██████▎   | 1506/2382 [5:38:22<3:20:05, 13.71s/it]                                                       {'loss': 1.8788, 'learning_rate': 0.0003148002325493445, 'epoch': 0.63}
 63%|██████▎   | 1506/2382 [5:38:22<3:20:05, 13.71s/it] 63%|██████▎   | 1507/2382 [5:38:37<3:26:23, 14.15s/it]                                                       {'loss': 1.8521, 'learning_rate': 0.0003141687721698363, 'epoch': 0.63}
 63%|██████▎   | 1507/2382 [5:38:37<3:26:23, 14.15s/it] 63%|██████▎   | 1508/2382 [5:38:50<3:21:44, 13.85s/it]                                                       {'loss': 1.7679, 'learning_rate': 0.00031353765550210655, 'epoch': 0.63}
 63%|██████▎   | 1508/2382 [5:38:50<3:21:44, 13.85s/it] 63%|██████▎   | 1509/2382 [5:39:05<3:25:39, 14.13s/it]                                                       {'loss': 1.7772, 'learning_rate': 0.0003129068837134631, 'epoch': 0.63}
 63%|██████▎   | 1509/2382 [5:39:05<3:25:39, 14.13s/it] 63%|██████▎   | 1510/2382 [5:39:19<3:23:55, 14.03s/it]                                                       {'loss': 1.9107, 'learning_rate': 0.0003122764579705759, 'epoch': 0.63}
 63%|██████▎   | 1510/2382 [5:39:19<3:23:55, 14.03s/it] 63%|██████▎   | 1511/2382 [5:39:31<3:18:16, 13.66s/it]                                                       {'loss': 1.8297, 'learning_rate': 0.0003116463794394746, 'epoch': 0.63}
 63%|██████▎   | 1511/2382 [5:39:32<3:18:16, 13.66s/it] 63%|██████▎   | 1512/2382 [5:39:44<3:12:30, 13.28s/it]                                                       {'loss': 1.8834, 'learning_rate': 0.0003110166492855468, 'epoch': 0.63}
 63%|██████▎   | 1512/2382 [5:39:44<3:12:30, 13.28s/it] 64%|██████▎   | 1513/2382 [5:39:57<3:11:55, 13.25s/it]                                                       {'loss': 1.8588, 'learning_rate': 0.00031038726867353586, 'epoch': 0.63}
 64%|██████▎   | 1513/2382 [5:39:57<3:11:55, 13.25s/it] 64%|██████▎   | 1514/2382 [5:40:09<3:04:05, 12.73s/it]                                                       {'loss': 1.9682, 'learning_rate': 0.0003097582387675385, 'epoch': 0.64}
 64%|██████▎   | 1514/2382 [5:40:09<3:04:05, 12.73s/it] 64%|██████▎   | 1515/2382 [5:40:23<3:10:40, 13.20s/it]                                                       {'loss': 1.7907, 'learning_rate': 0.00030912956073100286, 'epoch': 0.64}
 64%|██████▎   | 1515/2382 [5:40:23<3:10:40, 13.20s/it] 64%|██████▎   | 1516/2382 [5:40:36<3:10:41, 13.21s/it]                                                       {'loss': 1.8231, 'learning_rate': 0.00030850123572672626, 'epoch': 0.64}
 64%|██████▎   | 1516/2382 [5:40:36<3:10:41, 13.21s/it] 64%|██████▎   | 1517/2382 [5:40:48<3:02:37, 12.67s/it]                                                       {'loss': 1.7964, 'learning_rate': 0.00030787326491685284, 'epoch': 0.64}
 64%|██████▎   | 1517/2382 [5:40:48<3:02:37, 12.67s/it] 64%|██████▎   | 1518/2382 [5:41:01<3:04:18, 12.80s/it]                                                       {'loss': 1.8712, 'learning_rate': 0.00030724564946287204, 'epoch': 0.64}
 64%|██████▎   | 1518/2382 [5:41:01<3:04:18, 12.80s/it] 64%|██████▍   | 1519/2382 [5:41:12<2:59:08, 12.45s/it]                                                       {'loss': 1.7545, 'learning_rate': 0.00030661839052561546, 'epoch': 0.64}
 64%|██████▍   | 1519/2382 [5:41:12<2:59:08, 12.45s/it] 64%|██████▍   | 1520/2382 [5:41:25<2:59:46, 12.51s/it]                                                       {'loss': 1.8887, 'learning_rate': 0.0003059914892652559, 'epoch': 0.64}
 64%|██████▍   | 1520/2382 [5:41:25<2:59:46, 12.51s/it] 64%|██████▍   | 1521/2382 [5:41:40<3:09:48, 13.23s/it]                                                       {'loss': 1.8679, 'learning_rate': 0.0003053649468413043, 'epoch': 0.64}
 64%|██████▍   | 1521/2382 [5:41:40<3:09:48, 13.23s/it] 64%|██████▍   | 1522/2382 [5:41:51<3:02:47, 12.75s/it]                                                       {'loss': 1.8047, 'learning_rate': 0.00030473876441260785, 'epoch': 0.64}
 64%|██████▍   | 1522/2382 [5:41:51<3:02:47, 12.75s/it] 64%|██████▍   | 1523/2382 [5:42:03<2:57:43, 12.41s/it]                                                       {'loss': 1.8062, 'learning_rate': 0.00030411294313734805, 'epoch': 0.64}
 64%|██████▍   | 1523/2382 [5:42:03<2:57:43, 12.41s/it] 64%|██████▍   | 1524/2382 [5:42:17<3:03:29, 12.83s/it]                                                       {'loss': 1.8492, 'learning_rate': 0.0003034874841730382, 'epoch': 0.64}
 64%|██████▍   | 1524/2382 [5:42:17<3:03:29, 12.83s/it] 64%|██████▍   | 1525/2382 [5:42:28<2:58:01, 12.46s/it]                                                       {'loss': 1.8861, 'learning_rate': 0.00030286238867652184, 'epoch': 0.64}
 64%|██████▍   | 1525/2382 [5:42:28<2:58:01, 12.46s/it] 64%|██████▍   | 1526/2382 [5:42:41<2:59:57, 12.61s/it]                                                       {'loss': 1.8471, 'learning_rate': 0.00030223765780396973, 'epoch': 0.64}
 64%|██████▍   | 1526/2382 [5:42:41<2:59:57, 12.61s/it] 64%|██████▍   | 1527/2382 [5:42:53<2:53:52, 12.20s/it]                                                       {'loss': 1.9261, 'learning_rate': 0.00030161329271087865, 'epoch': 0.64}
 64%|██████▍   | 1527/2382 [5:42:53<2:53:52, 12.20s/it] 64%|██████▍   | 1528/2382 [5:43:08<3:05:24, 13.03s/it]                                                       {'loss': 1.884, 'learning_rate': 0.00030098929455206903, 'epoch': 0.64}
 64%|██████▍   | 1528/2382 [5:43:08<3:05:24, 13.03s/it] 64%|██████▍   | 1529/2382 [5:43:20<3:00:18, 12.68s/it]                                                       {'loss': 1.8658, 'learning_rate': 0.0003003656644816817, 'epoch': 0.64}
 64%|██████▍   | 1529/2382 [5:43:20<3:00:18, 12.68s/it] 64%|██████▍   | 1530/2382 [5:43:34<3:09:31, 13.35s/it]                                                       {'loss': 1.8222, 'learning_rate': 0.00029974240365317754, 'epoch': 0.64}
 64%|██████▍   | 1530/2382 [5:43:34<3:09:31, 13.35s/it] 64%|██████▍   | 1531/2382 [5:43:47<3:05:49, 13.10s/it]                                                       {'loss': 1.8556, 'learning_rate': 0.0002991195132193342, 'epoch': 0.64}
 64%|██████▍   | 1531/2382 [5:43:47<3:05:49, 13.10s/it] 64%|██████▍   | 1532/2382 [5:44:01<3:08:34, 13.31s/it]                                                       {'loss': 1.7065, 'learning_rate': 0.0002984969943322442, 'epoch': 0.64}
 64%|██████▍   | 1532/2382 [5:44:01<3:08:34, 13.31s/it] 64%|██████▍   | 1533/2382 [5:44:15<3:12:59, 13.64s/it]                                                       {'loss': 1.8936, 'learning_rate': 0.0002978748481433131, 'epoch': 0.64}
 64%|██████▍   | 1533/2382 [5:44:15<3:12:59, 13.64s/it] 64%|██████▍   | 1534/2382 [5:44:30<3:19:09, 14.09s/it]                                                       {'loss': 1.8841, 'learning_rate': 0.000297253075803257, 'epoch': 0.64}
 64%|██████▍   | 1534/2382 [5:44:30<3:19:09, 14.09s/it] 64%|██████▍   | 1535/2382 [5:44:45<3:22:59, 14.38s/it]                                                       {'loss': 1.9014, 'learning_rate': 0.0002966316784621, 'epoch': 0.64}
 64%|██████▍   | 1535/2382 [5:44:45<3:22:59, 14.38s/it] 64%|██████▍   | 1536/2382 [5:44:59<3:18:09, 14.05s/it]                                                       {'loss': 1.8056, 'learning_rate': 0.0002960106572691733, 'epoch': 0.64}
 64%|██████▍   | 1536/2382 [5:44:59<3:18:09, 14.05s/it] 65%|██████▍   | 1537/2382 [5:45:13<3:18:03, 14.06s/it]                                                       {'loss': 1.8616, 'learning_rate': 0.0002953900133731123, 'epoch': 0.65}
 65%|██████▍   | 1537/2382 [5:45:13<3:18:03, 14.06s/it] 65%|██████▍   | 1538/2382 [5:45:28<3:22:48, 14.42s/it]                                                       {'loss': 1.7953, 'learning_rate': 0.0002947697479218543, 'epoch': 0.65}
 65%|██████▍   | 1538/2382 [5:45:28<3:22:48, 14.42s/it] 65%|██████▍   | 1539/2382 [5:45:45<3:34:41, 15.28s/it]                                                       {'loss': 1.8254, 'learning_rate': 0.0002941498620626366, 'epoch': 0.65}
 65%|██████▍   | 1539/2382 [5:45:45<3:34:41, 15.28s/it] 65%|██████▍   | 1540/2382 [5:45:59<3:26:23, 14.71s/it]                                                       {'loss': 1.9345, 'learning_rate': 0.0002935303569419949, 'epoch': 0.65}
 65%|██████▍   | 1540/2382 [5:45:59<3:26:23, 14.71s/it] 65%|██████▍   | 1541/2382 [5:46:12<3:19:32, 14.24s/it]                                                       {'loss': 1.9512, 'learning_rate': 0.0002929112337057601, 'epoch': 0.65}
 65%|██████▍   | 1541/2382 [5:46:12<3:19:32, 14.24s/it] 65%|██████▍   | 1542/2382 [5:46:26<3:18:01, 14.14s/it]                                                       {'loss': 1.905, 'learning_rate': 0.0002922924934990568, 'epoch': 0.65}
 65%|██████▍   | 1542/2382 [5:46:26<3:18:01, 14.14s/it] 65%|██████▍   | 1543/2382 [5:46:38<3:10:55, 13.65s/it]                                                       {'loss': 1.8495, 'learning_rate': 0.00029167413746630176, 'epoch': 0.65}
 65%|██████▍   | 1543/2382 [5:46:38<3:10:55, 13.65s/it] 65%|██████▍   | 1544/2382 [5:46:53<3:15:16, 13.98s/it]                                                       {'loss': 1.7974, 'learning_rate': 0.0002910561667512005, 'epoch': 0.65}
 65%|██████▍   | 1544/2382 [5:46:53<3:15:16, 13.98s/it] 65%|██████▍   | 1545/2382 [5:47:05<3:08:24, 13.51s/it]                                                       {'loss': 1.9073, 'learning_rate': 0.00029043858249674616, 'epoch': 0.65}
 65%|██████▍   | 1545/2382 [5:47:05<3:08:24, 13.51s/it] 65%|██████▍   | 1546/2382 [5:47:23<3:23:53, 14.63s/it]                                                       {'loss': 1.7579, 'learning_rate': 0.0002898213858452173, 'epoch': 0.65}
 65%|██████▍   | 1546/2382 [5:47:23<3:23:53, 14.63s/it] 65%|██████▍   | 1547/2382 [5:47:38<3:25:56, 14.80s/it]                                                       {'loss': 1.744, 'learning_rate': 0.00028920457793817506, 'epoch': 0.65}
 65%|██████▍   | 1547/2382 [5:47:38<3:25:56, 14.80s/it] 65%|██████▍   | 1548/2382 [5:47:49<3:11:27, 13.77s/it]                                                       {'loss': 1.8611, 'learning_rate': 0.00028858815991646185, 'epoch': 0.65}
 65%|██████▍   | 1548/2382 [5:47:49<3:11:27, 13.77s/it] 65%|██████▌   | 1549/2382 [5:48:04<3:15:13, 14.06s/it]                                                       {'loss': 1.7641, 'learning_rate': 0.00028797213292019926, 'epoch': 0.65}
 65%|██████▌   | 1549/2382 [5:48:04<3:15:13, 14.06s/it] 65%|██████▌   | 1550/2382 [5:48:17<3:10:59, 13.77s/it]                                                       {'loss': 1.8622, 'learning_rate': 0.00028735649808878485, 'epoch': 0.65}
 65%|██████▌   | 1550/2382 [5:48:17<3:10:59, 13.77s/it] 65%|██████▌   | 1551/2382 [5:48:29<3:04:53, 13.35s/it]                                                       {'loss': 1.8803, 'learning_rate': 0.0002867412565608915, 'epoch': 0.65}
 65%|██████▌   | 1551/2382 [5:48:29<3:04:53, 13.35s/it] 65%|██████▌   | 1552/2382 [5:48:41<2:58:55, 12.93s/it]                                                       {'loss': 1.9117, 'learning_rate': 0.0002861264094744647, 'epoch': 0.65}
 65%|██████▌   | 1552/2382 [5:48:41<2:58:55, 12.93s/it] 65%|██████▌   | 1553/2382 [5:48:54<2:56:19, 12.76s/it]                                                       {'loss': 1.8004, 'learning_rate': 0.00028551195796671963, 'epoch': 0.65}
 65%|██████▌   | 1553/2382 [5:48:54<2:56:19, 12.76s/it] 65%|██████▌   | 1554/2382 [5:49:09<3:05:25, 13.44s/it]                                                       {'loss': 1.8396, 'learning_rate': 0.0002848979031741406, 'epoch': 0.65}
 65%|██████▌   | 1554/2382 [5:49:09<3:05:25, 13.44s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 1024). Running this sequence through the model will result in indexing errors
 65%|██████▌   | 1555/2382 [5:49:22<3:03:00, 13.28s/it]                                                       {'loss': 1.8738, 'learning_rate': 0.00028428424623247787, 'epoch': 0.65}
 65%|██████▌   | 1555/2382 [5:49:22<3:03:00, 13.28s/it] 65%|██████▌   | 1556/2382 [5:49:36<3:05:22, 13.47s/it]                                                       {'loss': 1.8547, 'learning_rate': 0.00028367098827674573, 'epoch': 0.65}
 65%|██████▌   | 1556/2382 [5:49:36<3:05:22, 13.47s/it] 65%|██████▌   | 1557/2382 [5:49:49<3:04:40, 13.43s/it]                                                       {'loss': 1.8499, 'learning_rate': 0.00028305813044122096, 'epoch': 0.65}
 65%|██████▌   | 1557/2382 [5:49:49<3:04:40, 13.43s/it] 65%|██████▌   | 1558/2382 [5:50:02<3:02:56, 13.32s/it]                                                       {'loss': 1.9195, 'learning_rate': 0.00028244567385943964, 'epoch': 0.65}
 65%|██████▌   | 1558/2382 [5:50:02<3:02:56, 13.32s/it] 65%|██████▌   | 1559/2382 [5:50:16<3:06:41, 13.61s/it]                                                       {'loss': 1.7534, 'learning_rate': 0.0002818336196641959, 'epoch': 0.65}
 65%|██████▌   | 1559/2382 [5:50:16<3:06:41, 13.61s/it] 65%|██████▌   | 1560/2382 [5:50:30<3:08:28, 13.76s/it]                                                       {'loss': 1.9199, 'learning_rate': 0.0002812219689875397, 'epoch': 0.65}
 65%|██████▌   | 1560/2382 [5:50:30<3:08:28, 13.76s/it] 66%|██████▌   | 1561/2382 [5:50:44<3:09:32, 13.85s/it]                                                       {'loss': 1.8192, 'learning_rate': 0.00028061072296077484, 'epoch': 0.66}
 66%|██████▌   | 1561/2382 [5:50:44<3:09:32, 13.85s/it] 66%|██████▌   | 1562/2382 [5:50:57<3:05:17, 13.56s/it]                                                       {'loss': 1.9418, 'learning_rate': 0.00027999988271445645, 'epoch': 0.66}
 66%|██████▌   | 1562/2382 [5:50:57<3:05:17, 13.56s/it] 66%|██████▌   | 1563/2382 [5:51:09<2:56:04, 12.90s/it]                                                       {'loss': 1.7752, 'learning_rate': 0.0002793894493783892, 'epoch': 0.66}
 66%|██████▌   | 1563/2382 [5:51:09<2:56:04, 12.90s/it] 66%|██████▌   | 1564/2382 [5:51:22<2:56:17, 12.93s/it]                                                       {'loss': 1.8836, 'learning_rate': 0.0002787794240816254, 'epoch': 0.66}
 66%|██████▌   | 1564/2382 [5:51:22<2:56:17, 12.93s/it] 66%|██████▌   | 1565/2382 [5:51:34<2:55:23, 12.88s/it]                                                       {'loss': 1.8304, 'learning_rate': 0.000278169807952462, 'epoch': 0.66}
 66%|██████▌   | 1565/2382 [5:51:34<2:55:23, 12.88s/it] 66%|██████▌   | 1566/2382 [5:51:47<2:53:02, 12.72s/it]                                                       {'loss': 1.9029, 'learning_rate': 0.00027756060211843957, 'epoch': 0.66}
 66%|██████▌   | 1566/2382 [5:51:47<2:53:02, 12.72s/it] 66%|██████▌   | 1567/2382 [5:52:02<3:01:36, 13.37s/it]                                                       {'loss': 1.9272, 'learning_rate': 0.0002769518077063399, 'epoch': 0.66}
 66%|██████▌   | 1567/2382 [5:52:02<3:01:36, 13.37s/it] 66%|██████▌   | 1568/2382 [5:52:16<3:03:48, 13.55s/it]                                                       {'loss': 1.8621, 'learning_rate': 0.00027634342584218364, 'epoch': 0.66}
 66%|██████▌   | 1568/2382 [5:52:16<3:03:48, 13.55s/it] 66%|██████▌   | 1569/2382 [5:52:30<3:06:00, 13.73s/it]                                                       {'loss': 1.7386, 'learning_rate': 0.00027573545765122853, 'epoch': 0.66}
 66%|██████▌   | 1569/2382 [5:52:30<3:06:00, 13.73s/it] 66%|██████▌   | 1570/2382 [5:52:45<3:10:11, 14.05s/it]                                                       {'loss': 1.8121, 'learning_rate': 0.0002751279042579672, 'epoch': 0.66}
 66%|██████▌   | 1570/2382 [5:52:45<3:10:11, 14.05s/it] 66%|██████▌   | 1571/2382 [5:52:59<3:12:11, 14.22s/it]                                                       {'loss': 1.8278, 'learning_rate': 0.0002745207667861246, 'epoch': 0.66}
 66%|██████▌   | 1571/2382 [5:52:59<3:12:11, 14.22s/it] 66%|██████▌   | 1572/2382 [5:53:14<3:12:22, 14.25s/it]                                                       {'loss': 1.7663, 'learning_rate': 0.00027391404635865725, 'epoch': 0.66}
 66%|██████▌   | 1572/2382 [5:53:14<3:12:22, 14.25s/it] 66%|██████▌   | 1573/2382 [5:53:26<3:06:32, 13.84s/it]                                                       {'loss': 1.8493, 'learning_rate': 0.0002733077440977494, 'epoch': 0.66}
 66%|██████▌   | 1573/2382 [5:53:26<3:06:32, 13.84s/it] 66%|██████▌   | 1574/2382 [5:53:40<3:04:30, 13.70s/it]                                                       {'loss': 1.8469, 'learning_rate': 0.0002727018611248125, 'epoch': 0.66}
 66%|██████▌   | 1574/2382 [5:53:40<3:04:30, 13.70s/it] 66%|██████▌   | 1575/2382 [5:53:54<3:04:39, 13.73s/it]                                                       {'loss': 1.9609, 'learning_rate': 0.0002720963985604822, 'epoch': 0.66}
 66%|██████▌   | 1575/2382 [5:53:54<3:04:39, 13.73s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1791 > 1024). Running this sequence through the model will result in indexing errors
 66%|██████▌   | 1576/2382 [5:54:05<2:56:02, 13.10s/it]                                                       {'loss': 1.8432, 'learning_rate': 0.00027149135752461696, 'epoch': 0.66}
 66%|██████▌   | 1576/2382 [5:54:05<2:56:02, 13.10s/it] 66%|██████▌   | 1577/2382 [5:54:20<3:04:35, 13.76s/it]                                                       {'loss': 1.8068, 'learning_rate': 0.0002708867391362948, 'epoch': 0.66}
 66%|██████▌   | 1577/2382 [5:54:20<3:04:35, 13.76s/it] 66%|██████▌   | 1578/2382 [5:54:33<3:00:37, 13.48s/it]                                                       {'loss': 1.8292, 'learning_rate': 0.0002702825445138127, 'epoch': 0.66}
 66%|██████▌   | 1578/2382 [5:54:33<3:00:37, 13.48s/it] 66%|██████▋   | 1579/2382 [5:54:44<2:51:04, 12.78s/it]                                                       {'loss': 1.8448, 'learning_rate': 0.00026967877477468395, 'epoch': 0.66}
 66%|██████▋   | 1579/2382 [5:54:44<2:51:04, 12.78s/it] 66%|██████▋   | 1580/2382 [5:54:58<2:55:18, 13.11s/it]                                                       {'loss': 1.8301, 'learning_rate': 0.00026907543103563516, 'epoch': 0.66}
 66%|██████▋   | 1580/2382 [5:54:58<2:55:18, 13.11s/it] 66%|██████▋   | 1581/2382 [5:55:15<3:07:55, 14.08s/it]                                                       {'loss': 1.7234, 'learning_rate': 0.0002684725144126056, 'epoch': 0.66}
 66%|██████▋   | 1581/2382 [5:55:15<3:07:55, 14.08s/it] 66%|██████▋   | 1582/2382 [5:55:25<2:53:55, 13.04s/it]                                                       {'loss': 1.8526, 'learning_rate': 0.0002678700260207449, 'epoch': 0.66}
 66%|██████▋   | 1582/2382 [5:55:25<2:53:55, 13.04s/it] 66%|██████▋   | 1583/2382 [5:55:37<2:48:05, 12.62s/it]                                                       {'loss': 1.8769, 'learning_rate': 0.0002672679669744097, 'epoch': 0.66}
 66%|██████▋   | 1583/2382 [5:55:37<2:48:05, 12.62s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1218 > 1024). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (1377 > 1024). Running this sequence through the model will result in indexing errors
 66%|██████▋   | 1584/2382 [5:55:50<2:49:16, 12.73s/it]                                                       {'loss': 1.9064, 'learning_rate': 0.00026666633838716316, 'epoch': 0.66}
 66%|██████▋   | 1584/2382 [5:55:50<2:49:16, 12.73s/it] 67%|██████▋   | 1585/2382 [5:56:03<2:51:55, 12.94s/it]                                                       {'loss': 1.8278, 'learning_rate': 0.00026606514137177226, 'epoch': 0.67}
 67%|██████▋   | 1585/2382 [5:56:03<2:51:55, 12.94s/it] 67%|██████▋   | 1586/2382 [5:56:16<2:49:05, 12.75s/it]                                                       {'loss': 1.8329, 'learning_rate': 0.0002654643770402058, 'epoch': 0.67}
 67%|██████▋   | 1586/2382 [5:56:16<2:49:05, 12.75s/it] 67%|██████▋   | 1587/2382 [5:56:31<2:58:52, 13.50s/it]                                                       {'loss': 1.8158, 'learning_rate': 0.0002648640465036316, 'epoch': 0.67}
 67%|██████▋   | 1587/2382 [5:56:31<2:58:52, 13.50s/it] 67%|██████▋   | 1588/2382 [5:56:41<2:46:40, 12.60s/it]                                                       {'loss': 1.992, 'learning_rate': 0.00026426415087241623, 'epoch': 0.67}
 67%|██████▋   | 1588/2382 [5:56:41<2:46:40, 12.60s/it] 67%|██████▋   | 1589/2382 [5:56:54<2:47:51, 12.70s/it]                                                       {'loss': 1.8651, 'learning_rate': 0.0002636646912561208, 'epoch': 0.67}
 67%|██████▋   | 1589/2382 [5:56:54<2:47:51, 12.70s/it] 67%|██████▋   | 1590/2382 [5:57:07<2:48:27, 12.76s/it]                                                       {'loss': 1.8527, 'learning_rate': 0.0002630656687635007, 'epoch': 0.67}
 67%|██████▋   | 1590/2382 [5:57:07<2:48:27, 12.76s/it] 67%|██████▋   | 1591/2382 [5:57:20<2:49:01, 12.82s/it]                                                       {'loss': 1.8985, 'learning_rate': 0.00026246708450250255, 'epoch': 0.67}
 67%|██████▋   | 1591/2382 [5:57:20<2:49:01, 12.82s/it] 67%|██████▋   | 1592/2382 [5:57:36<2:58:33, 13.56s/it]                                                       {'loss': 1.859, 'learning_rate': 0.0002618689395802624, 'epoch': 0.67}
 67%|██████▋   | 1592/2382 [5:57:36<2:58:33, 13.56s/it] 67%|██████▋   | 1593/2382 [5:57:47<2:51:50, 13.07s/it]                                                       {'loss': 1.8153, 'learning_rate': 0.00026127123510310407, 'epoch': 0.67}
 67%|██████▋   | 1593/2382 [5:57:47<2:51:50, 13.07s/it] 67%|██████▋   | 1594/2382 [5:57:58<2:43:15, 12.43s/it]                                                       {'loss': 1.8161, 'learning_rate': 0.000260673972176536, 'epoch': 0.67}
 67%|██████▋   | 1594/2382 [5:57:58<2:43:15, 12.43s/it] 67%|██████▋   | 1595/2382 [5:58:11<2:44:22, 12.53s/it]                                                       {'loss': 1.8302, 'learning_rate': 0.0002600771519052506, 'epoch': 0.67}
 67%|██████▋   | 1595/2382 [5:58:11<2:44:22, 12.53s/it] 67%|██████▋   | 1596/2382 [5:58:24<2:46:28, 12.71s/it]                                                       {'loss': 1.8314, 'learning_rate': 0.0002594807753931211, 'epoch': 0.67}
 67%|██████▋   | 1596/2382 [5:58:24<2:46:28, 12.71s/it] 67%|██████▋   | 1597/2382 [5:58:36<2:42:15, 12.40s/it]                                                       {'loss': 1.8263, 'learning_rate': 0.00025888484374320033, 'epoch': 0.67}
 67%|██████▋   | 1597/2382 [5:58:36<2:42:15, 12.40s/it] 67%|██████▋   | 1598/2382 [5:58:52<2:58:18, 13.65s/it]                                                       {'loss': 1.7357, 'learning_rate': 0.000258289358057718, 'epoch': 0.67}
 67%|██████▋   | 1598/2382 [5:58:52<2:58:18, 13.65s/it] 67%|██████▋   | 1599/2382 [5:59:04<2:51:23, 13.13s/it]                                                       {'loss': 1.8501, 'learning_rate': 0.00025769431943807933, 'epoch': 0.67}
 67%|██████▋   | 1599/2382 [5:59:04<2:51:23, 13.13s/it] 67%|██████▋   | 1600/2382 [5:59:21<3:05:52, 14.26s/it]                                                       {'loss': 1.8553, 'learning_rate': 0.0002570997289848625, 'epoch': 0.67}
 67%|██████▋   | 1600/2382 [5:59:21<3:05:52, 14.26s/it] 67%|██████▋   | 1601/2382 [5:59:34<3:00:53, 13.90s/it]                                                       {'loss': 1.7418, 'learning_rate': 0.00025650558779781636, 'epoch': 0.67}
 67%|██████▋   | 1601/2382 [5:59:34<3:00:53, 13.90s/it] 67%|██████▋   | 1602/2382 [5:59:46<2:51:45, 13.21s/it]                                                       {'loss': 1.8447, 'learning_rate': 0.00025591189697585947, 'epoch': 0.67}
 67%|██████▋   | 1602/2382 [5:59:46<2:51:45, 13.21s/it] 67%|██████▋   | 1603/2382 [6:00:00<2:55:08, 13.49s/it]                                                       {'loss': 1.7346, 'learning_rate': 0.0002553186576170767, 'epoch': 0.67}
 67%|██████▋   | 1603/2382 [6:00:00<2:55:08, 13.49s/it] 67%|██████▋   | 1604/2382 [6:00:15<2:59:36, 13.85s/it]                                                       {'loss': 1.8039, 'learning_rate': 0.00025472587081871854, 'epoch': 0.67}
 67%|██████▋   | 1604/2382 [6:00:15<2:59:36, 13.85s/it] 67%|██████▋   | 1605/2382 [6:00:27<2:51:09, 13.22s/it]                                                       {'loss': 1.8575, 'learning_rate': 0.00025413353767719804, 'epoch': 0.67}
 67%|██████▋   | 1605/2382 [6:00:27<2:51:09, 13.22s/it] 67%|██████▋   | 1606/2382 [6:00:41<2:57:04, 13.69s/it]                                                       {'loss': 1.7472, 'learning_rate': 0.0002535416592880896, 'epoch': 0.67}
 67%|██████▋   | 1606/2382 [6:00:41<2:57:04, 13.69s/it] 67%|██████▋   | 1607/2382 [6:00:54<2:54:40, 13.52s/it]                                                       {'loss': 1.9269, 'learning_rate': 0.0002529502367461257, 'epoch': 0.67}
 67%|██████▋   | 1607/2382 [6:00:54<2:54:40, 13.52s/it] 68%|██████▊   | 1608/2382 [6:01:08<2:55:06, 13.57s/it]                                                       {'loss': 1.8416, 'learning_rate': 0.0002523592711451964, 'epoch': 0.67}
 68%|██████▊   | 1608/2382 [6:01:08<2:55:06, 13.57s/it] 68%|██████▊   | 1609/2382 [6:01:23<2:58:45, 13.88s/it]                                                       {'loss': 1.8031, 'learning_rate': 0.00025176876357834664, 'epoch': 0.68}
 68%|██████▊   | 1609/2382 [6:01:23<2:58:45, 13.88s/it] 68%|██████▊   | 1610/2382 [6:01:35<2:50:40, 13.26s/it]                                                       {'loss': 1.9867, 'learning_rate': 0.0002511787151377735, 'epoch': 0.68}
 68%|██████▊   | 1610/2382 [6:01:35<2:50:40, 13.26s/it] 68%|██████▊   | 1611/2382 [6:01:49<2:53:25, 13.50s/it]                                                       {'loss': 1.8623, 'learning_rate': 0.0002505891269148256, 'epoch': 0.68}
 68%|██████▊   | 1611/2382 [6:01:49<2:53:25, 13.50s/it] 68%|██████▊   | 1612/2382 [6:02:02<2:52:44, 13.46s/it]                                                       {'loss': 1.9084, 'learning_rate': 0.0002500000000000001, 'epoch': 0.68}
 68%|██████▊   | 1612/2382 [6:02:02<2:52:44, 13.46s/it] 68%|██████▊   | 1613/2382 [6:02:15<2:51:35, 13.39s/it]                                                       {'loss': 1.8416, 'learning_rate': 0.0002494113354829406, 'epoch': 0.68}
 68%|██████▊   | 1613/2382 [6:02:15<2:51:35, 13.39s/it] 68%|██████▊   | 1614/2382 [6:02:30<2:55:22, 13.70s/it]                                                       {'loss': 1.8364, 'learning_rate': 0.00024882313445243585, 'epoch': 0.68}
 68%|██████▊   | 1614/2382 [6:02:30<2:55:22, 13.70s/it] 68%|██████▊   | 1615/2382 [6:02:44<2:57:34, 13.89s/it]                                                       {'loss': 1.8653, 'learning_rate': 0.00024823539799641726, 'epoch': 0.68}
 68%|██████▊   | 1615/2382 [6:02:44<2:57:34, 13.89s/it] 68%|██████▊   | 1616/2382 [6:02:56<2:52:03, 13.48s/it]                                                       {'loss': 1.975, 'learning_rate': 0.00024764812720195714, 'epoch': 0.68}
 68%|██████▊   | 1616/2382 [6:02:56<2:52:03, 13.48s/it] 68%|██████▊   | 1617/2382 [6:03:09<2:46:44, 13.08s/it]                                                       {'loss': 1.7855, 'learning_rate': 0.0002470613231552661, 'epoch': 0.68}
 68%|██████▊   | 1617/2382 [6:03:09<2:46:44, 13.08s/it] 68%|██████▊   | 1618/2382 [6:03:21<2:44:02, 12.88s/it]                                                       {'loss': 1.8946, 'learning_rate': 0.0002464749869416914, 'epoch': 0.68}
 68%|██████▊   | 1618/2382 [6:03:21<2:44:02, 12.88s/it] 68%|██████▊   | 1619/2382 [6:03:32<2:38:01, 12.43s/it]                                                       {'loss': 1.8674, 'learning_rate': 0.00024588911964571554, 'epoch': 0.68}
 68%|██████▊   | 1619/2382 [6:03:32<2:38:01, 12.43s/it] 68%|██████▊   | 1620/2382 [6:03:44<2:35:09, 12.22s/it]                                                       {'loss': 1.8221, 'learning_rate': 0.0002453037223509534, 'epoch': 0.68}
 68%|██████▊   | 1620/2382 [6:03:44<2:35:09, 12.22s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1348 > 1024). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (1549 > 1024). Running this sequence through the model will result in indexing errors
 68%|██████▊   | 1621/2382 [6:03:57<2:37:38, 12.43s/it]                                                       {'loss': 1.9159, 'learning_rate': 0.0002447187961401506, 'epoch': 0.68}
 68%|██████▊   | 1621/2382 [6:03:57<2:37:38, 12.43s/it] 68%|██████▊   | 1622/2382 [6:04:11<2:44:18, 12.97s/it]                                                       {'loss': 1.8385, 'learning_rate': 0.00024413434209518138, 'epoch': 0.68}
 68%|██████▊   | 1622/2382 [6:04:11<2:44:18, 12.97s/it] 68%|██████▊   | 1623/2382 [6:04:24<2:44:09, 12.98s/it]                                                       {'loss': 1.7615, 'learning_rate': 0.000243550361297047, 'epoch': 0.68}
 68%|██████▊   | 1623/2382 [6:04:24<2:44:09, 12.98s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1167 > 1024). Running this sequence through the model will result in indexing errors
 68%|██████▊   | 1624/2382 [6:04:37<2:42:32, 12.87s/it]                                                       {'loss': 1.9008, 'learning_rate': 0.00024296685482587282, 'epoch': 0.68}
 68%|██████▊   | 1624/2382 [6:04:37<2:42:32, 12.87s/it] 68%|██████▊   | 1625/2382 [6:04:49<2:41:11, 12.78s/it]                                                       {'loss': 1.8809, 'learning_rate': 0.00024238382376090713, 'epoch': 0.68}
 68%|██████▊   | 1625/2382 [6:04:49<2:41:11, 12.78s/it] 68%|██████▊   | 1626/2382 [6:05:04<2:48:01, 13.34s/it]                                                       {'loss': 1.8744, 'learning_rate': 0.00024180126918051909, 'epoch': 0.68}
 68%|██████▊   | 1626/2382 [6:05:04<2:48:01, 13.34s/it] 68%|██████▊   | 1627/2382 [6:05:17<2:45:05, 13.12s/it]                                                       {'loss': 1.8578, 'learning_rate': 0.00024121919216219646, 'epoch': 0.68}
 68%|██████▊   | 1627/2382 [6:05:17<2:45:05, 13.12s/it] 68%|██████▊   | 1628/2382 [6:05:30<2:43:40, 13.02s/it]                                                       {'loss': 1.8442, 'learning_rate': 0.00024063759378254373, 'epoch': 0.68}
 68%|██████▊   | 1628/2382 [6:05:30<2:43:40, 13.02s/it] 68%|██████▊   | 1629/2382 [6:05:43<2:46:07, 13.24s/it]                                                       {'loss': 1.9639, 'learning_rate': 0.00024005647511728023, 'epoch': 0.68}
 68%|██████▊   | 1629/2382 [6:05:43<2:46:07, 13.24s/it] 68%|██████▊   | 1630/2382 [6:05:58<2:50:30, 13.60s/it]                                                       {'loss': 1.7619, 'learning_rate': 0.00023947583724123745, 'epoch': 0.68}
 68%|██████▊   | 1630/2382 [6:05:58<2:50:30, 13.60s/it] 68%|██████▊   | 1631/2382 [6:06:13<2:57:47, 14.20s/it]                                                       {'loss': 1.8844, 'learning_rate': 0.00023889568122835837, 'epoch': 0.68}
 68%|██████▊   | 1631/2382 [6:06:13<2:57:47, 14.20s/it] 69%|██████▊   | 1632/2382 [6:06:25<2:46:53, 13.35s/it]                                                       {'loss': 1.9621, 'learning_rate': 0.00023831600815169408, 'epoch': 0.68}
 69%|██████▊   | 1632/2382 [6:06:25<2:46:53, 13.35s/it] 69%|██████▊   | 1633/2382 [6:06:40<2:54:57, 14.02s/it]                                                       {'loss': 1.8454, 'learning_rate': 0.00023773681908340283, 'epoch': 0.69}
 69%|██████▊   | 1633/2382 [6:06:40<2:54:57, 14.02s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1055 > 1024). Running this sequence through the model will result in indexing errors
 69%|██████▊   | 1634/2382 [6:06:54<2:55:31, 14.08s/it]                                                       {'loss': 1.8661, 'learning_rate': 0.0002371581150947476, 'epoch': 0.69}
 69%|██████▊   | 1634/2382 [6:06:54<2:55:31, 14.08s/it] 69%|██████▊   | 1635/2382 [6:07:08<2:54:27, 14.01s/it]                                                       {'loss': 1.7719, 'learning_rate': 0.0002365798972560943, 'epoch': 0.69}
 69%|██████▊   | 1635/2382 [6:07:08<2:54:27, 14.01s/it] 69%|██████▊   | 1636/2382 [6:07:20<2:47:03, 13.44s/it]                                                       {'loss': 1.8875, 'learning_rate': 0.0002360021666369091, 'epoch': 0.69}
 69%|██████▊   | 1636/2382 [6:07:20<2:47:03, 13.44s/it] 69%|██████▊   | 1637/2382 [6:07:35<2:51:58, 13.85s/it]                                                       {'loss': 1.8163, 'learning_rate': 0.0002354249243057575, 'epoch': 0.69}
 69%|██████▊   | 1637/2382 [6:07:35<2:51:58, 13.85s/it] 69%|██████▉   | 1638/2382 [6:07:49<2:50:58, 13.79s/it]                                                       {'loss': 1.7891, 'learning_rate': 0.00023484817133030206, 'epoch': 0.69}
 69%|██████▉   | 1638/2382 [6:07:49<2:50:58, 13.79s/it] 69%|██████▉   | 1639/2382 [6:08:03<2:50:49, 13.80s/it]                                                       {'loss': 1.8329, 'learning_rate': 0.0002342719087772995, 'epoch': 0.69}
 69%|██████▉   | 1639/2382 [6:08:03<2:50:49, 13.80s/it] 69%|██████▉   | 1640/2382 [6:08:19<3:01:37, 14.69s/it]                                                       {'loss': 1.8352, 'learning_rate': 0.00023369613771260007, 'epoch': 0.69}
 69%|██████▉   | 1640/2382 [6:08:19<3:01:37, 14.69s/it] 69%|██████▉   | 1641/2382 [6:08:32<2:53:59, 14.09s/it]                                                       {'loss': 1.9913, 'learning_rate': 0.000233120859201145, 'epoch': 0.69}
 69%|██████▉   | 1641/2382 [6:08:32<2:53:59, 14.09s/it] 69%|██████▉   | 1642/2382 [6:08:45<2:48:00, 13.62s/it]                                                       {'loss': 1.8829, 'learning_rate': 0.0002325460743069639, 'epoch': 0.69}
 69%|██████▉   | 1642/2382 [6:08:45<2:48:00, 13.62s/it] 69%|██████▉   | 1643/2382 [6:08:56<2:39:22, 12.94s/it]                                                       {'loss': 1.8036, 'learning_rate': 0.00023197178409317394, 'epoch': 0.69}
 69%|██████▉   | 1643/2382 [6:08:56<2:39:22, 12.94s/it] 69%|██████▉   | 1644/2382 [6:09:10<2:41:29, 13.13s/it]                                                       {'loss': 1.8219, 'learning_rate': 0.00023139798962197716, 'epoch': 0.69}
 69%|██████▉   | 1644/2382 [6:09:10<2:41:29, 13.13s/it] 69%|██████▉   | 1645/2382 [6:09:28<3:00:09, 14.67s/it]                                                       {'loss': 1.791, 'learning_rate': 0.00023082469195465893, 'epoch': 0.69}
 69%|██████▉   | 1645/2382 [6:09:28<3:00:09, 14.67s/it] 69%|██████▉   | 1646/2382 [6:09:40<2:51:16, 13.96s/it]                                                       {'loss': 1.7873, 'learning_rate': 0.00023025189215158509, 'epoch': 0.69}
 69%|██████▉   | 1646/2382 [6:09:40<2:51:16, 13.96s/it] 69%|██████▉   | 1647/2382 [6:09:57<3:00:13, 14.71s/it]                                                       {'loss': 1.8742, 'learning_rate': 0.0002296795912722014, 'epoch': 0.69}
 69%|██████▉   | 1647/2382 [6:09:57<3:00:13, 14.71s/it] 69%|██████▉   | 1648/2382 [6:10:14<3:08:45, 15.43s/it]                                                       {'loss': 1.7808, 'learning_rate': 0.00022910779037503003, 'epoch': 0.69}
 69%|██████▉   | 1648/2382 [6:10:14<3:08:45, 15.43s/it] 69%|██████▉   | 1649/2382 [6:10:26<2:56:22, 14.44s/it]                                                       {'loss': 1.864, 'learning_rate': 0.00022853649051766918, 'epoch': 0.69}
 69%|██████▉   | 1649/2382 [6:10:26<2:56:22, 14.44s/it] 69%|██████▉   | 1650/2382 [6:10:40<2:54:56, 14.34s/it]                                                       {'loss': 1.9343, 'learning_rate': 0.00022796569275678973, 'epoch': 0.69}
 69%|██████▉   | 1650/2382 [6:10:40<2:54:56, 14.34s/it] 69%|██████▉   | 1651/2382 [6:10:53<2:51:20, 14.06s/it]                                                       {'loss': 1.9778, 'learning_rate': 0.00022739539814813425, 'epoch': 0.69}
 69%|██████▉   | 1651/2382 [6:10:53<2:51:20, 14.06s/it] 69%|██████▉   | 1652/2382 [6:11:06<2:46:52, 13.72s/it]                                                       {'loss': 1.8787, 'learning_rate': 0.00022682560774651457, 'epoch': 0.69}
 69%|██████▉   | 1652/2382 [6:11:06<2:46:52, 13.72s/it] 69%|██████▉   | 1653/2382 [6:11:20<2:45:13, 13.60s/it]                                                       {'loss': 1.7992, 'learning_rate': 0.00022625632260581002, 'epoch': 0.69}
 69%|██████▉   | 1653/2382 [6:11:20<2:45:13, 13.60s/it] 69%|██████▉   | 1654/2382 [6:11:34<2:48:15, 13.87s/it]                                                       {'loss': 1.869, 'learning_rate': 0.00022568754377896516, 'epoch': 0.69}
 69%|██████▉   | 1654/2382 [6:11:34<2:48:15, 13.87s/it] 69%|██████▉   | 1655/2382 [6:11:47<2:45:04, 13.62s/it]                                                       {'loss': 1.844, 'learning_rate': 0.00022511927231798812, 'epoch': 0.69}
 69%|██████▉   | 1655/2382 [6:11:47<2:45:04, 13.62s/it] 70%|██████▉   | 1656/2382 [6:12:01<2:43:43, 13.53s/it]                                                       {'loss': 1.8285, 'learning_rate': 0.0002245515092739488, 'epoch': 0.69}
 70%|██████▉   | 1656/2382 [6:12:01<2:43:43, 13.53s/it] 70%|██████▉   | 1657/2382 [6:12:14<2:44:59, 13.65s/it]                                                       {'loss': 1.82, 'learning_rate': 0.00022398425569697666, 'epoch': 0.7}
 70%|██████▉   | 1657/2382 [6:12:14<2:44:59, 13.65s/it] 70%|██████▉   | 1658/2382 [6:12:28<2:42:51, 13.50s/it]                                                       {'loss': 1.8086, 'learning_rate': 0.00022341751263625886, 'epoch': 0.7}
 70%|██████▉   | 1658/2382 [6:12:28<2:42:51, 13.50s/it] 70%|██████▉   | 1659/2382 [6:12:40<2:37:27, 13.07s/it]                                                       {'loss': 1.8018, 'learning_rate': 0.00022285128114003856, 'epoch': 0.7}
 70%|██████▉   | 1659/2382 [6:12:40<2:37:27, 13.07s/it] 70%|██████▉   | 1660/2382 [6:12:54<2:42:16, 13.49s/it]                                                       {'loss': 1.8386, 'learning_rate': 0.00022228556225561204, 'epoch': 0.7}
 70%|██████▉   | 1660/2382 [6:12:54<2:42:16, 13.49s/it] 70%|██████▉   | 1661/2382 [6:13:06<2:34:29, 12.86s/it]                                                       {'loss': 1.9743, 'learning_rate': 0.00022172035702932823, 'epoch': 0.7}
 70%|██████▉   | 1661/2382 [6:13:06<2:34:29, 12.86s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1159 > 1024). Running this sequence through the model will result in indexing errors
 70%|██████▉   | 1662/2382 [6:13:20<2:41:14, 13.44s/it]                                                       {'loss': 1.838, 'learning_rate': 0.00022115566650658536, 'epoch': 0.7}
 70%|██████▉   | 1662/2382 [6:13:20<2:41:14, 13.44s/it] 70%|██████▉   | 1663/2382 [6:13:33<2:39:09, 13.28s/it]                                                       {'loss': 1.9104, 'learning_rate': 0.00022059149173183013, 'epoch': 0.7}
 70%|██████▉   | 1663/2382 [6:13:33<2:39:09, 13.28s/it] 70%|██████▉   | 1664/2382 [6:13:47<2:40:11, 13.39s/it]                                                       {'loss': 1.8913, 'learning_rate': 0.00022002783374855517, 'epoch': 0.7}
 70%|██████▉   | 1664/2382 [6:13:47<2:40:11, 13.39s/it] 70%|██████▉   | 1665/2382 [6:14:01<2:44:02, 13.73s/it]                                                       {'loss': 1.9323, 'learning_rate': 0.00021946469359929743, 'epoch': 0.7}
 70%|██████▉   | 1665/2382 [6:14:01<2:44:02, 13.73s/it] 70%|██████▉   | 1666/2382 [6:14:15<2:42:59, 13.66s/it]                                                       {'loss': 1.8271, 'learning_rate': 0.00021890207232563554, 'epoch': 0.7}
 70%|██████▉   | 1666/2382 [6:14:15<2:42:59, 13.66s/it] 70%|██████▉   | 1667/2382 [6:14:26<2:33:40, 12.90s/it]                                                       {'loss': 1.8363, 'learning_rate': 0.00021833997096818897, 'epoch': 0.7}
 70%|██████▉   | 1667/2382 [6:14:26<2:33:40, 12.90s/it] 70%|███████   | 1668/2382 [6:14:40<2:36:47, 13.18s/it]                                                       {'loss': 1.8147, 'learning_rate': 0.00021777839056661552, 'epoch': 0.7}
 70%|███████   | 1668/2382 [6:14:40<2:36:47, 13.18s/it] 70%|███████   | 1669/2382 [6:14:52<2:32:58, 12.87s/it]                                                       {'loss': 1.8671, 'learning_rate': 0.00021721733215960892, 'epoch': 0.7}
 70%|███████   | 1669/2382 [6:14:52<2:32:58, 12.87s/it] 70%|███████   | 1670/2382 [6:15:03<2:26:30, 12.35s/it]                                                       {'loss': 1.8954, 'learning_rate': 0.00021665679678489804, 'epoch': 0.7}
 70%|███████   | 1670/2382 [6:15:03<2:26:30, 12.35s/it] 70%|███████   | 1671/2382 [6:15:15<2:24:01, 12.15s/it]                                                       {'loss': 1.8303, 'learning_rate': 0.00021609678547924416, 'epoch': 0.7}
 70%|███████   | 1671/2382 [6:15:15<2:24:01, 12.15s/it] 70%|███████   | 1672/2382 [6:15:29<2:29:22, 12.62s/it]                                                       {'loss': 1.8689, 'learning_rate': 0.0002155372992784389, 'epoch': 0.7}
 70%|███████   | 1672/2382 [6:15:29<2:29:22, 12.62s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1304 > 1024). Running this sequence through the model will result in indexing errors
 70%|███████   | 1673/2382 [6:15:41<2:29:23, 12.64s/it]                                                       {'loss': 1.8372, 'learning_rate': 0.00021497833921730315, 'epoch': 0.7}
 70%|███████   | 1673/2382 [6:15:41<2:29:23, 12.64s/it] 70%|███████   | 1674/2382 [6:15:53<2:25:56, 12.37s/it]                                                       {'loss': 1.8264, 'learning_rate': 0.00021441990632968438, 'epoch': 0.7}
 70%|███████   | 1674/2382 [6:15:53<2:25:56, 12.37s/it] 70%|███████   | 1675/2382 [6:16:05<2:26:22, 12.42s/it]                                                       {'loss': 1.844, 'learning_rate': 0.00021386200164845526, 'epoch': 0.7}
 70%|███████   | 1675/2382 [6:16:05<2:26:22, 12.42s/it] 70%|███████   | 1676/2382 [6:16:18<2:26:42, 12.47s/it]                                                       {'loss': 1.9125, 'learning_rate': 0.00021330462620551094, 'epoch': 0.7}
 70%|███████   | 1676/2382 [6:16:18<2:26:42, 12.47s/it] 70%|███████   | 1677/2382 [6:16:33<2:33:40, 13.08s/it]                                                       {'loss': 1.782, 'learning_rate': 0.0002127477810317685, 'epoch': 0.7}
 70%|███████   | 1677/2382 [6:16:33<2:33:40, 13.08s/it] 70%|███████   | 1678/2382 [6:16:50<2:48:37, 14.37s/it]                                                       {'loss': 1.9483, 'learning_rate': 0.0002121914671571633, 'epoch': 0.7}
 70%|███████   | 1678/2382 [6:16:50<2:48:37, 14.37s/it] 70%|███████   | 1679/2382 [6:17:02<2:41:15, 13.76s/it]                                                       {'loss': 1.9199, 'learning_rate': 0.00021163568561064882, 'epoch': 0.7}
 70%|███████   | 1679/2382 [6:17:02<2:41:15, 13.76s/it] 71%|███████   | 1680/2382 [6:17:17<2:44:52, 14.09s/it]                                                       {'loss': 1.8197, 'learning_rate': 0.00021108043742019356, 'epoch': 0.71}
 71%|███████   | 1680/2382 [6:17:17<2:44:52, 14.09s/it] 71%|███████   | 1681/2382 [6:17:29<2:37:30, 13.48s/it]                                                       {'loss': 1.847, 'learning_rate': 0.00021052572361277968, 'epoch': 0.71}
 71%|███████   | 1681/2382 [6:17:29<2:37:30, 13.48s/it] 71%|███████   | 1682/2382 [6:17:42<2:35:24, 13.32s/it]                                                       {'loss': 1.8478, 'learning_rate': 0.00020997154521440098, 'epoch': 0.71}
 71%|███████   | 1682/2382 [6:17:42<2:35:24, 13.32s/it] 71%|███████   | 1683/2382 [6:17:55<2:32:41, 13.11s/it]                                                       {'loss': 1.8859, 'learning_rate': 0.0002094179032500607, 'epoch': 0.71}
 71%|███████   | 1683/2382 [6:17:55<2:32:41, 13.11s/it] 71%|███████   | 1684/2382 [6:18:09<2:36:38, 13.47s/it]                                                       {'loss': 1.7934, 'learning_rate': 0.00020886479874377, 'epoch': 0.71}
 71%|███████   | 1684/2382 [6:18:09<2:36:38, 13.47s/it] 71%|███████   | 1685/2382 [6:18:23<2:39:46, 13.75s/it]                                                       {'loss': 1.8437, 'learning_rate': 0.00020831223271854611, 'epoch': 0.71}
 71%|███████   | 1685/2382 [6:18:23<2:39:46, 13.75s/it] 71%|███████   | 1686/2382 [6:18:35<2:31:46, 13.08s/it]                                                       {'loss': 1.9506, 'learning_rate': 0.00020776020619641024, 'epoch': 0.71}
 71%|███████   | 1686/2382 [6:18:35<2:31:46, 13.08s/it] 71%|███████   | 1687/2382 [6:18:50<2:38:44, 13.70s/it]                                                       {'loss': 1.8094, 'learning_rate': 0.00020720872019838567, 'epoch': 0.71}
 71%|███████   | 1687/2382 [6:18:50<2:38:44, 13.70s/it] 71%|███████   | 1688/2382 [6:19:03<2:34:53, 13.39s/it]                                                       {'loss': 1.8084, 'learning_rate': 0.00020665777574449608, 'epoch': 0.71}
 71%|███████   | 1688/2382 [6:19:03<2:34:53, 13.39s/it] 71%|███████   | 1689/2382 [6:19:17<2:37:32, 13.64s/it]                                                       {'loss': 1.7636, 'learning_rate': 0.00020610737385376348, 'epoch': 0.71}
 71%|███████   | 1689/2382 [6:19:17<2:37:32, 13.64s/it] 71%|███████   | 1690/2382 [6:19:30<2:33:49, 13.34s/it]                                                       {'loss': 1.7859, 'learning_rate': 0.000205557515544206, 'epoch': 0.71}
 71%|███████   | 1690/2382 [6:19:30<2:33:49, 13.34s/it] 71%|███████   | 1691/2382 [6:19:43<2:34:09, 13.39s/it]                                                       {'loss': 1.8201, 'learning_rate': 0.00020500820183283697, 'epoch': 0.71}
 71%|███████   | 1691/2382 [6:19:43<2:34:09, 13.39s/it] 71%|███████   | 1692/2382 [6:19:55<2:27:36, 12.84s/it]                                                       {'loss': 1.7828, 'learning_rate': 0.00020445943373566177, 'epoch': 0.71}
 71%|███████   | 1692/2382 [6:19:55<2:27:36, 12.84s/it] 71%|███████   | 1693/2382 [6:20:08<2:29:56, 13.06s/it]                                                       {'loss': 1.8647, 'learning_rate': 0.00020391121226767724, 'epoch': 0.71}
 71%|███████   | 1693/2382 [6:20:08<2:29:56, 13.06s/it] 71%|███████   | 1694/2382 [6:20:21<2:28:49, 12.98s/it]                                                       {'loss': 1.9401, 'learning_rate': 0.00020336353844286877, 'epoch': 0.71}
 71%|███████   | 1694/2382 [6:20:21<2:28:49, 12.98s/it] 71%|███████   | 1695/2382 [6:20:36<2:35:18, 13.56s/it]                                                       {'loss': 1.7978, 'learning_rate': 0.00020281641327420918, 'epoch': 0.71}
 71%|███████   | 1695/2382 [6:20:36<2:35:18, 13.56s/it] 71%|███████   | 1696/2382 [6:20:51<2:38:47, 13.89s/it]                                                       {'loss': 1.9153, 'learning_rate': 0.00020226983777365604, 'epoch': 0.71}
 71%|███████   | 1696/2382 [6:20:51<2:38:47, 13.89s/it] 71%|███████   | 1697/2382 [6:21:04<2:36:50, 13.74s/it]                                                       {'loss': 1.7918, 'learning_rate': 0.0002017238129521506, 'epoch': 0.71}
 71%|███████   | 1697/2382 [6:21:04<2:36:50, 13.74s/it] 71%|███████▏  | 1698/2382 [6:21:16<2:31:32, 13.29s/it]                                                       {'loss': 1.8832, 'learning_rate': 0.00020117833981961563, 'epoch': 0.71}
 71%|███████▏  | 1698/2382 [6:21:16<2:31:32, 13.29s/it] 71%|███████▏  | 1699/2382 [6:21:29<2:30:01, 13.18s/it]                                                       {'loss': 1.8451, 'learning_rate': 0.00020063341938495312, 'epoch': 0.71}
 71%|███████▏  | 1699/2382 [6:21:29<2:30:01, 13.18s/it] 71%|███████▏  | 1700/2382 [6:21:41<2:26:15, 12.87s/it]                                                       {'loss': 1.9643, 'learning_rate': 0.00020008905265604316, 'epoch': 0.71}
 71%|███████▏  | 1700/2382 [6:21:41<2:26:15, 12.87s/it] 71%|███████▏  | 1701/2382 [6:21:55<2:27:15, 12.97s/it]                                                       {'loss': 1.7604, 'learning_rate': 0.00019954524063974172, 'epoch': 0.71}
 71%|███████▏  | 1701/2382 [6:21:55<2:27:15, 12.97s/it] 71%|███████▏  | 1702/2382 [6:22:07<2:26:34, 12.93s/it]                                                       {'loss': 1.9704, 'learning_rate': 0.00019900198434187838, 'epoch': 0.71}
 71%|███████▏  | 1702/2382 [6:22:07<2:26:34, 12.93s/it] 71%|███████▏  | 1703/2382 [6:22:21<2:28:08, 13.09s/it]                                                       {'loss': 1.8112, 'learning_rate': 0.00019845928476725522, 'epoch': 0.71}
 71%|███████▏  | 1703/2382 [6:22:21<2:28:08, 13.09s/it] 72%|███████▏  | 1704/2382 [6:22:34<2:27:21, 13.04s/it]                                                       {'loss': 1.7951, 'learning_rate': 0.00019791714291964463, 'epoch': 0.72}
 72%|███████▏  | 1704/2382 [6:22:34<2:27:21, 13.04s/it] 72%|███████▏  | 1705/2382 [6:22:49<2:33:38, 13.62s/it]                                                       {'loss': 1.8874, 'learning_rate': 0.0001973755598017874, 'epoch': 0.72}
 72%|███████▏  | 1705/2382 [6:22:49<2:33:38, 13.62s/it] 72%|███████▏  | 1706/2382 [6:23:03<2:35:02, 13.76s/it]                                                       {'loss': 1.8364, 'learning_rate': 0.00019683453641539052, 'epoch': 0.72}
 72%|███████▏  | 1706/2382 [6:23:03<2:35:02, 13.76s/it] 72%|███████▏  | 1707/2382 [6:23:15<2:28:37, 13.21s/it]                                                       {'loss': 1.8786, 'learning_rate': 0.0001962940737611264, 'epoch': 0.72}
 72%|███████▏  | 1707/2382 [6:23:15<2:28:37, 13.21s/it] 72%|███████▏  | 1708/2382 [6:23:28<2:27:10, 13.10s/it]                                                       {'loss': 1.894, 'learning_rate': 0.0001957541728386295, 'epoch': 0.72}
 72%|███████▏  | 1708/2382 [6:23:28<2:27:10, 13.10s/it] 72%|███████▏  | 1709/2382 [6:23:41<2:26:56, 13.10s/it]                                                       {'loss': 1.9217, 'learning_rate': 0.00019521483464649597, 'epoch': 0.72}
 72%|███████▏  | 1709/2382 [6:23:41<2:26:56, 13.10s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1675 > 1024). Running this sequence through the model will result in indexing errors
 72%|███████▏  | 1710/2382 [6:23:56<2:33:22, 13.69s/it]                                                       {'loss': 1.7994, 'learning_rate': 0.0001946760601822809, 'epoch': 0.72}
 72%|███████▏  | 1710/2382 [6:23:56<2:33:22, 13.69s/it] 72%|███████▏  | 1711/2382 [6:24:12<2:41:35, 14.45s/it]                                                       {'loss': 1.8301, 'learning_rate': 0.00019413785044249677, 'epoch': 0.72}
 72%|███████▏  | 1711/2382 [6:24:12<2:41:35, 14.45s/it] 72%|███████▏  | 1712/2382 [6:24:27<2:44:11, 14.70s/it]                                                       {'loss': 1.7761, 'learning_rate': 0.00019360020642261155, 'epoch': 0.72}
 72%|███████▏  | 1712/2382 [6:24:27<2:44:11, 14.70s/it] 72%|███████▏  | 1713/2382 [6:24:40<2:35:44, 13.97s/it]                                                       {'loss': 1.9392, 'learning_rate': 0.00019306312911704683, 'epoch': 0.72}
 72%|███████▏  | 1713/2382 [6:24:40<2:35:44, 13.97s/it] 72%|███████▏  | 1714/2382 [6:24:53<2:33:45, 13.81s/it]                                                       {'loss': 1.8137, 'learning_rate': 0.00019252661951917567, 'epoch': 0.72}
 72%|███████▏  | 1714/2382 [6:24:53<2:33:45, 13.81s/it] 72%|███████▏  | 1715/2382 [6:25:05<2:27:46, 13.29s/it]                                                       {'loss': 1.907, 'learning_rate': 0.00019199067862132164, 'epoch': 0.72}
 72%|███████▏  | 1715/2382 [6:25:05<2:27:46, 13.29s/it] 72%|███████▏  | 1716/2382 [6:25:21<2:35:15, 13.99s/it]                                                       {'loss': 1.7371, 'learning_rate': 0.00019145530741475632, 'epoch': 0.72}
 72%|███████▏  | 1716/2382 [6:25:21<2:35:15, 13.99s/it] 72%|███████▏  | 1717/2382 [6:25:33<2:29:49, 13.52s/it]                                                       {'loss': 1.9026, 'learning_rate': 0.00019092050688969737, 'epoch': 0.72}
 72%|███████▏  | 1717/2382 [6:25:33<2:29:49, 13.52s/it] 72%|███████▏  | 1718/2382 [6:25:46<2:27:31, 13.33s/it]                                                       {'loss': 1.8237, 'learning_rate': 0.00019038627803530712, 'epoch': 0.72}
 72%|███████▏  | 1718/2382 [6:25:46<2:27:31, 13.33s/it] 72%|███████▏  | 1719/2382 [6:26:00<2:27:53, 13.38s/it]                                                       {'loss': 1.9198, 'learning_rate': 0.0001898526218396907, 'epoch': 0.72}
 72%|███████▏  | 1719/2382 [6:26:00<2:27:53, 13.38s/it] 72%|███████▏  | 1720/2382 [6:26:12<2:23:53, 13.04s/it]                                                       {'loss': 1.8639, 'learning_rate': 0.00018931953928989366, 'epoch': 0.72}
 72%|███████▏  | 1720/2382 [6:26:12<2:23:53, 13.04s/it] 72%|███████▏  | 1721/2382 [6:26:24<2:20:57, 12.80s/it]                                                       {'loss': 1.848, 'learning_rate': 0.00018878703137190046, 'epoch': 0.72}
 72%|███████▏  | 1721/2382 [6:26:24<2:20:57, 12.80s/it] 72%|███████▏  | 1722/2382 [6:26:37<2:22:22, 12.94s/it]                                                       {'loss': 1.8768, 'learning_rate': 0.00018825509907063325, 'epoch': 0.72}
 72%|███████▏  | 1722/2382 [6:26:37<2:22:22, 12.94s/it] 72%|███████▏  | 1723/2382 [6:26:51<2:26:00, 13.29s/it]                                                       {'loss': 1.85, 'learning_rate': 0.0001877237433699493, 'epoch': 0.72}
 72%|███████▏  | 1723/2382 [6:26:51<2:26:00, 13.29s/it] 72%|███████▏  | 1724/2382 [6:27:06<2:30:33, 13.73s/it]                                                       {'loss': 1.9094, 'learning_rate': 0.00018719296525263924, 'epoch': 0.72}
 72%|███████▏  | 1724/2382 [6:27:06<2:30:33, 13.73s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (2371 > 1024). Running this sequence through the model will result in indexing errors
 72%|███████▏  | 1725/2382 [6:27:18<2:25:22, 13.28s/it]                                                       {'loss': 1.9523, 'learning_rate': 0.0001866627657004258, 'epoch': 0.72}
 72%|███████▏  | 1725/2382 [6:27:18<2:25:22, 13.28s/it] 72%|███████▏  | 1726/2382 [6:27:34<2:34:05, 14.09s/it]                                                       {'loss': 1.9169, 'learning_rate': 0.00018613314569396088, 'epoch': 0.72}
 72%|███████▏  | 1726/2382 [6:27:34<2:34:05, 14.09s/it] 73%|███████▎  | 1727/2382 [6:27:49<2:34:30, 14.15s/it]                                                       {'loss': 1.8102, 'learning_rate': 0.00018560410621282542, 'epoch': 0.72}
 73%|███████▎  | 1727/2382 [6:27:49<2:34:30, 14.15s/it] 73%|███████▎  | 1728/2382 [6:28:02<2:30:27, 13.80s/it]                                                       {'loss': 1.9051, 'learning_rate': 0.00018507564823552563, 'epoch': 0.73}
 73%|███████▎  | 1728/2382 [6:28:02<2:30:27, 13.80s/it] 73%|███████▎  | 1729/2382 [6:28:15<2:27:54, 13.59s/it]                                                       {'loss': 1.8571, 'learning_rate': 0.0001845477727394929, 'epoch': 0.73}
 73%|███████▎  | 1729/2382 [6:28:15<2:27:54, 13.59s/it] 73%|███████▎  | 1730/2382 [6:28:28<2:27:14, 13.55s/it]                                                       {'loss': 1.8646, 'learning_rate': 0.00018402048070108106, 'epoch': 0.73}
 73%|███████▎  | 1730/2382 [6:28:28<2:27:14, 13.55s/it] 73%|███████▎  | 1731/2382 [6:28:40<2:21:30, 13.04s/it]                                                       {'loss': 1.8932, 'learning_rate': 0.00018349377309556487, 'epoch': 0.73}
 73%|███████▎  | 1731/2382 [6:28:40<2:21:30, 13.04s/it] 73%|███████▎  | 1732/2382 [6:28:53<2:22:12, 13.13s/it]                                                       {'loss': 1.8856, 'learning_rate': 0.00018296765089713767, 'epoch': 0.73}
 73%|███████▎  | 1732/2382 [6:28:53<2:22:12, 13.13s/it] 73%|███████▎  | 1733/2382 [6:29:06<2:20:36, 13.00s/it]                                                       {'loss': 1.7532, 'learning_rate': 0.00018244211507891062, 'epoch': 0.73}
 73%|███████▎  | 1733/2382 [6:29:06<2:20:36, 13.00s/it] 73%|███████▎  | 1734/2382 [6:29:23<2:33:03, 14.17s/it]                                                       {'loss': 1.8334, 'learning_rate': 0.00018191716661291013, 'epoch': 0.73}
 73%|███████▎  | 1734/2382 [6:29:23<2:33:03, 14.17s/it] 73%|███████▎  | 1735/2382 [6:29:38<2:36:14, 14.49s/it]                                                       {'loss': 1.8883, 'learning_rate': 0.00018139280647007594, 'epoch': 0.73}
 73%|███████▎  | 1735/2382 [6:29:38<2:36:14, 14.49s/it] 73%|███████▎  | 1736/2382 [6:29:51<2:30:06, 13.94s/it]                                                       {'loss': 1.8598, 'learning_rate': 0.00018086903562025998, 'epoch': 0.73}
 73%|███████▎  | 1736/2382 [6:29:51<2:30:06, 13.94s/it] 73%|███████▎  | 1737/2382 [6:30:06<2:32:46, 14.21s/it]                                                       {'loss': 1.957, 'learning_rate': 0.00018034585503222438, 'epoch': 0.73}
 73%|███████▎  | 1737/2382 [6:30:06<2:32:46, 14.21s/it] 73%|███████▎  | 1738/2382 [6:30:20<2:32:40, 14.22s/it]                                                       {'loss': 1.8913, 'learning_rate': 0.0001798232656736389, 'epoch': 0.73}
 73%|███████▎  | 1738/2382 [6:30:20<2:32:40, 14.22s/it] 73%|███████▎  | 1739/2382 [6:30:32<2:25:46, 13.60s/it]                                                       {'loss': 1.8043, 'learning_rate': 0.0001793012685110803, 'epoch': 0.73}
 73%|███████▎  | 1739/2382 [6:30:32<2:25:46, 13.60s/it] 73%|███████▎  | 1740/2382 [6:30:45<2:21:54, 13.26s/it]                                                       {'loss': 1.8504, 'learning_rate': 0.00017877986451002992, 'epoch': 0.73}
 73%|███████▎  | 1740/2382 [6:30:45<2:21:54, 13.26s/it] 73%|███████▎  | 1741/2382 [6:30:59<2:24:58, 13.57s/it]                                                       {'loss': 1.8058, 'learning_rate': 0.0001782590546348719, 'epoch': 0.73}
 73%|███████▎  | 1741/2382 [6:30:59<2:24:58, 13.57s/it] 73%|███████▎  | 1742/2382 [6:31:10<2:17:06, 12.85s/it]                                                       {'loss': 1.7842, 'learning_rate': 0.00017773883984889178, 'epoch': 0.73}
 73%|███████▎  | 1742/2382 [6:31:10<2:17:06, 12.85s/it] 73%|███████▎  | 1743/2382 [6:31:22<2:12:51, 12.47s/it]                                                       {'loss': 1.8873, 'learning_rate': 0.00017721922111427386, 'epoch': 0.73}
 73%|███████▎  | 1743/2382 [6:31:22<2:12:51, 12.47s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1030 > 1024). Running this sequence through the model will result in indexing errors
 73%|███████▎  | 1744/2382 [6:31:38<2:25:27, 13.68s/it]                                                       {'loss': 1.7284, 'learning_rate': 0.00017670019939210026, 'epoch': 0.73}
 73%|███████▎  | 1744/2382 [6:31:38<2:25:27, 13.68s/it] 73%|███████▎  | 1745/2382 [6:31:50<2:19:28, 13.14s/it]                                                       {'loss': 1.8869, 'learning_rate': 0.00017618177564234904, 'epoch': 0.73}
 73%|███████▎  | 1745/2382 [6:31:50<2:19:28, 13.14s/it] 73%|███████▎  | 1746/2382 [6:32:04<2:22:26, 13.44s/it]                                                       {'loss': 1.9454, 'learning_rate': 0.0001756639508238922, 'epoch': 0.73}
 73%|███████▎  | 1746/2382 [6:32:04<2:22:26, 13.44s/it] 73%|███████▎  | 1747/2382 [6:32:17<2:19:58, 13.23s/it]                                                       {'loss': 1.8823, 'learning_rate': 0.00017514672589449376, 'epoch': 0.73}
 73%|███████▎  | 1747/2382 [6:32:17<2:19:58, 13.23s/it] 73%|███████▎  | 1748/2382 [6:32:31<2:24:03, 13.63s/it]                                                       {'loss': 1.862, 'learning_rate': 0.00017463010181080867, 'epoch': 0.73}
 73%|███████▎  | 1748/2382 [6:32:31<2:24:03, 13.63s/it] 73%|███████▎  | 1749/2382 [6:32:46<2:25:21, 13.78s/it]                                                       {'loss': 1.7764, 'learning_rate': 0.00017411407952837977, 'epoch': 0.73}
 73%|███████▎  | 1749/2382 [6:32:46<2:25:21, 13.78s/it] 73%|███████▎  | 1750/2382 [6:32:57<2:19:07, 13.21s/it]                                                       {'loss': 1.8946, 'learning_rate': 0.00017359866000163758, 'epoch': 0.73}
 73%|███████▎  | 1750/2382 [6:32:57<2:19:07, 13.21s/it] 74%|███████▎  | 1751/2382 [6:33:13<2:26:08, 13.90s/it]                                                       {'loss': 1.8084, 'learning_rate': 0.00017308384418389722, 'epoch': 0.73}
 74%|███████▎  | 1751/2382 [6:33:13<2:26:08, 13.90s/it] 74%|███████▎  | 1752/2382 [6:33:29<2:32:31, 14.53s/it]                                                       {'loss': 1.8389, 'learning_rate': 0.0001725696330273575, 'epoch': 0.74}
 74%|███████▎  | 1752/2382 [6:33:29<2:32:31, 14.53s/it] 74%|███████▎  | 1753/2382 [6:33:43<2:30:53, 14.39s/it]                                                       {'loss': 1.8324, 'learning_rate': 0.0001720560274830988, 'epoch': 0.74}
 74%|███████▎  | 1753/2382 [6:33:43<2:30:53, 14.39s/it] 74%|███████▎  | 1754/2382 [6:33:55<2:24:17, 13.79s/it]                                                       {'loss': 1.9543, 'learning_rate': 0.00017154302850108156, 'epoch': 0.74}
 74%|███████▎  | 1754/2382 [6:33:55<2:24:17, 13.79s/it] 74%|███████▎  | 1755/2382 [6:34:14<2:39:59, 15.31s/it]                                                       {'loss': 1.824, 'learning_rate': 0.00017103063703014372, 'epoch': 0.74}
 74%|███████▎  | 1755/2382 [6:34:14<2:39:59, 15.31s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1137 > 1024). Running this sequence through the model will result in indexing errors
 74%|███████▎  | 1756/2382 [6:34:26<2:30:01, 14.38s/it]                                                       {'loss': 1.932, 'learning_rate': 0.00017051885401800015, 'epoch': 0.74}
 74%|███████▎  | 1756/2382 [6:34:26<2:30:01, 14.38s/it] 74%|███████▍  | 1757/2382 [6:34:38<2:21:42, 13.60s/it]                                                       {'loss': 1.8886, 'learning_rate': 0.00017000768041124039, 'epoch': 0.74}
 74%|███████▍  | 1757/2382 [6:34:38<2:21:42, 13.60s/it] 74%|███████▍  | 1758/2382 [6:34:54<2:27:29, 14.18s/it]                                                       {'loss': 1.8388, 'learning_rate': 0.00016949711715532606, 'epoch': 0.74}
 74%|███████▍  | 1758/2382 [6:34:54<2:27:29, 14.18s/it] 74%|███████▍  | 1759/2382 [6:35:06<2:22:28, 13.72s/it]                                                       {'loss': 1.7672, 'learning_rate': 0.00016898716519459073, 'epoch': 0.74}
 74%|███████▍  | 1759/2382 [6:35:06<2:22:28, 13.72s/it] 74%|███████▍  | 1760/2382 [6:35:20<2:20:45, 13.58s/it]                                                       {'loss': 1.8152, 'learning_rate': 0.0001684778254722371, 'epoch': 0.74}
 74%|███████▍  | 1760/2382 [6:35:20<2:20:45, 13.58s/it] 74%|███████▍  | 1761/2382 [6:35:33<2:19:44, 13.50s/it]                                                       {'loss': 1.8708, 'learning_rate': 0.00016796909893033502, 'epoch': 0.74}
 74%|███████▍  | 1761/2382 [6:35:33<2:19:44, 13.50s/it] 74%|███████▍  | 1762/2382 [6:35:52<2:35:37, 15.06s/it]                                                       {'loss': 1.8465, 'learning_rate': 0.00016746098650982072, 'epoch': 0.74}
 74%|███████▍  | 1762/2382 [6:35:52<2:35:37, 15.06s/it] 74%|███████▍  | 1763/2382 [6:36:07<2:35:03, 15.03s/it]                                                       {'loss': 1.8819, 'learning_rate': 0.0001669534891504944, 'epoch': 0.74}
 74%|███████▍  | 1763/2382 [6:36:07<2:35:03, 15.03s/it] 74%|███████▍  | 1764/2382 [6:36:25<2:46:14, 16.14s/it]                                                       {'loss': 1.8266, 'learning_rate': 0.00016644660779101885, 'epoch': 0.74}
 74%|███████▍  | 1764/2382 [6:36:25<2:46:14, 16.14s/it] 74%|███████▍  | 1765/2382 [6:36:38<2:34:05, 14.98s/it]                                                       {'loss': 1.8506, 'learning_rate': 0.00016594034336891688, 'epoch': 0.74}
 74%|███████▍  | 1765/2382 [6:36:38<2:34:05, 14.98s/it] 74%|███████▍  | 1766/2382 [6:36:53<2:34:13, 15.02s/it]                                                       {'loss': 1.8852, 'learning_rate': 0.00016543469682057105, 'epoch': 0.74}
 74%|███████▍  | 1766/2382 [6:36:53<2:34:13, 15.02s/it] 74%|███████▍  | 1767/2382 [6:37:04<2:21:15, 13.78s/it]                                                       {'loss': 1.8662, 'learning_rate': 0.00016492966908122033, 'epoch': 0.74}
 74%|███████▍  | 1767/2382 [6:37:04<2:21:15, 13.78s/it] 74%|███████▍  | 1768/2382 [6:37:17<2:19:22, 13.62s/it]                                                       {'loss': 1.7066, 'learning_rate': 0.0001644252610849597, 'epoch': 0.74}
 74%|███████▍  | 1768/2382 [6:37:17<2:19:22, 13.62s/it] 74%|███████▍  | 1769/2382 [6:37:30<2:17:06, 13.42s/it]                                                       {'loss': 1.8344, 'learning_rate': 0.0001639214737647377, 'epoch': 0.74}
 74%|███████▍  | 1769/2382 [6:37:30<2:17:06, 13.42s/it] 74%|███████▍  | 1770/2382 [6:37:44<2:17:58, 13.53s/it]                                                       {'loss': 1.7921, 'learning_rate': 0.0001634183080523548, 'epoch': 0.74}
 74%|███████▍  | 1770/2382 [6:37:44<2:17:58, 13.53s/it] 74%|███████▍  | 1771/2382 [6:37:59<2:23:19, 14.08s/it]                                                       {'loss': 1.864, 'learning_rate': 0.00016291576487846205, 'epoch': 0.74}
 74%|███████▍  | 1771/2382 [6:37:59<2:23:19, 14.08s/it] 74%|███████▍  | 1772/2382 [6:38:13<2:21:57, 13.96s/it]                                                       {'loss': 1.8443, 'learning_rate': 0.00016241384517255852, 'epoch': 0.74}
 74%|███████▍  | 1772/2382 [6:38:13<2:21:57, 13.96s/it] 74%|███████▍  | 1773/2382 [6:38:26<2:18:43, 13.67s/it]                                                       {'loss': 1.8342, 'learning_rate': 0.00016191254986299043, 'epoch': 0.74}
 74%|███████▍  | 1773/2382 [6:38:26<2:18:43, 13.67s/it] 74%|███████▍  | 1774/2382 [6:38:39<2:17:29, 13.57s/it]                                                       {'loss': 1.8254, 'learning_rate': 0.0001614118798769491, 'epoch': 0.74}
 74%|███████▍  | 1774/2382 [6:38:39<2:17:29, 13.57s/it] 75%|███████▍  | 1775/2382 [6:38:52<2:15:41, 13.41s/it]                                                       {'loss': 1.8464, 'learning_rate': 0.00016091183614046933, 'epoch': 0.74}
 75%|███████▍  | 1775/2382 [6:38:52<2:15:41, 13.41s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1957 > 1024). Running this sequence through the model will result in indexing errors
 75%|███████▍  | 1776/2382 [6:39:05<2:13:13, 13.19s/it]                                                       {'loss': 1.917, 'learning_rate': 0.0001604124195784276, 'epoch': 0.75}
 75%|███████▍  | 1776/2382 [6:39:05<2:13:13, 13.19s/it] 75%|███████▍  | 1777/2382 [6:39:19<2:17:40, 13.65s/it]                                                       {'loss': 1.962, 'learning_rate': 0.0001599136311145402, 'epoch': 0.75}
 75%|███████▍  | 1777/2382 [6:39:20<2:17:40, 13.65s/it] 75%|███████▍  | 1778/2382 [6:39:33<2:15:48, 13.49s/it]                                                       {'loss': 1.841, 'learning_rate': 0.00015941547167136211, 'epoch': 0.75}
 75%|███████▍  | 1778/2382 [6:39:33<2:15:48, 13.49s/it] 75%|███████▍  | 1779/2382 [6:39:44<2:08:13, 12.76s/it]                                                       {'loss': 1.8468, 'learning_rate': 0.0001589179421702842, 'epoch': 0.75}
 75%|███████▍  | 1779/2382 [6:39:44<2:08:13, 12.76s/it] 75%|███████▍  | 1780/2382 [6:39:57<2:10:32, 13.01s/it]                                                       {'loss': 1.9563, 'learning_rate': 0.00015842104353153285, 'epoch': 0.75}
 75%|███████▍  | 1780/2382 [6:39:57<2:10:32, 13.01s/it] 75%|███████▍  | 1781/2382 [6:40:11<2:12:53, 13.27s/it]                                                       {'loss': 1.7365, 'learning_rate': 0.00015792477667416716, 'epoch': 0.75}
 75%|███████▍  | 1781/2382 [6:40:11<2:12:53, 13.27s/it] 75%|███████▍  | 1782/2382 [6:40:24<2:10:00, 13.00s/it]                                                       {'loss': 1.8223, 'learning_rate': 0.00015742914251607793, 'epoch': 0.75}
 75%|███████▍  | 1782/2382 [6:40:24<2:10:00, 13.00s/it] 75%|███████▍  | 1783/2382 [6:40:35<2:06:29, 12.67s/it]                                                       {'loss': 1.9253, 'learning_rate': 0.00015693414197398564, 'epoch': 0.75}
 75%|███████▍  | 1783/2382 [6:40:35<2:06:29, 12.67s/it] 75%|███████▍  | 1784/2382 [6:40:48<2:07:30, 12.79s/it]                                                       {'loss': 1.8317, 'learning_rate': 0.00015643977596343917, 'epoch': 0.75}
 75%|███████▍  | 1784/2382 [6:40:48<2:07:30, 12.79s/it] 75%|███████▍  | 1785/2382 [6:41:03<2:12:59, 13.37s/it]                                                       {'loss': 1.8943, 'learning_rate': 0.000155946045398813, 'epoch': 0.75}
 75%|███████▍  | 1785/2382 [6:41:03<2:12:59, 13.37s/it] 75%|███████▍  | 1786/2382 [6:41:16<2:11:58, 13.29s/it]                                                       {'loss': 1.9381, 'learning_rate': 0.0001554529511933071, 'epoch': 0.75}
 75%|███████▍  | 1786/2382 [6:41:16<2:11:58, 13.29s/it] 75%|███████▌  | 1787/2382 [6:41:33<2:21:13, 14.24s/it]                                                       {'loss': 1.8394, 'learning_rate': 0.0001549604942589441, 'epoch': 0.75}
 75%|███████▌  | 1787/2382 [6:41:33<2:21:13, 14.24s/it] 75%|███████▌  | 1788/2382 [6:41:45<2:14:53, 13.63s/it]                                                       {'loss': 1.9087, 'learning_rate': 0.00015446867550656767, 'epoch': 0.75}
 75%|███████▌  | 1788/2382 [6:41:45<2:14:53, 13.63s/it] 75%|███████▌  | 1789/2382 [6:41:57<2:11:09, 13.27s/it]                                                       {'loss': 1.7517, 'learning_rate': 0.00015397749584584165, 'epoch': 0.75}
 75%|███████▌  | 1789/2382 [6:41:57<2:11:09, 13.27s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1348 > 1024). Running this sequence through the model will result in indexing errors
 75%|███████▌  | 1790/2382 [6:42:13<2:16:56, 13.88s/it]                                                       {'loss': 1.9098, 'learning_rate': 0.00015348695618524756, 'epoch': 0.75}
 75%|███████▌  | 1790/2382 [6:42:13<2:16:56, 13.88s/it] 75%|███████▌  | 1791/2382 [6:42:26<2:14:38, 13.67s/it]                                                       {'loss': 1.7804, 'learning_rate': 0.00015299705743208292, 'epoch': 0.75}
 75%|███████▌  | 1791/2382 [6:42:26<2:14:38, 13.67s/it] 75%|███████▌  | 1792/2382 [6:42:41<2:19:13, 14.16s/it]                                                       {'loss': 1.7901, 'learning_rate': 0.00015250780049246026, 'epoch': 0.75}
 75%|███████▌  | 1792/2382 [6:42:41<2:19:13, 14.16s/it] 75%|███████▌  | 1793/2382 [6:42:54<2:13:43, 13.62s/it]                                                       {'loss': 1.8133, 'learning_rate': 0.0001520191862713049, 'epoch': 0.75}
 75%|███████▌  | 1793/2382 [6:42:54<2:13:43, 13.62s/it] 75%|███████▌  | 1794/2382 [6:43:08<2:14:44, 13.75s/it]                                                       {'loss': 1.844, 'learning_rate': 0.00015153121567235335, 'epoch': 0.75}
 75%|███████▌  | 1794/2382 [6:43:08<2:14:44, 13.75s/it] 75%|███████▌  | 1795/2382 [6:43:22<2:17:06, 14.01s/it]                                                       {'loss': 1.8488, 'learning_rate': 0.00015104388959815142, 'epoch': 0.75}
 75%|███████▌  | 1795/2382 [6:43:22<2:17:06, 14.01s/it] 75%|███████▌  | 1796/2382 [6:43:37<2:19:22, 14.27s/it]                                                       {'loss': 1.8853, 'learning_rate': 0.00015055720895005342, 'epoch': 0.75}
 75%|███████▌  | 1796/2382 [6:43:37<2:19:22, 14.27s/it] 75%|███████▌  | 1797/2382 [6:43:54<2:25:31, 14.93s/it]                                                       {'loss': 1.8216, 'learning_rate': 0.00015007117462821919, 'epoch': 0.75}
 75%|███████▌  | 1797/2382 [6:43:54<2:25:31, 14.93s/it] 75%|███████▌  | 1798/2382 [6:44:06<2:17:19, 14.11s/it]                                                       {'loss': 1.8788, 'learning_rate': 0.0001495857875316136, 'epoch': 0.75}
 75%|███████▌  | 1798/2382 [6:44:06<2:17:19, 14.11s/it] 76%|███████▌  | 1799/2382 [6:44:23<2:26:54, 15.12s/it]                                                       {'loss': 1.8244, 'learning_rate': 0.00014910104855800428, 'epoch': 0.75}
 76%|███████▌  | 1799/2382 [6:44:23<2:26:54, 15.12s/it] 76%|███████▌  | 1800/2382 [6:44:37<2:23:57, 14.84s/it]                                                       {'loss': 1.8999, 'learning_rate': 0.0001486169586039602, 'epoch': 0.76}
 76%|███████▌  | 1800/2382 [6:44:37<2:23:57, 14.84s/it] 76%|███████▌  | 1801/2382 [6:44:50<2:17:08, 14.16s/it]                                                       {'loss': 1.8137, 'learning_rate': 0.0001481335185648498, 'epoch': 0.76}
 76%|███████▌  | 1801/2382 [6:44:50<2:17:08, 14.16s/it] 76%|███████▌  | 1802/2382 [6:45:02<2:09:38, 13.41s/it]                                                       {'loss': 1.8226, 'learning_rate': 0.00014765072933483947, 'epoch': 0.76}
 76%|███████▌  | 1802/2382 [6:45:02<2:09:38, 13.41s/it] 76%|███████▌  | 1803/2382 [6:45:14<2:05:06, 12.96s/it]                                                       {'loss': 1.8469, 'learning_rate': 0.00014716859180689162, 'epoch': 0.76}
 76%|███████▌  | 1803/2382 [6:45:14<2:05:06, 12.96s/it] 76%|███████▌  | 1804/2382 [6:45:27<2:06:47, 13.16s/it]                                                       {'loss': 1.8224, 'learning_rate': 0.00014668710687276365, 'epoch': 0.76}
 76%|███████▌  | 1804/2382 [6:45:27<2:06:47, 13.16s/it] 76%|███████▌  | 1805/2382 [6:45:42<2:12:37, 13.79s/it]                                                       {'loss': 1.8051, 'learning_rate': 0.00014620627542300584, 'epoch': 0.76}
 76%|███████▌  | 1805/2382 [6:45:42<2:12:37, 13.79s/it] 76%|███████▌  | 1806/2382 [6:45:58<2:18:09, 14.39s/it]                                                       {'loss': 1.7978, 'learning_rate': 0.00014572609834695972, 'epoch': 0.76}
 76%|███████▌  | 1806/2382 [6:45:58<2:18:09, 14.39s/it] 76%|███████▌  | 1807/2382 [6:46:13<2:18:18, 14.43s/it]                                                       {'loss': 1.7712, 'learning_rate': 0.00014524657653275654, 'epoch': 0.76}
 76%|███████▌  | 1807/2382 [6:46:13<2:18:18, 14.43s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1393 > 1024). Running this sequence through the model will result in indexing errors
 76%|███████▌  | 1808/2382 [6:46:27<2:17:14, 14.35s/it]                                                       {'loss': 1.7869, 'learning_rate': 0.00014476771086731566, 'epoch': 0.76}
 76%|███████▌  | 1808/2382 [6:46:27<2:17:14, 14.35s/it] 76%|███████▌  | 1809/2382 [6:46:39<2:10:23, 13.65s/it]                                                       {'loss': 1.9636, 'learning_rate': 0.00014428950223634263, 'epoch': 0.76}
 76%|███████▌  | 1809/2382 [6:46:39<2:10:23, 13.65s/it] 76%|███████▌  | 1810/2382 [6:46:52<2:08:20, 13.46s/it]                                                       {'loss': 1.8917, 'learning_rate': 0.00014381195152432768, 'epoch': 0.76}
 76%|███████▌  | 1810/2382 [6:46:52<2:08:20, 13.46s/it] 76%|███████▌  | 1811/2382 [6:47:04<2:03:18, 12.96s/it]                                                       {'loss': 1.8614, 'learning_rate': 0.00014333505961454452, 'epoch': 0.76}
 76%|███████▌  | 1811/2382 [6:47:04<2:03:18, 12.96s/it] 76%|███████▌  | 1812/2382 [6:47:16<2:01:30, 12.79s/it]                                                       {'loss': 1.8489, 'learning_rate': 0.00014285882738904822, 'epoch': 0.76}
 76%|███████▌  | 1812/2382 [6:47:16<2:01:30, 12.79s/it] 76%|███████▌  | 1813/2382 [6:47:31<2:05:55, 13.28s/it]                                                       {'loss': 1.835, 'learning_rate': 0.0001423832557286735, 'epoch': 0.76}
 76%|███████▌  | 1813/2382 [6:47:31<2:05:55, 13.28s/it] 76%|███████▌  | 1814/2382 [6:47:45<2:07:36, 13.48s/it]                                                       {'loss': 1.8062, 'learning_rate': 0.0001419083455130337, 'epoch': 0.76}
 76%|███████▌  | 1814/2382 [6:47:45<2:07:36, 13.48s/it] 76%|███████▌  | 1815/2382 [6:47:57<2:05:14, 13.25s/it]                                                       {'loss': 1.8659, 'learning_rate': 0.0001414340976205183, 'epoch': 0.76}
 76%|███████▌  | 1815/2382 [6:47:57<2:05:14, 13.25s/it] 76%|███████▌  | 1816/2382 [6:48:11<2:05:34, 13.31s/it]                                                       {'loss': 1.8679, 'learning_rate': 0.00014096051292829205, 'epoch': 0.76}
 76%|███████▌  | 1816/2382 [6:48:11<2:05:34, 13.31s/it] 76%|███████▋  | 1817/2382 [6:48:23<2:02:51, 13.05s/it]                                                       {'loss': 1.8169, 'learning_rate': 0.0001404875923122928, 'epoch': 0.76}
 76%|███████▋  | 1817/2382 [6:48:23<2:02:51, 13.05s/it] 76%|███████▋  | 1818/2382 [6:48:35<1:59:09, 12.68s/it]                                                       {'loss': 1.7801, 'learning_rate': 0.00014001533664723047, 'epoch': 0.76}
 76%|███████▋  | 1818/2382 [6:48:35<1:59:09, 12.68s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1103 > 1024). Running this sequence through the model will result in indexing errors
 76%|███████▋  | 1819/2382 [6:48:48<2:00:02, 12.79s/it]                                                       {'loss': 1.7921, 'learning_rate': 0.00013954374680658484, 'epoch': 0.76}
 76%|███████▋  | 1819/2382 [6:48:48<2:00:02, 12.79s/it] 76%|███████▋  | 1820/2382 [6:49:01<1:59:47, 12.79s/it]                                                       {'loss': 1.7942, 'learning_rate': 0.0001390728236626045, 'epoch': 0.76}
 76%|███████▋  | 1820/2382 [6:49:01<1:59:47, 12.79s/it] 76%|███████▋  | 1821/2382 [6:49:13<1:57:17, 12.55s/it]                                                       {'loss': 1.8979, 'learning_rate': 0.00013860256808630427, 'epoch': 0.76}
 76%|███████▋  | 1821/2382 [6:49:13<1:57:17, 12.55s/it] 76%|███████▋  | 1822/2382 [6:49:26<1:58:32, 12.70s/it]                                                       {'loss': 1.8988, 'learning_rate': 0.0001381329809474649, 'epoch': 0.76}
 76%|███████▋  | 1822/2382 [6:49:26<1:58:32, 12.70s/it] 77%|███████▋  | 1823/2382 [6:49:39<2:00:10, 12.90s/it]                                                       {'loss': 1.7441, 'learning_rate': 0.0001376640631146307, 'epoch': 0.77}
 77%|███████▋  | 1823/2382 [6:49:39<2:00:10, 12.90s/it] 77%|███████▋  | 1824/2382 [6:49:57<2:13:45, 14.38s/it]                                                       {'loss': 1.8258, 'learning_rate': 0.00013719581545510763, 'epoch': 0.77}
 77%|███████▋  | 1824/2382 [6:49:57<2:13:45, 14.38s/it] 77%|███████▋  | 1825/2382 [6:50:17<2:28:00, 15.94s/it]                                                       {'loss': 1.7706, 'learning_rate': 0.00013672823883496244, 'epoch': 0.77}
 77%|███████▋  | 1825/2382 [6:50:17<2:28:00, 15.94s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1133 > 1024). Running this sequence through the model will result in indexing errors
 77%|███████▋  | 1826/2382 [6:50:31<2:24:43, 15.62s/it]                                                       {'loss': 1.8459, 'learning_rate': 0.00013626133411902093, 'epoch': 0.77}
 77%|███████▋  | 1826/2382 [6:50:31<2:24:43, 15.62s/it] 77%|███████▋  | 1827/2382 [6:50:46<2:20:54, 15.23s/it]                                                       {'loss': 1.9413, 'learning_rate': 0.0001357951021708655, 'epoch': 0.77}
 77%|███████▋  | 1827/2382 [6:50:46<2:20:54, 15.23s/it] 77%|███████▋  | 1828/2382 [6:50:58<2:13:14, 14.43s/it]                                                       {'loss': 1.772, 'learning_rate': 0.00013532954385283481, 'epoch': 0.77}
 77%|███████▋  | 1828/2382 [6:50:58<2:13:14, 14.43s/it] 77%|███████▋  | 1829/2382 [6:51:12<2:11:30, 14.27s/it]                                                       {'loss': 1.8685, 'learning_rate': 0.00013486466002602133, 'epoch': 0.77}
 77%|███████▋  | 1829/2382 [6:51:12<2:11:30, 14.27s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1097 > 1024). Running this sequence through the model will result in indexing errors
 77%|███████▋  | 1830/2382 [6:51:26<2:10:21, 14.17s/it]                                                       {'loss': 1.8286, 'learning_rate': 0.00013440045155027014, 'epoch': 0.77}
 77%|███████▋  | 1830/2382 [6:51:26<2:10:21, 14.17s/it] 77%|███████▋  | 1831/2382 [6:51:38<2:03:01, 13.40s/it]                                                       {'loss': 1.8729, 'learning_rate': 0.00013393691928417688, 'epoch': 0.77}
 77%|███████▋  | 1831/2382 [6:51:38<2:03:01, 13.40s/it] 77%|███████▋  | 1832/2382 [6:51:51<2:01:08, 13.22s/it]                                                       {'loss': 1.9129, 'learning_rate': 0.00013347406408508694, 'epoch': 0.77}
 77%|███████▋  | 1832/2382 [6:51:51<2:01:08, 13.22s/it] 77%|███████▋  | 1833/2382 [6:52:05<2:03:15, 13.47s/it]                                                       {'loss': 1.8691, 'learning_rate': 0.00013301188680909287, 'epoch': 0.77}
 77%|███████▋  | 1833/2382 [6:52:05<2:03:15, 13.47s/it] 77%|███████▋  | 1834/2382 [6:52:17<1:59:37, 13.10s/it]                                                       {'loss': 1.8842, 'learning_rate': 0.00013255038831103382, 'epoch': 0.77}
 77%|███████▋  | 1834/2382 [6:52:17<1:59:37, 13.10s/it] 77%|███████▋  | 1835/2382 [6:52:31<2:02:37, 13.45s/it]                                                       {'loss': 1.8308, 'learning_rate': 0.0001320895694444932, 'epoch': 0.77}
 77%|███████▋  | 1835/2382 [6:52:31<2:02:37, 13.45s/it] 77%|███████▋  | 1836/2382 [6:52:45<2:04:47, 13.71s/it]                                                       {'loss': 1.7576, 'learning_rate': 0.00013162943106179747, 'epoch': 0.77}
 77%|███████▋  | 1836/2382 [6:52:45<2:04:47, 13.71s/it] 77%|███████▋  | 1837/2382 [6:52:58<2:00:32, 13.27s/it]                                                       {'loss': 1.8141, 'learning_rate': 0.0001311699740140146, 'epoch': 0.77}
 77%|███████▋  | 1837/2382 [6:52:58<2:00:32, 13.27s/it] 77%|███████▋  | 1838/2382 [6:53:10<1:56:47, 12.88s/it]                                                       {'loss': 1.8727, 'learning_rate': 0.00013071119915095226, 'epoch': 0.77}
 77%|███████▋  | 1838/2382 [6:53:10<1:56:47, 12.88s/it] 77%|███████▋  | 1839/2382 [6:53:22<1:54:21, 12.64s/it]                                                       {'loss': 1.8805, 'learning_rate': 0.00013025310732115618, 'epoch': 0.77}
 77%|███████▋  | 1839/2382 [6:53:22<1:54:21, 12.64s/it] 77%|███████▋  | 1840/2382 [6:53:35<1:55:07, 12.74s/it]                                                       {'loss': 1.787, 'learning_rate': 0.00012979569937190887, 'epoch': 0.77}
 77%|███████▋  | 1840/2382 [6:53:35<1:55:07, 12.74s/it] 77%|███████▋  | 1841/2382 [6:53:47<1:54:21, 12.68s/it]                                                       {'loss': 1.8247, 'learning_rate': 0.00012933897614922813, 'epoch': 0.77}
 77%|███████▋  | 1841/2382 [6:53:47<1:54:21, 12.68s/it] 77%|███████▋  | 1842/2382 [6:54:01<1:56:59, 13.00s/it]                                                       {'loss': 1.789, 'learning_rate': 0.00012888293849786504, 'epoch': 0.77}
 77%|███████▋  | 1842/2382 [6:54:01<1:56:59, 13.00s/it] 77%|███████▋  | 1843/2382 [6:54:14<1:56:53, 13.01s/it]                                                       {'loss': 1.9672, 'learning_rate': 0.00012842758726130281, 'epoch': 0.77}
 77%|███████▋  | 1843/2382 [6:54:14<1:56:53, 13.01s/it] 77%|███████▋  | 1844/2382 [6:54:28<2:00:11, 13.40s/it]                                                       {'loss': 1.8786, 'learning_rate': 0.00012797292328175524, 'epoch': 0.77}
 77%|███████▋  | 1844/2382 [6:54:28<2:00:11, 13.40s/it] 77%|███████▋  | 1845/2382 [6:54:41<1:57:43, 13.15s/it]                                                       {'loss': 1.8852, 'learning_rate': 0.00012751894740016434, 'epoch': 0.77}
 77%|███████▋  | 1845/2382 [6:54:41<1:57:43, 13.15s/it] 77%|███████▋  | 1846/2382 [6:54:59<2:09:58, 14.55s/it]                                                       {'loss': 1.8106, 'learning_rate': 0.00012706566045620027, 'epoch': 0.77}
 77%|███████▋  | 1846/2382 [6:54:59<2:09:58, 14.55s/it] 78%|███████▊  | 1847/2382 [6:55:14<2:12:16, 14.83s/it]                                                       {'loss': 1.8451, 'learning_rate': 0.00012661306328825818, 'epoch': 0.78}
 78%|███████▊  | 1847/2382 [6:55:14<2:12:16, 14.83s/it] 78%|███████▊  | 1848/2382 [6:55:28<2:08:42, 14.46s/it]                                                       {'loss': 1.8255, 'learning_rate': 0.00012616115673345785, 'epoch': 0.78}
 78%|███████▊  | 1848/2382 [6:55:28<2:08:42, 14.46s/it] 78%|███████▊  | 1849/2382 [6:55:41<2:04:50, 14.05s/it]                                                       {'loss': 1.9267, 'learning_rate': 0.0001257099416276416, 'epoch': 0.78}
 78%|███████▊  | 1849/2382 [6:55:41<2:04:50, 14.05s/it] 78%|███████▊  | 1850/2382 [6:55:52<1:56:13, 13.11s/it]                                                       {'loss': 1.7966, 'learning_rate': 0.00012525941880537307, 'epoch': 0.78}
 78%|███████▊  | 1850/2382 [6:55:52<1:56:13, 13.11s/it] 78%|███████▊  | 1851/2382 [6:56:06<1:59:17, 13.48s/it]                                                       {'loss': 1.8348, 'learning_rate': 0.0001248095890999349, 'epoch': 0.78}
 78%|███████▊  | 1851/2382 [6:56:06<1:59:17, 13.48s/it] 78%|███████▊  | 1852/2382 [6:56:19<1:58:04, 13.37s/it]                                                       {'loss': 1.8127, 'learning_rate': 0.00012436045334332825, 'epoch': 0.78}
 78%|███████▊  | 1852/2382 [6:56:19<1:58:04, 13.37s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1135 > 1024). Running this sequence through the model will result in indexing errors
 78%|███████▊  | 1853/2382 [6:56:34<2:01:05, 13.73s/it]                                                       {'loss': 1.8969, 'learning_rate': 0.00012391201236627074, 'epoch': 0.78}
 78%|███████▊  | 1853/2382 [6:56:34<2:01:05, 13.73s/it] 78%|███████▊  | 1854/2382 [6:56:48<2:01:26, 13.80s/it]                                                       {'loss': 1.7188, 'learning_rate': 0.00012346426699819457, 'epoch': 0.78}
 78%|███████▊  | 1854/2382 [6:56:48<2:01:26, 13.80s/it] 78%|███████▊  | 1855/2382 [6:57:00<1:58:04, 13.44s/it]                                                       {'loss': 1.839, 'learning_rate': 0.00012301721806724564, 'epoch': 0.78}
 78%|███████▊  | 1855/2382 [6:57:00<1:58:04, 13.44s/it] 78%|███████▊  | 1856/2382 [6:57:14<1:59:23, 13.62s/it]                                                       {'loss': 1.8962, 'learning_rate': 0.0001225708664002818, 'epoch': 0.78}
 78%|███████▊  | 1856/2382 [6:57:14<1:59:23, 13.62s/it] 78%|███████▊  | 1857/2382 [6:57:28<1:57:41, 13.45s/it]                                                       {'loss': 1.8692, 'learning_rate': 0.00012212521282287093, 'epoch': 0.78}
 78%|███████▊  | 1857/2382 [6:57:28<1:57:41, 13.45s/it] 78%|███████▊  | 1858/2382 [6:57:41<1:57:40, 13.47s/it]                                                       {'loss': 1.7664, 'learning_rate': 0.0001216802581592899, 'epoch': 0.78}
 78%|███████▊  | 1858/2382 [6:57:41<1:57:40, 13.47s/it] 78%|███████▊  | 1859/2382 [6:57:55<1:57:46, 13.51s/it]                                                       {'loss': 1.8176, 'learning_rate': 0.00012123600323252294, 'epoch': 0.78}
 78%|███████▊  | 1859/2382 [6:57:55<1:57:46, 13.51s/it] 78%|███████▊  | 1860/2382 [6:58:08<1:56:38, 13.41s/it]                                                       {'loss': 1.9247, 'learning_rate': 0.00012079244886426016, 'epoch': 0.78}
 78%|███████▊  | 1860/2382 [6:58:08<1:56:38, 13.41s/it] 78%|███████▊  | 1861/2382 [6:58:23<1:59:45, 13.79s/it]                                                       {'loss': 1.9569, 'learning_rate': 0.00012034959587489542, 'epoch': 0.78}
 78%|███████▊  | 1861/2382 [6:58:23<1:59:45, 13.79s/it] 78%|███████▊  | 1862/2382 [6:58:35<1:57:07, 13.51s/it]                                                       {'loss': 1.7628, 'learning_rate': 0.00011990744508352603, 'epoch': 0.78}
 78%|███████▊  | 1862/2382 [6:58:35<1:57:07, 13.51s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1266 > 1024). Running this sequence through the model will result in indexing errors
 78%|███████▊  | 1863/2382 [6:58:50<2:00:36, 13.94s/it]                                                       {'loss': 1.8283, 'learning_rate': 0.00011946599730794972, 'epoch': 0.78}
 78%|███████▊  | 1863/2382 [6:58:50<2:00:36, 13.94s/it] 78%|███████▊  | 1864/2382 [6:59:03<1:56:59, 13.55s/it]                                                       {'loss': 1.7522, 'learning_rate': 0.00011902525336466464, 'epoch': 0.78}
 78%|███████▊  | 1864/2382 [6:59:03<1:56:59, 13.55s/it] 78%|███████▊  | 1865/2382 [6:59:18<2:00:50, 14.02s/it]                                                       {'loss': 1.8129, 'learning_rate': 0.00011858521406886675, 'epoch': 0.78}
 78%|███████▊  | 1865/2382 [6:59:18<2:00:50, 14.02s/it] 78%|███████▊  | 1866/2382 [6:59:31<1:57:06, 13.62s/it]                                                       {'loss': 1.9787, 'learning_rate': 0.00011814588023444878, 'epoch': 0.78}
 78%|███████▊  | 1866/2382 [6:59:31<1:57:06, 13.62s/it] 78%|███████▊  | 1867/2382 [6:59:45<1:58:49, 13.84s/it]                                                       {'loss': 1.8145, 'learning_rate': 0.0001177072526739989, 'epoch': 0.78}
 78%|███████▊  | 1867/2382 [6:59:45<1:58:49, 13.84s/it] 78%|███████▊  | 1868/2382 [6:59:58<1:54:52, 13.41s/it]                                                       {'loss': 1.9247, 'learning_rate': 0.00011726933219879854, 'epoch': 0.78}
 78%|███████▊  | 1868/2382 [6:59:58<1:54:52, 13.41s/it] 78%|███████▊  | 1869/2382 [7:00:14<2:03:32, 14.45s/it]                                                       {'loss': 1.8043, 'learning_rate': 0.00011683211961882134, 'epoch': 0.78}
 78%|███████▊  | 1869/2382 [7:00:14<2:03:32, 14.45s/it] 79%|███████▊  | 1870/2382 [7:00:29<2:03:27, 14.47s/it]                                                       {'loss': 1.7989, 'learning_rate': 0.000116395615742732, 'epoch': 0.78}
 79%|███████▊  | 1870/2382 [7:00:29<2:03:27, 14.47s/it] 79%|███████▊  | 1871/2382 [7:00:44<2:05:16, 14.71s/it]                                                       {'loss': 1.8934, 'learning_rate': 0.00011595982137788402, 'epoch': 0.79}
 79%|███████▊  | 1871/2382 [7:00:44<2:05:16, 14.71s/it] 79%|███████▊  | 1872/2382 [7:00:59<2:04:42, 14.67s/it]                                                       {'loss': 1.8269, 'learning_rate': 0.00011552473733031893, 'epoch': 0.79}
 79%|███████▊  | 1872/2382 [7:00:59<2:04:42, 14.67s/it] 79%|███████▊  | 1873/2382 [7:01:13<2:02:46, 14.47s/it]                                                       {'loss': 1.8252, 'learning_rate': 0.00011509036440476439, 'epoch': 0.79}
 79%|███████▊  | 1873/2382 [7:01:13<2:02:46, 14.47s/it] 79%|███████▊  | 1874/2382 [7:01:24<1:54:41, 13.55s/it]                                                       {'loss': 1.8554, 'learning_rate': 0.00011465670340463241, 'epoch': 0.79}
 79%|███████▊  | 1874/2382 [7:01:24<1:54:41, 13.55s/it] 79%|███████▊  | 1875/2382 [7:01:39<1:58:13, 13.99s/it]                                                       {'loss': 1.7774, 'learning_rate': 0.00011422375513201854, 'epoch': 0.79}
 79%|███████▊  | 1875/2382 [7:01:39<1:58:13, 13.99s/it] 79%|███████▉  | 1876/2382 [7:01:53<1:58:35, 14.06s/it]                                                       {'loss': 1.8367, 'learning_rate': 0.00011379152038770029, 'epoch': 0.79}
 79%|███████▉  | 1876/2382 [7:01:53<1:58:35, 14.06s/it] 79%|███████▉  | 1877/2382 [7:02:05<1:50:52, 13.17s/it]                                                       {'loss': 1.8836, 'learning_rate': 0.00011335999997113489, 'epoch': 0.79}
 79%|███████▉  | 1877/2382 [7:02:05<1:50:52, 13.17s/it] 79%|███████▉  | 1878/2382 [7:02:16<1:47:05, 12.75s/it]                                                       {'loss': 1.9145, 'learning_rate': 0.00011292919468045875, 'epoch': 0.79}
 79%|███████▉  | 1878/2382 [7:02:16<1:47:05, 12.75s/it] 79%|███████▉  | 1879/2382 [7:02:31<1:52:47, 13.45s/it]                                                       {'loss': 1.7904, 'learning_rate': 0.00011249910531248564, 'epoch': 0.79}
 79%|███████▉  | 1879/2382 [7:02:31<1:52:47, 13.45s/it] 79%|███████▉  | 1880/2382 [7:02:44<1:51:16, 13.30s/it]                                                       {'loss': 1.7838, 'learning_rate': 0.00011206973266270476, 'epoch': 0.79}
 79%|███████▉  | 1880/2382 [7:02:44<1:51:16, 13.30s/it] 79%|███████▉  | 1881/2382 [7:02:57<1:49:44, 13.14s/it]                                                       {'loss': 1.836, 'learning_rate': 0.00011164107752528002, 'epoch': 0.79}
 79%|███████▉  | 1881/2382 [7:02:57<1:49:44, 13.14s/it] 79%|███████▉  | 1882/2382 [7:03:13<1:55:26, 13.85s/it]                                                       {'loss': 1.8343, 'learning_rate': 0.00011121314069304811, 'epoch': 0.79}
 79%|███████▉  | 1882/2382 [7:03:13<1:55:26, 13.85s/it] 79%|███████▉  | 1883/2382 [7:03:27<1:56:30, 14.01s/it]                                                       {'loss': 1.7947, 'learning_rate': 0.00011078592295751738, 'epoch': 0.79}
 79%|███████▉  | 1883/2382 [7:03:27<1:56:30, 14.01s/it] 79%|███████▉  | 1884/2382 [7:03:43<2:02:03, 14.71s/it]                                                       {'loss': 1.8176, 'learning_rate': 0.00011035942510886565, 'epoch': 0.79}
 79%|███████▉  | 1884/2382 [7:03:43<2:02:03, 14.71s/it] 79%|███████▉  | 1885/2382 [7:03:55<1:53:21, 13.68s/it]                                                       {'loss': 1.8221, 'learning_rate': 0.0001099336479359398, 'epoch': 0.79}
 79%|███████▉  | 1885/2382 [7:03:55<1:53:21, 13.68s/it] 79%|███████▉  | 1886/2382 [7:04:06<1:48:36, 13.14s/it]                                                       {'loss': 1.8902, 'learning_rate': 0.00010950859222625314, 'epoch': 0.79}
 79%|███████▉  | 1886/2382 [7:04:06<1:48:36, 13.14s/it] 79%|███████▉  | 1887/2382 [7:04:20<1:48:26, 13.15s/it]                                                       {'loss': 1.8478, 'learning_rate': 0.0001090842587659851, 'epoch': 0.79}
 79%|███████▉  | 1887/2382 [7:04:20<1:48:26, 13.15s/it] 79%|███████▉  | 1888/2382 [7:04:34<1:51:04, 13.49s/it]                                                       {'loss': 1.7821, 'learning_rate': 0.00010866064833997914, 'epoch': 0.79}
 79%|███████▉  | 1888/2382 [7:04:34<1:51:04, 13.49s/it] 79%|███████▉  | 1889/2382 [7:04:48<1:52:58, 13.75s/it]                                                       {'loss': 1.8157, 'learning_rate': 0.00010823776173174116, 'epoch': 0.79}
 79%|███████▉  | 1889/2382 [7:04:48<1:52:58, 13.75s/it] 79%|███████▉  | 1890/2382 [7:05:01<1:51:21, 13.58s/it]                                                       {'loss': 1.8439, 'learning_rate': 0.00010781559972343869, 'epoch': 0.79}
 79%|███████▉  | 1890/2382 [7:05:01<1:51:21, 13.58s/it] 79%|███████▉  | 1891/2382 [7:05:13<1:46:55, 13.07s/it]                                                       {'loss': 1.8147, 'learning_rate': 0.00010739416309589867, 'epoch': 0.79}
 79%|███████▉  | 1891/2382 [7:05:13<1:46:55, 13.07s/it] 79%|███████▉  | 1892/2382 [7:05:25<1:43:22, 12.66s/it]                                                       {'loss': 1.8733, 'learning_rate': 0.00010697345262860636, 'epoch': 0.79}
 79%|███████▉  | 1892/2382 [7:05:25<1:43:22, 12.66s/it] 79%|███████▉  | 1893/2382 [7:05:39<1:46:31, 13.07s/it]                                                       {'loss': 1.8312, 'learning_rate': 0.0001065534690997042, 'epoch': 0.79}
 79%|███████▉  | 1893/2382 [7:05:39<1:46:31, 13.07s/it] 80%|███████▉  | 1894/2382 [7:05:52<1:46:10, 13.05s/it]                                                       {'loss': 1.7959, 'learning_rate': 0.00010613421328599005, 'epoch': 0.79}
 80%|███████▉  | 1894/2382 [7:05:52<1:46:10, 13.05s/it] 80%|███████▉  | 1895/2382 [7:06:05<1:46:31, 13.12s/it]                                                       {'loss': 1.8416, 'learning_rate': 0.00010571568596291559, 'epoch': 0.8}
 80%|███████▉  | 1895/2382 [7:06:05<1:46:31, 13.12s/it] 80%|███████▉  | 1896/2382 [7:06:19<1:46:18, 13.12s/it]                                                       {'loss': 1.8712, 'learning_rate': 0.00010529788790458534, 'epoch': 0.8}
 80%|███████▉  | 1896/2382 [7:06:19<1:46:18, 13.12s/it] 80%|███████▉  | 1897/2382 [7:06:31<1:45:24, 13.04s/it]                                                       {'loss': 1.7763, 'learning_rate': 0.00010488081988375492, 'epoch': 0.8}
 80%|███████▉  | 1897/2382 [7:06:31<1:45:24, 13.04s/it] 80%|███████▉  | 1898/2382 [7:06:46<1:49:30, 13.58s/it]                                                       {'loss': 1.8425, 'learning_rate': 0.00010446448267182951, 'epoch': 0.8}
 80%|███████▉  | 1898/2382 [7:06:46<1:49:30, 13.58s/it] 80%|███████▉  | 1899/2382 [7:07:00<1:49:57, 13.66s/it]                                                       {'loss': 1.778, 'learning_rate': 0.0001040488770388625, 'epoch': 0.8}
 80%|███████▉  | 1899/2382 [7:07:00<1:49:57, 13.66s/it] 80%|███████▉  | 1900/2382 [7:07:14<1:49:34, 13.64s/it]                                                       {'loss': 1.7885, 'learning_rate': 0.00010363400375355464, 'epoch': 0.8}
 80%|███████▉  | 1900/2382 [7:07:14<1:49:34, 13.64s/it] 80%|███████▉  | 1901/2382 [7:07:30<1:55:27, 14.40s/it]                                                       {'loss': 1.8614, 'learning_rate': 0.00010321986358325169, 'epoch': 0.8}
 80%|███████▉  | 1901/2382 [7:07:30<1:55:27, 14.40s/it] 80%|███████▉  | 1902/2382 [7:07:42<1:49:17, 13.66s/it]                                                       {'loss': 1.8, 'learning_rate': 0.00010280645729394367, 'epoch': 0.8}
 80%|███████▉  | 1902/2382 [7:07:42<1:49:17, 13.66s/it] 80%|███████▉  | 1903/2382 [7:08:00<2:00:28, 15.09s/it]                                                       {'loss': 1.8789, 'learning_rate': 0.0001023937856502633, 'epoch': 0.8}
 80%|███████▉  | 1903/2382 [7:08:00<2:00:28, 15.09s/it] 80%|███████▉  | 1904/2382 [7:08:14<1:56:01, 14.56s/it]                                                       {'loss': 1.7567, 'learning_rate': 0.00010198184941548405, 'epoch': 0.8}
 80%|███████▉  | 1904/2382 [7:08:14<1:56:01, 14.56s/it] 80%|███████▉  | 1905/2382 [7:08:27<1:53:41, 14.30s/it]                                                       {'loss': 1.8699, 'learning_rate': 0.00010157064935151988, 'epoch': 0.8}
 80%|███████▉  | 1905/2382 [7:08:27<1:53:41, 14.30s/it] 80%|████████  | 1906/2382 [7:08:41<1:51:33, 14.06s/it]                                                       {'loss': 1.7693, 'learning_rate': 0.00010116018621892236, 'epoch': 0.8}
 80%|████████  | 1906/2382 [7:08:41<1:51:33, 14.06s/it] 80%|████████  | 1907/2382 [7:08:53<1:45:58, 13.39s/it]                                                       {'loss': 1.9257, 'learning_rate': 0.00010075046077688066, 'epoch': 0.8}
 80%|████████  | 1907/2382 [7:08:53<1:45:58, 13.39s/it] 80%|████████  | 1908/2382 [7:09:06<1:45:22, 13.34s/it]                                                       {'loss': 1.825, 'learning_rate': 0.00010034147378321923, 'epoch': 0.8}
 80%|████████  | 1908/2382 [7:09:06<1:45:22, 13.34s/it] 80%|████████  | 1909/2382 [7:09:18<1:42:10, 12.96s/it]                                                       {'loss': 1.9117, 'learning_rate': 9.993322599439691e-05, 'epoch': 0.8}
 80%|████████  | 1909/2382 [7:09:18<1:42:10, 12.96s/it] 80%|████████  | 1910/2382 [7:09:30<1:40:34, 12.79s/it]                                                       {'loss': 1.8366, 'learning_rate': 9.952571816550494e-05, 'epoch': 0.8}
 80%|████████  | 1910/2382 [7:09:30<1:40:34, 12.79s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1237 > 1024). Running this sequence through the model will result in indexing errors
 80%|████████  | 1911/2382 [7:09:42<1:38:45, 12.58s/it]                                                       {'loss': 1.7677, 'learning_rate': 9.911895105026625e-05, 'epoch': 0.8}
 80%|████████  | 1911/2382 [7:09:42<1:38:45, 12.58s/it] 80%|████████  | 1912/2382 [7:09:58<1:45:45, 13.50s/it]                                                       {'loss': 1.767, 'learning_rate': 9.871292540103377e-05, 'epoch': 0.8}
 80%|████████  | 1912/2382 [7:09:58<1:45:45, 13.50s/it] 80%|████████  | 1913/2382 [7:10:10<1:41:54, 13.04s/it]                                                       {'loss': 1.7577, 'learning_rate': 9.830764196878872e-05, 'epoch': 0.8}
 80%|████████  | 1913/2382 [7:10:10<1:41:54, 13.04s/it] 80%|████████  | 1914/2382 [7:10:22<1:39:10, 12.71s/it]                                                       {'loss': 1.7741, 'learning_rate': 9.790310150313974e-05, 'epoch': 0.8}
 80%|████████  | 1914/2382 [7:10:22<1:39:10, 12.71s/it] 80%|████████  | 1915/2382 [7:10:35<1:40:06, 12.86s/it]                                                       {'loss': 1.768, 'learning_rate': 9.749930475232155e-05, 'epoch': 0.8}
 80%|████████  | 1915/2382 [7:10:35<1:40:06, 12.86s/it] 80%|████████  | 1916/2382 [7:10:50<1:43:34, 13.33s/it]                                                       {'loss': 1.7552, 'learning_rate': 9.70962524631926e-05, 'epoch': 0.8}
 80%|████████  | 1916/2382 [7:10:50<1:43:34, 13.33s/it] 80%|████████  | 1917/2382 [7:11:04<1:46:57, 13.80s/it]                                                       {'loss': 1.8006, 'learning_rate': 9.6693945381235e-05, 'epoch': 0.8}
 80%|████████  | 1917/2382 [7:11:04<1:46:57, 13.80s/it] 81%|████████  | 1918/2382 [7:11:18<1:46:04, 13.72s/it]                                                       {'loss': 1.7986, 'learning_rate': 9.629238425055231e-05, 'epoch': 0.8}
 81%|████████  | 1918/2382 [7:11:18<1:46:04, 13.72s/it] 81%|████████  | 1919/2382 [7:11:31<1:45:20, 13.65s/it]                                                       {'loss': 1.7905, 'learning_rate': 9.58915698138686e-05, 'epoch': 0.81}
 81%|████████  | 1919/2382 [7:11:31<1:45:20, 13.65s/it] 81%|████████  | 1920/2382 [7:11:47<1:49:27, 14.22s/it]                                                       {'loss': 1.8537, 'learning_rate': 9.549150281252633e-05, 'epoch': 0.81}
 81%|████████  | 1920/2382 [7:11:47<1:49:27, 14.22s/it] 81%|████████  | 1921/2382 [7:12:01<1:49:39, 14.27s/it]                                                       {'loss': 1.8513, 'learning_rate': 9.509218398648617e-05, 'epoch': 0.81}
 81%|████████  | 1921/2382 [7:12:01<1:49:39, 14.27s/it] 81%|████████  | 1922/2382 [7:12:14<1:45:16, 13.73s/it]                                                       {'loss': 1.882, 'learning_rate': 9.46936140743243e-05, 'epoch': 0.81}
 81%|████████  | 1922/2382 [7:12:14<1:45:16, 13.73s/it] 81%|████████  | 1923/2382 [7:12:30<1:50:12, 14.41s/it]                                                       {'loss': 1.9148, 'learning_rate': 9.429579381323233e-05, 'epoch': 0.81}
 81%|████████  | 1923/2382 [7:12:30<1:50:12, 14.41s/it] 81%|████████  | 1924/2382 [7:12:45<1:51:22, 14.59s/it]                                                       {'loss': 1.8381, 'learning_rate': 9.389872393901499e-05, 'epoch': 0.81}
 81%|████████  | 1924/2382 [7:12:45<1:51:22, 14.59s/it] 81%|████████  | 1925/2382 [7:13:03<1:59:16, 15.66s/it]                                                       {'loss': 1.7657, 'learning_rate': 9.350240518608922e-05, 'epoch': 0.81}
 81%|████████  | 1925/2382 [7:13:03<1:59:16, 15.66s/it] 81%|████████  | 1926/2382 [7:13:16<1:53:25, 14.92s/it]                                                       {'loss': 1.7483, 'learning_rate': 9.31068382874825e-05, 'epoch': 0.81}
 81%|████████  | 1926/2382 [7:13:16<1:53:25, 14.92s/it] 81%|████████  | 1927/2382 [7:13:31<1:53:25, 14.96s/it]                                                       {'loss': 1.7744, 'learning_rate': 9.271202397483213e-05, 'epoch': 0.81}
 81%|████████  | 1927/2382 [7:13:31<1:53:25, 14.96s/it] 81%|████████  | 1928/2382 [7:13:45<1:50:15, 14.57s/it]                                                       {'loss': 1.9257, 'learning_rate': 9.231796297838297e-05, 'epoch': 0.81}
 81%|████████  | 1928/2382 [7:13:45<1:50:15, 14.57s/it] 81%|████████  | 1929/2382 [7:13:58<1:47:17, 14.21s/it]                                                       {'loss': 1.9289, 'learning_rate': 9.192465602698651e-05, 'epoch': 0.81}
 81%|████████  | 1929/2382 [7:13:58<1:47:17, 14.21s/it] 81%|████████  | 1930/2382 [7:14:12<1:46:18, 14.11s/it]                                                       {'loss': 1.8615, 'learning_rate': 9.153210384809995e-05, 'epoch': 0.81}
 81%|████████  | 1930/2382 [7:14:12<1:46:18, 14.11s/it] 81%|████████  | 1931/2382 [7:14:25<1:42:57, 13.70s/it]                                                       {'loss': 1.7738, 'learning_rate': 9.114030716778432e-05, 'epoch': 0.81}
 81%|████████  | 1931/2382 [7:14:25<1:42:57, 13.70s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1343 > 1024). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (1070 > 1024). Running this sequence through the model will result in indexing errors
 81%|████████  | 1932/2382 [7:14:38<1:41:47, 13.57s/it]                                                       {'loss': 1.7686, 'learning_rate': 9.074926671070321e-05, 'epoch': 0.81}
 81%|████████  | 1932/2382 [7:14:38<1:41:47, 13.57s/it] 81%|████████  | 1933/2382 [7:14:51<1:40:57, 13.49s/it]                                                       {'loss': 1.8355, 'learning_rate': 9.03589832001217e-05, 'epoch': 0.81}
 81%|████████  | 1933/2382 [7:14:51<1:40:57, 13.49s/it] 81%|████████  | 1934/2382 [7:15:04<1:38:34, 13.20s/it]                                                       {'loss': 1.8972, 'learning_rate': 8.996945735790446e-05, 'epoch': 0.81}
 81%|████████  | 1934/2382 [7:15:04<1:38:34, 13.20s/it] 81%|████████  | 1935/2382 [7:15:17<1:37:59, 13.15s/it]                                                       {'loss': 1.7742, 'learning_rate': 8.958068990451524e-05, 'epoch': 0.81}
 81%|████████  | 1935/2382 [7:15:17<1:37:59, 13.15s/it] 81%|████████▏ | 1936/2382 [7:15:30<1:36:44, 13.01s/it]                                                       {'loss': 1.7997, 'learning_rate': 8.919268155901456e-05, 'epoch': 0.81}
 81%|████████▏ | 1936/2382 [7:15:30<1:36:44, 13.01s/it] 81%|████████▏ | 1937/2382 [7:15:42<1:35:31, 12.88s/it]                                                       {'loss': 1.8479, 'learning_rate': 8.88054330390593e-05, 'epoch': 0.81}
 81%|████████▏ | 1937/2382 [7:15:42<1:35:31, 12.88s/it] 81%|████████▏ | 1938/2382 [7:15:54<1:32:02, 12.44s/it]                                                       {'loss': 1.8808, 'learning_rate': 8.841894506090098e-05, 'epoch': 0.81}
 81%|████████▏ | 1938/2382 [7:15:54<1:32:02, 12.44s/it] 81%|████████▏ | 1939/2382 [7:16:10<1:39:42, 13.50s/it]                                                       {'loss': 1.853, 'learning_rate': 8.803321833938432e-05, 'epoch': 0.81}
 81%|████████▏ | 1939/2382 [7:16:10<1:39:42, 13.50s/it] 81%|████████▏ | 1940/2382 [7:16:23<1:39:38, 13.53s/it]                                                       {'loss': 1.8318, 'learning_rate': 8.764825358794587e-05, 'epoch': 0.81}
 81%|████████▏ | 1940/2382 [7:16:23<1:39:38, 13.53s/it] 81%|████████▏ | 1941/2382 [7:16:37<1:40:28, 13.67s/it]                                                       {'loss': 1.8417, 'learning_rate': 8.7264051518613e-05, 'epoch': 0.81}
 81%|████████▏ | 1941/2382 [7:16:37<1:40:28, 13.67s/it] 82%|████████▏ | 1942/2382 [7:16:51<1:40:25, 13.69s/it]                                                       {'loss': 1.8795, 'learning_rate': 8.688061284200266e-05, 'epoch': 0.81}
 82%|████████▏ | 1942/2382 [7:16:51<1:40:25, 13.69s/it] 82%|████████▏ | 1943/2382 [7:17:05<1:40:20, 13.71s/it]                                                       {'loss': 1.8664, 'learning_rate': 8.649793826731922e-05, 'epoch': 0.82}
 82%|████████▏ | 1943/2382 [7:17:05<1:40:20, 13.71s/it] 82%|████████▏ | 1944/2382 [7:17:16<1:35:26, 13.07s/it]                                                       {'loss': 1.804, 'learning_rate': 8.611602850235445e-05, 'epoch': 0.82}
 82%|████████▏ | 1944/2382 [7:17:16<1:35:26, 13.07s/it] 82%|████████▏ | 1945/2382 [7:17:30<1:37:29, 13.38s/it]                                                       {'loss': 1.8118, 'learning_rate': 8.573488425348519e-05, 'epoch': 0.82}
 82%|████████▏ | 1945/2382 [7:17:30<1:37:29, 13.38s/it] 82%|████████▏ | 1946/2382 [7:17:43<1:35:44, 13.18s/it]                                                       {'loss': 1.7938, 'learning_rate': 8.535450622567231e-05, 'epoch': 0.82}
 82%|████████▏ | 1946/2382 [7:17:43<1:35:44, 13.18s/it] 82%|████████▏ | 1947/2382 [7:17:56<1:33:47, 12.94s/it]                                                       {'loss': 1.8602, 'learning_rate': 8.49748951224597e-05, 'epoch': 0.82}
 82%|████████▏ | 1947/2382 [7:17:56<1:33:47, 12.94s/it] 82%|████████▏ | 1948/2382 [7:18:10<1:37:54, 13.54s/it]                                                       {'loss': 1.8622, 'learning_rate': 8.459605164597267e-05, 'epoch': 0.82}
 82%|████████▏ | 1948/2382 [7:18:10<1:37:54, 13.54s/it] 82%|████████▏ | 1949/2382 [7:18:22<1:32:48, 12.86s/it]                                                       {'loss': 1.827, 'learning_rate': 8.421797649691681e-05, 'epoch': 0.82}
 82%|████████▏ | 1949/2382 [7:18:22<1:32:48, 12.86s/it] 82%|████████▏ | 1950/2382 [7:18:34<1:30:29, 12.57s/it]                                                       {'loss': 1.8776, 'learning_rate': 8.384067037457638e-05, 'epoch': 0.82}
 82%|████████▏ | 1950/2382 [7:18:34<1:30:29, 12.57s/it] 82%|████████▏ | 1951/2382 [7:18:46<1:30:55, 12.66s/it]                                                       {'loss': 1.8969, 'learning_rate': 8.346413397681352e-05, 'epoch': 0.82}
 82%|████████▏ | 1951/2382 [7:18:46<1:30:55, 12.66s/it] 82%|████████▏ | 1952/2382 [7:19:00<1:32:39, 12.93s/it]                                                       {'loss': 1.8874, 'learning_rate': 8.308836800006647e-05, 'epoch': 0.82}
 82%|████████▏ | 1952/2382 [7:19:00<1:32:39, 12.93s/it] 82%|████████▏ | 1953/2382 [7:19:16<1:38:16, 13.74s/it]                                                       {'loss': 1.7873, 'learning_rate': 8.271337313934868e-05, 'epoch': 0.82}
 82%|████████▏ | 1953/2382 [7:19:16<1:38:16, 13.74s/it] 82%|████████▏ | 1954/2382 [7:19:30<1:39:24, 13.94s/it]                                                       {'loss': 1.7886, 'learning_rate': 8.233915008824733e-05, 'epoch': 0.82}
 82%|████████▏ | 1954/2382 [7:19:30<1:39:24, 13.94s/it] 82%|████████▏ | 1955/2382 [7:19:41<1:33:03, 13.08s/it]                                                       {'loss': 1.8665, 'learning_rate': 8.196569953892202e-05, 'epoch': 0.82}
 82%|████████▏ | 1955/2382 [7:19:41<1:33:03, 13.08s/it] 82%|████████▏ | 1956/2382 [7:19:55<1:33:26, 13.16s/it]                                                       {'loss': 1.9435, 'learning_rate': 8.159302218210368e-05, 'epoch': 0.82}
 82%|████████▏ | 1956/2382 [7:19:55<1:33:26, 13.16s/it] 82%|████████▏ | 1957/2382 [7:20:07<1:31:24, 12.90s/it]                                                       {'loss': 1.8776, 'learning_rate': 8.122111870709286e-05, 'epoch': 0.82}
 82%|████████▏ | 1957/2382 [7:20:07<1:31:24, 12.90s/it] 82%|████████▏ | 1958/2382 [7:20:22<1:36:34, 13.67s/it]                                                       {'loss': 1.7363, 'learning_rate': 8.084998980175878e-05, 'epoch': 0.82}
 82%|████████▏ | 1958/2382 [7:20:22<1:36:34, 13.67s/it] 82%|████████▏ | 1959/2382 [7:20:35<1:35:15, 13.51s/it]                                                       {'loss': 1.9086, 'learning_rate': 8.047963615253833e-05, 'epoch': 0.82}
 82%|████████▏ | 1959/2382 [7:20:35<1:35:15, 13.51s/it] 82%|████████▏ | 1960/2382 [7:20:47<1:30:43, 12.90s/it]                                                       {'loss': 1.8331, 'learning_rate': 8.011005844443425e-05, 'epoch': 0.82}
 82%|████████▏ | 1960/2382 [7:20:47<1:30:43, 12.90s/it] 82%|████████▏ | 1961/2382 [7:21:01<1:32:28, 13.18s/it]                                                       {'loss': 1.8376, 'learning_rate': 7.974125736101418e-05, 'epoch': 0.82}
 82%|████████▏ | 1961/2382 [7:21:01<1:32:28, 13.18s/it] 82%|████████▏ | 1962/2382 [7:21:14<1:31:33, 13.08s/it]                                                       {'loss': 1.8559, 'learning_rate': 7.937323358440934e-05, 'epoch': 0.82}
 82%|████████▏ | 1962/2382 [7:21:14<1:31:33, 13.08s/it] 82%|████████▏ | 1963/2382 [7:21:28<1:35:12, 13.63s/it]                                                       {'loss': 1.826, 'learning_rate': 7.900598779531331e-05, 'epoch': 0.82}
 82%|████████▏ | 1963/2382 [7:21:28<1:35:12, 13.63s/it] 82%|████████▏ | 1964/2382 [7:21:42<1:34:12, 13.52s/it]                                                       {'loss': 1.7717, 'learning_rate': 7.863952067298042e-05, 'epoch': 0.82}
 82%|████████▏ | 1964/2382 [7:21:42<1:34:12, 13.52s/it] 82%|████████▏ | 1965/2382 [7:21:53<1:28:39, 12.76s/it]                                                       {'loss': 1.8687, 'learning_rate': 7.827383289522516e-05, 'epoch': 0.82}
 82%|████████▏ | 1965/2382 [7:21:53<1:28:39, 12.76s/it] 83%|████████▎ | 1966/2382 [7:22:08<1:33:13, 13.45s/it]                                                       {'loss': 1.7455, 'learning_rate': 7.790892513842019e-05, 'epoch': 0.83}
 83%|████████▎ | 1966/2382 [7:22:08<1:33:13, 13.45s/it] 83%|████████▎ | 1967/2382 [7:22:20<1:31:17, 13.20s/it]                                                       {'loss': 1.8714, 'learning_rate': 7.75447980774957e-05, 'epoch': 0.83}
 83%|████████▎ | 1967/2382 [7:22:20<1:31:17, 13.20s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1990 > 1024). Running this sequence through the model will result in indexing errors
 83%|████████▎ | 1968/2382 [7:22:34<1:31:47, 13.30s/it]                                                       {'loss': 1.9218, 'learning_rate': 7.718145238593793e-05, 'epoch': 0.83}
 83%|████████▎ | 1968/2382 [7:22:34<1:31:47, 13.30s/it] 83%|████████▎ | 1969/2382 [7:22:50<1:37:06, 14.11s/it]                                                       {'loss': 1.8262, 'learning_rate': 7.681888873578785e-05, 'epoch': 0.83}
 83%|████████▎ | 1969/2382 [7:22:50<1:37:06, 14.11s/it] 83%|████████▎ | 1970/2382 [7:23:04<1:35:58, 13.98s/it]                                                       {'loss': 1.8773, 'learning_rate': 7.645710779763981e-05, 'epoch': 0.83}
 83%|████████▎ | 1970/2382 [7:23:04<1:35:58, 13.98s/it] 83%|████████▎ | 1971/2382 [7:23:18<1:36:48, 14.13s/it]                                                       {'loss': 1.7323, 'learning_rate': 7.609611024064062e-05, 'epoch': 0.83}
 83%|████████▎ | 1971/2382 [7:23:18<1:36:48, 14.13s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1476 > 1024). Running this sequence through the model will result in indexing errors
 83%|████████▎ | 1972/2382 [7:23:31<1:34:04, 13.77s/it]                                                       {'loss': 1.9483, 'learning_rate': 7.573589673248832e-05, 'epoch': 0.83}
 83%|████████▎ | 1972/2382 [7:23:31<1:34:04, 13.77s/it] 83%|████████▎ | 1973/2382 [7:23:45<1:33:57, 13.78s/it]                                                       {'loss': 1.7674, 'learning_rate': 7.537646793943032e-05, 'epoch': 0.83}
 83%|████████▎ | 1973/2382 [7:23:45<1:33:57, 13.78s/it] 83%|████████▎ | 1974/2382 [7:23:58<1:33:05, 13.69s/it]                                                       {'loss': 1.8904, 'learning_rate': 7.501782452626305e-05, 'epoch': 0.83}
 83%|████████▎ | 1974/2382 [7:23:58<1:33:05, 13.69s/it] 83%|████████▎ | 1975/2382 [7:24:10<1:29:03, 13.13s/it]                                                       {'loss': 1.8046, 'learning_rate': 7.465996715633027e-05, 'epoch': 0.83}
 83%|████████▎ | 1975/2382 [7:24:10<1:29:03, 13.13s/it] 83%|████████▎ | 1976/2382 [7:24:23<1:27:29, 12.93s/it]                                                       {'loss': 1.7765, 'learning_rate': 7.430289649152156e-05, 'epoch': 0.83}
 83%|████████▎ | 1976/2382 [7:24:23<1:27:29, 12.93s/it] 83%|████████▎ | 1977/2382 [7:24:34<1:24:31, 12.52s/it]                                                       {'loss': 1.836, 'learning_rate': 7.394661319227175e-05, 'epoch': 0.83}
 83%|████████▎ | 1977/2382 [7:24:34<1:24:31, 12.52s/it] 83%|████████▎ | 1978/2382 [7:24:48<1:27:33, 13.00s/it]                                                       {'loss': 1.9112, 'learning_rate': 7.359111791755917e-05, 'epoch': 0.83}
 83%|████████▎ | 1978/2382 [7:24:48<1:27:33, 13.00s/it] 83%|████████▎ | 1979/2382 [7:25:00<1:24:25, 12.57s/it]                                                       {'loss': 1.9172, 'learning_rate': 7.323641132490494e-05, 'epoch': 0.83}
 83%|████████▎ | 1979/2382 [7:25:00<1:24:25, 12.57s/it] 83%|████████▎ | 1980/2382 [7:25:13<1:26:08, 12.86s/it]                                                       {'loss': 1.7654, 'learning_rate': 7.288249407037084e-05, 'epoch': 0.83}
 83%|████████▎ | 1980/2382 [7:25:13<1:26:08, 12.86s/it] 83%|████████▎ | 1981/2382 [7:25:28<1:28:54, 13.30s/it]                                                       {'loss': 1.8232, 'learning_rate': 7.252936680855942e-05, 'epoch': 0.83}
 83%|████████▎ | 1981/2382 [7:25:28<1:28:54, 13.30s/it] 83%|████████▎ | 1982/2382 [7:25:43<1:33:15, 13.99s/it]                                                       {'loss': 1.7818, 'learning_rate': 7.217703019261135e-05, 'epoch': 0.83}
 83%|████████▎ | 1982/2382 [7:25:43<1:33:15, 13.99s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1061 > 1024). Running this sequence through the model will result in indexing errors
 83%|████████▎ | 1983/2382 [7:25:59<1:36:16, 14.48s/it]                                                       {'loss': 1.7512, 'learning_rate': 7.182548487420554e-05, 'epoch': 0.83}
 83%|████████▎ | 1983/2382 [7:25:59<1:36:16, 14.48s/it] 83%|████████▎ | 1984/2382 [7:26:16<1:41:45, 15.34s/it]                                                       {'loss': 1.7989, 'learning_rate': 7.147473150355693e-05, 'epoch': 0.83}
 83%|████████▎ | 1984/2382 [7:26:16<1:41:45, 15.34s/it] 83%|████████▎ | 1985/2382 [7:26:30<1:38:37, 14.90s/it]                                                       {'loss': 1.7901, 'learning_rate': 7.112477072941598e-05, 'epoch': 0.83}
 83%|████████▎ | 1985/2382 [7:26:30<1:38:37, 14.90s/it] 83%|████████▎ | 1986/2382 [7:26:41<1:30:56, 13.78s/it]                                                       {'loss': 1.8454, 'learning_rate': 7.077560319906695e-05, 'epoch': 0.83}
 83%|████████▎ | 1986/2382 [7:26:41<1:30:56, 13.78s/it] 83%|████████▎ | 1987/2382 [7:26:58<1:35:55, 14.57s/it]                                                       {'loss': 1.8584, 'learning_rate': 7.042722955832703e-05, 'epoch': 0.83}
 83%|████████▎ | 1987/2382 [7:26:58<1:35:55, 14.57s/it] 83%|████████▎ | 1988/2382 [7:27:13<1:36:08, 14.64s/it]                                                       {'loss': 1.7163, 'learning_rate': 7.007965045154474e-05, 'epoch': 0.83}
 83%|████████▎ | 1988/2382 [7:27:13<1:36:08, 14.64s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 1024). Running this sequence through the model will result in indexing errors
 84%|████████▎ | 1989/2382 [7:27:24<1:29:55, 13.73s/it]                                                       {'loss': 1.8671, 'learning_rate': 6.973286652159949e-05, 'epoch': 0.83}
 84%|████████▎ | 1989/2382 [7:27:24<1:29:55, 13.73s/it] 84%|████████▎ | 1990/2382 [7:27:38<1:29:22, 13.68s/it]                                                       {'loss': 1.8093, 'learning_rate': 6.938687840989971e-05, 'epoch': 0.84}
 84%|████████▎ | 1990/2382 [7:27:38<1:29:22, 13.68s/it] 84%|████████▎ | 1991/2382 [7:27:49<1:24:46, 13.01s/it]                                                       {'loss': 1.8597, 'learning_rate': 6.904168675638195e-05, 'epoch': 0.84}
 84%|████████▎ | 1991/2382 [7:27:49<1:24:46, 13.01s/it] 84%|████████▎ | 1992/2382 [7:28:02<1:24:09, 12.95s/it]                                                       {'loss': 1.8788, 'learning_rate': 6.86972921995096e-05, 'epoch': 0.84}
 84%|████████▎ | 1992/2382 [7:28:02<1:24:09, 12.95s/it] 84%|████████▎ | 1993/2382 [7:28:17<1:27:44, 13.53s/it]                                                       {'loss': 1.856, 'learning_rate': 6.835369537627178e-05, 'epoch': 0.84}
 84%|████████▎ | 1993/2382 [7:28:17<1:27:44, 13.53s/it] 84%|████████▎ | 1994/2382 [7:28:30<1:25:51, 13.28s/it]                                                       {'loss': 1.8935, 'learning_rate': 6.801089692218215e-05, 'epoch': 0.84}
 84%|████████▎ | 1994/2382 [7:28:30<1:25:51, 13.28s/it] 84%|████████▍ | 1995/2382 [7:28:44<1:27:54, 13.63s/it]                                                       {'loss': 1.8397, 'learning_rate': 6.766889747127742e-05, 'epoch': 0.84}
 84%|████████▍ | 1995/2382 [7:28:44<1:27:54, 13.63s/it] 84%|████████▍ | 1996/2382 [7:29:00<1:31:49, 14.27s/it]                                                       {'loss': 1.7927, 'learning_rate': 6.73276976561169e-05, 'epoch': 0.84}
 84%|████████▍ | 1996/2382 [7:29:00<1:31:49, 14.27s/it] 84%|████████▍ | 1997/2382 [7:29:14<1:31:43, 14.30s/it]                                                       {'loss': 1.805, 'learning_rate': 6.698729810778065e-05, 'epoch': 0.84}
 84%|████████▍ | 1997/2382 [7:29:14<1:31:43, 14.30s/it] 84%|████████▍ | 1998/2382 [7:29:26<1:26:47, 13.56s/it]                                                       {'loss': 1.7742, 'learning_rate': 6.664769945586885e-05, 'epoch': 0.84}
 84%|████████▍ | 1998/2382 [7:29:26<1:26:47, 13.56s/it] 84%|████████▍ | 1999/2382 [7:29:41<1:29:44, 14.06s/it]                                                       {'loss': 1.7903, 'learning_rate': 6.630890232849984e-05, 'epoch': 0.84}
 84%|████████▍ | 1999/2382 [7:29:41<1:29:44, 14.06s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1494 > 1024). Running this sequence through the model will result in indexing errors
 84%|████████▍ | 2000/2382 [7:29:56<1:30:08, 14.16s/it]                                                       {'loss': 1.758, 'learning_rate': 6.597090735230987e-05, 'epoch': 0.84}
 84%|████████▍ | 2000/2382 [7:29:56<1:30:08, 14.16s/it] 84%|████████▍ | 2001/2382 [7:30:07<1:24:36, 13.32s/it]                                                       {'loss': 1.8957, 'learning_rate': 6.563371515245154e-05, 'epoch': 0.84}
 84%|████████▍ | 2001/2382 [7:30:07<1:24:36, 13.32s/it] 84%|████████▍ | 2002/2382 [7:30:19<1:22:48, 13.08s/it]                                                       {'loss': 1.8329, 'learning_rate': 6.529732635259234e-05, 'epoch': 0.84}
 84%|████████▍ | 2002/2382 [7:30:19<1:22:48, 13.08s/it] 84%|████████▍ | 2003/2382 [7:30:32<1:21:45, 12.94s/it]                                                       {'loss': 1.7606, 'learning_rate': 6.496174157491408e-05, 'epoch': 0.84}
 84%|████████▍ | 2003/2382 [7:30:32<1:21:45, 12.94s/it] 84%|████████▍ | 2004/2382 [7:30:48<1:26:37, 13.75s/it]                                                       {'loss': 1.8665, 'learning_rate': 6.462696144011149e-05, 'epoch': 0.84}
 84%|████████▍ | 2004/2382 [7:30:48<1:26:37, 13.75s/it] 84%|████████▍ | 2005/2382 [7:31:03<1:30:15, 14.36s/it]                                                       {'loss': 1.8686, 'learning_rate': 6.429298656739069e-05, 'epoch': 0.84}
 84%|████████▍ | 2005/2382 [7:31:03<1:30:15, 14.36s/it] 84%|████████▍ | 2006/2382 [7:31:15<1:25:12, 13.60s/it]                                                       {'loss': 1.8818, 'learning_rate': 6.395981757446867e-05, 'epoch': 0.84}
 84%|████████▍ | 2006/2382 [7:31:15<1:25:12, 13.60s/it] 84%|████████▍ | 2007/2382 [7:31:27<1:20:48, 12.93s/it]                                                       {'loss': 1.848, 'learning_rate': 6.362745507757189e-05, 'epoch': 0.84}
 84%|████████▍ | 2007/2382 [7:31:27<1:20:48, 12.93s/it] 84%|████████▍ | 2008/2382 [7:31:38<1:18:02, 12.52s/it]                                                       {'loss': 1.8736, 'learning_rate': 6.329589969143517e-05, 'epoch': 0.84}
 84%|████████▍ | 2008/2382 [7:31:38<1:18:02, 12.52s/it] 84%|████████▍ | 2009/2382 [7:31:53<1:21:11, 13.06s/it]                                                       {'loss': 1.8683, 'learning_rate': 6.296515202930014e-05, 'epoch': 0.84}
 84%|████████▍ | 2009/2382 [7:31:53<1:21:11, 13.06s/it] 84%|████████▍ | 2010/2382 [7:32:06<1:21:20, 13.12s/it]                                                       {'loss': 1.903, 'learning_rate': 6.2635212702915e-05, 'epoch': 0.84}
 84%|████████▍ | 2010/2382 [7:32:06<1:21:20, 13.12s/it] 84%|████████▍ | 2011/2382 [7:32:19<1:20:39, 13.04s/it]                                                       {'loss': 1.8065, 'learning_rate': 6.230608232253226e-05, 'epoch': 0.84}
 84%|████████▍ | 2011/2382 [7:32:19<1:20:39, 13.04s/it] 84%|████████▍ | 2012/2382 [7:32:31<1:18:18, 12.70s/it]                                                       {'loss': 1.7999, 'learning_rate': 6.197776149690871e-05, 'epoch': 0.84}
 84%|████████▍ | 2012/2382 [7:32:31<1:18:18, 12.70s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1143 > 1024). Running this sequence through the model will result in indexing errors
 85%|████████▍ | 2013/2382 [7:32:43<1:17:16, 12.57s/it]                                                       {'loss': 1.7837, 'learning_rate': 6.165025083330356e-05, 'epoch': 0.84}
 85%|████████▍ | 2013/2382 [7:32:43<1:17:16, 12.57s/it] 85%|████████▍ | 2014/2382 [7:32:55<1:15:39, 12.34s/it]                                                       {'loss': 1.8357, 'learning_rate': 6.132355093747765e-05, 'epoch': 0.85}
 85%|████████▍ | 2014/2382 [7:32:55<1:15:39, 12.34s/it] 85%|████████▍ | 2015/2382 [7:33:09<1:18:31, 12.84s/it]                                                       {'loss': 1.8355, 'learning_rate': 6.099766241369231e-05, 'epoch': 0.85}
 85%|████████▍ | 2015/2382 [7:33:09<1:18:31, 12.84s/it] 85%|████████▍ | 2016/2382 [7:33:23<1:20:21, 13.17s/it]                                                       {'loss': 1.8694, 'learning_rate': 6.0672585864707806e-05, 'epoch': 0.85}
 85%|████████▍ | 2016/2382 [7:33:23<1:20:21, 13.17s/it] 85%|████████▍ | 2017/2382 [7:33:35<1:19:20, 13.04s/it]                                                       {'loss': 1.7995, 'learning_rate': 6.034832189178302e-05, 'epoch': 0.85}
 85%|████████▍ | 2017/2382 [7:33:35<1:19:20, 13.04s/it] 85%|████████▍ | 2018/2382 [7:33:48<1:18:02, 12.86s/it]                                                       {'loss': 1.8286, 'learning_rate': 6.002487109467347e-05, 'epoch': 0.85}
 85%|████████▍ | 2018/2382 [7:33:48<1:18:02, 12.86s/it] 85%|████████▍ | 2019/2382 [7:34:00<1:16:05, 12.58s/it]                                                       {'loss': 1.8932, 'learning_rate': 5.9702234071631e-05, 'epoch': 0.85}
 85%|████████▍ | 2019/2382 [7:34:00<1:16:05, 12.58s/it] 85%|████████▍ | 2020/2382 [7:34:13<1:17:00, 12.76s/it]                                                       {'loss': 1.7983, 'learning_rate': 5.9380411419402206e-05, 'epoch': 0.85}
 85%|████████▍ | 2020/2382 [7:34:13<1:17:00, 12.76s/it] 85%|████████▍ | 2021/2382 [7:34:26<1:17:36, 12.90s/it]                                                       {'loss': 1.8385, 'learning_rate': 5.905940373322732e-05, 'epoch': 0.85}
 85%|████████▍ | 2021/2382 [7:34:26<1:17:36, 12.90s/it] 85%|████████▍ | 2022/2382 [7:34:41<1:20:13, 13.37s/it]                                                       {'loss': 1.8913, 'learning_rate': 5.8739211606839427e-05, 'epoch': 0.85}
 85%|████████▍ | 2022/2382 [7:34:41<1:20:13, 13.37s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1416 > 1024). Running this sequence through the model will result in indexing errors
 85%|████████▍ | 2023/2382 [7:34:53<1:18:18, 13.09s/it]                                                       {'loss': 1.7645, 'learning_rate': 5.841983563246278e-05, 'epoch': 0.85}
 85%|████████▍ | 2023/2382 [7:34:53<1:18:18, 13.09s/it] 85%|████████▍ | 2024/2382 [7:35:05<1:15:38, 12.68s/it]                                                       {'loss': 1.9687, 'learning_rate': 5.810127640081259e-05, 'epoch': 0.85}
 85%|████████▍ | 2024/2382 [7:35:05<1:15:38, 12.68s/it] 85%|████████▌ | 2025/2382 [7:35:21<1:21:50, 13.75s/it]                                                       {'loss': 1.8077, 'learning_rate': 5.778353450109286e-05, 'epoch': 0.85}
 85%|████████▌ | 2025/2382 [7:35:21<1:21:50, 13.75s/it] 85%|████████▌ | 2026/2382 [7:35:34<1:20:48, 13.62s/it]                                                       {'loss': 1.8327, 'learning_rate': 5.746661052099639e-05, 'epoch': 0.85}
 85%|████████▌ | 2026/2382 [7:35:34<1:20:48, 13.62s/it] 85%|████████▌ | 2027/2382 [7:35:48<1:20:41, 13.64s/it]                                                       {'loss': 1.7864, 'learning_rate': 5.7150505046702884e-05, 'epoch': 0.85}
 85%|████████▌ | 2027/2382 [7:35:48<1:20:41, 13.64s/it] 85%|████████▌ | 2028/2382 [7:36:01<1:20:14, 13.60s/it]                                                       {'loss': 1.7751, 'learning_rate': 5.683521866287833e-05, 'epoch': 0.85}
 85%|████████▌ | 2028/2382 [7:36:01<1:20:14, 13.60s/it] 85%|████████▌ | 2029/2382 [7:36:17<1:23:01, 14.11s/it]                                                       {'loss': 1.8203, 'learning_rate': 5.652075195267337e-05, 'epoch': 0.85}
 85%|████████▌ | 2029/2382 [7:36:17<1:23:01, 14.11s/it] 85%|████████▌ | 2030/2382 [7:36:30<1:22:03, 13.99s/it]                                                       {'loss': 1.9006, 'learning_rate': 5.6207105497722956e-05, 'epoch': 0.85}
 85%|████████▌ | 2030/2382 [7:36:30<1:22:03, 13.99s/it] 85%|████████▌ | 2031/2382 [7:36:43<1:19:06, 13.52s/it]                                                       {'loss': 1.8544, 'learning_rate': 5.589427987814483e-05, 'epoch': 0.85}
 85%|████████▌ | 2031/2382 [7:36:43<1:19:06, 13.52s/it] 85%|████████▌ | 2032/2382 [7:36:59<1:23:10, 14.26s/it]                                                       {'loss': 1.8152, 'learning_rate': 5.5582275672538315e-05, 'epoch': 0.85}
 85%|████████▌ | 2032/2382 [7:36:59<1:23:10, 14.26s/it] 85%|████████▌ | 2033/2382 [7:37:12<1:21:15, 13.97s/it]                                                       {'loss': 1.8371, 'learning_rate': 5.527109345798365e-05, 'epoch': 0.85}
 85%|████████▌ | 2033/2382 [7:37:12<1:21:15, 13.97s/it] 85%|████████▌ | 2034/2382 [7:37:26<1:20:23, 13.86s/it]                                                       {'loss': 1.7693, 'learning_rate': 5.4960733810040797e-05, 'epoch': 0.85}
 85%|████████▌ | 2034/2382 [7:37:26<1:20:23, 13.86s/it] 85%|████████▌ | 2035/2382 [7:37:40<1:20:14, 13.87s/it]                                                       {'loss': 1.7939, 'learning_rate': 5.465119730274798e-05, 'epoch': 0.85}
 85%|████████▌ | 2035/2382 [7:37:40<1:20:14, 13.87s/it] 85%|████████▌ | 2036/2382 [7:37:54<1:20:55, 14.03s/it]                                                       {'loss': 1.8374, 'learning_rate': 5.434248450862123e-05, 'epoch': 0.85}
 85%|████████▌ | 2036/2382 [7:37:54<1:20:55, 14.03s/it] 86%|████████▌ | 2037/2382 [7:38:07<1:17:52, 13.54s/it]                                                       {'loss': 1.9155, 'learning_rate': 5.403459599865307e-05, 'epoch': 0.85}
 86%|████████▌ | 2037/2382 [7:38:07<1:17:52, 13.54s/it] 86%|████████▌ | 2038/2382 [7:38:20<1:18:03, 13.62s/it]                                                       {'loss': 1.8252, 'learning_rate': 5.372753234231137e-05, 'epoch': 0.86}
 86%|████████▌ | 2038/2382 [7:38:20<1:18:03, 13.62s/it] 86%|████████▌ | 2039/2382 [7:38:36<1:20:38, 14.11s/it]                                                       {'loss': 1.9083, 'learning_rate': 5.34212941075381e-05, 'epoch': 0.86}
 86%|████████▌ | 2039/2382 [7:38:36<1:20:38, 14.11s/it] 86%|████████▌ | 2040/2382 [7:38:51<1:22:12, 14.42s/it]                                                       {'loss': 1.7758, 'learning_rate': 5.3115881860749005e-05, 'epoch': 0.86}
 86%|████████▌ | 2040/2382 [7:38:51<1:22:12, 14.42s/it] 86%|████████▌ | 2041/2382 [7:39:07<1:24:36, 14.89s/it]                                                       {'loss': 1.829, 'learning_rate': 5.2811296166831666e-05, 'epoch': 0.86}
 86%|████████▌ | 2041/2382 [7:39:07<1:24:36, 14.89s/it] 86%|████████▌ | 2042/2382 [7:39:18<1:19:05, 13.96s/it]                                                       {'loss': 1.8456, 'learning_rate': 5.250753758914506e-05, 'epoch': 0.86}
 86%|████████▌ | 2042/2382 [7:39:18<1:19:05, 13.96s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1049 > 1024). Running this sequence through the model will result in indexing errors
 86%|████████▌ | 2043/2382 [7:39:33<1:19:16, 14.03s/it]                                                       {'loss': 1.8117, 'learning_rate': 5.2204606689518485e-05, 'epoch': 0.86}
 86%|████████▌ | 2043/2382 [7:39:33<1:19:16, 14.03s/it] 86%|████████▌ | 2044/2382 [7:39:48<1:21:47, 14.52s/it]                                                       {'loss': 1.8144, 'learning_rate': 5.190250402825014e-05, 'epoch': 0.86}
 86%|████████▌ | 2044/2382 [7:39:48<1:21:47, 14.52s/it] 86%|████████▌ | 2045/2382 [7:40:01<1:18:18, 13.94s/it]                                                       {'loss': 1.8285, 'learning_rate': 5.160123016410645e-05, 'epoch': 0.86}
 86%|████████▌ | 2045/2382 [7:40:01<1:18:18, 13.94s/it] 86%|████████▌ | 2046/2382 [7:40:15<1:17:39, 13.87s/it]                                                       {'loss': 1.8846, 'learning_rate': 5.130078565432089e-05, 'epoch': 0.86}
 86%|████████▌ | 2046/2382 [7:40:15<1:17:39, 13.87s/it] 86%|████████▌ | 2047/2382 [7:40:27<1:14:10, 13.29s/it]                                                       {'loss': 1.8655, 'learning_rate': 5.100117105459279e-05, 'epoch': 0.86}
 86%|████████▌ | 2047/2382 [7:40:27<1:14:10, 13.29s/it] 86%|████████▌ | 2048/2382 [7:40:41<1:15:21, 13.54s/it]                                                       {'loss': 1.8754, 'learning_rate': 5.0702386919086685e-05, 'epoch': 0.86}
 86%|████████▌ | 2048/2382 [7:40:41<1:15:21, 13.54s/it] 86%|████████▌ | 2049/2382 [7:40:53<1:12:39, 13.09s/it]                                                       {'loss': 1.7718, 'learning_rate': 5.040443380043114e-05, 'epoch': 0.86}
 86%|████████▌ | 2049/2382 [7:40:53<1:12:39, 13.09s/it] 86%|████████▌ | 2050/2382 [7:41:05<1:11:47, 12.98s/it]                                                       {'loss': 1.8351, 'learning_rate': 5.010731224971748e-05, 'epoch': 0.86}
 86%|████████▌ | 2050/2382 [7:41:05<1:11:47, 12.98s/it] 86%|████████▌ | 2051/2382 [7:41:19<1:11:52, 13.03s/it]                                                       {'loss': 1.8405, 'learning_rate': 4.981102281649913e-05, 'epoch': 0.86}
 86%|████████▌ | 2051/2382 [7:41:19<1:11:52, 13.03s/it] 86%|████████▌ | 2052/2382 [7:41:30<1:08:38, 12.48s/it]                                                       {'loss': 1.8328, 'learning_rate': 4.9515566048790485e-05, 'epoch': 0.86}
 86%|████████▌ | 2052/2382 [7:41:30<1:08:38, 12.48s/it] 86%|████████▌ | 2053/2382 [7:41:44<1:11:32, 13.05s/it]                                                       {'loss': 1.8187, 'learning_rate': 4.922094249306558e-05, 'epoch': 0.86}
 86%|████████▌ | 2053/2382 [7:41:44<1:11:32, 13.05s/it] 86%|████████▌ | 2054/2382 [7:41:57<1:11:30, 13.08s/it]                                                       {'loss': 1.915, 'learning_rate': 4.892715269425746e-05, 'epoch': 0.86}
 86%|████████▌ | 2054/2382 [7:41:57<1:11:30, 13.08s/it] 86%|████████▋ | 2055/2382 [7:42:12<1:14:26, 13.66s/it]                                                       {'loss': 1.8224, 'learning_rate': 4.863419719575724e-05, 'epoch': 0.86}
 86%|████████▋ | 2055/2382 [7:42:12<1:14:26, 13.66s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1333 > 1024). Running this sequence through the model will result in indexing errors
 86%|████████▋ | 2056/2382 [7:42:24<1:11:03, 13.08s/it]                                                       {'loss': 1.8867, 'learning_rate': 4.834207653941269e-05, 'epoch': 0.86}
 86%|████████▋ | 2056/2382 [7:42:24<1:11:03, 13.08s/it] 86%|████████▋ | 2057/2382 [7:42:39<1:13:38, 13.59s/it]                                                       {'loss': 1.862, 'learning_rate': 4.805079126552769e-05, 'epoch': 0.86}
 86%|████████▋ | 2057/2382 [7:42:39<1:13:38, 13.59s/it] 86%|████████▋ | 2058/2382 [7:42:53<1:14:47, 13.85s/it]                                                       {'loss': 1.7875, 'learning_rate': 4.7760341912860936e-05, 'epoch': 0.86}
 86%|████████▋ | 2058/2382 [7:42:53<1:14:47, 13.85s/it] 86%|████████▋ | 2059/2382 [7:43:07<1:14:30, 13.84s/it]                                                       {'loss': 1.8812, 'learning_rate': 4.74707290186247e-05, 'epoch': 0.86}
 86%|████████▋ | 2059/2382 [7:43:07<1:14:30, 13.84s/it] 86%|████████▋ | 2060/2382 [7:43:21<1:13:35, 13.71s/it]                                                       {'loss': 1.8261, 'learning_rate': 4.7181953118484556e-05, 'epoch': 0.86}
 86%|████████▋ | 2060/2382 [7:43:21<1:13:35, 13.71s/it] 87%|████████▋ | 2061/2382 [7:43:33<1:12:03, 13.47s/it]                                                       {'loss': 1.937, 'learning_rate': 4.689401474655791e-05, 'epoch': 0.86}
 87%|████████▋ | 2061/2382 [7:43:33<1:12:03, 13.47s/it] 87%|████████▋ | 2062/2382 [7:43:48<1:13:08, 13.71s/it]                                                       {'loss': 1.8253, 'learning_rate': 4.6606914435412815e-05, 'epoch': 0.87}
 87%|████████▋ | 2062/2382 [7:43:48<1:13:08, 13.71s/it] 87%|████████▋ | 2063/2382 [7:44:02<1:13:31, 13.83s/it]                                                       {'loss': 1.8788, 'learning_rate': 4.632065271606756e-05, 'epoch': 0.87}
 87%|████████▋ | 2063/2382 [7:44:02<1:13:31, 13.83s/it] 87%|████████▋ | 2064/2382 [7:44:13<1:08:34, 12.94s/it]                                                       {'loss': 1.8422, 'learning_rate': 4.603523011798932e-05, 'epoch': 0.87}
 87%|████████▋ | 2064/2382 [7:44:13<1:08:34, 12.94s/it] 87%|████████▋ | 2065/2382 [7:44:25<1:08:04, 12.89s/it]                                                       {'loss': 1.8288, 'learning_rate': 4.5750647169092995e-05, 'epoch': 0.87}
 87%|████████▋ | 2065/2382 [7:44:25<1:08:04, 12.89s/it] 87%|████████▋ | 2066/2382 [7:44:37<1:06:30, 12.63s/it]                                                       {'loss': 1.8801, 'learning_rate': 4.546690439574081e-05, 'epoch': 0.87}
 87%|████████▋ | 2066/2382 [7:44:38<1:06:30, 12.63s/it] 87%|████████▋ | 2067/2382 [7:44:52<1:09:20, 13.21s/it]                                                       {'loss': 1.8289, 'learning_rate': 4.518400232274078e-05, 'epoch': 0.87}
 87%|████████▋ | 2067/2382 [7:44:52<1:09:20, 13.21s/it] 87%|████████▋ | 2068/2382 [7:45:06<1:10:30, 13.47s/it]                                                       {'loss': 1.8084, 'learning_rate': 4.49019414733462e-05, 'epoch': 0.87}
 87%|████████▋ | 2068/2382 [7:45:06<1:10:30, 13.47s/it] 87%|████████▋ | 2069/2382 [7:45:19<1:08:40, 13.16s/it]                                                       {'loss': 1.8338, 'learning_rate': 4.462072236925413e-05, 'epoch': 0.87}
 87%|████████▋ | 2069/2382 [7:45:19<1:08:40, 13.16s/it] 87%|████████▋ | 2070/2382 [7:45:32<1:09:34, 13.38s/it]                                                       {'loss': 1.747, 'learning_rate': 4.434034553060501e-05, 'epoch': 0.87}
 87%|████████▋ | 2070/2382 [7:45:32<1:09:34, 13.38s/it] 87%|████████▋ | 2071/2382 [7:45:46<1:09:37, 13.43s/it]                                                       {'loss': 1.803, 'learning_rate': 4.4060811475981234e-05, 'epoch': 0.87}
 87%|████████▋ | 2071/2382 [7:45:46<1:09:37, 13.43s/it] 87%|████████▋ | 2072/2382 [7:46:00<1:10:54, 13.72s/it]                                                       {'loss': 1.7706, 'learning_rate': 4.378212072240656e-05, 'epoch': 0.87}
 87%|████████▋ | 2072/2382 [7:46:00<1:10:54, 13.72s/it] 87%|████████▋ | 2073/2382 [7:46:12<1:08:09, 13.23s/it]                                                       {'loss': 1.9168, 'learning_rate': 4.3504273785344936e-05, 'epoch': 0.87}
 87%|████████▋ | 2073/2382 [7:46:12<1:08:09, 13.23s/it] 87%|████████▋ | 2074/2382 [7:46:23<1:04:20, 12.54s/it]                                                       {'loss': 1.8205, 'learning_rate': 4.322727117869951e-05, 'epoch': 0.87}
 87%|████████▋ | 2074/2382 [7:46:23<1:04:20, 12.54s/it] 87%|████████▋ | 2075/2382 [7:46:35<1:03:16, 12.37s/it]                                                       {'loss': 1.8825, 'learning_rate': 4.2951113414812e-05, 'epoch': 0.87}
 87%|████████▋ | 2075/2382 [7:46:35<1:03:16, 12.37s/it] 87%|████████▋ | 2076/2382 [7:46:47<1:02:40, 12.29s/it]                                                       {'loss': 1.8447, 'learning_rate': 4.2675801004461165e-05, 'epoch': 0.87}
 87%|████████▋ | 2076/2382 [7:46:47<1:02:40, 12.29s/it] 87%|████████▋ | 2077/2382 [7:47:01<1:03:59, 12.59s/it]                                                       {'loss': 1.9423, 'learning_rate': 4.240133445686234e-05, 'epoch': 0.87}
 87%|████████▋ | 2077/2382 [7:47:01<1:03:59, 12.59s/it] 87%|████████▋ | 2078/2382 [7:47:13<1:03:59, 12.63s/it]                                                       {'loss': 1.8031, 'learning_rate': 4.212771427966649e-05, 'epoch': 0.87}
 87%|████████▋ | 2078/2382 [7:47:13<1:03:59, 12.63s/it] 87%|████████▋ | 2079/2382 [7:47:25<1:02:49, 12.44s/it]                                                       {'loss': 1.7783, 'learning_rate': 4.1854940978959034e-05, 'epoch': 0.87}
 87%|████████▋ | 2079/2382 [7:47:25<1:02:49, 12.44s/it] 87%|████████▋ | 2080/2382 [7:47:39<1:03:35, 12.63s/it]                                                       {'loss': 1.8641, 'learning_rate': 4.158301505925904e-05, 'epoch': 0.87}
 87%|████████▋ | 2080/2382 [7:47:39<1:03:35, 12.63s/it] 87%|████████▋ | 2081/2382 [7:47:51<1:03:32, 12.67s/it]                                                       {'loss': 1.8266, 'learning_rate': 4.1311937023518264e-05, 'epoch': 0.87}
 87%|████████▋ | 2081/2382 [7:47:51<1:03:32, 12.67s/it] 87%|████████▋ | 2082/2382 [7:48:05<1:05:13, 13.05s/it]                                                       {'loss': 1.8455, 'learning_rate': 4.1041707373120354e-05, 'epoch': 0.87}
 87%|████████▋ | 2082/2382 [7:48:05<1:05:13, 13.05s/it] 87%|████████▋ | 2083/2382 [7:48:19<1:06:32, 13.35s/it]                                                       {'loss': 1.9749, 'learning_rate': 4.077232660787944e-05, 'epoch': 0.87}
 87%|████████▋ | 2083/2382 [7:48:19<1:06:32, 13.35s/it] 87%|████████▋ | 2084/2382 [7:48:33<1:06:59, 13.49s/it]                                                       {'loss': 1.8364, 'learning_rate': 4.0503795226039805e-05, 'epoch': 0.87}
 87%|████████▋ | 2084/2382 [7:48:33<1:06:59, 13.49s/it] 88%|████████▊ | 2085/2382 [7:48:45<1:04:42, 13.07s/it]                                                       {'loss': 1.8854, 'learning_rate': 4.0236113724274713e-05, 'epoch': 0.87}
 88%|████████▊ | 2085/2382 [7:48:45<1:04:42, 13.07s/it] 88%|████████▊ | 2086/2382 [7:48:58<1:04:35, 13.09s/it]                                                       {'loss': 1.8504, 'learning_rate': 3.996928259768551e-05, 'epoch': 0.88}
 88%|████████▊ | 2086/2382 [7:48:58<1:04:35, 13.09s/it] 88%|████████▊ | 2087/2382 [7:49:12<1:05:52, 13.40s/it]                                                       {'loss': 1.7643, 'learning_rate': 3.9703302339800686e-05, 'epoch': 0.88}
 88%|████████▊ | 2087/2382 [7:49:12<1:05:52, 13.40s/it] 88%|████████▊ | 2088/2382 [7:49:29<1:10:49, 14.46s/it]                                                       {'loss': 1.8292, 'learning_rate': 3.9438173442575e-05, 'epoch': 0.88}
 88%|████████▊ | 2088/2382 [7:49:29<1:10:49, 14.46s/it] 88%|████████▊ | 2089/2382 [7:49:43<1:10:00, 14.34s/it]                                                       {'loss': 1.8168, 'learning_rate': 3.9173896396388295e-05, 'epoch': 0.88}
 88%|████████▊ | 2089/2382 [7:49:43<1:10:00, 14.34s/it] 88%|████████▊ | 2090/2382 [7:49:54<1:04:54, 13.34s/it]                                                       {'loss': 1.8221, 'learning_rate': 3.8910471690045243e-05, 'epoch': 0.88}
 88%|████████▊ | 2090/2382 [7:49:54<1:04:54, 13.34s/it] 88%|████████▊ | 2091/2382 [7:50:08<1:05:05, 13.42s/it]                                                       {'loss': 1.8373, 'learning_rate': 3.8647899810773713e-05, 'epoch': 0.88}
 88%|████████▊ | 2091/2382 [7:50:08<1:05:05, 13.42s/it] 88%|████████▊ | 2092/2382 [7:50:21<1:04:30, 13.35s/it]                                                       {'loss': 1.7891, 'learning_rate': 3.8386181244224274e-05, 'epoch': 0.88}
 88%|████████▊ | 2092/2382 [7:50:21<1:04:30, 13.35s/it] 88%|████████▊ | 2093/2382 [7:50:35<1:05:26, 13.59s/it]                                                       {'loss': 1.8292, 'learning_rate': 3.8125316474469317e-05, 'epoch': 0.88}
 88%|████████▊ | 2093/2382 [7:50:35<1:05:26, 13.59s/it] 88%|████████▊ | 2094/2382 [7:50:50<1:07:22, 14.04s/it]                                                       {'loss': 1.8904, 'learning_rate': 3.786530598400206e-05, 'epoch': 0.88}
 88%|████████▊ | 2094/2382 [7:50:50<1:07:22, 14.04s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1641 > 1024). Running this sequence through the model will result in indexing errors
 88%|████████▊ | 2095/2382 [7:51:04<1:05:57, 13.79s/it]                                                       {'loss': 1.8528, 'learning_rate': 3.760615025373543e-05, 'epoch': 0.88}
 88%|████████▊ | 2095/2382 [7:51:04<1:05:57, 13.79s/it] 88%|████████▊ | 2096/2382 [7:51:15<1:02:04, 13.02s/it]                                                       {'loss': 1.8474, 'learning_rate': 3.734784976300165e-05, 'epoch': 0.88}
 88%|████████▊ | 2096/2382 [7:51:15<1:02:04, 13.02s/it] 88%|████████▊ | 2097/2382 [7:51:26<59:21, 12.50s/it]                                                       {'loss': 1.8514, 'learning_rate': 3.709040498955102e-05, 'epoch': 0.88}
 88%|████████▊ | 2097/2382 [7:51:26<59:21, 12.50s/it] 88%|████████▊ | 2098/2382 [7:51:40<1:00:48, 12.85s/it]                                                       {'loss': 1.8215, 'learning_rate': 3.683381640955097e-05, 'epoch': 0.88}
 88%|████████▊ | 2098/2382 [7:51:40<1:00:48, 12.85s/it] 88%|████████▊ | 2099/2382 [7:51:54<1:01:57, 13.14s/it]                                                       {'loss': 1.9221, 'learning_rate': 3.6578084497585484e-05, 'epoch': 0.88}
 88%|████████▊ | 2099/2382 [7:51:54<1:01:57, 13.14s/it] 88%|████████▊ | 2100/2382 [7:52:06<1:00:18, 12.83s/it]                                                       {'loss': 1.888, 'learning_rate': 3.632320972665415e-05, 'epoch': 0.88}
 88%|████████▊ | 2100/2382 [7:52:06<1:00:18, 12.83s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1702 > 1024). Running this sequence through the model will result in indexing errors
 88%|████████▊ | 2101/2382 [7:52:21<1:03:37, 13.59s/it]                                                       {'loss': 1.8726, 'learning_rate': 3.6069192568170926e-05, 'epoch': 0.88}
 88%|████████▊ | 2101/2382 [7:52:21<1:03:37, 13.59s/it] 88%|████████▊ | 2102/2382 [7:52:35<1:03:32, 13.62s/it]                                                       {'loss': 1.8233, 'learning_rate': 3.5816033491963716e-05, 'epoch': 0.88}
 88%|████████▊ | 2102/2382 [7:52:35<1:03:32, 13.62s/it] 88%|████████▊ | 2103/2382 [7:52:48<1:02:13, 13.38s/it]                                                       {'loss': 1.8032, 'learning_rate': 3.5563732966273245e-05, 'epoch': 0.88}
 88%|████████▊ | 2103/2382 [7:52:48<1:02:13, 13.38s/it] 88%|████████▊ | 2104/2382 [7:53:01<1:02:31, 13.50s/it]                                                       {'loss': 1.8389, 'learning_rate': 3.53122914577525e-05, 'epoch': 0.88}
 88%|████████▊ | 2104/2382 [7:53:01<1:02:31, 13.50s/it] 88%|████████▊ | 2105/2382 [7:53:14<1:01:38, 13.35s/it]                                                       {'loss': 1.8327, 'learning_rate': 3.5061709431465195e-05, 'epoch': 0.88}
 88%|████████▊ | 2105/2382 [7:53:14<1:01:38, 13.35s/it] 88%|████████▊ | 2106/2382 [7:53:29<1:03:14, 13.75s/it]                                                       {'loss': 1.8777, 'learning_rate': 3.4811987350885807e-05, 'epoch': 0.88}
 88%|████████▊ | 2106/2382 [7:53:29<1:03:14, 13.75s/it] 88%|████████▊ | 2107/2382 [7:53:44<1:04:25, 14.06s/it]                                                       {'loss': 1.775, 'learning_rate': 3.456312567789793e-05, 'epoch': 0.88}
 88%|████████▊ | 2107/2382 [7:53:44<1:04:25, 14.06s/it] 88%|████████▊ | 2108/2382 [7:53:55<1:00:15, 13.19s/it]                                                       {'loss': 1.7674, 'learning_rate': 3.431512487279392e-05, 'epoch': 0.88}
 88%|████████▊ | 2108/2382 [7:53:55<1:00:15, 13.19s/it] 89%|████████▊ | 2109/2382 [7:54:08<59:57, 13.18s/it]                                                       {'loss': 1.8034, 'learning_rate': 3.406798539427386e-05, 'epoch': 0.89}
 89%|████████▊ | 2109/2382 [7:54:08<59:57, 13.18s/it] 89%|████████▊ | 2110/2382 [7:54:20<58:15, 12.85s/it]                                                     {'loss': 1.8673, 'learning_rate': 3.38217076994447e-05, 'epoch': 0.89}
 89%|████████▊ | 2110/2382 [7:54:20<58:15, 12.85s/it] 89%|████████▊ | 2111/2382 [7:54:34<58:34, 12.97s/it]                                                     {'loss': 1.8837, 'learning_rate': 3.357629224381964e-05, 'epoch': 0.89}
 89%|████████▊ | 2111/2382 [7:54:34<58:34, 12.97s/it] 89%|████████▊ | 2112/2382 [7:54:48<59:45, 13.28s/it]                                                     {'loss': 1.9438, 'learning_rate': 3.3331739481316624e-05, 'epoch': 0.89}
 89%|████████▊ | 2112/2382 [7:54:48<59:45, 13.28s/it] 89%|████████▊ | 2113/2382 [7:55:01<59:31, 13.28s/it]                                                     {'loss': 1.8574, 'learning_rate': 3.308804986425851e-05, 'epoch': 0.89}
 89%|████████▊ | 2113/2382 [7:55:01<59:31, 13.28s/it] 89%|████████▊ | 2114/2382 [7:55:12<56:08, 12.57s/it]                                                     {'loss': 1.9329, 'learning_rate': 3.284522384337124e-05, 'epoch': 0.89}
 89%|████████▊ | 2114/2382 [7:55:12<56:08, 12.57s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1458 > 1024). Running this sequence through the model will result in indexing errors
 89%|████████▉ | 2115/2382 [7:55:25<56:34, 12.71s/it]                                                     {'loss': 1.9068, 'learning_rate': 3.260326186778373e-05, 'epoch': 0.89}
 89%|████████▉ | 2115/2382 [7:55:25<56:34, 12.71s/it] 89%|████████▉ | 2116/2382 [7:55:40<59:25, 13.40s/it]                                                     {'loss': 1.8526, 'learning_rate': 3.23621643850267e-05, 'epoch': 0.89}
 89%|████████▉ | 2116/2382 [7:55:40<59:25, 13.40s/it] 89%|████████▉ | 2117/2382 [7:55:53<59:20, 13.43s/it]                                                     {'loss': 1.8881, 'learning_rate': 3.212193184103196e-05, 'epoch': 0.89}
 89%|████████▉ | 2117/2382 [7:55:53<59:20, 13.43s/it] 89%|████████▉ | 2118/2382 [7:56:06<58:08, 13.21s/it]                                                     {'loss': 1.8404, 'learning_rate': 3.18825646801314e-05, 'epoch': 0.89}
 89%|████████▉ | 2118/2382 [7:56:06<58:08, 13.21s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 1024). Running this sequence through the model will result in indexing errors
 89%|████████▉ | 2119/2382 [7:56:19<57:37, 13.15s/it]                                                     {'loss': 1.8286, 'learning_rate': 3.164406334505637e-05, 'epoch': 0.89}
 89%|████████▉ | 2119/2382 [7:56:19<57:37, 13.15s/it] 89%|████████▉ | 2120/2382 [7:56:34<59:12, 13.56s/it]                                                     {'loss': 1.9023, 'learning_rate': 3.14064282769369e-05, 'epoch': 0.89}
 89%|████████▉ | 2120/2382 [7:56:34<59:12, 13.56s/it] 89%|████████▉ | 2121/2382 [7:56:46<57:17, 13.17s/it]                                                     {'loss': 1.8072, 'learning_rate': 3.116965991530052e-05, 'epoch': 0.89}
 89%|████████▉ | 2121/2382 [7:56:46<57:17, 13.17s/it] 89%|████████▉ | 2122/2382 [7:56:58<55:37, 12.84s/it]                                                     {'loss': 1.8647, 'learning_rate': 3.093375869807202e-05, 'epoch': 0.89}
 89%|████████▉ | 2122/2382 [7:56:58<55:37, 12.84s/it] 89%|████████▉ | 2123/2382 [7:57:12<57:11, 13.25s/it]                                                     {'loss': 1.8488, 'learning_rate': 3.069872506157212e-05, 'epoch': 0.89}
 89%|████████▉ | 2123/2382 [7:57:12<57:11, 13.25s/it] 89%|████████▉ | 2124/2382 [7:57:25<56:07, 13.05s/it]                                                     {'loss': 1.8609, 'learning_rate': 3.0464559440517015e-05, 'epoch': 0.89}
 89%|████████▉ | 2124/2382 [7:57:25<56:07, 13.05s/it] 89%|████████▉ | 2125/2382 [7:57:37<55:23, 12.93s/it]                                                     {'loss': 1.8651, 'learning_rate': 3.0231262268017256e-05, 'epoch': 0.89}
 89%|████████▉ | 2125/2382 [7:57:37<55:23, 12.93s/it] 89%|████████▉ | 2126/2382 [7:57:52<56:58, 13.35s/it]                                                     {'loss': 1.8964, 'learning_rate': 2.9998833975577233e-05, 'epoch': 0.89}
 89%|████████▉ | 2126/2382 [7:57:52<56:58, 13.35s/it] 89%|████████▉ | 2127/2382 [7:58:06<58:33, 13.78s/it]                                                     {'loss': 1.8132, 'learning_rate': 2.9767274993094283e-05, 'epoch': 0.89}
 89%|████████▉ | 2127/2382 [7:58:06<58:33, 13.78s/it] 89%|████████▉ | 2128/2382 [7:58:21<59:15, 14.00s/it]                                                     {'loss': 1.8155, 'learning_rate': 2.953658574885776e-05, 'epoch': 0.89}
 89%|████████▉ | 2128/2382 [7:58:21<59:15, 14.00s/it] 89%|████████▉ | 2129/2382 [7:58:33<57:07, 13.55s/it]                                                     {'loss': 1.8542, 'learning_rate': 2.9306766669548458e-05, 'epoch': 0.89}
 89%|████████▉ | 2129/2382 [7:58:33<57:07, 13.55s/it] 89%|████████▉ | 2130/2382 [7:58:45<54:30, 12.98s/it]                                                     {'loss': 1.8697, 'learning_rate': 2.9077818180237692e-05, 'epoch': 0.89}
 89%|████████▉ | 2130/2382 [7:58:45<54:30, 12.98s/it] 89%|████████▉ | 2131/2382 [7:58:58<54:41, 13.07s/it]                                                     {'loss': 1.8577, 'learning_rate': 2.8849740704386563e-05, 'epoch': 0.89}
 89%|████████▉ | 2131/2382 [7:58:58<54:41, 13.07s/it] 90%|████████▉ | 2132/2382 [7:59:10<52:16, 12.54s/it]                                                     {'loss': 1.8251, 'learning_rate': 2.862253466384507e-05, 'epoch': 0.89}
 90%|████████▉ | 2132/2382 [7:59:10<52:16, 12.54s/it] 90%|████████▉ | 2133/2382 [7:59:22<51:41, 12.46s/it]                                                     {'loss': 1.8578, 'learning_rate': 2.8396200478851497e-05, 'epoch': 0.9}
 90%|████████▉ | 2133/2382 [7:59:22<51:41, 12.46s/it] 90%|████████▉ | 2134/2382 [7:59:37<54:42, 13.24s/it]                                                     {'loss': 1.8015, 'learning_rate': 2.8170738568031707e-05, 'epoch': 0.9}
 90%|████████▉ | 2134/2382 [7:59:37<54:42, 13.24s/it] 90%|████████▉ | 2135/2382 [7:59:50<53:56, 13.10s/it]                                                     {'loss': 1.7702, 'learning_rate': 2.7946149348397788e-05, 'epoch': 0.9}
 90%|████████▉ | 2135/2382 [7:59:50<53:56, 13.10s/it] 90%|████████▉ | 2136/2382 [8:00:05<55:57, 13.65s/it]                                                     {'loss': 1.9046, 'learning_rate': 2.7722433235348065e-05, 'epoch': 0.9}
 90%|████████▉ | 2136/2382 [8:00:05<55:57, 13.65s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1056 > 1024). Running this sequence through the model will result in indexing errors
 90%|████████▉ | 2137/2382 [8:00:19<56:02, 13.72s/it]                                                     {'loss': 1.96, 'learning_rate': 2.7499590642665774e-05, 'epoch': 0.9}
 90%|████████▉ | 2137/2382 [8:00:19<56:02, 13.72s/it] 90%|████████▉ | 2138/2382 [8:00:34<57:16, 14.09s/it]                                                     {'loss': 1.7472, 'learning_rate': 2.727762198251871e-05, 'epoch': 0.9}
 90%|████████▉ | 2138/2382 [8:00:34<57:16, 14.09s/it] 90%|████████▉ | 2139/2382 [8:00:46<54:40, 13.50s/it]                                                     {'loss': 1.8542, 'learning_rate': 2.705652766545802e-05, 'epoch': 0.9}
 90%|████████▉ | 2139/2382 [8:00:46<54:40, 13.50s/it] 90%|████████▉ | 2140/2382 [8:01:00<55:35, 13.78s/it]                                                     {'loss': 1.9021, 'learning_rate': 2.683630810041787e-05, 'epoch': 0.9}
 90%|████████▉ | 2140/2382 [8:01:00<55:35, 13.78s/it] 90%|████████▉ | 2141/2382 [8:01:13<54:00, 13.45s/it]                                                     {'loss': 1.8734, 'learning_rate': 2.6616963694714392e-05, 'epoch': 0.9}
 90%|████████▉ | 2141/2382 [8:01:13<54:00, 13.45s/it] 90%|████████▉ | 2142/2382 [8:01:26<53:30, 13.38s/it]                                                     {'loss': 1.8117, 'learning_rate': 2.6398494854045054e-05, 'epoch': 0.9}
 90%|████████▉ | 2142/2382 [8:01:26<53:30, 13.38s/it] 90%|████████▉ | 2143/2382 [8:01:39<52:23, 13.15s/it]                                                     {'loss': 1.8325, 'learning_rate': 2.6180901982487683e-05, 'epoch': 0.9}
 90%|████████▉ | 2143/2382 [8:01:39<52:23, 13.15s/it] 90%|█████████ | 2144/2382 [8:01:52<52:33, 13.25s/it]                                                     {'loss': 1.9347, 'learning_rate': 2.596418548250029e-05, 'epoch': 0.9}
 90%|█████████ | 2144/2382 [8:01:52<52:33, 13.25s/it] 90%|█████████ | 2145/2382 [8:02:08<55:39, 14.09s/it]                                                     {'loss': 1.7579, 'learning_rate': 2.5748345754919688e-05, 'epoch': 0.9}
 90%|█████████ | 2145/2382 [8:02:08<55:39, 14.09s/it] 90%|█████████ | 2146/2382 [8:02:23<55:53, 14.21s/it]                                                     {'loss': 1.92, 'learning_rate': 2.55333831989612e-05, 'epoch': 0.9}
 90%|█████████ | 2146/2382 [8:02:23<55:53, 14.21s/it] 90%|█████████ | 2147/2382 [8:02:33<51:39, 13.19s/it]                                                     {'loss': 1.8488, 'learning_rate': 2.531929821221768e-05, 'epoch': 0.9}
 90%|█████████ | 2147/2382 [8:02:33<51:39, 13.19s/it] 90%|█████████ | 2148/2382 [8:02:46<50:32, 12.96s/it]                                                     {'loss': 1.7969, 'learning_rate': 2.5106091190658597e-05, 'epoch': 0.9}
 90%|█████████ | 2148/2382 [8:02:46<50:32, 12.96s/it] 90%|█████████ | 2149/2382 [8:03:04<55:52, 14.39s/it]                                                     {'loss': 1.8712, 'learning_rate': 2.4893762528630015e-05, 'epoch': 0.9}
 90%|█████████ | 2149/2382 [8:03:04<55:52, 14.39s/it] 90%|█████████ | 2150/2382 [8:03:22<1:00:43, 15.70s/it]                                                       {'loss': 1.8814, 'learning_rate': 2.46823126188529e-05, 'epoch': 0.9}
 90%|█████████ | 2150/2382 [8:03:22<1:00:43, 15.70s/it] 90%|█████████ | 2151/2382 [8:03:35<57:09, 14.84s/it]                                                       {'loss': 1.8674, 'learning_rate': 2.4471741852423235e-05, 'epoch': 0.9}
 90%|█████████ | 2151/2382 [8:03:35<57:09, 14.84s/it] 90%|█████████ | 2152/2382 [8:03:48<55:08, 14.39s/it]                                                     {'loss': 1.9002, 'learning_rate': 2.4262050618810815e-05, 'epoch': 0.9}
 90%|█████████ | 2152/2382 [8:03:48<55:08, 14.39s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1099 > 1024). Running this sequence through the model will result in indexing errors
 90%|█████████ | 2153/2382 [8:04:03<54:42, 14.34s/it]                                                     {'loss': 1.8346, 'learning_rate': 2.4053239305858676e-05, 'epoch': 0.9}
 90%|█████████ | 2153/2382 [8:04:03<54:42, 14.34s/it] 90%|█████████ | 2154/2382 [8:04:18<55:58, 14.73s/it]                                                     {'loss': 1.7699, 'learning_rate': 2.384530829978232e-05, 'epoch': 0.9}
 90%|█████████ | 2154/2382 [8:04:18<55:58, 14.73s/it] 90%|█████████ | 2155/2382 [8:04:34<56:48, 15.01s/it]                                                     {'loss': 1.8297, 'learning_rate': 2.363825798516911e-05, 'epoch': 0.9}
 90%|█████████ | 2155/2382 [8:04:34<56:48, 15.01s/it] 91%|█████████ | 2156/2382 [8:04:48<54:56, 14.59s/it]                                                     {'loss': 1.7417, 'learning_rate': 2.3432088744977487e-05, 'epoch': 0.9}
 91%|█████████ | 2156/2382 [8:04:48<54:56, 14.59s/it] 91%|█████████ | 2157/2382 [8:05:00<52:32, 14.01s/it]                                                     {'loss': 1.9579, 'learning_rate': 2.32268009605362e-05, 'epoch': 0.91}
 91%|█████████ | 2157/2382 [8:05:00<52:32, 14.01s/it] 91%|█████████ | 2158/2382 [8:05:14<52:01, 13.93s/it]                                                     {'loss': 1.8688, 'learning_rate': 2.3022395011543685e-05, 'epoch': 0.91}
 91%|█████████ | 2158/2382 [8:05:14<52:01, 13.93s/it] 91%|█████████ | 2159/2382 [8:05:27<51:07, 13.76s/it]                                                     {'loss': 1.7606, 'learning_rate': 2.281887127606741e-05, 'epoch': 0.91}
 91%|█████████ | 2159/2382 [8:05:27<51:07, 13.76s/it] 91%|█████████ | 2160/2382 [8:05:41<50:27, 13.64s/it]                                                     {'loss': 2.0156, 'learning_rate': 2.261623013054298e-05, 'epoch': 0.91}
 91%|█████████ | 2160/2382 [8:05:41<50:27, 13.64s/it] 91%|█████████ | 2161/2382 [8:05:53<48:55, 13.28s/it]                                                     {'loss': 1.9243, 'learning_rate': 2.241447194977364e-05, 'epoch': 0.91}
 91%|█████████ | 2161/2382 [8:05:53<48:55, 13.28s/it] 91%|█████████ | 2162/2382 [8:06:05<47:10, 12.87s/it]                                                     {'loss': 1.8316, 'learning_rate': 2.2213597106929607e-05, 'epoch': 0.91}
 91%|█████████ | 2162/2382 [8:06:05<47:10, 12.87s/it] 91%|█████████ | 2163/2382 [8:06:18<47:19, 12.97s/it]                                                     {'loss': 1.9134, 'learning_rate': 2.201360597354718e-05, 'epoch': 0.91}
 91%|█████████ | 2163/2382 [8:06:18<47:19, 12.97s/it] 91%|█████████ | 2164/2382 [8:06:31<47:10, 12.98s/it]                                                     {'loss': 1.8475, 'learning_rate': 2.181449891952819e-05, 'epoch': 0.91}
 91%|█████████ | 2164/2382 [8:06:31<47:10, 12.98s/it] 91%|█████████ | 2165/2382 [8:06:43<45:21, 12.54s/it]                                                     {'loss': 1.8448, 'learning_rate': 2.1616276313139227e-05, 'epoch': 0.91}
 91%|█████████ | 2165/2382 [8:06:43<45:21, 12.54s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1441 > 1024). Running this sequence through the model will result in indexing errors
 91%|█████████ | 2166/2382 [8:06:56<45:42, 12.70s/it]                                                     {'loss': 1.8593, 'learning_rate': 2.1418938521010955e-05, 'epoch': 0.91}
 91%|█████████ | 2166/2382 [8:06:56<45:42, 12.70s/it] 91%|█████████ | 2167/2382 [8:07:09<46:24, 12.95s/it]                                                     {'loss': 1.8374, 'learning_rate': 2.1222485908137746e-05, 'epoch': 0.91}
 91%|█████████ | 2167/2382 [8:07:09<46:24, 12.95s/it] 91%|█████████ | 2168/2382 [8:07:23<46:29, 13.04s/it]                                                     {'loss': 1.8102, 'learning_rate': 2.1026918837876497e-05, 'epoch': 0.91}
 91%|█████████ | 2168/2382 [8:07:23<46:29, 13.04s/it] 91%|█████████ | 2169/2382 [8:07:38<48:23, 13.63s/it]                                                     {'loss': 1.9931, 'learning_rate': 2.0832237671946363e-05, 'epoch': 0.91}
 91%|█████████ | 2169/2382 [8:07:38<48:23, 13.63s/it] 91%|█████████ | 2170/2382 [8:07:49<46:13, 13.08s/it]                                                     {'loss': 1.8491, 'learning_rate': 2.0638442770427867e-05, 'epoch': 0.91}
 91%|█████████ | 2170/2382 [8:07:49<46:13, 13.08s/it] 91%|█████████ | 2171/2382 [8:08:02<45:45, 13.01s/it]                                                     {'loss': 1.8469, 'learning_rate': 2.0445534491762395e-05, 'epoch': 0.91}
 91%|█████████ | 2171/2382 [8:08:02<45:45, 13.01s/it] 91%|█████████ | 2172/2382 [8:08:17<47:20, 13.53s/it]                                                     {'loss': 1.8095, 'learning_rate': 2.025351319275137e-05, 'epoch': 0.91}
 91%|█████████ | 2172/2382 [8:08:17<47:20, 13.53s/it] 91%|█████████ | 2173/2382 [8:08:30<46:52, 13.45s/it]                                                     {'loss': 1.7983, 'learning_rate': 2.0062379228555526e-05, 'epoch': 0.91}
 91%|█████████ | 2173/2382 [8:08:30<46:52, 13.45s/it] 91%|█████████▏| 2174/2382 [8:08:43<45:57, 13.26s/it]                                                     {'loss': 1.8212, 'learning_rate': 1.9872132952694632e-05, 'epoch': 0.91}
 91%|█████████▏| 2174/2382 [8:08:43<45:57, 13.26s/it] 91%|█████████▏| 2175/2382 [8:08:56<45:29, 13.19s/it]                                                     {'loss': 1.8268, 'learning_rate': 1.968277471704649e-05, 'epoch': 0.91}
 91%|█████████▏| 2175/2382 [8:08:56<45:29, 13.19s/it] 91%|█████████▏| 2176/2382 [8:09:10<45:32, 13.27s/it]                                                     {'loss': 1.878, 'learning_rate': 1.9494304871846447e-05, 'epoch': 0.91}
 91%|█████████▏| 2176/2382 [8:09:10<45:32, 13.27s/it] 91%|█████████▏| 2177/2382 [8:09:22<44:31, 13.03s/it]                                                     {'loss': 1.824, 'learning_rate': 1.9306723765686595e-05, 'epoch': 0.91}
 91%|█████████▏| 2177/2382 [8:09:22<44:31, 13.03s/it] 91%|█████████▏| 2178/2382 [8:09:35<44:14, 13.01s/it]                                                     {'loss': 1.8195, 'learning_rate': 1.9120031745515298e-05, 'epoch': 0.91}
 91%|█████████▏| 2178/2382 [8:09:35<44:14, 13.01s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1227 > 1024). Running this sequence through the model will result in indexing errors
 91%|█████████▏| 2179/2382 [8:09:48<44:12, 13.07s/it]                                                     {'loss': 1.8476, 'learning_rate': 1.893422915663645e-05, 'epoch': 0.91}
 91%|█████████▏| 2179/2382 [8:09:48<44:12, 13.07s/it] 92%|█████████▏| 2180/2382 [8:10:02<44:37, 13.25s/it]                                                     {'loss': 1.7952, 'learning_rate': 1.8749316342708823e-05, 'epoch': 0.91}
 92%|█████████▏| 2180/2382 [8:10:02<44:37, 13.25s/it] 92%|█████████▏| 2181/2382 [8:10:17<45:55, 13.71s/it]                                                     {'loss': 1.8213, 'learning_rate': 1.8565293645745495e-05, 'epoch': 0.92}
 92%|█████████▏| 2181/2382 [8:10:17<45:55, 13.71s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1121 > 1024). Running this sequence through the model will result in indexing errors
 92%|█████████▏| 2182/2382 [8:10:30<45:39, 13.70s/it]                                                     {'loss': 1.9521, 'learning_rate': 1.8382161406113208e-05, 'epoch': 0.92}
 92%|█████████▏| 2182/2382 [8:10:30<45:39, 13.70s/it] 92%|█████████▏| 2183/2382 [8:10:42<43:23, 13.08s/it]                                                     {'loss': 1.9315, 'learning_rate': 1.8199919962531843e-05, 'epoch': 0.92}
 92%|█████████▏| 2183/2382 [8:10:42<43:23, 13.08s/it] 92%|█████████▏| 2184/2382 [8:10:55<42:46, 12.96s/it]                                                     {'loss': 1.8033, 'learning_rate': 1.801856965207338e-05, 'epoch': 0.92}
 92%|█████████▏| 2184/2382 [8:10:55<42:46, 12.96s/it] 92%|█████████▏| 2185/2382 [8:11:08<42:59, 13.10s/it]                                                     {'loss': 1.899, 'learning_rate': 1.7838110810161788e-05, 'epoch': 0.92}
 92%|█████████▏| 2185/2382 [8:11:08<42:59, 13.10s/it] 92%|█████████▏| 2186/2382 [8:11:21<42:55, 13.14s/it]                                                     {'loss': 1.8845, 'learning_rate': 1.765854377057219e-05, 'epoch': 0.92}
 92%|█████████▏| 2186/2382 [8:11:21<42:55, 13.14s/it] 92%|█████████▏| 2187/2382 [8:11:34<42:31, 13.09s/it]                                                     {'loss': 1.8247, 'learning_rate': 1.747986886543007e-05, 'epoch': 0.92}
 92%|█████████▏| 2187/2382 [8:11:34<42:31, 13.09s/it] 92%|█████████▏| 2188/2382 [8:11:50<45:06, 13.95s/it]                                                     {'loss': 1.8069, 'learning_rate': 1.7302086425210973e-05, 'epoch': 0.92}
 92%|█████████▏| 2188/2382 [8:11:50<45:06, 13.95s/it] 92%|█████████▏| 2189/2382 [8:12:03<43:52, 13.64s/it]                                                     {'loss': 1.7978, 'learning_rate': 1.7125196778739804e-05, 'epoch': 0.92}
 92%|█████████▏| 2189/2382 [8:12:03<43:52, 13.64s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1311 > 1024). Running this sequence through the model will result in indexing errors
 92%|█████████▏| 2190/2382 [8:12:17<43:22, 13.55s/it]                                                     {'loss': 1.8703, 'learning_rate': 1.6949200253189966e-05, 'epoch': 0.92}
 92%|█████████▏| 2190/2382 [8:12:17<43:22, 13.55s/it] 92%|█████████▏| 2191/2382 [8:12:28<41:11, 12.94s/it]                                                     {'loss': 1.8502, 'learning_rate': 1.677409717408307e-05, 'epoch': 0.92}
 92%|█████████▏| 2191/2382 [8:12:28<41:11, 12.94s/it] 92%|█████████▏| 2192/2382 [8:12:43<42:57, 13.57s/it]                                                     {'loss': 1.8067, 'learning_rate': 1.659988786528821e-05, 'epoch': 0.92}
 92%|█████████▏| 2192/2382 [8:12:43<42:57, 13.57s/it] 92%|█████████▏| 2193/2382 [8:12:56<41:50, 13.28s/it]                                                     {'loss': 1.8166, 'learning_rate': 1.6426572649021475e-05, 'epoch': 0.92}
 92%|█████████▏| 2193/2382 [8:12:56<41:50, 13.28s/it] 92%|█████████▏| 2194/2382 [8:13:10<42:24, 13.54s/it]                                                     {'loss': 1.8098, 'learning_rate': 1.6254151845844943e-05, 'epoch': 0.92}
 92%|█████████▏| 2194/2382 [8:13:10<42:24, 13.54s/it] 92%|█████████▏| 2195/2382 [8:13:24<42:16, 13.57s/it]                                                     {'loss': 1.7826, 'learning_rate': 1.608262577466679e-05, 'epoch': 0.92}
 92%|█████████▏| 2195/2382 [8:13:24<42:16, 13.57s/it] 92%|█████████▏| 2196/2382 [8:13:37<42:16, 13.64s/it]                                                     {'loss': 1.8118, 'learning_rate': 1.5911994752739965e-05, 'epoch': 0.92}
 92%|█████████▏| 2196/2382 [8:13:37<42:16, 13.64s/it] 92%|█████████▏| 2197/2382 [8:13:49<40:06, 13.01s/it]                                                     {'loss': 1.8535, 'learning_rate': 1.5742259095662127e-05, 'epoch': 0.92}
 92%|█████████▏| 2197/2382 [8:13:49<40:06, 13.01s/it] 92%|█████████▏| 2198/2382 [8:14:03<41:09, 13.42s/it]                                                     {'loss': 1.8127, 'learning_rate': 1.557341911737481e-05, 'epoch': 0.92}
 92%|█████████▏| 2198/2382 [8:14:03<41:09, 13.42s/it] 92%|█████████▏| 2199/2382 [8:14:15<39:32, 12.97s/it]                                                     {'loss': 1.8607, 'learning_rate': 1.5405475130162992e-05, 'epoch': 0.92}
 92%|█████████▏| 2199/2382 [8:14:15<39:32, 12.97s/it] 92%|█████████▏| 2200/2382 [8:14:30<40:44, 13.43s/it]                                                     {'loss': 1.9152, 'learning_rate': 1.5238427444654367e-05, 'epoch': 0.92}
 92%|█████████▏| 2200/2382 [8:14:30<40:44, 13.43s/it] 92%|█████████▏| 2201/2382 [8:14:41<39:04, 12.96s/it]                                                     {'loss': 1.8517, 'learning_rate': 1.5072276369818783e-05, 'epoch': 0.92}
 92%|█████████▏| 2201/2382 [8:14:42<39:04, 12.96s/it] 92%|█████████▏| 2202/2382 [8:14:58<42:22, 14.12s/it]                                                     {'loss': 1.7694, 'learning_rate': 1.4907022212967803e-05, 'epoch': 0.92}
 92%|█████████▏| 2202/2382 [8:14:58<42:22, 14.12s/it] 92%|█████████▏| 2203/2382 [8:15:11<41:11, 13.81s/it]                                                     {'loss': 1.9523, 'learning_rate': 1.4742665279753986e-05, 'epoch': 0.92}
 92%|█████████▏| 2203/2382 [8:15:11<41:11, 13.81s/it] 93%|█████████▎| 2204/2382 [8:15:25<40:55, 13.79s/it]                                                     {'loss': 1.8902, 'learning_rate': 1.4579205874170554e-05, 'epoch': 0.92}
 93%|█████████▎| 2204/2382 [8:15:25<40:55, 13.79s/it] 93%|█████████▎| 2205/2382 [8:15:42<43:11, 14.64s/it]                                                     {'loss': 1.7564, 'learning_rate': 1.4416644298550497e-05, 'epoch': 0.93}
 93%|█████████▎| 2205/2382 [8:15:42<43:11, 14.64s/it] 93%|█████████▎| 2206/2382 [8:15:57<43:16, 14.75s/it]                                                     {'loss': 1.7958, 'learning_rate': 1.4254980853566246e-05, 'epoch': 0.93}
 93%|█████████▎| 2206/2382 [8:15:57<43:16, 14.75s/it] 93%|█████████▎| 2207/2382 [8:16:09<40:54, 14.03s/it]                                                     {'loss': 1.8556, 'learning_rate': 1.4094215838229174e-05, 'epoch': 0.93}
 93%|█████████▎| 2207/2382 [8:16:09<40:54, 14.03s/it] 93%|█████████▎| 2208/2382 [8:16:21<38:51, 13.40s/it]                                                     {'loss': 1.9405, 'learning_rate': 1.3934349549888647e-05, 'epoch': 0.93}
 93%|█████████▎| 2208/2382 [8:16:21<38:51, 13.40s/it] 93%|█████████▎| 2209/2382 [8:16:36<39:38, 13.75s/it]                                                     {'loss': 1.7813, 'learning_rate': 1.3775382284232084e-05, 'epoch': 0.93}
 93%|█████████▎| 2209/2382 [8:16:36<39:38, 13.75s/it] 93%|█████████▎| 2210/2382 [8:16:49<38:39, 13.48s/it]                                                     {'loss': 1.7976, 'learning_rate': 1.3617314335283792e-05, 'epoch': 0.93}
 93%|█████████▎| 2210/2382 [8:16:49<38:39, 13.48s/it] 93%|█████████▎| 2211/2382 [8:17:03<39:43, 13.94s/it]                                                     {'loss': 1.815, 'learning_rate': 1.3460145995404849e-05, 'epoch': 0.93}
 93%|█████████▎| 2211/2382 [8:17:03<39:43, 13.94s/it] 93%|█████████▎| 2212/2382 [8:17:16<37:54, 13.38s/it]                                                     {'loss': 1.886, 'learning_rate': 1.3303877555292442e-05, 'epoch': 0.93}
 93%|█████████▎| 2212/2382 [8:17:16<37:54, 13.38s/it] 93%|█████████▎| 2213/2382 [8:17:29<37:42, 13.39s/it]                                                     {'loss': 1.8949, 'learning_rate': 1.3148509303979372e-05, 'epoch': 0.93}
 93%|█████████▎| 2213/2382 [8:17:29<37:42, 13.39s/it] 93%|█████████▎| 2214/2382 [8:17:41<36:13, 12.94s/it]                                                     {'loss': 1.9266, 'learning_rate': 1.2994041528833267e-05, 'epoch': 0.93}
 93%|█████████▎| 2214/2382 [8:17:41<36:13, 12.94s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1159 > 1024). Running this sequence through the model will result in indexing errors
 93%|█████████▎| 2215/2382 [8:17:54<35:54, 12.90s/it]                                                     {'loss': 1.7572, 'learning_rate': 1.2840474515556311e-05, 'epoch': 0.93}
 93%|█████████▎| 2215/2382 [8:17:54<35:54, 12.90s/it] 93%|█████████▎| 2216/2382 [8:18:05<34:02, 12.30s/it]                                                     {'loss': 1.936, 'learning_rate': 1.2687808548184798e-05, 'epoch': 0.93}
 93%|█████████▎| 2216/2382 [8:18:05<34:02, 12.30s/it] 93%|█████████▎| 2217/2382 [8:18:19<35:35, 12.95s/it]                                                     {'loss': 1.7962, 'learning_rate': 1.2536043909088191e-05, 'epoch': 0.93}
 93%|█████████▎| 2217/2382 [8:18:19<35:35, 12.95s/it] 93%|█████████▎| 2218/2382 [8:18:34<36:43, 13.43s/it]                                                     {'loss': 1.9656, 'learning_rate': 1.2385180878969115e-05, 'epoch': 0.93}
 93%|█████████▎| 2218/2382 [8:18:34<36:43, 13.43s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1165 > 1024). Running this sequence through the model will result in indexing errors
 93%|█████████▎| 2219/2382 [8:18:47<36:27, 13.42s/it]                                                     {'loss': 1.8371, 'learning_rate': 1.2235219736862534e-05, 'epoch': 0.93}
 93%|█████████▎| 2219/2382 [8:18:47<36:27, 13.42s/it] 93%|█████████▎| 2220/2382 [8:18:58<34:40, 12.84s/it]                                                     {'loss': 1.9151, 'learning_rate': 1.2086160760135078e-05, 'epoch': 0.93}
 93%|█████████▎| 2220/2382 [8:18:58<34:40, 12.84s/it] 93%|█████████▎| 2221/2382 [8:19:11<34:24, 12.83s/it]                                                     {'loss': 1.8557, 'learning_rate': 1.1938004224484989e-05, 'epoch': 0.93}
 93%|█████████▎| 2221/2382 [8:19:11<34:24, 12.83s/it] 93%|█████████▎| 2222/2382 [8:19:23<33:29, 12.56s/it]                                                     {'loss': 1.827, 'learning_rate': 1.1790750403941231e-05, 'epoch': 0.93}
 93%|█████████▎| 2222/2382 [8:19:23<33:29, 12.56s/it] 93%|█████████▎| 2223/2382 [8:19:37<33:55, 12.80s/it]                                                     {'loss': 1.8986, 'learning_rate': 1.1644399570863273e-05, 'epoch': 0.93}
 93%|█████████▎| 2223/2382 [8:19:37<33:55, 12.80s/it] 93%|█████████▎| 2224/2382 [8:19:50<34:26, 13.08s/it]                                                     {'loss': 1.8724, 'learning_rate': 1.1498951995940144e-05, 'epoch': 0.93}
 93%|█████████▎| 2224/2382 [8:19:50<34:26, 13.08s/it] 93%|█████████▎| 2225/2382 [8:20:03<34:13, 13.08s/it]                                                     {'loss': 1.8921, 'learning_rate': 1.1354407948190536e-05, 'epoch': 0.93}
 93%|█████████▎| 2225/2382 [8:20:03<34:13, 13.08s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1186 > 1024). Running this sequence through the model will result in indexing errors
 93%|█████████▎| 2226/2382 [8:20:17<34:42, 13.35s/it]                                                     {'loss': 1.8177, 'learning_rate': 1.1210767694961654e-05, 'epoch': 0.93}
 93%|█████████▎| 2226/2382 [8:20:17<34:42, 13.35s/it] 93%|█████████▎| 2227/2382 [8:20:30<33:45, 13.06s/it]                                                     {'loss': 1.8838, 'learning_rate': 1.1068031501929366e-05, 'epoch': 0.93}
 93%|█████████▎| 2227/2382 [8:20:30<33:45, 13.06s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1122 > 1024). Running this sequence through the model will result in indexing errors
 94%|█████████▎| 2228/2382 [8:20:42<33:02, 12.87s/it]                                                     {'loss': 1.7973, 'learning_rate': 1.0926199633097156e-05, 'epoch': 0.94}
 94%|█████████▎| 2228/2382 [8:20:42<33:02, 12.87s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1443 > 1024). Running this sequence through the model will result in indexing errors
 94%|█████████▎| 2229/2382 [8:20:54<32:22, 12.70s/it]                                                     {'loss': 1.8107, 'learning_rate': 1.0785272350796127e-05, 'epoch': 0.94}
 94%|█████████▎| 2229/2382 [8:20:54<32:22, 12.70s/it] 94%|█████████▎| 2230/2382 [8:21:07<31:47, 12.55s/it]                                                     {'loss': 1.8202, 'learning_rate': 1.0645249915683997e-05, 'epoch': 0.94}
 94%|█████████▎| 2230/2382 [8:21:07<31:47, 12.55s/it] 94%|█████████▎| 2231/2382 [8:21:22<33:34, 13.34s/it]                                                     {'loss': 1.8183, 'learning_rate': 1.0506132586745098e-05, 'epoch': 0.94}
 94%|█████████▎| 2231/2382 [8:21:22<33:34, 13.34s/it] 94%|█████████▎| 2232/2382 [8:21:33<31:49, 12.73s/it]                                                     {'loss': 1.9571, 'learning_rate': 1.0367920621289494e-05, 'epoch': 0.94}
 94%|█████████▎| 2232/2382 [8:21:33<31:49, 12.73s/it] 94%|█████████▎| 2233/2382 [8:21:48<33:21, 13.43s/it]                                                     {'loss': 1.8344, 'learning_rate': 1.023061427495281e-05, 'epoch': 0.94}
 94%|█████████▎| 2233/2382 [8:21:48<33:21, 13.43s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1030 > 1024). Running this sequence through the model will result in indexing errors
 94%|█████████▍| 2234/2382 [8:22:01<32:50, 13.32s/it]                                                     {'loss': 1.8581, 'learning_rate': 1.0094213801695729e-05, 'epoch': 0.94}
 94%|█████████▍| 2234/2382 [8:22:01<32:50, 13.32s/it] 94%|█████████▍| 2235/2382 [8:22:16<33:32, 13.69s/it]                                                     {'loss': 1.8563, 'learning_rate': 9.958719453803277e-06, 'epoch': 0.94}
 94%|█████████▍| 2235/2382 [8:22:16<33:32, 13.69s/it] 94%|█████████▍| 2236/2382 [8:22:29<32:56, 13.54s/it]                                                     {'loss': 1.8545, 'learning_rate': 9.824131481884658e-06, 'epoch': 0.94}
 94%|█████████▍| 2236/2382 [8:22:29<32:56, 13.54s/it] 94%|█████████▍| 2237/2382 [8:22:42<32:10, 13.32s/it]                                                     {'loss': 1.7744, 'learning_rate': 9.690450134872519e-06, 'epoch': 0.94}
 94%|█████████▍| 2237/2382 [8:22:42<32:10, 13.32s/it] 94%|█████████▍| 2238/2382 [8:22:54<31:26, 13.10s/it]                                                     {'loss': 1.837, 'learning_rate': 9.557675660022746e-06, 'epoch': 0.94}
 94%|█████████▍| 2238/2382 [8:22:54<31:26, 13.10s/it] 94%|█████████▍| 2239/2382 [8:23:07<31:01, 13.02s/it]                                                     {'loss': 1.8011, 'learning_rate': 9.42580830291373e-06, 'epoch': 0.94}
 94%|█████████▍| 2239/2382 [8:23:07<31:01, 13.02s/it] 94%|█████████▍| 2240/2382 [8:23:20<30:24, 12.85s/it]                                                     {'loss': 1.8518, 'learning_rate': 9.294848307446201e-06, 'epoch': 0.94}
 94%|█████████▍| 2240/2382 [8:23:20<30:24, 12.85s/it] 94%|█████████▍| 2241/2382 [8:23:32<30:06, 12.81s/it]                                                     {'loss': 1.8855, 'learning_rate': 9.164795915842572e-06, 'epoch': 0.94}
 94%|█████████▍| 2241/2382 [8:23:32<30:06, 12.81s/it] 94%|█████████▍| 2242/2382 [8:23:47<30:56, 13.26s/it]                                                     {'loss': 1.9012, 'learning_rate': 9.035651368646646e-06, 'epoch': 0.94}
 94%|█████████▍| 2242/2382 [8:23:47<30:56, 13.26s/it] 94%|█████████▍| 2243/2382 [8:24:00<30:30, 13.17s/it]                                                     {'loss': 1.8562, 'learning_rate': 8.907414904723022e-06, 'epoch': 0.94}
 94%|█████████▍| 2243/2382 [8:24:00<30:30, 13.17s/it] 94%|█████████▍| 2244/2382 [8:24:15<31:34, 13.73s/it]                                                     {'loss': 1.7861, 'learning_rate': 8.780086761256634e-06, 'epoch': 0.94}
 94%|█████████▍| 2244/2382 [8:24:15<31:34, 13.73s/it] 94%|█████████▍| 2245/2382 [8:24:30<32:06, 14.06s/it]                                                     {'loss': 1.8043, 'learning_rate': 8.653667173752544e-06, 'epoch': 0.94}
 94%|█████████▍| 2245/2382 [8:24:30<32:06, 14.06s/it] 94%|█████████▍| 2246/2382 [8:24:43<31:31, 13.91s/it]                                                     {'loss': 1.8843, 'learning_rate': 8.528156376035324e-06, 'epoch': 0.94}
 94%|█████████▍| 2246/2382 [8:24:43<31:31, 13.91s/it] 94%|█████████▍| 2247/2382 [8:24:57<31:10, 13.86s/it]                                                     {'loss': 1.8079, 'learning_rate': 8.403554600248498e-06, 'epoch': 0.94}
 94%|█████████▍| 2247/2382 [8:24:57<31:10, 13.86s/it] 94%|█████████▍| 2248/2382 [8:25:11<31:08, 13.94s/it]                                                     {'loss': 1.8243, 'learning_rate': 8.27986207685455e-06, 'epoch': 0.94}
 94%|█████████▍| 2248/2382 [8:25:11<31:08, 13.94s/it] 94%|█████████▍| 2249/2382 [8:25:22<29:00, 13.09s/it]                                                     {'loss': 1.8695, 'learning_rate': 8.157079034633974e-06, 'epoch': 0.94}
 94%|█████████▍| 2249/2382 [8:25:22<29:00, 13.09s/it] 94%|█████████▍| 2250/2382 [8:25:36<29:04, 13.22s/it]                                                     {'loss': 1.8161, 'learning_rate': 8.035205700685167e-06, 'epoch': 0.94}
 94%|█████████▍| 2250/2382 [8:25:36<29:04, 13.22s/it] 95%|█████████▍| 2251/2382 [8:25:49<28:53, 13.24s/it]                                                     {'loss': 1.7594, 'learning_rate': 7.914242300424034e-06, 'epoch': 0.94}
 95%|█████████▍| 2251/2382 [8:25:49<28:53, 13.24s/it] 95%|█████████▍| 2252/2382 [8:26:00<27:09, 12.53s/it]                                                     {'loss': 1.8671, 'learning_rate': 7.794189057583333e-06, 'epoch': 0.95}
 95%|█████████▍| 2252/2382 [8:26:00<27:09, 12.53s/it] 95%|█████████▍| 2253/2382 [8:26:10<25:46, 11.99s/it]                                                     {'loss': 1.7789, 'learning_rate': 7.675046194212553e-06, 'epoch': 0.95}
 95%|█████████▍| 2253/2382 [8:26:10<25:46, 11.99s/it] 95%|█████████▍| 2254/2382 [8:26:24<26:27, 12.40s/it]                                                     {'loss': 1.8081, 'learning_rate': 7.5568139306771975e-06, 'epoch': 0.95}
 95%|█████████▍| 2254/2382 [8:26:24<26:27, 12.40s/it] 95%|█████████▍| 2255/2382 [8:26:36<26:11, 12.37s/it]                                                     {'loss': 1.9125, 'learning_rate': 7.439492485658617e-06, 'epoch': 0.95}
 95%|█████████▍| 2255/2382 [8:26:36<26:11, 12.37s/it] 95%|█████████▍| 2256/2382 [8:26:49<25:58, 12.37s/it]                                                     {'loss': 1.8818, 'learning_rate': 7.323082076153509e-06, 'epoch': 0.95}
 95%|█████████▍| 2256/2382 [8:26:49<25:58, 12.37s/it] 95%|█████████▍| 2257/2382 [8:27:00<25:04, 12.03s/it]                                                     {'loss': 1.8323, 'learning_rate': 7.207582917473532e-06, 'epoch': 0.95}
 95%|█████████▍| 2257/2382 [8:27:00<25:04, 12.03s/it] 95%|█████████▍| 2258/2382 [8:27:14<26:28, 12.81s/it]                                                     {'loss': 1.8342, 'learning_rate': 7.092995223244858e-06, 'epoch': 0.95}
 95%|█████████▍| 2258/2382 [8:27:14<26:28, 12.81s/it] 95%|█████████▍| 2259/2382 [8:27:26<25:16, 12.33s/it]                                                     {'loss': 1.9251, 'learning_rate': 6.979319205407953e-06, 'epoch': 0.95}
 95%|█████████▍| 2259/2382 [8:27:26<25:16, 12.33s/it] 95%|█████████▍| 2260/2382 [8:27:39<26:00, 12.80s/it]                                                     {'loss': 1.7994, 'learning_rate': 6.866555074216962e-06, 'epoch': 0.95}
 95%|█████████▍| 2260/2382 [8:27:39<26:00, 12.80s/it] 95%|█████████▍| 2261/2382 [8:27:54<26:34, 13.17s/it]                                                     {'loss': 1.903, 'learning_rate': 6.754703038239329e-06, 'epoch': 0.95}
 95%|█████████▍| 2261/2382 [8:27:54<26:34, 13.17s/it] 95%|█████████▍| 2262/2382 [8:28:06<26:05, 13.04s/it]                                                     {'loss': 1.754, 'learning_rate': 6.6437633043555655e-06, 'epoch': 0.95}
 95%|█████████▍| 2262/2382 [8:28:06<26:05, 13.04s/it] 95%|█████████▌| 2263/2382 [8:28:21<26:59, 13.61s/it]                                                     {'loss': 1.8419, 'learning_rate': 6.533736077758867e-06, 'epoch': 0.95}
 95%|█████████▌| 2263/2382 [8:28:21<26:59, 13.61s/it] 95%|█████████▌| 2264/2382 [8:28:32<25:13, 12.83s/it]                                                     {'loss': 1.8062, 'learning_rate': 6.424621561954613e-06, 'epoch': 0.95}
 95%|█████████▌| 2264/2382 [8:28:32<25:13, 12.83s/it] 95%|█████████▌| 2265/2382 [8:28:46<25:46, 13.22s/it]                                                     {'loss': 1.7731, 'learning_rate': 6.316419958760089e-06, 'epoch': 0.95}
 95%|█████████▌| 2265/2382 [8:28:46<25:46, 13.22s/it] 95%|█████████▌| 2266/2382 [8:28:59<25:13, 13.05s/it]                                                     {'loss': 1.753, 'learning_rate': 6.2091314683039304e-06, 'epoch': 0.95}
 95%|█████████▌| 2266/2382 [8:28:59<25:13, 13.05s/it] 95%|█████████▌| 2267/2382 [8:29:11<24:31, 12.80s/it]                                                     {'loss': 1.8794, 'learning_rate': 6.102756289025957e-06, 'epoch': 0.95}
 95%|█████████▌| 2267/2382 [8:29:11<24:31, 12.80s/it] 95%|█████████▌| 2268/2382 [8:29:25<25:02, 13.18s/it]                                                     {'loss': 1.8358, 'learning_rate': 5.997294617676841e-06, 'epoch': 0.95}
 95%|█████████▌| 2268/2382 [8:29:25<25:02, 13.18s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1205 > 1024). Running this sequence through the model will result in indexing errors
 95%|█████████▌| 2269/2382 [8:29:40<25:27, 13.51s/it]                                                     {'loss': 1.802, 'learning_rate': 5.892746649317438e-06, 'epoch': 0.95}
 95%|█████████▌| 2269/2382 [8:29:40<25:27, 13.51s/it] 95%|█████████▌| 2270/2382 [8:29:50<23:18, 12.48s/it]                                                     {'loss': 1.9402, 'learning_rate': 5.789112577318789e-06, 'epoch': 0.95}
 95%|█████████▌| 2270/2382 [8:29:50<23:18, 12.48s/it] 95%|█████████▌| 2271/2382 [8:30:02<22:45, 12.30s/it]                                                     {'loss': 1.899, 'learning_rate': 5.686392593361567e-06, 'epoch': 0.95}
 95%|█████████▌| 2271/2382 [8:30:02<22:45, 12.30s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1409 > 1024). Running this sequence through the model will result in indexing errors
 95%|█████████▌| 2272/2382 [8:30:14<22:38, 12.35s/it]                                                     {'loss': 1.8696, 'learning_rate': 5.5845868874357386e-06, 'epoch': 0.95}
 95%|█████████▌| 2272/2382 [8:30:14<22:38, 12.35s/it] 95%|█████████▌| 2273/2382 [8:30:25<21:52, 12.05s/it]                                                     {'loss': 1.8936, 'learning_rate': 5.483695647840181e-06, 'epoch': 0.95}
 95%|█████████▌| 2273/2382 [8:30:25<21:52, 12.05s/it] 95%|█████████▌| 2274/2382 [8:30:41<23:25, 13.02s/it]                                                     {'loss': 1.8743, 'learning_rate': 5.383719061182457e-06, 'epoch': 0.95}
 95%|█████████▌| 2274/2382 [8:30:41<23:25, 13.02s/it] 96%|█████████▌| 2275/2382 [8:30:54<23:26, 13.14s/it]                                                     {'loss': 1.7887, 'learning_rate': 5.284657312378427e-06, 'epoch': 0.95}
 96%|█████████▌| 2275/2382 [8:30:54<23:26, 13.14s/it] 96%|█████████▌| 2276/2382 [8:31:08<23:45, 13.45s/it]                                                     {'loss': 1.8696, 'learning_rate': 5.186510584651693e-06, 'epoch': 0.96}
 96%|█████████▌| 2276/2382 [8:31:08<23:45, 13.45s/it] 96%|█████████▌| 2277/2382 [8:31:21<22:57, 13.11s/it]                                                     {'loss': 1.8353, 'learning_rate': 5.089279059533658e-06, 'epoch': 0.96}
 96%|█████████▌| 2277/2382 [8:31:21<22:57, 13.11s/it] 96%|█████████▌| 2278/2382 [8:31:33<22:29, 12.98s/it]                                                     {'loss': 1.8435, 'learning_rate': 4.992962916862853e-06, 'epoch': 0.96}
 96%|█████████▌| 2278/2382 [8:31:33<22:29, 12.98s/it] 96%|█████████▌| 2279/2382 [8:31:45<21:37, 12.60s/it]                                                     {'loss': 1.7844, 'learning_rate': 4.897562334784722e-06, 'epoch': 0.96}
 96%|█████████▌| 2279/2382 [8:31:45<21:37, 12.60s/it] 96%|█████████▌| 2280/2382 [8:31:57<21:12, 12.48s/it]                                                     {'loss': 1.8534, 'learning_rate': 4.803077489751395e-06, 'epoch': 0.96}
 96%|█████████▌| 2280/2382 [8:31:57<21:12, 12.48s/it] 96%|█████████▌| 2281/2382 [8:32:10<21:19, 12.67s/it]                                                     {'loss': 1.868, 'learning_rate': 4.709508556521136e-06, 'epoch': 0.96}
 96%|█████████▌| 2281/2382 [8:32:10<21:19, 12.67s/it] 96%|█████████▌| 2282/2382 [8:32:22<20:52, 12.53s/it]                                                     {'loss': 1.8384, 'learning_rate': 4.6168557081582855e-06, 'epoch': 0.96}
 96%|█████████▌| 2282/2382 [8:32:22<20:52, 12.53s/it] 96%|█████████▌| 2283/2382 [8:32:37<21:51, 13.25s/it]                                                     {'loss': 1.8299, 'learning_rate': 4.52511911603265e-06, 'epoch': 0.96}
 96%|█████████▌| 2283/2382 [8:32:37<21:51, 13.25s/it] 96%|█████████▌| 2284/2382 [8:32:53<22:41, 13.89s/it]                                                     {'loss': 1.7754, 'learning_rate': 4.434298949819449e-06, 'epoch': 0.96}
 96%|█████████▌| 2284/2382 [8:32:53<22:41, 13.89s/it] 96%|█████████▌| 2285/2382 [8:33:06<21:59, 13.60s/it]                                                     {'loss': 1.858, 'learning_rate': 4.344395377498811e-06, 'epoch': 0.96}
 96%|█████████▌| 2285/2382 [8:33:06<21:59, 13.60s/it] 96%|█████████▌| 2286/2382 [8:33:20<22:07, 13.83s/it]                                                     {'loss': 1.9089, 'learning_rate': 4.255408565355612e-06, 'epoch': 0.96}
 96%|█████████▌| 2286/2382 [8:33:20<22:07, 13.83s/it] 96%|█████████▌| 2287/2382 [8:33:31<20:29, 12.95s/it]                                                     {'loss': 1.8645, 'learning_rate': 4.167338677979026e-06, 'epoch': 0.96}
 96%|█████████▌| 2287/2382 [8:33:31<20:29, 12.95s/it] 96%|█████████▌| 2288/2382 [8:33:47<21:39, 13.83s/it]                                                     {'loss': 1.8106, 'learning_rate': 4.080185878262421e-06, 'epoch': 0.96}
 96%|█████████▌| 2288/2382 [8:33:47<21:39, 13.83s/it] 96%|█████████▌| 2289/2382 [8:34:01<21:37, 13.95s/it]                                                     {'loss': 1.8185, 'learning_rate': 3.99395032740274e-06, 'epoch': 0.96}
 96%|█████████▌| 2289/2382 [8:34:01<21:37, 13.95s/it] 96%|█████████▌| 2290/2382 [8:34:13<20:35, 13.43s/it]                                                     {'loss': 1.811, 'learning_rate': 3.908632184900562e-06, 'epoch': 0.96}
 96%|█████████▌| 2290/2382 [8:34:13<20:35, 13.43s/it] 96%|█████████▌| 2291/2382 [8:34:27<20:42, 13.66s/it]                                                     {'loss': 1.9298, 'learning_rate': 3.8242316085594916e-06, 'epoch': 0.96}
 96%|█████████▌| 2291/2382 [8:34:27<20:42, 13.66s/it] 96%|█████████▌| 2292/2382 [8:34:42<20:48, 13.88s/it]                                                     {'loss': 1.854, 'learning_rate': 3.7407487544861563e-06, 'epoch': 0.96}
 96%|█████████▌| 2292/2382 [8:34:42<20:48, 13.88s/it] 96%|█████████▋| 2293/2382 [8:34:54<19:36, 13.22s/it]                                                     {'loss': 1.8847, 'learning_rate': 3.6581837770895965e-06, 'epoch': 0.96}
 96%|█████████▋| 2293/2382 [8:34:54<19:36, 13.22s/it] 96%|█████████▋| 2294/2382 [8:35:06<18:53, 12.88s/it]                                                     {'loss': 1.8094, 'learning_rate': 3.576536829081323e-06, 'epoch': 0.96}
 96%|█████████▋| 2294/2382 [8:35:06<18:53, 12.88s/it] 96%|█████████▋| 2295/2382 [8:35:18<18:37, 12.85s/it]                                                     {'loss': 1.8113, 'learning_rate': 3.4958080614748145e-06, 'epoch': 0.96}
 96%|█████████▋| 2295/2382 [8:35:18<18:37, 12.85s/it] 96%|█████████▋| 2296/2382 [8:35:31<18:29, 12.90s/it]                                                     {'loss': 1.8432, 'learning_rate': 3.4159976235852984e-06, 'epoch': 0.96}
 96%|█████████▋| 2296/2382 [8:35:31<18:29, 12.90s/it] 96%|█████████▋| 2297/2382 [8:35:47<19:13, 13.57s/it]                                                     {'loss': 1.8342, 'learning_rate': 3.3371056630293604e-06, 'epoch': 0.96}
 96%|█████████▋| 2297/2382 [8:35:47<19:13, 13.57s/it] 96%|█████████▋| 2298/2382 [8:35:58<18:03, 12.90s/it]                                                     {'loss': 1.8523, 'learning_rate': 3.2591323257248896e-06, 'epoch': 0.96}
 96%|█████████▋| 2298/2382 [8:35:58<18:03, 12.90s/it] 97%|█████████▋| 2299/2382 [8:36:10<17:42, 12.80s/it]                                                     {'loss': 1.8304, 'learning_rate': 3.1820777558907444e-06, 'epoch': 0.96}
 97%|█████████▋| 2299/2382 [8:36:10<17:42, 12.80s/it] 97%|█████████▋| 2300/2382 [8:36:23<17:34, 12.86s/it]                                                     {'loss': 1.7725, 'learning_rate': 3.1059420960462548e-06, 'epoch': 0.97}
 97%|█████████▋| 2300/2382 [8:36:23<17:34, 12.86s/it] 97%|█████████▋| 2301/2382 [8:36:39<18:35, 13.77s/it]                                                     {'loss': 1.8394, 'learning_rate': 3.030725487011388e-06, 'epoch': 0.97}
 97%|█████████▋| 2301/2382 [8:36:39<18:35, 13.77s/it] 97%|█████████▋| 2302/2382 [8:36:53<18:22, 13.78s/it]                                                     {'loss': 1.909, 'learning_rate': 2.956428067906025e-06, 'epoch': 0.97}
 97%|█████████▋| 2302/2382 [8:36:53<18:22, 13.78s/it] 97%|█████████▋| 2303/2382 [8:37:06<17:42, 13.45s/it]                                                     {'loss': 1.7823, 'learning_rate': 2.8830499761500207e-06, 'epoch': 0.97}
 97%|█████████▋| 2303/2382 [8:37:06<17:42, 13.45s/it] 97%|█████████▋| 2304/2382 [8:37:21<18:00, 13.86s/it]                                                     {'loss': 1.8678, 'learning_rate': 2.8105913474628653e-06, 'epoch': 0.97}
 97%|█████████▋| 2304/2382 [8:37:21<18:00, 13.86s/it] 97%|█████████▋| 2305/2382 [8:37:32<16:54, 13.18s/it]                                                     {'loss': 1.8488, 'learning_rate': 2.739052315863355e-06, 'epoch': 0.97}
 97%|█████████▋| 2305/2382 [8:37:32<16:54, 13.18s/it] 97%|█████████▋| 2306/2382 [8:37:49<17:57, 14.18s/it]                                                     {'loss': 1.8016, 'learning_rate': 2.6684330136694245e-06, 'epoch': 0.97}
 97%|█████████▋| 2306/2382 [8:37:49<17:57, 14.18s/it] 97%|█████████▋| 2307/2382 [8:38:03<17:35, 14.08s/it]                                                     {'loss': 1.7839, 'learning_rate': 2.5987335714979797e-06, 'epoch': 0.97}
 97%|█████████▋| 2307/2382 [8:38:03<17:35, 14.08s/it] 97%|█████████▋| 2308/2382 [8:38:15<16:48, 13.62s/it]                                                     {'loss': 1.8307, 'learning_rate': 2.529954118264455e-06, 'epoch': 0.97}
 97%|█████████▋| 2308/2382 [8:38:15<16:48, 13.62s/it] 97%|█████████▋| 2309/2382 [8:38:26<15:44, 12.94s/it]                                                     {'loss': 1.9043, 'learning_rate': 2.4620947811827e-06, 'epoch': 0.97}
 97%|█████████▋| 2309/2382 [8:38:26<15:44, 12.94s/it] 97%|█████████▋| 2310/2382 [8:38:39<15:20, 12.79s/it]                                                     {'loss': 1.8071, 'learning_rate': 2.395155685764705e-06, 'epoch': 0.97}
 97%|█████████▋| 2310/2382 [8:38:39<15:20, 12.79s/it] 97%|█████████▋| 2311/2382 [8:38:51<15:01, 12.69s/it]                                                     {'loss': 1.7522, 'learning_rate': 2.329136955820488e-06, 'epoch': 0.97}
 97%|█████████▋| 2311/2382 [8:38:51<15:01, 12.69s/it] 97%|█████████▋| 2312/2382 [8:39:05<15:10, 13.00s/it]                                                     {'loss': 1.9139, 'learning_rate': 2.2640387134577057e-06, 'epoch': 0.97}
 97%|█████████▋| 2312/2382 [8:39:05<15:10, 13.00s/it] 97%|█████████▋| 2313/2382 [8:39:17<14:28, 12.59s/it]                                                     {'loss': 1.8754, 'learning_rate': 2.199861079081433e-06, 'epoch': 0.97}
 97%|█████████▋| 2313/2382 [8:39:17<14:28, 12.59s/it] 97%|█████████▋| 2314/2382 [8:39:30<14:34, 12.86s/it]                                                     {'loss': 1.8054, 'learning_rate': 2.136604171394052e-06, 'epoch': 0.97}
 97%|█████████▋| 2314/2382 [8:39:30<14:34, 12.86s/it] 97%|█████████▋| 2315/2382 [8:39:45<14:50, 13.30s/it]                                                     {'loss': 1.8058, 'learning_rate': 2.0742681073950276e-06, 'epoch': 0.97}
 97%|█████████▋| 2315/2382 [8:39:45<14:50, 13.30s/it] 97%|█████████▋| 2316/2382 [8:39:57<14:12, 12.92s/it]                                                     {'loss': 1.8464, 'learning_rate': 2.012853002380466e-06, 'epoch': 0.97}
 97%|█████████▋| 2316/2382 [8:39:57<14:12, 12.92s/it] 97%|█████████▋| 2317/2382 [8:40:08<13:39, 12.61s/it]                                                     {'loss': 1.7686, 'learning_rate': 1.9523589699433354e-06, 'epoch': 0.97}
 97%|█████████▋| 2317/2382 [8:40:08<13:39, 12.61s/it] 97%|█████████▋| 2318/2382 [8:40:23<13:55, 13.05s/it]                                                     {'loss': 1.7787, 'learning_rate': 1.8927861219728005e-06, 'epoch': 0.97}
 97%|█████████▋| 2318/2382 [8:40:23<13:55, 13.05s/it] 97%|█████████▋| 2319/2382 [8:40:34<13:19, 12.70s/it]                                                     {'loss': 1.8046, 'learning_rate': 1.8341345686543331e-06, 'epoch': 0.97}
 97%|█████████▋| 2319/2382 [8:40:34<13:19, 12.70s/it] 97%|█████████▋| 2320/2382 [8:40:47<13:06, 12.68s/it]                                                     {'loss': 1.8166, 'learning_rate': 1.776404418469213e-06, 'epoch': 0.97}
 97%|█████████▋| 2320/2382 [8:40:47<13:06, 12.68s/it] 97%|█████████▋| 2321/2382 [8:41:00<12:52, 12.66s/it]                                                     {'loss': 1.8715, 'learning_rate': 1.7195957781946382e-06, 'epoch': 0.97}
 97%|█████████▋| 2321/2382 [8:41:00<12:52, 12.66s/it] 97%|█████████▋| 2322/2382 [8:41:15<13:18, 13.31s/it]                                                     {'loss': 1.7507, 'learning_rate': 1.6637087529033922e-06, 'epoch': 0.97}
 97%|█████████▋| 2322/2382 [8:41:15<13:18, 13.31s/it] 98%|█████████▊| 2323/2382 [8:41:27<12:52, 13.10s/it]                                                     {'loss': 1.8157, 'learning_rate': 1.6087434459635674e-06, 'epoch': 0.97}
 98%|█████████▊| 2323/2382 [8:41:27<12:52, 13.10s/it] 98%|█████████▊| 2324/2382 [8:41:40<12:32, 12.97s/it]                                                     {'loss': 1.853, 'learning_rate': 1.554699959038619e-06, 'epoch': 0.98}
 98%|█████████▊| 2324/2382 [8:41:40<12:32, 12.97s/it] 98%|█████████▊| 2325/2382 [8:41:52<12:14, 12.89s/it]                                                     {'loss': 1.8597, 'learning_rate': 1.5015783920867554e-06, 'epoch': 0.98}
 98%|█████████▊| 2325/2382 [8:41:52<12:14, 12.89s/it] 98%|█████████▊| 2326/2382 [8:42:04<11:38, 12.47s/it]                                                     {'loss': 1.8223, 'learning_rate': 1.4493788433612708e-06, 'epoch': 0.98}
 98%|█████████▊| 2326/2382 [8:42:04<11:38, 12.47s/it] 98%|█████████▊| 2327/2382 [8:42:17<11:36, 12.67s/it]                                                     {'loss': 1.8357, 'learning_rate': 1.3981014094099353e-06, 'epoch': 0.98}
 98%|█████████▊| 2327/2382 [8:42:17<11:36, 12.67s/it] 98%|█████████▊| 2328/2382 [8:42:33<12:08, 13.50s/it]                                                     {'loss': 1.8628, 'learning_rate': 1.347746185074994e-06, 'epoch': 0.98}
 98%|█████████▊| 2328/2382 [8:42:33<12:08, 13.50s/it] 98%|█████████▊| 2329/2382 [8:42:48<12:31, 14.18s/it]                                                     {'loss': 1.8626, 'learning_rate': 1.2983132634931117e-06, 'epoch': 0.98}
 98%|█████████▊| 2329/2382 [8:42:48<12:31, 14.18s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1181 > 1024). Running this sequence through the model will result in indexing errors
 98%|█████████▊| 2330/2382 [8:43:02<12:02, 13.90s/it]                                                     {'loss': 1.8731, 'learning_rate': 1.2498027360948739e-06, 'epoch': 0.98}
 98%|█████████▊| 2330/2382 [8:43:02<12:02, 13.90s/it] 98%|█████████▊| 2331/2382 [8:43:16<12:02, 14.18s/it]                                                     {'loss': 1.8714, 'learning_rate': 1.2022146926049527e-06, 'epoch': 0.98}
 98%|█████████▊| 2331/2382 [8:43:16<12:02, 14.18s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (1074 > 1024). Running this sequence through the model will result in indexing errors
 98%|█████████▊| 2332/2382 [8:43:30<11:35, 13.92s/it]                                                     {'loss': 1.7863, 'learning_rate': 1.1555492210418294e-06, 'epoch': 0.98}
 98%|█████████▊| 2332/2382 [8:43:30<11:35, 13.92s/it] 98%|█████████▊| 2333/2382 [8:43:47<12:10, 14.91s/it]                                                     {'loss': 1.8842, 'learning_rate': 1.1098064077174619e-06, 'epoch': 0.98}
 98%|█████████▊| 2333/2382 [8:43:47<12:10, 14.91s/it] 98%|█████████▊| 2334/2382 [8:44:00<11:33, 14.44s/it]                                                     {'loss': 1.8147, 'learning_rate': 1.0649863372373946e-06, 'epoch': 0.98}
 98%|█████████▊| 2334/2382 [8:44:00<11:33, 14.44s/it] 98%|█████████▊| 2335/2382 [8:44:16<11:30, 14.69s/it]                                                     {'loss': 1.8058, 'learning_rate': 1.0210890925004267e-06, 'epoch': 0.98}
 98%|█████████▊| 2335/2382 [8:44:16<11:30, 14.69s/it] 98%|█████████▊| 2336/2382 [8:44:29<10:56, 14.26s/it]                                                     {'loss': 1.8982, 'learning_rate': 9.781147546985004e-07, 'epoch': 0.98}
 98%|█████████▊| 2336/2382 [8:44:29<10:56, 14.26s/it] 98%|█████████▊| 2337/2382 [8:44:41<10:17, 13.73s/it]                                                     {'loss': 1.9131, 'learning_rate': 9.360634033165338e-07, 'epoch': 0.98}
 98%|█████████▊| 2337/2382 [8:44:41<10:17, 13.73s/it] 98%|█████████▊| 2338/2382 [8:44:54<09:54, 13.51s/it]                                                     {'loss': 1.8608, 'learning_rate': 8.949351161324226e-07, 'epoch': 0.98}
 98%|█████████▊| 2338/2382 [8:44:54<09:54, 13.51s/it] 98%|█████████▊| 2339/2382 [8:45:10<10:05, 14.07s/it]                                                     {'loss': 1.8816, 'learning_rate': 8.547299692165944e-07, 'epoch': 0.98}
 98%|█████████▊| 2339/2382 [8:45:10<10:05, 14.07s/it] 98%|█████████▊| 2340/2382 [8:45:22<09:33, 13.65s/it]                                                     {'loss': 1.9696, 'learning_rate': 8.15448036932176e-07, 'epoch': 0.98}
 98%|█████████▊| 2340/2382 [8:45:22<09:33, 13.65s/it] 98%|█████████▊| 2341/2382 [8:45:36<09:21, 13.70s/it]                                                     {'loss': 1.7418, 'learning_rate': 7.770893919346045e-07, 'epoch': 0.98}
 98%|█████████▊| 2341/2382 [8:45:36<09:21, 13.70s/it] 98%|█████████▊| 2342/2382 [8:45:48<08:47, 13.18s/it]                                                     {'loss': 1.9449, 'learning_rate': 7.396541051717942e-07, 'epoch': 0.98}
 98%|█████████▊| 2342/2382 [8:45:48<08:47, 13.18s/it] 98%|█████████▊| 2343/2382 [8:45:59<08:09, 12.54s/it]                                                     {'loss': 1.8569, 'learning_rate': 7.031422458836368e-07, 'epoch': 0.98}
 98%|█████████▊| 2343/2382 [8:45:59<08:09, 12.54s/it] 98%|█████████▊| 2344/2382 [8:46:13<08:09, 12.87s/it]                                                     {'loss': 1.821, 'learning_rate': 6.675538816022231e-07, 'epoch': 0.98}
 98%|█████████▊| 2344/2382 [8:46:13<08:09, 12.87s/it] 98%|█████████▊| 2345/2382 [8:46:26<07:54, 12.83s/it]                                                     {'loss': 1.8396, 'learning_rate': 6.328890781513441e-07, 'epoch': 0.98}
 98%|█████████▊| 2345/2382 [8:46:26<07:54, 12.83s/it] 98%|█████████▊| 2346/2382 [8:46:39<07:51, 13.09s/it]                                                     {'loss': 1.8436, 'learning_rate': 5.991478996468236e-07, 'epoch': 0.98}
 98%|█████████▊| 2346/2382 [8:46:39<07:51, 13.09s/it] 99%|█████████▊| 2347/2382 [8:46:53<07:48, 13.39s/it]                                                     {'loss': 1.8189, 'learning_rate': 5.663304084960185e-07, 'epoch': 0.98}
 99%|█████████▊| 2347/2382 [8:46:53<07:48, 13.39s/it] 99%|█████████▊| 2348/2382 [8:47:07<07:37, 13.47s/it]                                                     {'loss': 1.8674, 'learning_rate': 5.344366653978194e-07, 'epoch': 0.99}
 99%|█████████▊| 2348/2382 [8:47:07<07:37, 13.47s/it] 99%|█████████▊| 2349/2382 [8:47:19<07:11, 13.08s/it]                                                     {'loss': 1.7939, 'learning_rate': 5.034667293427053e-07, 'epoch': 0.99}
 99%|█████████▊| 2349/2382 [8:47:19<07:11, 13.08s/it] 99%|█████████▊| 2350/2382 [8:47:33<07:03, 13.23s/it]                                                     {'loss': 1.8716, 'learning_rate': 4.7342065761224464e-07, 'epoch': 0.99}
 99%|█████████▊| 2350/2382 [8:47:33<07:03, 13.23s/it] 99%|█████████▊| 2351/2382 [8:47:44<06:36, 12.78s/it]                                                     {'loss': 1.7445, 'learning_rate': 4.44298505779539e-07, 'epoch': 0.99}
 99%|█████████▊| 2351/2382 [8:47:44<06:36, 12.78s/it] 99%|█████████▊| 2352/2382 [8:47:57<06:24, 12.81s/it]                                                     {'loss': 1.935, 'learning_rate': 4.1610032770855735e-07, 'epoch': 0.99}
 99%|█████████▊| 2352/2382 [8:47:57<06:24, 12.81s/it] 99%|█████████▉| 2353/2382 [8:48:08<05:51, 12.12s/it]                                                     {'loss': 1.8826, 'learning_rate': 3.8882617555446863e-07, 'epoch': 0.99}
 99%|█████████▉| 2353/2382 [8:48:08<05:51, 12.12s/it] 99%|█████████▉| 2354/2382 [8:48:21<05:44, 12.32s/it]                                                     {'loss': 1.78, 'learning_rate': 3.6247609976319816e-07, 'epoch': 0.99}
 99%|█████████▉| 2354/2382 [8:48:21<05:44, 12.32s/it] 99%|█████████▉| 2355/2382 [8:48:32<05:24, 12.02s/it]                                                     {'loss': 1.7797, 'learning_rate': 3.3705014907176034e-07, 'epoch': 0.99}
 99%|█████████▉| 2355/2382 [8:48:32<05:24, 12.02s/it] 99%|█████████▉| 2356/2382 [8:48:45<05:20, 12.34s/it]                                                     {'loss': 1.8675, 'learning_rate': 3.1254837050764817e-07, 'epoch': 0.99}
 99%|█████████▉| 2356/2382 [8:48:45<05:20, 12.34s/it] 99%|█████████▉| 2357/2382 [8:48:58<05:16, 12.64s/it]                                                     {'loss': 1.7292, 'learning_rate': 2.889708093891663e-07, 'epoch': 0.99}
 99%|█████████▉| 2357/2382 [8:48:58<05:16, 12.64s/it] 99%|█████████▉| 2358/2382 [8:49:13<05:15, 13.16s/it]                                                     {'loss': 1.9053, 'learning_rate': 2.6631750932515354e-07, 'epoch': 0.99}
 99%|█████████▉| 2358/2382 [8:49:13<05:15, 13.16s/it] 99%|█████████▉| 2359/2382 [8:49:27<05:10, 13.51s/it]                                                     {'loss': 1.798, 'learning_rate': 2.445885122149272e-07, 'epoch': 0.99}
 99%|█████████▉| 2359/2382 [8:49:27<05:10, 13.51s/it] 99%|█████████▉| 2360/2382 [8:49:40<04:52, 13.30s/it]                                                     {'loss': 1.8453, 'learning_rate': 2.2378385824833868e-07, 'epoch': 0.99}
 99%|█████████▉| 2360/2382 [8:49:40<04:52, 13.30s/it] 99%|█████████▉| 2361/2382 [8:49:52<04:34, 13.08s/it]                                                     {'loss': 1.842, 'learning_rate': 2.0390358590538505e-07, 'epoch': 0.99}
 99%|█████████▉| 2361/2382 [8:49:52<04:34, 13.08s/it] 99%|█████████▉| 2362/2382 [8:50:08<04:33, 13.70s/it]                                                     {'loss': 1.8474, 'learning_rate': 1.8494773195648628e-07, 'epoch': 0.99}
 99%|█████████▉| 2362/2382 [8:50:08<04:33, 13.70s/it] 99%|█████████▉| 2363/2382 [8:50:20<04:14, 13.40s/it]                                                     {'loss': 1.8566, 'learning_rate': 1.6691633146226349e-07, 'epoch': 0.99}
 99%|█████████▉| 2363/2382 [8:50:20<04:14, 13.40s/it] 99%|█████████▉| 2364/2382 [8:50:36<04:10, 13.94s/it]                                                     {'loss': 1.8713, 'learning_rate': 1.498094177733722e-07, 'epoch': 0.99}
 99%|█████████▉| 2364/2382 [8:50:36<04:10, 13.94s/it] 99%|█████████▉| 2365/2382 [8:50:49<03:52, 13.66s/it]                                                     {'loss': 1.8006, 'learning_rate': 1.3362702253061353e-07, 'epoch': 0.99}
 99%|█████████▉| 2365/2382 [8:50:49<03:52, 13.66s/it] 99%|█████████▉| 2366/2382 [8:51:03<03:42, 13.91s/it]                                                     {'loss': 1.9326, 'learning_rate': 1.1836917566482308e-07, 'epoch': 0.99}
 99%|█████████▉| 2366/2382 [8:51:03<03:42, 13.91s/it] 99%|█████████▉| 2367/2382 [8:51:15<03:18, 13.25s/it]                                                     {'loss': 1.8255, 'learning_rate': 1.0403590539675989e-07, 'epoch': 0.99}
 99%|█████████▉| 2367/2382 [8:51:15<03:18, 13.25s/it] 99%|█████████▉| 2368/2382 [8:51:27<03:03, 13.10s/it]                                                     {'loss': 1.8185, 'learning_rate': 9.06272382371065e-08, 'epoch': 0.99}
 99%|█████████▉| 2368/2382 [8:51:27<03:03, 13.10s/it] 99%|█████████▉| 2369/2382 [8:51:42<02:55, 13.47s/it]                                                     {'loss': 1.8577, 'learning_rate': 7.814319898646893e-08, 'epoch': 0.99}
 99%|█████████▉| 2369/2382 [8:51:42<02:55, 13.47s/it] 99%|█████████▉| 2370/2382 [8:51:56<02:44, 13.70s/it]                                                     {'loss': 1.8246, 'learning_rate': 6.658381073515462e-08, 'epoch': 0.99}
 99%|█████████▉| 2370/2382 [8:51:56<02:44, 13.70s/it]100%|█████████▉| 2371/2382 [8:52:12<02:38, 14.37s/it]                                                     {'loss': 1.7656, 'learning_rate': 5.5949094863283477e-08, 'epoch': 1.0}
100%|█████████▉| 2371/2382 [8:52:12<02:38, 14.37s/it]100%|█████████▉| 2372/2382 [8:52:25<02:20, 14.02s/it]                                                     {'loss': 1.8107, 'learning_rate': 4.623907104084335e-08, 'epoch': 1.0}
100%|█████████▉| 2372/2382 [8:52:25<02:20, 14.02s/it]100%|█████████▉| 2373/2382 [8:52:40<02:07, 14.14s/it]                                                     {'loss': 1.8502, 'learning_rate': 3.7453757227245974e-08, 'epoch': 1.0}
100%|█████████▉| 2373/2382 [8:52:40<02:07, 14.14s/it]100%|█████████▉| 2374/2382 [8:52:56<01:57, 14.74s/it]                                                     {'loss': 1.8645, 'learning_rate': 2.959316967188208e-08, 'epoch': 1.0}
100%|█████████▉| 2374/2382 [8:52:56<01:57, 14.74s/it]100%|█████████▉| 2375/2382 [8:53:07<01:36, 13.81s/it]                                                     {'loss': 1.8109, 'learning_rate': 2.265732291356626e-08, 'epoch': 1.0}
100%|█████████▉| 2375/2382 [8:53:07<01:36, 13.81s/it]100%|█████████▉| 2376/2382 [8:53:21<01:23, 13.84s/it]                                                     {'loss': 1.7895, 'learning_rate': 1.6646229780759027e-08, 'epoch': 1.0}
100%|█████████▉| 2376/2382 [8:53:21<01:23, 13.84s/it]100%|█████████▉| 2377/2382 [8:53:33<01:06, 13.26s/it]                                                     {'loss': 1.8437, 'learning_rate': 1.1559901391511308e-08, 'epoch': 1.0}
100%|█████████▉| 2377/2382 [8:53:33<01:06, 13.26s/it]100%|█████████▉| 2378/2382 [8:53:46<00:52, 13.10s/it]                                                     {'loss': 1.9206, 'learning_rate': 7.3983471535199464e-09, 'epoch': 1.0}
100%|█████████▉| 2378/2382 [8:53:46<00:52, 13.10s/it]100%|█████████▉| 2379/2382 [8:53:58<00:38, 12.88s/it]                                                     {'loss': 1.926, 'learning_rate': 4.1615747639056626e-09, 'epoch': 1.0}
100%|█████████▉| 2379/2382 [8:53:58<00:38, 12.88s/it]100%|█████████▉| 2380/2382 [8:54:11<00:25, 12.93s/it]                                                     {'loss': 1.8332, 'learning_rate': 1.8495902093795814e-09, 'epoch': 1.0}
100%|█████████▉| 2380/2382 [8:54:11<00:25, 12.93s/it]100%|█████████▉| 2381/2382 [8:54:27<00:13, 13.62s/it]                                                     {'loss': 1.8236, 'learning_rate': 4.623977661322165e-10, 'epoch': 1.0}
100%|█████████▉| 2381/2382 [8:54:27<00:13, 13.62s/it]100%|██████████| 2382/2382 [8:54:39<00:00, 13.28s/it]                                                     {'loss': 1.8344, 'learning_rate': 0.0, 'epoch': 1.0}
100%|██████████| 2382/2382 [8:54:39<00:00, 13.28s/it]                                                     {'train_runtime': 32081.4954, 'train_samples_per_second': 19.014, 'train_steps_per_second': 0.074, 'train_loss': 1.9054984634509116, 'epoch': 1.0}
100%|██████████| 2382/2382 [8:54:41<00:00, 13.28s/it]100%|██████████| 2382/2382 [8:54:41<00:00, 13.47s/it]
[2024-08-12 22:38:23,021] [INFO] [launch.py:347:main] Process 3007568 exits successfully.
[2024-08-12 22:38:23,022] [INFO] [launch.py:347:main] Process 3007563 exits successfully.
[2024-08-12 22:38:23,022] [INFO] [launch.py:347:main] Process 3007562 exits successfully.
[2024-08-12 22:38:23,023] [INFO] [launch.py:347:main] Process 3007567 exits successfully.
[2024-08-12 22:38:23,023] [INFO] [launch.py:347:main] Process 3007566 exits successfully.
[2024-08-12 22:38:23,023] [INFO] [launch.py:347:main] Process 3007565 exits successfully.
[2024-08-12 22:38:24,024] [INFO] [launch.py:347:main] Process 3007564 exits successfully.
[2024-08-12 22:38:24,024] [INFO] [launch.py:347:main] Process 3007561 exits successfully.
